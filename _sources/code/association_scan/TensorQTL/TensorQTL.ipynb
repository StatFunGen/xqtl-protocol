{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# QTL Association Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "We perform QTL association testing using TensorQTL [[cf. Taylor-Weiner et al (2019)](https://doi.org/10.1186/s13059-019-1836-7)]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input\n",
    "\n",
    "- List of molecular phenotype files: a list of `bed.gz` files containing the table for the molecular phenotype. It should have a companion index file in `tbi` format. It is the output of gene_annotation or phenotype_by_chorm\n",
    "- List of genotypes in both PLINK binary format (bed/bim/fam) and PLINK 2 binary genotype table (pgen/pvar/psam) for each chromosome, previously processed through our genotype QC pipelines.\n",
    "- Covariate file, a file with #id + samples name as colnames and each row a covariate: fixed and known covariates as well as hidden covariates recovered from factor analysis.\n",
    "- Optionally, a list of traits (genes, regions of molecular features etc) to analyze.\n",
    "\n",
    "### Example phenotype list\n",
    "\n",
    "\n",
    "The header of the bed.gz is per the [TensorQTL](https://github.com/broadinstitute/tensorqtl) convention:\n",
    "\n",
    "- Phenotypes must be provided in BED format, sorted by chromosome and [start,end] position, with a single header line starting with # and the first four columns corresponding to: chr, start, end, phenotype_id, with the remaining columns corresponding to samples (the identifiers must match those in the genotype input). The BED file should specify the cis-window (usually the TSS), with start = the minimum start for each gene, end = the maximum end for each gene(extracted from phenotype referenced gtf file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>#id</th><th scope=col>#dir</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 9</td><td>output/phenotype/phenotype_by_chrom/bulk_rnaseq.chr9.bed.gz </td></tr>\n",
       "\t<tr><td>19</td><td>output/phenotype/phenotype_by_chrom/bulk_rnaseq.chr19.bed.gz</td></tr>\n",
       "\t<tr><td> 1</td><td>output/phenotype/phenotype_by_chrom/bulk_rnaseq.chr1.bed.gz </td></tr>\n",
       "\t<tr><td> 6</td><td>output/phenotype/phenotype_by_chrom/bulk_rnaseq.chr6.bed.gz </td></tr>\n",
       "\t<tr><td>15</td><td>output/phenotype/phenotype_by_chrom/bulk_rnaseq.chr15.bed.gz</td></tr>\n",
       "\t<tr><td>11</td><td>output/phenotype/phenotype_by_chrom/bulk_rnaseq.chr11.bed.gz</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 6 × 2\n",
       "\\begin{tabular}{ll}\n",
       " \\#id & \\#dir\\\\\n",
       " <int> & <chr>\\\\\n",
       "\\hline\n",
       "\t  9 & output/phenotype/phenotype\\_by\\_chrom/bulk\\_rnaseq.chr9.bed.gz \\\\\n",
       "\t 19 & output/phenotype/phenotype\\_by\\_chrom/bulk\\_rnaseq.chr19.bed.gz\\\\\n",
       "\t  1 & output/phenotype/phenotype\\_by\\_chrom/bulk\\_rnaseq.chr1.bed.gz \\\\\n",
       "\t  6 & output/phenotype/phenotype\\_by\\_chrom/bulk\\_rnaseq.chr6.bed.gz \\\\\n",
       "\t 15 & output/phenotype/phenotype\\_by\\_chrom/bulk\\_rnaseq.chr15.bed.gz\\\\\n",
       "\t 11 & output/phenotype/phenotype\\_by\\_chrom/bulk\\_rnaseq.chr11.bed.gz\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 6 × 2\n",
       "\n",
       "| #id &lt;int&gt; | #dir &lt;chr&gt; |\n",
       "|---|---|\n",
       "|  9 | output/phenotype/phenotype_by_chrom/bulk_rnaseq.chr9.bed.gz  |\n",
       "| 19 | output/phenotype/phenotype_by_chrom/bulk_rnaseq.chr19.bed.gz |\n",
       "|  1 | output/phenotype/phenotype_by_chrom/bulk_rnaseq.chr1.bed.gz  |\n",
       "|  6 | output/phenotype/phenotype_by_chrom/bulk_rnaseq.chr6.bed.gz  |\n",
       "| 15 | output/phenotype/phenotype_by_chrom/bulk_rnaseq.chr15.bed.gz |\n",
       "| 11 | output/phenotype/phenotype_by_chrom/bulk_rnaseq.chr11.bed.gz |\n",
       "\n"
      ],
      "text/plain": [
       "  #id #dir                                                        \n",
       "1  9  output/phenotype/phenotype_by_chrom/bulk_rnaseq.chr9.bed.gz \n",
       "2 19  output/phenotype/phenotype_by_chrom/bulk_rnaseq.chr19.bed.gz\n",
       "3  1  output/phenotype/phenotype_by_chrom/bulk_rnaseq.chr1.bed.gz \n",
       "4  6  output/phenotype/phenotype_by_chrom/bulk_rnaseq.chr6.bed.gz \n",
       "5 15  output/phenotype/phenotype_by_chrom/bulk_rnaseq.chr15.bed.gz\n",
       "6 11  output/phenotype/phenotype_by_chrom/bulk_rnaseq.chr11.bed.gz"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 5 × 8</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>#chr</th><th scope=col>start</th><th scope=col>end</th><th scope=col>ID</th><th scope=col>strand</th><th scope=col>sample0</th><th scope=col>sample1</th><th scope=col>sample2</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>chr9</td><td>3364328</td><td>3364791</td><td>ENSG00000215297</td><td>-</td><td>-0.4736331</td><td>-0.4922869</td><td>-0.4186161</td></tr>\n",
       "\t<tr><td>chr9</td><td>4792943</td><td>4885916</td><td>ENSG00000120158</td><td>+</td><td>-0.3648387</td><td> 1.3652152</td><td>-0.2774209</td></tr>\n",
       "\t<tr><td>chr9</td><td>5098340</td><td>5099324</td><td>ENSG00000235917</td><td>+</td><td>-0.7548631</td><td> 1.1789688</td><td>-0.9199175</td></tr>\n",
       "\t<tr><td>chr9</td><td>5299863</td><td>5304715</td><td>ENSG00000107014</td><td>-</td><td> 0.6902035</td><td>-0.9455643</td><td>-0.9455643</td></tr>\n",
       "\t<tr><td>chr9</td><td>5357970</td><td>5437924</td><td>ENSG00000107020</td><td>-</td><td>-0.1081115</td><td>-0.5687344</td><td> 0.4551426</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 5 × 8\n",
       "\\begin{tabular}{llllllll}\n",
       " \\#chr & start & end & ID & strand & sample0 & sample1 & sample2\\\\\n",
       " <chr> & <int> & <int> & <chr> & <chr> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t chr9 & 3364328 & 3364791 & ENSG00000215297 & - & -0.4736331 & -0.4922869 & -0.4186161\\\\\n",
       "\t chr9 & 4792943 & 4885916 & ENSG00000120158 & + & -0.3648387 &  1.3652152 & -0.2774209\\\\\n",
       "\t chr9 & 5098340 & 5099324 & ENSG00000235917 & + & -0.7548631 &  1.1789688 & -0.9199175\\\\\n",
       "\t chr9 & 5299863 & 5304715 & ENSG00000107014 & - &  0.6902035 & -0.9455643 & -0.9455643\\\\\n",
       "\t chr9 & 5357970 & 5437924 & ENSG00000107020 & - & -0.1081115 & -0.5687344 &  0.4551426\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 5 × 8\n",
       "\n",
       "| #chr &lt;chr&gt; | start &lt;int&gt; | end &lt;int&gt; | ID &lt;chr&gt; | strand &lt;chr&gt; | sample0 &lt;dbl&gt; | sample1 &lt;dbl&gt; | sample2 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| chr9 | 3364328 | 3364791 | ENSG00000215297 | - | -0.4736331 | -0.4922869 | -0.4186161 |\n",
       "| chr9 | 4792943 | 4885916 | ENSG00000120158 | + | -0.3648387 |  1.3652152 | -0.2774209 |\n",
       "| chr9 | 5098340 | 5099324 | ENSG00000235917 | + | -0.7548631 |  1.1789688 | -0.9199175 |\n",
       "| chr9 | 5299863 | 5304715 | ENSG00000107014 | - |  0.6902035 | -0.9455643 | -0.9455643 |\n",
       "| chr9 | 5357970 | 5437924 | ENSG00000107020 | - | -0.1081115 | -0.5687344 |  0.4551426 |\n",
       "\n"
      ],
      "text/plain": [
       "  #chr start   end     ID              strand sample0    sample1    sample2   \n",
       "1 chr9 3364328 3364791 ENSG00000215297 -      -0.4736331 -0.4922869 -0.4186161\n",
       "2 chr9 4792943 4885916 ENSG00000120158 +      -0.3648387  1.3652152 -0.2774209\n",
       "3 chr9 5098340 5099324 ENSG00000235917 +      -0.7548631  1.1789688 -0.9199175\n",
       "4 chr9 5299863 5304715 ENSG00000107014 -       0.6902035 -0.9455643 -0.9455643\n",
       "5 chr9 5357970 5437924 ENSG00000107020 -      -0.1081115 -0.5687344  0.4551426"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Load Phenotype File List\n",
    "# -----------------------------\n",
    "# The input is a text file listing phenotype .bed.gz files by chromosome\n",
    "pheno_path <- fread(\"output/phenotype/phenotype_by_chrom/bulk_rnaseq.phenotype_by_chrom_files.txt\")\n",
    "head(pheno_path)\n",
    "\n",
    "# -----------------------------\n",
    "# Load Phenotype Data for One Chromosome (e.g., Chr9)\n",
    "# -----------------------------\n",
    "# Each file is in BED-like format (.bed.gz), commonly used in QTL pipelines\n",
    "pheno <- fread(\"output/phenotype/phenotype_by_chrom/bulk_rnaseq.chr9.bed.gz\")\n",
    "pheno[1:5, 1:8]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Example genotype file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“package ‘data.table’ was built under R version 4.4.3”\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>#id</th><th scope=col>#path</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>11</td><td>/mnt/vast/hpc/homes/al4225/xqtl_protocol_data/output/genotype_by_chrom/wgs.merged.plink_qc.11.bed</td></tr>\n",
       "\t<tr><td> 3</td><td>/mnt/vast/hpc/homes/al4225/xqtl_protocol_data/output/genotype_by_chrom/wgs.merged.plink_qc.3.bed </td></tr>\n",
       "\t<tr><td>10</td><td>/mnt/vast/hpc/homes/al4225/xqtl_protocol_data/output/genotype_by_chrom/wgs.merged.plink_qc.10.bed</td></tr>\n",
       "\t<tr><td>22</td><td>/mnt/vast/hpc/homes/al4225/xqtl_protocol_data/output/genotype_by_chrom/wgs.merged.plink_qc.22.bed</td></tr>\n",
       "\t<tr><td>20</td><td>/mnt/vast/hpc/homes/al4225/xqtl_protocol_data/output/genotype_by_chrom/wgs.merged.plink_qc.20.bed</td></tr>\n",
       "\t<tr><td>15</td><td>/mnt/vast/hpc/homes/al4225/xqtl_protocol_data/output/genotype_by_chrom/wgs.merged.plink_qc.15.bed</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 6 × 2\n",
       "\\begin{tabular}{ll}\n",
       " \\#id & \\#path\\\\\n",
       " <int> & <chr>\\\\\n",
       "\\hline\n",
       "\t 11 & /mnt/vast/hpc/homes/al4225/xqtl\\_protocol\\_data/output/genotype\\_by\\_chrom/wgs.merged.plink\\_qc.11.bed\\\\\n",
       "\t  3 & /mnt/vast/hpc/homes/al4225/xqtl\\_protocol\\_data/output/genotype\\_by\\_chrom/wgs.merged.plink\\_qc.3.bed \\\\\n",
       "\t 10 & /mnt/vast/hpc/homes/al4225/xqtl\\_protocol\\_data/output/genotype\\_by\\_chrom/wgs.merged.plink\\_qc.10.bed\\\\\n",
       "\t 22 & /mnt/vast/hpc/homes/al4225/xqtl\\_protocol\\_data/output/genotype\\_by\\_chrom/wgs.merged.plink\\_qc.22.bed\\\\\n",
       "\t 20 & /mnt/vast/hpc/homes/al4225/xqtl\\_protocol\\_data/output/genotype\\_by\\_chrom/wgs.merged.plink\\_qc.20.bed\\\\\n",
       "\t 15 & /mnt/vast/hpc/homes/al4225/xqtl\\_protocol\\_data/output/genotype\\_by\\_chrom/wgs.merged.plink\\_qc.15.bed\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 6 × 2\n",
       "\n",
       "| #id &lt;int&gt; | #path &lt;chr&gt; |\n",
       "|---|---|\n",
       "| 11 | /mnt/vast/hpc/homes/al4225/xqtl_protocol_data/output/genotype_by_chrom/wgs.merged.plink_qc.11.bed |\n",
       "|  3 | /mnt/vast/hpc/homes/al4225/xqtl_protocol_data/output/genotype_by_chrom/wgs.merged.plink_qc.3.bed  |\n",
       "| 10 | /mnt/vast/hpc/homes/al4225/xqtl_protocol_data/output/genotype_by_chrom/wgs.merged.plink_qc.10.bed |\n",
       "| 22 | /mnt/vast/hpc/homes/al4225/xqtl_protocol_data/output/genotype_by_chrom/wgs.merged.plink_qc.22.bed |\n",
       "| 20 | /mnt/vast/hpc/homes/al4225/xqtl_protocol_data/output/genotype_by_chrom/wgs.merged.plink_qc.20.bed |\n",
       "| 15 | /mnt/vast/hpc/homes/al4225/xqtl_protocol_data/output/genotype_by_chrom/wgs.merged.plink_qc.15.bed |\n",
       "\n"
      ],
      "text/plain": [
       "  #id\n",
       "1 11 \n",
       "2  3 \n",
       "3 10 \n",
       "4 22 \n",
       "5 20 \n",
       "6 15 \n",
       "  #path                                                                                            \n",
       "1 /mnt/vast/hpc/homes/al4225/xqtl_protocol_data/output/genotype_by_chrom/wgs.merged.plink_qc.11.bed\n",
       "2 /mnt/vast/hpc/homes/al4225/xqtl_protocol_data/output/genotype_by_chrom/wgs.merged.plink_qc.3.bed \n",
       "3 /mnt/vast/hpc/homes/al4225/xqtl_protocol_data/output/genotype_by_chrom/wgs.merged.plink_qc.10.bed\n",
       "4 /mnt/vast/hpc/homes/al4225/xqtl_protocol_data/output/genotype_by_chrom/wgs.merged.plink_qc.22.bed\n",
       "5 /mnt/vast/hpc/homes/al4225/xqtl_protocol_data/output/genotype_by_chrom/wgs.merged.plink_qc.20.bed\n",
       "6 /mnt/vast/hpc/homes/al4225/xqtl_protocol_data/output/genotype_by_chrom/wgs.merged.plink_qc.15.bed"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading: output/genotype_by_chrom/wgs.merged.plink_qc.21.bim\n",
      "\n",
      "Reading: output/genotype_by_chrom/wgs.merged.plink_qc.21.fam\n",
      "\n",
      "Reading: output/genotype_by_chrom/wgs.merged.plink_qc.21.bed\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 5 × 5 of type int</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>sample0</th><th scope=col>sample1</th><th scope=col>sample2</th><th scope=col>sample3</th><th scope=col>sample4</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>chr21:5091891_A_G</th><td>0</td><td>0</td><td>0</td><td>NA</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>chr21:5097593_CGTCCCTTCCCGAGGTTCCAGGCGGACGT_C</th><td>0</td><td>0</td><td>0</td><td>NA</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>chr21:5097593_CGTCCCTTCCCGAGGTTCCAGGCGGACGT_CGTCCCTTCCCGAGGTTCCAGGCGGACGTGTCCCTTCCCGAGGTTCCAGGCGGACGT</th><td>0</td><td>0</td><td>0</td><td>NA</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>chr21:5097593_CGTCCCTTCCCGAGGTTCCAGGCGGACGT_TGTCCCTTCCCGAGGTTCCAGGCGGACGT</th><td>0</td><td>0</td><td>0</td><td>NA</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>chr21:5103954_G_C</th><td>0</td><td>0</td><td>0</td><td> 0</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 5 × 5 of type int\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & sample0 & sample1 & sample2 & sample3 & sample4\\\\\n",
       "\\hline\n",
       "\tchr21:5091891\\_A\\_G & 0 & 0 & 0 & NA & 0\\\\\n",
       "\tchr21:5097593\\_CGTCCCTTCCCGAGGTTCCAGGCGGACGT\\_C & 0 & 0 & 0 & NA & 0\\\\\n",
       "\tchr21:5097593\\_CGTCCCTTCCCGAGGTTCCAGGCGGACGT\\_CGTCCCTTCCCGAGGTTCCAGGCGGACGTGTCCCTTCCCGAGGTTCCAGGCGGACGT & 0 & 0 & 0 & NA & 0\\\\\n",
       "\tchr21:5097593\\_CGTCCCTTCCCGAGGTTCCAGGCGGACGT\\_TGTCCCTTCCCGAGGTTCCAGGCGGACGT & 0 & 0 & 0 & NA & 0\\\\\n",
       "\tchr21:5103954\\_G\\_C & 0 & 0 & 0 &  0 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 5 × 5 of type int\n",
       "\n",
       "| <!--/--> | sample0 | sample1 | sample2 | sample3 | sample4 |\n",
       "|---|---|---|---|---|---|\n",
       "| chr21:5091891_A_G | 0 | 0 | 0 | NA | 0 |\n",
       "| chr21:5097593_CGTCCCTTCCCGAGGTTCCAGGCGGACGT_C | 0 | 0 | 0 | NA | 0 |\n",
       "| chr21:5097593_CGTCCCTTCCCGAGGTTCCAGGCGGACGT_CGTCCCTTCCCGAGGTTCCAGGCGGACGTGTCCCTTCCCGAGGTTCCAGGCGGACGT | 0 | 0 | 0 | NA | 0 |\n",
       "| chr21:5097593_CGTCCCTTCCCGAGGTTCCAGGCGGACGT_TGTCCCTTCCCGAGGTTCCAGGCGGACGT | 0 | 0 | 0 | NA | 0 |\n",
       "| chr21:5103954_G_C | 0 | 0 | 0 |  0 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "                                                                                                      sample0\n",
       "chr21:5091891_A_G                                                                                     0      \n",
       "chr21:5097593_CGTCCCTTCCCGAGGTTCCAGGCGGACGT_C                                                         0      \n",
       "chr21:5097593_CGTCCCTTCCCGAGGTTCCAGGCGGACGT_CGTCCCTTCCCGAGGTTCCAGGCGGACGTGTCCCTTCCCGAGGTTCCAGGCGGACGT 0      \n",
       "chr21:5097593_CGTCCCTTCCCGAGGTTCCAGGCGGACGT_TGTCCCTTCCCGAGGTTCCAGGCGGACGT                             0      \n",
       "chr21:5103954_G_C                                                                                     0      \n",
       "                                                                                                      sample1\n",
       "chr21:5091891_A_G                                                                                     0      \n",
       "chr21:5097593_CGTCCCTTCCCGAGGTTCCAGGCGGACGT_C                                                         0      \n",
       "chr21:5097593_CGTCCCTTCCCGAGGTTCCAGGCGGACGT_CGTCCCTTCCCGAGGTTCCAGGCGGACGTGTCCCTTCCCGAGGTTCCAGGCGGACGT 0      \n",
       "chr21:5097593_CGTCCCTTCCCGAGGTTCCAGGCGGACGT_TGTCCCTTCCCGAGGTTCCAGGCGGACGT                             0      \n",
       "chr21:5103954_G_C                                                                                     0      \n",
       "                                                                                                      sample2\n",
       "chr21:5091891_A_G                                                                                     0      \n",
       "chr21:5097593_CGTCCCTTCCCGAGGTTCCAGGCGGACGT_C                                                         0      \n",
       "chr21:5097593_CGTCCCTTCCCGAGGTTCCAGGCGGACGT_CGTCCCTTCCCGAGGTTCCAGGCGGACGTGTCCCTTCCCGAGGTTCCAGGCGGACGT 0      \n",
       "chr21:5097593_CGTCCCTTCCCGAGGTTCCAGGCGGACGT_TGTCCCTTCCCGAGGTTCCAGGCGGACGT                             0      \n",
       "chr21:5103954_G_C                                                                                     0      \n",
       "                                                                                                      sample3\n",
       "chr21:5091891_A_G                                                                                     NA     \n",
       "chr21:5097593_CGTCCCTTCCCGAGGTTCCAGGCGGACGT_C                                                         NA     \n",
       "chr21:5097593_CGTCCCTTCCCGAGGTTCCAGGCGGACGT_CGTCCCTTCCCGAGGTTCCAGGCGGACGTGTCCCTTCCCGAGGTTCCAGGCGGACGT NA     \n",
       "chr21:5097593_CGTCCCTTCCCGAGGTTCCAGGCGGACGT_TGTCCCTTCCCGAGGTTCCAGGCGGACGT                             NA     \n",
       "chr21:5103954_G_C                                                                                      0     \n",
       "                                                                                                      sample4\n",
       "chr21:5091891_A_G                                                                                     0      \n",
       "chr21:5097593_CGTCCCTTCCCGAGGTTCCAGGCGGACGT_C                                                         0      \n",
       "chr21:5097593_CGTCCCTTCCCGAGGTTCCAGGCGGACGT_CGTCCCTTCCCGAGGTTCCAGGCGGACGTGTCCCTTCCCGAGGTTCCAGGCGGACGT 0      \n",
       "chr21:5097593_CGTCCCTTCCCGAGGTTCCAGGCGGACGT_TGTCCCTTCCCGAGGTTCCAGGCGGACGT                             0      \n",
       "chr21:5103954_G_C                                                                                     0      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load required libraries\n",
    "library(data.table)\n",
    "library(genio)\n",
    "\n",
    "# -----------------------------\n",
    "# Load Genotype File Paths\n",
    "# -----------------------------\n",
    "# The input is a text file with two columns: chromosome ID and corresponding PLINK prefix path\n",
    "geno_path <- fread(\"output/genotype_by_chrom/wgs.merged.plink_qc.genotype_by_chrom_files.txt\")\n",
    "head(geno_path)\n",
    "\n",
    "# -----------------------------\n",
    "# Read PLINK Files for One Chromosome (e.g., Chr21)\n",
    "# -----------------------------\n",
    "# This will automatically read .bed, .bim, and .fam files\n",
    "file_path <- \"output/genotype_by_chrom/wgs.merged.plink_qc.21\"\n",
    "plink_data <- read_plink(file_path)\n",
    "\n",
    "# Extract genotype matrix (individuals x SNPs)\n",
    "genotypes <- plink_data$X\n",
    "genotypes[1:5, 1:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Example covariates file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 19 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>#id</th><th scope=col>sample0</th><th scope=col>sample1</th><th scope=col>sample2</th><th scope=col>sample3</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>sex </td><td> 0.000000000</td><td> 0.00000000</td><td> 1.000000000</td><td> 0.000000000</td></tr>\n",
       "\t<tr><td>age </td><td>91.000000000</td><td>92.00000000</td><td>52.000000000</td><td>85.000000000</td></tr>\n",
       "\t<tr><td>rin </td><td> 4.000000000</td><td> 6.00000000</td><td> 3.000000000</td><td> 5.000000000</td></tr>\n",
       "\t<tr><td>pmi </td><td> 4.000000000</td><td>33.00000000</td><td>21.000000000</td><td>28.000000000</td></tr>\n",
       "\t<tr><td>PC1 </td><td> 0.007971940</td><td> 0.01551892</td><td> 0.007742702</td><td> 0.017287771</td></tr>\n",
       "\t<tr><td>PC2 </td><td> 0.211086385</td><td>-0.08141101</td><td>-0.132460948</td><td> 0.014621938</td></tr>\n",
       "\t<tr><td>PC3 </td><td>-0.050633431</td><td>-0.12687380</td><td>-0.120602702</td><td> 0.055990494</td></tr>\n",
       "\t<tr><td>PC4 </td><td>-0.014065335</td><td> 0.12781518</td><td>-0.017367114</td><td> 0.020156398</td></tr>\n",
       "\t<tr><td>PC5 </td><td>-0.124368908</td><td> 0.03655637</td><td> 0.028215755</td><td> 0.156124781</td></tr>\n",
       "\t<tr><td>PC6 </td><td>-0.175836871</td><td> 0.01975288</td><td>-0.007233068</td><td>-0.078524241</td></tr>\n",
       "\t<tr><td>PC7 </td><td>-0.014591287</td><td>-0.06608257</td><td>-0.041445073</td><td> 0.003383833</td></tr>\n",
       "\t<tr><td>PC8 </td><td> 0.100632611</td><td>-0.04379747</td><td>-0.039527812</td><td> 0.020061007</td></tr>\n",
       "\t<tr><td>PC9 </td><td>-0.043891771</td><td> 0.05800895</td><td>-0.049506134</td><td> 0.163379337</td></tr>\n",
       "\t<tr><td>PC10</td><td> 0.015669252</td><td>-0.04237315</td><td>-0.019432672</td><td>-0.139484459</td></tr>\n",
       "\t<tr><td>PC11</td><td>-0.077606914</td><td>-0.07344496</td><td>-0.039550084</td><td>-0.117880849</td></tr>\n",
       "\t<tr><td>PC12</td><td>-0.099994405</td><td> 0.05674175</td><td> 0.040751666</td><td>-0.076787323</td></tr>\n",
       "\t<tr><td>PC13</td><td> 0.087308831</td><td>-0.08719969</td><td>-0.030919853</td><td>-0.082366841</td></tr>\n",
       "\t<tr><td>PC14</td><td> 0.005660495</td><td>-0.03116481</td><td>-0.049474017</td><td> 0.014205662</td></tr>\n",
       "\t<tr><td>PC15</td><td>-0.024383688</td><td>-0.03245244</td><td> 0.151153844</td><td> 0.201390128</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 19 × 5\n",
       "\\begin{tabular}{lllll}\n",
       " \\#id & sample0 & sample1 & sample2 & sample3\\\\\n",
       " <chr> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t sex  &  0.000000000 &  0.00000000 &  1.000000000 &  0.000000000\\\\\n",
       "\t age  & 91.000000000 & 92.00000000 & 52.000000000 & 85.000000000\\\\\n",
       "\t rin  &  4.000000000 &  6.00000000 &  3.000000000 &  5.000000000\\\\\n",
       "\t pmi  &  4.000000000 & 33.00000000 & 21.000000000 & 28.000000000\\\\\n",
       "\t PC1  &  0.007971940 &  0.01551892 &  0.007742702 &  0.017287771\\\\\n",
       "\t PC2  &  0.211086385 & -0.08141101 & -0.132460948 &  0.014621938\\\\\n",
       "\t PC3  & -0.050633431 & -0.12687380 & -0.120602702 &  0.055990494\\\\\n",
       "\t PC4  & -0.014065335 &  0.12781518 & -0.017367114 &  0.020156398\\\\\n",
       "\t PC5  & -0.124368908 &  0.03655637 &  0.028215755 &  0.156124781\\\\\n",
       "\t PC6  & -0.175836871 &  0.01975288 & -0.007233068 & -0.078524241\\\\\n",
       "\t PC7  & -0.014591287 & -0.06608257 & -0.041445073 &  0.003383833\\\\\n",
       "\t PC8  &  0.100632611 & -0.04379747 & -0.039527812 &  0.020061007\\\\\n",
       "\t PC9  & -0.043891771 &  0.05800895 & -0.049506134 &  0.163379337\\\\\n",
       "\t PC10 &  0.015669252 & -0.04237315 & -0.019432672 & -0.139484459\\\\\n",
       "\t PC11 & -0.077606914 & -0.07344496 & -0.039550084 & -0.117880849\\\\\n",
       "\t PC12 & -0.099994405 &  0.05674175 &  0.040751666 & -0.076787323\\\\\n",
       "\t PC13 &  0.087308831 & -0.08719969 & -0.030919853 & -0.082366841\\\\\n",
       "\t PC14 &  0.005660495 & -0.03116481 & -0.049474017 &  0.014205662\\\\\n",
       "\t PC15 & -0.024383688 & -0.03245244 &  0.151153844 &  0.201390128\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 19 × 5\n",
       "\n",
       "| #id &lt;chr&gt; | sample0 &lt;dbl&gt; | sample1 &lt;dbl&gt; | sample2 &lt;dbl&gt; | sample3 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| sex  |  0.000000000 |  0.00000000 |  1.000000000 |  0.000000000 |\n",
       "| age  | 91.000000000 | 92.00000000 | 52.000000000 | 85.000000000 |\n",
       "| rin  |  4.000000000 |  6.00000000 |  3.000000000 |  5.000000000 |\n",
       "| pmi  |  4.000000000 | 33.00000000 | 21.000000000 | 28.000000000 |\n",
       "| PC1  |  0.007971940 |  0.01551892 |  0.007742702 |  0.017287771 |\n",
       "| PC2  |  0.211086385 | -0.08141101 | -0.132460948 |  0.014621938 |\n",
       "| PC3  | -0.050633431 | -0.12687380 | -0.120602702 |  0.055990494 |\n",
       "| PC4  | -0.014065335 |  0.12781518 | -0.017367114 |  0.020156398 |\n",
       "| PC5  | -0.124368908 |  0.03655637 |  0.028215755 |  0.156124781 |\n",
       "| PC6  | -0.175836871 |  0.01975288 | -0.007233068 | -0.078524241 |\n",
       "| PC7  | -0.014591287 | -0.06608257 | -0.041445073 |  0.003383833 |\n",
       "| PC8  |  0.100632611 | -0.04379747 | -0.039527812 |  0.020061007 |\n",
       "| PC9  | -0.043891771 |  0.05800895 | -0.049506134 |  0.163379337 |\n",
       "| PC10 |  0.015669252 | -0.04237315 | -0.019432672 | -0.139484459 |\n",
       "| PC11 | -0.077606914 | -0.07344496 | -0.039550084 | -0.117880849 |\n",
       "| PC12 | -0.099994405 |  0.05674175 |  0.040751666 | -0.076787323 |\n",
       "| PC13 |  0.087308831 | -0.08719969 | -0.030919853 | -0.082366841 |\n",
       "| PC14 |  0.005660495 | -0.03116481 | -0.049474017 |  0.014205662 |\n",
       "| PC15 | -0.024383688 | -0.03245244 |  0.151153844 |  0.201390128 |\n",
       "\n"
      ],
      "text/plain": [
       "   #id  sample0      sample1     sample2      sample3     \n",
       "1  sex   0.000000000  0.00000000  1.000000000  0.000000000\n",
       "2  age  91.000000000 92.00000000 52.000000000 85.000000000\n",
       "3  rin   4.000000000  6.00000000  3.000000000  5.000000000\n",
       "4  pmi   4.000000000 33.00000000 21.000000000 28.000000000\n",
       "5  PC1   0.007971940  0.01551892  0.007742702  0.017287771\n",
       "6  PC2   0.211086385 -0.08141101 -0.132460948  0.014621938\n",
       "7  PC3  -0.050633431 -0.12687380 -0.120602702  0.055990494\n",
       "8  PC4  -0.014065335  0.12781518 -0.017367114  0.020156398\n",
       "9  PC5  -0.124368908  0.03655637  0.028215755  0.156124781\n",
       "10 PC6  -0.175836871  0.01975288 -0.007233068 -0.078524241\n",
       "11 PC7  -0.014591287 -0.06608257 -0.041445073  0.003383833\n",
       "12 PC8   0.100632611 -0.04379747 -0.039527812  0.020061007\n",
       "13 PC9  -0.043891771  0.05800895 -0.049506134  0.163379337\n",
       "14 PC10  0.015669252 -0.04237315 -0.019432672 -0.139484459\n",
       "15 PC11 -0.077606914 -0.07344496 -0.039550084 -0.117880849\n",
       "16 PC12 -0.099994405  0.05674175  0.040751666 -0.076787323\n",
       "17 PC13  0.087308831 -0.08719969 -0.030919853 -0.082366841\n",
       "18 PC14  0.005660495 -0.03116481 -0.049474017  0.014205662\n",
       "19 PC15 -0.024383688 -0.03245244  0.151153844  0.201390128"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>19</li><li>151</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 19\n",
       "\\item 151\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 19\n",
       "2. 151\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  19 151"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cov file:\n",
    "cov = fread('output/covariate/covariates.wgs.merged.plink_qc.plink_qc.prune.pca.gz')\n",
    "cov[,1:5]\n",
    "dim(cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Example customized cis window file (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 6 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>#chr</th><th scope=col>start</th><th scope=col>end</th><th scope=col>gene_id</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>chr1</td><td>0</td><td>6480000</td><td>ENSG00000008128</td></tr>\n",
       "\t<tr><td>chr1</td><td>0</td><td>6480000</td><td>ENSG00000008130</td></tr>\n",
       "\t<tr><td>chr1</td><td>0</td><td>6480000</td><td>ENSG00000067606</td></tr>\n",
       "\t<tr><td>chr1</td><td>0</td><td>7101193</td><td>ENSG00000069424</td></tr>\n",
       "\t<tr><td>chr1</td><td>0</td><td>7960000</td><td>ENSG00000069812</td></tr>\n",
       "\t<tr><td>chr1</td><td>0</td><td>6480000</td><td>ENSG00000078369</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 6 × 4\n",
       "\\begin{tabular}{llll}\n",
       " \\#chr & start & end & gene\\_id\\\\\n",
       " <chr> & <int> & <int> & <chr>\\\\\n",
       "\\hline\n",
       "\t chr1 & 0 & 6480000 & ENSG00000008128\\\\\n",
       "\t chr1 & 0 & 6480000 & ENSG00000008130\\\\\n",
       "\t chr1 & 0 & 6480000 & ENSG00000067606\\\\\n",
       "\t chr1 & 0 & 7101193 & ENSG00000069424\\\\\n",
       "\t chr1 & 0 & 7960000 & ENSG00000069812\\\\\n",
       "\t chr1 & 0 & 6480000 & ENSG00000078369\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 6 × 4\n",
       "\n",
       "| #chr &lt;chr&gt; | start &lt;int&gt; | end &lt;int&gt; | gene_id &lt;chr&gt; |\n",
       "|---|---|---|---|\n",
       "| chr1 | 0 | 6480000 | ENSG00000008128 |\n",
       "| chr1 | 0 | 6480000 | ENSG00000008130 |\n",
       "| chr1 | 0 | 6480000 | ENSG00000067606 |\n",
       "| chr1 | 0 | 7101193 | ENSG00000069424 |\n",
       "| chr1 | 0 | 7960000 | ENSG00000069812 |\n",
       "| chr1 | 0 | 6480000 | ENSG00000078369 |\n",
       "\n"
      ],
      "text/plain": [
       "  #chr start end     gene_id        \n",
       "1 chr1 0     6480000 ENSG00000008128\n",
       "2 chr1 0     6480000 ENSG00000008130\n",
       "3 chr1 0     6480000 ENSG00000067606\n",
       "4 chr1 0     7101193 ENSG00000069424\n",
       "5 chr1 0     7960000 ENSG00000069812\n",
       "6 chr1 0     6480000 ENSG00000078369"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Load Customized Cis-Window File\n",
    "# -----------------------------\n",
    "# This file specifies the gene-level cis-window: start and end positions \n",
    "# used to define the SNP search region for each gene.\n",
    "# If you do not want to use a customized window, you can instead specify `--window` in the pipeline,\n",
    "# which by default sets a symmetric ±1Mb window around each gene TSS.\n",
    "\n",
    "window <- fread(\"reference_data/TAD/TADB_enhanced_cis.bed\")\n",
    "head(window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Example interaction file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>sample_id</th><th scope=col>int</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>sample0</td><td>0</td></tr>\n",
       "\t<tr><td>sample1</td><td>0</td></tr>\n",
       "\t<tr><td>sample2</td><td>0</td></tr>\n",
       "\t<tr><td>sample3</td><td>0</td></tr>\n",
       "\t<tr><td>sample4</td><td>1</td></tr>\n",
       "\t<tr><td>sample5</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 6 × 2\n",
       "\\begin{tabular}{ll}\n",
       " sample\\_id & int\\\\\n",
       " <chr> & <int>\\\\\n",
       "\\hline\n",
       "\t sample0 & 0\\\\\n",
       "\t sample1 & 0\\\\\n",
       "\t sample2 & 0\\\\\n",
       "\t sample3 & 0\\\\\n",
       "\t sample4 & 1\\\\\n",
       "\t sample5 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 6 × 2\n",
       "\n",
       "| sample_id &lt;chr&gt; | int &lt;int&gt; |\n",
       "|---|---|\n",
       "| sample0 | 0 |\n",
       "| sample1 | 0 |\n",
       "| sample2 | 0 |\n",
       "| sample3 | 0 |\n",
       "| sample4 | 1 |\n",
       "| sample5 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "  sample_id int\n",
       "1 sample0   0  \n",
       "2 sample1   0  \n",
       "3 sample2   0  \n",
       "4 sample3   0  \n",
       "5 sample4   1  \n",
       "6 sample5   1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Load Interaction File\n",
    "# -----------------------------\n",
    "# For iQTL analysis, if the interaction term is not included in your covariate file,\n",
    "# you need to provide it as a separate file via the `--interaction` parameter.\n",
    "\n",
    "int <- fread(\"data/ROSMAP_interaction_example.tsv\")\n",
    "head(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "\n",
    "For cis-analysis:\n",
    "\n",
    "- Optionally, a list of genomic regions associate with each molecular features to analyze. The default cis-analysis will use a window around TSS. This can be customized to take given start and end genomic coordinates. we currently suggest using 1Mb window around a gene because longer customized cis-windows (such as extending by TAD) does not yield significant improvements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "For trans-analysis:\n",
    "\n",
    " **Computational strategy designed for trans analysis:**\n",
    " \n",
    " Trans analysis faces significant memory challenges as we calculate all associations between all molecular traits × all genetic variants across the genome, creating a massive computational burden. To address this challenge, we implement a two-stage chromosome-based parallelization approach:\n",
    "\n",
    " **Stage 1 (trans_1): Chromosome-based parallelization**\n",
    " - Phenotype data is processed per chromosome (e.g., 22 separate jobs for autosomes)\n",
    " - For each phenotype chromosome, we test associations against variants from all 22 chromosomes\n",
    " - This creates phenotype_chr × genotype_chr combinations (e.g., phenotype chr1 vs genotype chr1-22); Garbage was collected between each chromosome combination caculation to release memory\n",
    " - Results are combined across all chromosome combinations and saved as compressed files\n",
    "\n",
    " **Stage 2 (trans_2): Significance filtering**\n",
    " - Supports p-value cutoffs (`--pvalue-cutoff`) or q-value cutoffs (`--qvalue-cutoff`)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Output  \n",
    "\n",
    "For each chromosome, several summary statistics files are generated, including both nominal test statistics for each test and region (gene) level association evidence.  \n",
    "\n",
    "### Nominal Association Results  \n",
    "\n",
    "The columns of the nominal association result are as follows:  \n",
    "\n",
    "- **chrom**: Variant chromosome.  \n",
    "- **pos**: Variant chromosomal position (basepairs).  \n",
    "- **molecular_trait_id**: Molecular trait identifier (gene).  \n",
    "- **variant_id**: ID of the variant (rsid or chr:position:ref:alt).  \n",
    "- **tss_distance**: Distance of the SNP to the gene transcription start site (TSS).  \n",
    "- **tes_distance**: Distance of the SNP to the gene transcription end site (TES).  \n",
    "- **cis_window_start_distance**: Distance of the SNP to the start of the cis window (if using a customized cis window).  \n",
    "- **cis_window_end_distance**: Distance of the SNP to the end of the cis window (if using a customized cis window).  \n",
    "- **af**: The allele frequency of this SNP.  \n",
    "- **ma_samples**: Number of samples carrying the minor allele.  \n",
    "- **ma_count**: Total number of minor alleles across individuals.  \n",
    "- **pvalue**: Nominal P-value from linear regression.  \n",
    "- **bhat**: Slope of the linear regression.  \n",
    "- **sebhat**: Standard error of bhat.  \n",
    "- **n**: Number of phenotypes after basic QC.  \n",
    "#### Multiple Testing Corrected Results:  \n",
    "- **qvalue**: Calculated q-value for each SNP (grouped by gene).  \n",
    "\n",
    "### Interaction Association Results  \n",
    "\n",
    "The columns of interaction association results are as follows (FIXME):  \n",
    "\n",
    "**Model:**  \n",
    "$$\n",
    "\\text{phenotype} = \\beta_0 + \\beta_1 \\cdot \\text{snp} + \\beta_2 \\cdot \\text{msex} + \\beta_3 \\cdot (\\text{snp} \\times \\text{msex}) + \\epsilon\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "(Taking msex as the interaction factor)  \n",
    "\n",
    "- **chrom**: Chromosome number.  \n",
    "- **pos**: Variant chromosomal position (basepairs).  \n",
    "- **a2**: Variant reference allele (A, C, T, or G).  \n",
    "- **a1**: Variant alternate allele.  \n",
    "- **molecular_trait_id**: Molecular trait identifier, varies from phenotypes to phenotypes.  \n",
    "- **variant_id**: ID of the top variant (rsid or chr:position:ref:alt).  \n",
    "- **af**: Alternative allele frequency in the MiGA cohort.  \n",
    "- **ma_samples**: Number of samples carrying the minor allele.  \n",
    "- **ma_count**: Total number of minor alleles across individuals.  \n",
    "- **pvalue**: P-value of the main effect from the nonlinear regression.  \n",
    "- **bhat**: Slope of the main effect from the nonlinear regression.  \n",
    "- **se**: Standard error of beta.  \n",
    "- **pvalue_msex**: P-value of the msex term from the nonlinear regression.  \n",
    "- **bhat_msex**: Slope of the msex term from the nonlinear regression.  \n",
    "- **se_msex**: Standard error of bhat_msex.  \n",
    "- **pvalue_msex_interaction**: P-value of the interaction term from the nonlinear regression.  \n",
    "- **bhat_msex_interaction**: Slope of the interaction term from the nonlinear regression.  \n",
    "- **se_msex_interaction**: Standard error of beta_msex_interaction.  \n",
    "- **molecular_trait_object_id**: An intermediate ID (can be ignored).  \n",
    "- **n**: Number of samples.\n",
    "#### Multiple Testing Corrected Results:  \n",
    "- **qvalue_main**: The q-value of the main effect.  \n",
    "- **qvalue_interaction**: The q-value of the interaction effect.  \n",
    "\n",
    "### Region (Gene) Level Association Evidence  \n",
    "\n",
    "The column specifications for region-level association evidence are as follows:  \n",
    "\n",
    "- **chrom**: Chromosome number.  \n",
    "- **pos**: Variant chromosomal position (basepairs).  \n",
    "- **n_variant**: Total number of variants tested in cis.  \n",
    "- **beta_shape1**: First parameter value of the fitted beta distribution.  \n",
    "- **beta_shape2**: Second parameter value of the fitted beta distribution.  \n",
    "- **true_df**: Effective degrees of freedom of the beta distribution approximation.  \n",
    "- **p_true_df**: Empirical P-value for the beta distribution approximation.  \n",
    "- **variant_id**: ID of the top variant (rsid or chr:position:ref:alt).  \n",
    "- **tss_distance**: Distance of the SNP to the gene transcription start site (TSS).  \n",
    "- **tes_distance**: Distance of the SNP to the gene transcription end site (TES).  \n",
    "- **ma_samples**: Number of samples carrying the minor allele.  \n",
    "- **ma_count**: Total number of minor alleles across individuals.  \n",
    "- **af**: Alternative allele frequency.  \n",
    "- **p_nominal**: Nominal P-value from linear regression.  \n",
    "- **bhat**: Slope of the linear regression.  \n",
    "- **sehat**: Standard error of the bhat.  \n",
    "- **p_perm**: First permutation P-value directly obtained from the permutations with the direct method.  \n",
    "- **p_beta**: Second permutation P-value obtained via beta approximation (this is the one to use for downstream analysis).  \n",
    "- **molecular_trait_object_id**: Molecular trait identifier (gene).  \n",
    "- **n_traits**: Group size in the permutation test.  \n",
    "- **genomic_inflation**: Genomic inflation factor (lambda), quantifying the extent of bulk inflation and the excess false positive rate.  \n",
    "#### Multiple Testing Corrected Results:  \n",
    "- **q_beta**: Q-value for p_beta using Storey's method (qvalue), more conservative than FDR.  \n",
    "- **q_perm**: Q-value for p_perm using Storey's method (qvalue), more conservative than FDR.  \n",
    "- **fdr_beta**: Adjusted P-value for p_beta using the Benjamini-Hochberg method (FDR).  \n",
    "- **fdr_perm**: Adjusted P-value for p_perm using the Benjamini-Hochberg method (FDR).  \n",
    "- **p_nominal_threshold**: Nominal p-value threshold for variants in the corresponding molecular trait, derived from empirical beta distribution as a result of permutation testing.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Minimal Working Example Steps\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "The data can be found on [Synapse](https://www.synapse.org/#!Synapse:syn36416559/files/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### i. Cis TensorQTL Command "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sos run pipeline/TensorQTL.ipynb cis \\\n",
    "    --genotype-file output/genotype_by_chrom/wgs.merged.plink_qc.genotype_by_chrom_files.txt \\\n",
    "    --phenotype-file output/phenotype/phenotype_by_chrom/bulk_rnaseq.phenotype_by_chrom_files.txt \\\n",
    "    --covariate-file output/covariate/covariates.wgs.merged.plink_qc.plink_qc.prune.pca.gz \\\n",
    "    --customized-cis-windows reference_data/TAD/TADB_enhanced_cis.bed \\\n",
    "    --cwd output/tensorqtl_cis/ \\\n",
    "    --MAC 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "```\n",
    "INFO: Running \u001b[32mcis_1\u001b[0m: \n",
    "INFO: \u001b[32mcis_1\u001b[0m (index=6) is \u001b[32mcompleted\u001b[0m.\n",
    "INFO: \u001b[32mcis_1\u001b[0m (index=7) is \u001b[32mcompleted\u001b[0m.\n",
    "INFO: \u001b[32mcis_1\u001b[0m (index=3) is \u001b[32mcompleted\u001b[0m.\n",
    "INFO: \u001b[32mcis_1\u001b[0m (index=5) is \u001b[32mcompleted\u001b[0m.\n",
    "INFO: \u001b[32mcis_1\u001b[0m (index=2) is \u001b[32mcompleted\u001b[0m.\n",
    "INFO: \u001b[32mcis_1\u001b[0m (index=1) is \u001b[32mcompleted\u001b[0m.\n",
    "INFO: \u001b[32mcis_1\u001b[0m (index=0) is \u001b[32mcompleted\u001b[0m.\n",
    "INFO: \u001b[32mcis_1\u001b[0m (index=4) is \u001b[32mcompleted\u001b[0m.\n",
    "INFO: \u001b[32mcis_1\u001b[0m (index=11) is \u001b[32mcompleted\u001b[0m.\n",
    "INFO: \u001b[32mcis_1\u001b[0m (index=13) is \u001b[32mcompleted\u001b[0m.\n",
    "INFO: \u001b[32mcis_1\u001b[0m (index=9) is \u001b[32mcompleted\u001b[0m.\n",
    "INFO: \u001b[32mcis_1\u001b[0m (index=8) is \u001b[32mcompleted\u001b[0m.\n",
    "INFO: \u001b[32mcis_1\u001b[0m (index=12) is \u001b[32mcompleted\u001b[0m.\n",
    "INFO: \u001b[32mcis_1\u001b[0m (index=15) is \u001b[32mcompleted\u001b[0m.\n",
    "INFO: \u001b[32mcis_1\u001b[0m (index=10) is \u001b[32mcompleted\u001b[0m.\n",
    "INFO: \u001b[32mcis_1\u001b[0m (index=14) is \u001b[32mcompleted\u001b[0m.\n",
    "INFO: \u001b[32mcis_1\u001b[0m (index=19) is \u001b[32mcompleted\u001b[0m.\n",
    "INFO: \u001b[32mcis_1\u001b[0m (index=17) is \u001b[32mcompleted\u001b[0m.\n",
    "INFO: \u001b[32mcis_1\u001b[0m (index=16) is \u001b[32mcompleted\u001b[0m.\n",
    "INFO: \u001b[32mcis_1\u001b[0m (index=20) is \u001b[32mcompleted\u001b[0m.\n",
    "INFO: \u001b[32mcis_1\u001b[0m (index=21) is \u001b[32mcompleted\u001b[0m.\n",
    "INFO: \u001b[32mcis_1\u001b[0m (index=18) is \u001b[32mcompleted\u001b[0m.\n",
    "INFO: \u001b[32mcis_1\u001b[0m output:   \u001b[32m/restricted/projectnb/xqtl/xqtl_protocol/toy_xqtl_protocol/output/tensorqtl_cis/bulk_rnaseq.chr20.cis_qtl_pairs.20.parquet /restricted/projectnb/xqtl/xqtl_protocol/toy_xqtl_protocol/output/tensorqtl_cis/bulk_rnaseq.chr20_chr20.cis_qtl.pairs.tsv.gz... (66 items in 22 groups)\u001b[0m\n",
    "INFO: Running \u001b[32mcis_2\u001b[0m: \n",
    "INFO: \u001b[32mcis_2\u001b[0m is \u001b[32mcompleted\u001b[0m.\n",
    "INFO: \u001b[32mcis_2\u001b[0m output:   \u001b[32moutput/tensorqtl_cis/bulk_rnaseq.cis_qtl_regional_significance.tsv.gz output/tensorqtl_cis/bulk_rnaseq.cis_qtl_regional_significance.summary.txt\u001b[0m\n",
    "INFO: Workflow cis (ID=wf24d8ec17aef888e) is executed successfully with 2 completed steps and 23 completed substeps.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### ii. Trans TensorQTL Command \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sos run pipeline/TensorQTL.ipynb trans \\\n",
    "    --genotype-file data/wgs.merged.plink_qc.genotype_trans_files.txt \\\n",
    "    --phenotype-file output/phenotype/phenotype_by_chrom_for_trans/bulk_rnaseq.phenotype_by_chrom_files.txt \\\n",
    "    --region-list data/combined_AD_genes.csv \\\n",
    "    --region-list-phenotype-column 4 \\\n",
    "    --covariate-file output/covariate/bulk_rnaseq_tmp_matrix.low_expression_filtered.outlier_removed.tmm.expression.covariates.wgs.merged.plink_qc.plink_qc.prune.pca.Marchenko_PC.gz \\\n",
    "    --cwd output/tensorqtl_trans/ \\\n",
    "    --MAC 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### iii. Interaction TensorQTL Command \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Example 1: Running full iQTL scan in parallel across all chromosomes\n",
    "# If using .txt files for genotype and phenotype input (with no --chromosome specified), the pipeline will run in parallel across all chromosomes.\n",
    "# Note: \"sex\" must be a column in your covariate file; otherwise, replace --interaction with a path to an interaction file.\n",
    "\n",
    "sos run pipeline/TensorQTL.ipynb cis \\\n",
    "    --genotype-file output/genotype_by_chrom/wgs.merged.plink_qc.genotype_by_chrom_files.txt \\\n",
    "    --phenotype-file output/phenotype/phenotype_by_chrom/bulk_rnaseq.phenotype_by_chrom_files.txt \\\n",
    "    --covariate-file output/covariate/covariates.wgs.merged.plink_qc.plink_qc.prune.pca.gz \\\n",
    "    --customized-cis-windows reference_data/TAD/TADB_enhanced_cis.bed \\\n",
    "    --cwd output/tensorqtl_int/ \\\n",
    "    --no-permutation \\\n",
    "    --maf-threshold 0.05 \\\n",
    "    --interaction sex \\\n",
    "    -j 22\n",
    "\n",
    "# Example 2: Run TensorQTL for a specific chromosome\n",
    "sos run pipeline/TensorQTL.ipynb cis \\\n",
    "    --genotype-file output/genotype_by_chrom/wgs.merged.plink_qc.genotype_by_chrom_files.txt \\\n",
    "    --phenotype-file output/phenotype/phenotype_by_chrom/bulk_rnaseq.phenotype_by_chrom_files.txt \\\n",
    "    --covariate-file output/covariate/covariates.wgs.merged.plink_qc.plink_qc.prune.pca.gz \\\n",
    "    --customized-cis-windows reference_data/TAD/TADB_enhanced_cis.bed \\\n",
    "    --cwd output/tensorqtl_int/ \\\n",
    "    --chromosome 21 \\\n",
    "    --no-permutation \\\n",
    "    --maf-threshold 0.05 \\\n",
    "    --interaction sex\n",
    "\n",
    "# Example 3: Run TensorQTL for a single chromosome with specific genotype and phenotype files\n",
    "sos run pipeline/TensorQTL.ipynb cis \\\n",
    "    --genotype-file output/genotype_by_chrom/wgs.merged.plink_qc.21.bed \\\n",
    "    --phenotype-file output/phenotype/phenotype_by_chrom/bulk_rnaseq.chr21.bed.gz \\\n",
    "    --covariate-file output/covariate/covariates.wgs.merged.plink_qc.plink_qc.prune.pca.gz \\\n",
    "    --customized-cis-windows reference_data/TAD/TADB_enhanced_cis.bed \\\n",
    "    --cwd output/tensorqtl_int/ \\\n",
    "    --chromosome 21 \\\n",
    "    --no-permutation \\\n",
    "    --maf-threshold 0.05 \\\n",
    "    --interaction sex \\\n",
    "    -s build\n",
    "\n",
    "# Example 4: Use a specific interaction file instead of an interaction column\n",
    "sos run pipeline/TensorQTL.ipynb cis \\\n",
    "    --genotype-file output/genotype_by_chrom/wgs.merged.plink_qc.21.bed \\\n",
    "    --phenotype-file output/phenotype/phenotype_by_chrom/bulk_rnaseq.chr21.bed.gz \\\n",
    "    --covariate-file output/covariate/covariates.wgs.merged.plink_qc.plink_qc.prune.pca.gz \\\n",
    "    --customized-cis-windows reference_data/TAD/TADB_enhanced_cis.bed \\\n",
    "    --cwd output/tensorqtl_int/ \\\n",
    "    --chromosome 21 \\\n",
    "    --no-permutation \\\n",
    "    --maf-threshold 0.05 \\\n",
    "    --interaction data/ROSMAP_interaction_example.tsv \\\n",
    "    -s build\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "| Step | Substep | Problem | Possible Reason | Solution |\n",
    "|------|---------|---------|------------------|---------|\n",
    "|  |  |  |  |  |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Command Interface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run TensorQTL.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  cis\n",
      "  trans\n",
      "\n",
      "Global Workflow Options:\n",
      "  --cwd output (as path)\n",
      "                        Path to the work directory of the analysis.\n",
      "  --phenotype-file VAL (as path, required)\n",
      "                        Phenotype file, or a list of phenotype per region.\n",
      "  --genotype-file VAL (as path, required)\n",
      "                        A genotype file in PLINK binary format (bed/bam/fam)\n",
      "                        format, or a list of genotype per chrom\n",
      "  --covariate-file VAL (as path, required)\n",
      "                        Covariate file\n",
      "  --name  f\"{phenotype_file:bn}_{covariate_file:bn}\"\n",
      "\n",
      "                        Prefix for the analysis output\n",
      "  --region-list . (as path)\n",
      "                        An optional subset of regions of molecular features to\n",
      "                        analyze. The last column is the gene names\n",
      "  --region-list-phenotype-column 4 (as int)\n",
      "  --keep-sample . (as path)\n",
      "                        Set list of sample to be keep\n",
      "  --interaction ''\n",
      "                        FIXME: please document\n",
      "  --customized-cis-windows . (as path)\n",
      "                        An optional list documenting the custom cis window for\n",
      "                        each region to analyze, with four column, chr, start,\n",
      "                        end, region ID (eg gene ID). If this list is not\n",
      "                        provided, the default `window` parameter (see below)\n",
      "                        will be used.\n",
      "  --phenotype-group . (as path)\n",
      "                        The phenotype group file to group molecule_trait into\n",
      "                        molecule_trait_object This applies to multiple molecular\n",
      "                        events in the same region, such as sQTL analysis.\n",
      "  --chromosome  (as list)\n",
      "                        The name of phenotype corresponding to gene_id or\n",
      "                        gene_name in the region\n",
      "  --MAC 0 (as int)\n",
      "                        Minor allele count cutoff\n",
      "  --window 1000000 (as int)\n",
      "                        Specify the cis window for the up and downstream radius\n",
      "                        to analyze around the region of interest in units of bp\n",
      "                        This parameter will be set to zero if\n",
      "                        `customized_cis_windows` is provided.\n",
      "  --numThreads 8 (as int)\n",
      "                        Number of threads\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "  --walltime 12h\n",
      "  --mem 16G\n",
      "  --container ''\n",
      "                        Container option for software to run the analysis:\n",
      "                        docker or singularity\n",
      "  --entrypoint  ('micromamba run -a \"\" -n' + ' ' + re.sub(r'(_apptainer:latest|_docker:latest|\\.sif)$', '', container.split('/')[-1])) if container else \"\"\n",
      "\n",
      "  --maf-threshold  MAC/(2.0*N) \n",
      "\n",
      "                        Minor allele frequency cutoff. It will overwrite minor\n",
      "                        allele cutoff. You may consider setting it to higher for\n",
      "                        interaction analysis if you have statistical power\n",
      "                        concerns\n",
      "\n",
      "Sections\n",
      "  cis_1:\n",
      "    Workflow Options:\n",
      "      --[no-]skip-nominal-if-exist (default to False)\n",
      "                        parse input file lists skip nominal association results\n",
      "                        if the files exists already This is false by default\n",
      "                        which means to recompute everything This is only\n",
      "                        relevant when the `parquet` files for nominal results\n",
      "                        exist but not the other files and you want to avoid\n",
      "                        computing the nominal results again\n",
      "      --[no-]permutation (default to True)\n",
      "  cis_2:\n",
      "  trans_1:\n",
      "    Workflow Options:\n",
      "      --batch-size 50000 (as int)\n",
      "      --pval-threshold 1.0 (as float)\n",
      "      --[no-]permutation (default to False)\n",
      "                        Permutation testing is incorrect when the analysis is\n",
      "                        done by chrom\n"
     ]
    }
   ],
   "source": [
    "sos run TensorQTL.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## Old Minimal working example\n",
    "\n",
    "An MWE is uploaded to [google drive](https://drive.google.com/drive/folders/1yjTwoO0DYGi-J9ouMsh9fHKfDmsXJ_4I?usp=sharing).\n",
    "The singularity image (sif) for running this MWE is uploaded to [google drive](https://drive.google.com/drive/folders/1mLOS3AVQM8yTaWtCbO8Q3xla98Nr5bZQ)\n",
    "\n",
    "FIXME: need to update these links. \n",
    "\n",
    "FIXME: Also need to update the example commands below using our new example dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/TensorQTL.ipynb cis \\\n",
    "    --genotype-file plink_files_list.txt \\\n",
    "    --phenotype-file MWE.bed.recipe \\\n",
    "    --covariate-file ALL.covariate.pca.BiCV.cov.gz \\\n",
    "    --cwd ./output/ \\\n",
    "    --MAC 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/TensorQTL.ipynb trans \\\n",
    "    --genotype-file plink_files_list.txt \\\n",
    "    --phenotype-file MWE.bed.recipe \\\n",
    "    --covariate-file ALL.covariate.pca.BiCV.cov.gz \\\n",
    "    --cwd ./output/ \\\n",
    "    --MAC 5 --region-name  gene_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Setup and global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Path to the work directory of the analysis.\n",
    "parameter: cwd = path('output')\n",
    "# Phenotype file, or a list of phenotype per region.\n",
    "parameter: phenotype_file = path\n",
    "# A genotype file in PLINK binary format (bed/bam/fam) format, or a list of genotype per chrom\n",
    "parameter: genotype_file = path\n",
    "# Covariate file\n",
    "parameter: covariate_file = path\n",
    "# Optional pattern to filter covariates (list of covariate prefixes or exact names)\n",
    "parameter: covariate_pattern = []\n",
    "# Prefix for the analysis output\n",
    "parameter: name = \"\"\n",
    "# An optional subset of regions of molecular features to analyze. The last column is the gene names\n",
    "parameter: region_list = path()\n",
    "parameter: region_list_phenotype_column = 4\n",
    "# Set list of sample to be keep\n",
    "parameter: keep_sample = path()\n",
    "# FIXME: please document\n",
    "parameter: interaction = \"\"\n",
    "\n",
    "# An optional list documenting the custom cis window for each region to analyze, with four column, chr, start, end, region ID (eg gene ID).\n",
    "# If this list is not provided, the default `window` parameter (see below) will be used.\n",
    "parameter: customized_cis_windows = path()\n",
    "\n",
    "# The phenotype group file to group molecule_trait into molecule_trait_object\n",
    "# This applies to multiple molecular events in the same region, such as sQTL analysis.\n",
    "parameter: phenotype_group = path() \n",
    "\n",
    "# The name of phenotype corresponding to gene_id or gene_name in the region\n",
    "parameter: chromosome = []\n",
    "# Minor allele count cutoff\n",
    "parameter: MAC = 0\n",
    "\n",
    "# Specify the cis window for the up and downstream radius to analyze around the region of interest in units of bp\n",
    "# This parameter will be set to zero if `customized_cis_windows` is provided.\n",
    "parameter: window = 1000000\n",
    "\n",
    "# Number of threads\n",
    "parameter: numThreads = 8\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "parameter: walltime = '12h'\n",
    "parameter: mem = '16G'\n",
    "# Container option for software to run the analysis: docker or singularity\n",
    "parameter: container = ''\n",
    "import re\n",
    "\n",
    "# Use the header of the covariate file to decide the sample size\n",
    "import pandas as pd\n",
    "N = len(pd.read_csv(covariate_file, sep = \"\\t\",nrows = 1).columns) - 1\n",
    "\n",
    "# Minor allele frequency cutoff. It will overwrite minor allele cutoff.\n",
    "# You may consider setting it to higher for interaction analysis if you have statistical power concerns\n",
    "parameter: maf_threshold = MAC/(2.0*N)\n",
    "\n",
    "# Filtering significant trans associations (for trans_2 workflow)\n",
    "parameter: pvalue_cutoff = \"5e-8\"\n",
    "parameter: qvalue_cutoff = \"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def adapt_file_path(file_path, reference_file):\n",
    "    \"\"\"\n",
    "    Adapt a single file path based on its existence and a reference file's path.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): The file path to adapt.\n",
    "    - reference_file (str): File path to use as a reference for adaptation.\n",
    "\n",
    "    Returns:\n",
    "    - str: Adapted file path.\n",
    "\n",
    "    Raises:\n",
    "    - FileNotFoundError: If no valid file path is found.\n",
    "    \"\"\"\n",
    "    reference_path = os.path.dirname(reference_file)\n",
    "\n",
    "    # Check if the file exists\n",
    "    if os.path.isfile(file_path):\n",
    "        return file_path\n",
    "\n",
    "    # Check file name without path\n",
    "    file_name = os.path.basename(file_path)\n",
    "    if os.path.isfile(file_name):\n",
    "        return file_name\n",
    "\n",
    "    # Check file name in reference file's directory\n",
    "    file_in_ref_dir = os.path.join(reference_path, file_name)\n",
    "    if os.path.isfile(file_in_ref_dir):\n",
    "        return file_in_ref_dir\n",
    "\n",
    "    # Check original file path prefixed with reference file's directory\n",
    "    file_prefixed = os.path.join(reference_path, file_path)\n",
    "    if os.path.isfile(file_prefixed):\n",
    "        return file_prefixed\n",
    "\n",
    "    # If all checks fail, raise an error\n",
    "    raise FileNotFoundError(f\"No valid path found for file: {file_path}\")\n",
    "\n",
    "def adapt_file_path_all(df, column_name, reference_file):\n",
    "    return df[column_name].apply(lambda x: adapt_file_path(x, reference_file))\n",
    "\n",
    "\n",
    "if (str(genotype_file).endswith(\"bed\") or str(genotype_file).endswith(\"pgen\")) and str(phenotype_file).endswith(\"bed.gz\"):\n",
    "    input_files = [[phenotype_file, genotype_file]]\n",
    "    if len(chromosome) > 0:\n",
    "        input_chroms = [int(x) for x in chromosome]\n",
    "    else:\n",
    "        input_chroms = [0]\n",
    "else:\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    molecular_pheno_files = pd.read_csv(phenotype_file, sep = \"\\t\")\n",
    "    \n",
    "    if \"#dir\" in molecular_pheno_files.columns and \"#chr\" not in molecular_pheno_files.columns:\n",
    "        molecular_pheno_files = molecular_pheno_files.rename(columns={\"#dir\": \"path\"})\n",
    "        if \"#id\" in molecular_pheno_files.columns:\n",
    "            molecular_pheno_files = molecular_pheno_files.rename(columns={\"#id\": \"#chr\"})\n",
    "    \n",
    "    if \"#chr\" in molecular_pheno_files.columns:\n",
    "        molecular_pheno_files = molecular_pheno_files.groupby(['#chr','path']).size().reset_index(name='count').drop(\"count\",axis = 1).rename(columns = {\"#chr\":\"#id\"})\n",
    "    genotype_files = pd.read_csv(genotype_file,sep = \"\\t\")\n",
    "    genotype_files[\"#id\"] = [x.replace(\"chr\",\"\") for x in genotype_files[\"#id\"].astype(str)] # e.g. remove chr1 to 1\n",
    "    genotype_files[\"#path\"] = genotype_files[\"#path\"].apply(lambda x: adapt_file_path(x, genotype_file))\n",
    "    molecular_pheno_files[\"#id\"] = [x.replace(\"chr\",\"\") for x in molecular_pheno_files[\"#id\"].astype(str)]\n",
    "    input_files = molecular_pheno_files.merge(genotype_files, on = \"#id\")\n",
    "    \n",
    "    # Only keep chromosome specified in --chromosome\n",
    "    if len(chromosome) > 0:\n",
    "        input_files = input_files[input_files['#id'].isin(chromosome)]\n",
    "    input_files = input_files.values.tolist()\n",
    "    input_chroms = [x[0] for x in input_files]\n",
    "    input_files = [x[1:] for x in input_files]\n",
    "    if len(name) == 0:\n",
    "        name = f'{path(input_files[0][0]):bnn}' if len(input_files) == 1 else f'{path(input_files[0][0]):bnnn}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## cis-xQTL association testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[cis_1]\n",
    "# parse input file lists\n",
    "# skip nominal association results if the files exists already\n",
    "# This is false by default which means to recompute everything\n",
    "# This is only relevant when the `parquet` files for nominal results exist but not the other files\n",
    "# and you want to avoid computing the nominal results again\n",
    "parameter: skip_nominal_if_exist = False\n",
    "parameter: permutation = True\n",
    "\n",
    "# Extract interaction name\n",
    "var_interaction = interaction\n",
    "if os.path.isfile(interaction):\n",
    "    interaction_s = pd.read_csv(interaction, sep='\\t', index_col=0)\n",
    "    var_interaction = interaction_s.columns[0] # interaction name\n",
    "test_regional_association = permutation and len(var_interaction) == 0\n",
    "\n",
    "input: input_files, group_by = len(input_files[0]), group_with = \"input_chroms\"\n",
    "output_files = dict([(\"parquet\", f'{cwd:a}/{_input[0]:bnn}{\"_%s\" % var_interaction if interaction else \"\"}.cis_qtl_pairs.{\"\" if input_chroms[_index] == 0 else input_chroms[_index]}.parquet'), # This convention is necessary to match the pattern of map_norminal output\n",
    "                     (\"nominal\", f'{cwd:a}/{_input[0]:bnn}{\"\" if input_chroms[_index] == 0 else \"_chr%s\" % input_chroms[_index]}{\"_%s\" % var_interaction if interaction else \"\"}.cis_qtl.pairs.tsv.gz')])\n",
    "if test_regional_association:\n",
    "    output_files[\"regional\"] = f'{cwd:a}/{_input[0]:bnn}{\"\" if input_chroms[_index] == 0 else \"_chr%s\" % input_chroms[_index]}{\"_%s\" % var_interaction if interaction else \"\"}.cis_qtl.regional.tsv.gz'\n",
    "output: output_files\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[\"nominal\"]:bnnn}'\n",
    "python: expand= \"$[ ]\", stderr = f'{_output[\"nominal\"]:nnn}.stderr', stdout = f'{_output[\"nominal\"]:nnn}.stdout' , container = container\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import tensorqtl\n",
    "    from tensorqtl import genotypeio, cis\n",
    "    from scipy.stats import chi2\n",
    "    import multiprocessing as mp\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    ## Define paths\n",
    "    plink_prefix_path = $[_input[1]:nar]\n",
    "    expression_bed = $[_input[0]:ar]\n",
    "\n",
    "    covariates_file = \"$[covariate_file:a]\"\n",
    "    window = $[window]\n",
    "    interaction = \"$[interaction]\"\n",
    "    ## Load Data\n",
    "    phenotype_df, phenotype_pos_df = tensorqtl.read_phenotype_bed(expression_bed)\n",
    "    phenotype_id = phenotype_pos_df.index.name\n",
    "\n",
    "    ## Analyze only the regions listed\n",
    "    if $[region_list.is_file()]:\n",
    "        region = pd.read_csv(\"$[region_list:a]\", comment=\"#\", header=None, sep=\"\\t\" )\n",
    "        phenotype_column = 1 if len(region.columns) == 1 else  $[region_list_phenotype_column]\n",
    "        keep_region = region.iloc[:,phenotype_column-1].to_list()\n",
    "        phenotype_df = phenotype_df[phenotype_df.index.isin(keep_region)]\n",
    "        phenotype_pos_df = phenotype_pos_df[phenotype_pos_df.index.isin(keep_region)]\n",
    "    covariates_df = pd.read_csv(covariates_file, sep='\\t', index_col=0).T\n",
    "    genotype_df, variant_df = genotypeio.load_genotypes(plink_prefix_path, dosages = True)\n",
    "\n",
    "    \n",
    "    ## use custom sample list to subset the covariates data\n",
    "    if $[keep_sample.is_file()]:\n",
    "        sample_list = pd.read_csv(\"$[keep_sample:a]\", comment=\"#\", header=None, names=[\"sample_id\"], sep=\"\\t\")\n",
    "        covariates_df.loc[sample_list.sample_id]\n",
    "\n",
    "    # Read interaction files or extract from covariates file.\n",
    "    var_interaction = interaction\n",
    "    interaction_s = []\n",
    "    if os.path.isfile(interaction):\n",
    "        # update var_interaction and interaction_s\n",
    "        interaction_s = pd.read_csv(interaction, sep='\\t', index_col=0)\n",
    "        interaction_s = interaction_s[interaction_s.index.isin(covariates_df.index)] \n",
    "        var_interaction = interaction_s.columns[0] # interaction name\n",
    "    # check if the interaction term in interaction table is in covariates file, if yes and interaction_s not yet loaded then, extract it out from covariates file\n",
    "    if var_interaction in covariates_df.columns:\n",
    "        # only load from covariate if it has not been loaded yet\n",
    "        if len(interaction_s) == 0:\n",
    "            interaction_s = covariates_df[var_interaction].to_frame()\n",
    "        covariates_df = covariates_df.drop(columns=[var_interaction])\n",
    "    if len(interaction) and len(interaction_s) == 0:\n",
    "        raise ValueError(f\"Cannot find interaction variable or file {interaction}\")\n",
    "\n",
    "    # drop samples that with missing value in iteraction\n",
    "    if len(interaction_s):\n",
    "        interaction_s = interaction_s.dropna() \n",
    "\n",
    "    ## Retaining only common samples\n",
    "    phenotype_df = phenotype_df[np.intersect1d(phenotype_df.columns, covariates_df.index)]\n",
    "    phenotype_df = phenotype_df[np.intersect1d(phenotype_df.columns, genotype_df.columns)] \n",
    "\n",
    "    if len(interaction_s):\n",
    "        phenotype_df = phenotype_df[np.intersect1d(phenotype_df.columns, interaction_s.index)]\n",
    "        interaction_s = interaction_s[interaction_s.index.isin(phenotype_df.columns)]    \n",
    "        interaction_s = interaction_s.loc[phenotype_df.columns]\n",
    "\n",
    "    covariates_df = covariates_df.transpose()[np.intersect1d(phenotype_df.columns, covariates_df.index)].transpose()\n",
    "    \n",
    "    ## To simplify things, there should really not be \"chr\" prefix\n",
    "    phenotype_pos_df.chr = phenotype_pos_df.chr.astype(str).str.replace(\"chr\", \"\")\n",
    "    variant_df.chrom =  variant_df.chrom.astype(\"str\").str.replace(\"chr\", \"\") \n",
    "\n",
    "    ## use custom cis windows list\n",
    "    if $[customized_cis_windows.is_file()]:\n",
    "        cis_list = pd.read_csv(\"$[customized_cis_windows:a]\", comment=\"#\", header=None, names=[\"chr\",\"start\",\"end\",phenotype_id], sep=\"\\t\")\n",
    "        cis_list.chr = cis_list.chr.astype(str).str.replace(\"chr\", \"\")  ## Again to simplify things for chr format concordance.\n",
    "        if cis_list[['chr', 'ID']].duplicated().sum() != 0: # if cis_list is not unique using identifier ['#chr', 'ID']\n",
    "                cis_list = cis_list.groupby(['ID', 'chr']).agg({ # use union start-end position and make cis_list unique\n",
    "                    'start': 'min',\n",
    "                    'end': 'max'\n",
    "                }).reset_index()\n",
    "\n",
    "                cis_list = cis_list[['chr', 'start', 'end', 'ID']]\n",
    "                #cis_list = cis_list.set_index('chr')\n",
    "        \n",
    "        phenotype_pos_df = phenotype_pos_df.reset_index() #move the phenotype id index to a new column of the dataframe\n",
    "        phenotype_df = phenotype_df.reset_index()\n",
    "        # Ensure phenotype_pos_df is a subset of cis_list based on ['#chr', 'ID']\n",
    "        original_count = len(phenotype_pos_df)\n",
    "        phenotype_pos_df = phenotype_pos_df[phenotype_pos_df.set_index(['chr', 'ID']).index.isin(cis_list.set_index([cis_list.columns[0],cis_list.columns[3]]).index)] \n",
    "        phenotype_df = phenotype_df[phenotype_df.set_index('ID').index.isin(cis_list.set_index(cis_list.columns[3]).index)] \n",
    "        phenotype_df = phenotype_df.set_index('ID')\n",
    "        removed_count = original_count - len(phenotype_pos_df)\n",
    "        print(f\"{removed_count} rows were removed from phenotype_pos_df\")\n",
    "\n",
    "        # Merge the dataframes on 'chr' and 'ID', including 'start' and 'end'\n",
    "        phenotype_pos_df = phenotype_pos_df.merge(cis_list[['chr', 'ID', 'start', 'end']], \n",
    "                                        left_on = [\"chr\",phenotype_id],\n",
    "                                        right_on = [cis_list.columns[0],cis_list.columns[3]],\n",
    "                                        suffixes=('_pheno', ''))\n",
    "\n",
    "        # Function to decide whether to keep or rename columns: \n",
    "        # If 'start' and 'end' values are the same in both dataframes, we keep the original columns without suffixes; \n",
    "        # If they're different, we name columns from cis_list with '_cis' suffixes and keep the name still for columns from phentype_pos_df.\n",
    "        # #in some cases (gene expression for eQTLs) the phenotype_id may be in the cis_list file\n",
    "        def rename_if_different(row, col):\n",
    "            if row[f'{col}'] == row[f'{col}_pheno']:\n",
    "                return row[col]\n",
    "            else:\n",
    "                return pd.Series({f'{col}_pheno': row[f'{col}_pheno'], f'{col}_cis': row[col]})\n",
    "        \n",
    "        # Apply the renaming logic\n",
    "        for col in ['start', 'end']:\n",
    "            if f'{col}_pheno' in phenotype_pos_df.columns:# this condition is to not execute when the original phenotype_pos_df don't have start, end but pos column.\n",
    "                temp = phenotype_pos_df.apply(lambda row: rename_if_different(row, col), axis=1)\n",
    "                phenotype_pos_df = phenotype_pos_df.drop(columns=[f'{col}_pheno']).join(temp)\n",
    "                print(f\"Dropped columns due to value mismatch: {col}_pheno\")\n",
    "        \n",
    "        phenotype_pos_df = phenotype_pos_df.set_index(phenotype_id)[[\"chr\",\"start\",\"end\"]] # The final phenotype_pos_df will have three columns(chr, start, end) and index is the phenotype ID\n",
    "        \n",
    "        if len(phenotype_df.index) != len(phenotype_pos_df.index):\n",
    "            raise ValueError(\"cannot uniquely match all the phentoype data in the input to the customized cis windows provided\")\n",
    "        window = 0 # In the updated tensorQTL, by default if there is a customized cis window, the actual cis window will be start - window & end + window, so it is necessary to change the window parameter to 0\n",
    "\n",
    "    ## Read phenotype group if availble\n",
    "    if $[phenotype_group.is_file()]:\n",
    "        group_s = pd.read_csv($[phenotype_group:r], sep='\\t', header=None, index_col=0).squeeze()\n",
    "    else:\n",
    "        group_s = None\n",
    "\n",
    "    ## cis-QTL mapping: nominal associations for all variant-phenotype pairs\n",
    "    if not ($[skip_nominal_if_exist] and $[_output[\"parquet\"].is_file()]):\n",
    "        if len(interaction_s):\n",
    "            cis.map_nominal(genotype_df, variant_df, \n",
    "                    phenotype_df, \n",
    "                    phenotype_pos_df, \n",
    "                    $[_output[\"parquet\"]:nnnr],\n",
    "                    covariates_df=covariates_df,\n",
    "                    interaction_df=interaction_s, \n",
    "                    maf_threshold_interaction=$[maf_threshold],\n",
    "                    window=window,\n",
    "                    group_s=group_s,\n",
    "                    run_eigenmt=True)\n",
    "        else:\n",
    "            cis.map_nominal(genotype_df, variant_df,\n",
    "                phenotype_df,\n",
    "                phenotype_pos_df,\n",
    "                $[_output[\"parquet\"]:nnnr],\n",
    "                covariates_df=covariates_df, \n",
    "                window=window, \n",
    "                maf_threshold=$[maf_threshold],\n",
    "                run_eigenmt=$['False' if permutation else 'True'],\n",
    "                group_s=group_s)\n",
    "\n",
    "    ## Load the parquet and save it as txt\n",
    "    pairs_df = pd.read_parquet($[_output[\"parquet\"]:r])\n",
    "    ## Remove rows whose 'pval_gi' is null for following t_pval_conversion\n",
    "    if len(interaction_s):\n",
    "        pairs_df = pairs_df.dropna(subset=['pval_gi'])\n",
    "    # print general information of parquet\n",
    "    print('Output Information:')\n",
    "    print(\"This is the file containing the immediate output of TensorQTL's map_nominal function \")\n",
    "    print(os.path.getsize($[_output[\"parquet\"]:r]))\n",
    "\n",
    "    ## Adds the group columns to pairs_df, if there is group_s use group_s, else use phenotype_id\n",
    "    if group_s is not None:\n",
    "        pairs_df = pairs_df.merge(pd.DataFrame( {\"molecular_trait_object_id\": group_s}),left_on = \"phenotype_id\", right_index = True)\n",
    "    else:\n",
    "        pairs_df[\"molecular_trait_object_id\"] = pairs_df.phenotype_id\n",
    "    ## if pos in phenotype_pos_df(start distance and end distance are the same), \n",
    "    ## add the column 'end_distance' with the same value as 'start_distance' to avoid mismatch of column and names\n",
    "    if 'end_distance' not in pairs_df.columns:\n",
    "        # Get the position of 'start_distance' column\n",
    "        start_pos = pairs_df.columns.get_loc('start_distance')\n",
    "        # Create a new DataFrame with the same values as start_distance\n",
    "        new_df = pairs_df.copy()\n",
    "        # Insert end_distance column after start_distance\n",
    "        new_df.insert(start_pos + 1, 'end_distance', pairs_df['start_distance'])\n",
    "        pairs_df = new_df\n",
    "\n",
    "    # rename columns\n",
    "    column_map = {'phenotype_id': 'molecular_trait_id'}\n",
    "   \n",
    "    if len(interaction_s):\n",
    "        # calculate genomic inflation factor lambda on interaction \n",
    "        lambda_col_interaction = pairs_df.groupby(\"molecular_trait_object_id\").apply(lambda x: chi2.ppf(1. - np.median(x.pval_gi), 1)/chi2.ppf(0.5,1))\n",
    "        column_map.update({\n",
    "            'pval_g': 'pvalue', 'b_g': 'bhat', 'b_g_se': 'se',\n",
    "            'pval_i': f'pvalue_{var_interaction}',\n",
    "            'b_i': f'bhat_{var_interaction}',\n",
    "            'b_i_se': f'sebhat_{var_interaction}',\n",
    "            'pval_gi': f'pvalue_{var_interaction}_interaction',\n",
    "            'b_gi': f'bhat_{var_interaction}_interaction',\n",
    "            'b_gi_se': f'sebhat_{var_interaction}_interaction'\n",
    "        })\n",
    "    else:\n",
    "        column_map.update({'pval_nominal': 'pvalue', 'slope': 'bhat', 'slope_se': 'sebhat'})\n",
    "    if $[customized_cis_windows.is_file()]:\n",
    "        column_map.update({'start_distance': 'cis_window_start_distance', 'end_distance': 'cis_window_end_distance'})\n",
    "    else:\n",
    "        column_map.update({'start_distance': 'tss_distance', 'end_distance': 'tes_distance'})\n",
    "    pairs_df.rename(columns=column_map, inplace=True)\n",
    "    pairs_df[\"n\"] = len(phenotype_df.columns.values)\n",
    "    pairs_df = variant_df.merge(pairs_df, right_on='variant_id', left_index=True)\n",
    "    pairs_df.rename(columns={'a1': 'a2', 'a0': 'a1'}, inplace=True)\n",
    "    # sort the table if chrom and pos is not in ascending order\n",
    "    if not all(pairs_df['pos'].iloc[i] <= pairs_df['pos'].iloc[i+1] for i in range(len(pairs_df)-1)):\n",
    "        pairs_df = pairs_df.sort_values(by=['chrom', 'pos'])\n",
    "    # save file\n",
    "    pairs_df.to_csv($[_output[\"nominal\"]:nr], sep='\\t', index = None)\n",
    "    # print general information of pairs_df\n",
    "    print('Output Information:')\n",
    "    print(\"Output Rows:\", len(pairs_df))\n",
    "    print(\"Output Columns:\", pairs_df.columns.tolist())\n",
    "    print(\"Output Preview:\", pairs_df.iloc[1:5, 1:10])\n",
    "\n",
    "    if $[test_regional_association]:\n",
    "        # calculate genomic inflation factor lambda for main variant effect \n",
    "        lambda_col = pairs_df.groupby(\"molecular_trait_object_id\").apply(lambda x: chi2.ppf(1. - np.median(x.pvalue), 1)/chi2.ppf(0.5,1))\n",
    "        cis_df = cis.map_cis(genotype_df, \n",
    "                            variant_df, \n",
    "                            phenotype_df,\n",
    "                            phenotype_pos_df,\n",
    "                            covariates_df=covariates_df, \n",
    "                            seed=999, \n",
    "                            window=window, \n",
    "                            maf_threshold = $[maf_threshold],\n",
    "                            group_s=group_s)\n",
    "        cis_df.index.name = \"molecular_trait_id\"\n",
    "        ## Add groups columns for eQTL analysis\n",
    "        if \"group_id\" not in cis_df.columns:\n",
    "            cis_df[\"group_id\"] = cis_df.index\n",
    "            cis_df[\"group_size\"] = 1\n",
    "        cis_df.rename(columns={\"group_id\": \"molecular_trait_object_id\", \"group_size\": \"n_traits\", \n",
    "                        'start_distance': 'tss_distance', 'end_distance': 'tes_distance',\n",
    "                        \"num_var\": \"n_variants\", \"pval_nominal\": \"p_nominal\", \n",
    "                        'slope': 'bhat', 'slope_se': 'sebhat',\n",
    "                        \"pval_true_df\": \"p_true_df\", \"pval_perm\": \"p_perm\", \"pval_beta\": \"p_beta\"}, inplace = True)\n",
    "        cis_df = cis_df.assign(genomic_inflation = lambda dataframe : dataframe[\"molecular_trait_object_id\"].map(lambda molecular_trait_object_id:lambda_col[molecular_trait_object_id]))\n",
    "        # merge cis_df with variant_df\n",
    "        cis_df = variant_df.merge(cis_df, right_on='variant_id', left_index=True)\n",
    "        cis_df.rename(columns={'a1': 'a2', 'a0': 'a1'}, inplace=True)\n",
    "        # sort the table if chrom and pos is not in ascending order\n",
    "        if not all(cis_df['pos'].iloc[i] <= cis_df['pos'].iloc[i+1] for i in range(len(cis_df)-1)):\n",
    "            cis_df = cis_df.sort_values(by=['chrom', 'pos'])\n",
    "        # save file\n",
    "        cis_df.to_csv(str($[_output[\"nominal\"]:nnnr])+str('.regional.tsv'), sep='\\t', index = None)\n",
    "        # print general information of cis_df\n",
    "        print('Output Information:')\n",
    "        print(\"Output Rows:\", len(cis_df))\n",
    "        print(\"Output Columns:\", cis_df.columns.tolist())\n",
    "        print(\"Output Preview:\", cis_df.iloc[0:5, 0:10])\n",
    "\n",
    "R: expand= \"$[ ]\", stderr = f'{_output[\"nominal\"]:nnn}.stderr', stdout = f'{_output[\"nominal\"]:nnn}.stdout', container = container\n",
    "    library(purrr)\n",
    "    library(tidyr)\n",
    "    library(readr)\n",
    "    library(dplyr)\n",
    "    library(qvalue)\n",
    "  \n",
    "    pairs_df = read_delim($[_output[\"nominal\"]:nr,], delim = '\\t')\n",
    "    compute_qvalues <- function(pvalues) {\n",
    "        tryCatch({\n",
    "            if(length(pvalues) < 2) {\n",
    "                return(pvalues)\n",
    "            } else {\n",
    "                return(qvalue(pvalues)$qvalues)\n",
    "            }\n",
    "        }, error = function(e) {\n",
    "            message(\"Too few p-values to calculate qvalue, fall back to BH\")\n",
    "            qvalue(pvalues, pi0 = 1)$qvalues\n",
    "        })\n",
    "    }\n",
    "    \n",
    "    var_interaction <- \"$[interaction]\"\n",
    "    # Check if 'interaction' is a file\n",
    "    if (file.exists(var_interaction)) {\n",
    "        # Read the file into 'interaction_s' dataframe\n",
    "        interaction_s <- read.delim(var_interaction, row.names = 1)\n",
    "        # Update 'var_interaction' to the first column name of 'interaction_s'\n",
    "        var_interaction <- names(interaction_s)[1]\n",
    "    }\n",
    "\n",
    "    if (is.null(var_interaction) || var_interaction == \"\") {\n",
    "        pairs_df = pairs_df %>% group_by(molecular_trait_id) %>% mutate(qvalue = compute_qvalues(pvalue))\n",
    "    } else {\n",
    "        pairs_df = pairs_df %>% group_by(molecular_trait_id) %>% mutate(qvalue_main = compute_qvalues(pvalue), qvalue_interaction = compute_qvalues($[\"pvalue_%s_interaction\" % var_interaction]))         \n",
    "    }\n",
    "\n",
    "    pairs_df %>% write_delim($[_output[\"nominal\"]:nr],\"\\t\")\n",
    "  \n",
    "bash: expand= \"$[ ]\", stderr = f'{_output[\"nominal\"]:nnn}.stderr', stdout = f'{_output[\"nominal\"]:nnn}.stdout', container = container\n",
    "        bgzip --compress-level 9 $[_output[\"nominal\"]:n] \n",
    "        tabix -S 1 -s 1 -b 2 -e 2 $[_output[\"nominal\"]]\n",
    "\n",
    "done_if(not test_regional_association)\n",
    "\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output[\"nominal\"]:nnn}.stderr', stdout = f'{_output[\"nominal\"]:nnn}.stdout', container = container\n",
    "        bgzip --compress-level 9 $[_output[\"nominal\"]:nnn].regional.tsv\n",
    "        tabix -S 1 -s 1 -b 2 -e 2 $[_output[\"nominal\"]:nnn].regional.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[cis_2]\n",
    "done_if(\"regional\" not in _input.labels)\n",
    "input: group_by = \"all\"\n",
    "output_file_prefix = name if len(_input[\"nominal\"]) > 1 else f'{_input[\"nominal\"][0]:bnnnn}'\n",
    "output: f'{cwd}/{output_file_prefix}.cis_qtl_regional_significance.tsv.gz',\n",
    "        f'{cwd}/{output_file_prefix}.cis_qtl_regional_significance.summary.txt'\n",
    "input_files = [str(x) for x in _input[\"regional\"]]\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand= \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',container = container\n",
    "    library(\"purrr\")\n",
    "    library(\"tidyr\")\n",
    "    library(\"dplyr\")\n",
    "    library(\"readr\")\n",
    "    library(\"qvalue\")\n",
    "    emprical_pd = tibble(map(c($[_input[\"regional\"]:r,]), ~read_delim(.x,\"\\t\")))%>%unnest()\n",
    "    emprical_pd[\"q_beta\"] = tryCatch(qvalue(emprical_pd$p_beta)$qvalue, error = function(e){print(\"Too few pvalue to calculate qvalue, fall back to BH\") \n",
    "                                                                                              qvalue(emprical_pd$p_beta,pi0 = 1 )$qvalue})  \n",
    "\n",
    "    emprical_pd[\"q_perm\"] = tryCatch(qvalue(emprical_pd$p_perm)$qvalue, error = function(e){print(\"Too few pvalue to calculate qvalue, fall back to BH\") \n",
    "                                                                                              qvalue(emprical_pd$p_perm,pi0 = 1 )$qvalue})\n",
    "    emprical_pd[\"fdr_beta\"] = p.adjust(emprical_pd$p_beta,\"fdr\")    \n",
    "    emprical_pd[\"fdr_perm\"] = p.adjust(emprical_pd$p_perm,\"fdr\")   \n",
    "\n",
    "\n",
    "    # Calculate the global nominal p-value threshold based on q_beta at FDR 0.05\n",
    "    if (!all(is.na(emprical_pd$p_beta))) {\n",
    "      lb <- emprical_pd %>% \n",
    "        filter(q_beta <= 0.05) %>% \n",
    "        pull(p_beta) %>% \n",
    "        sort()\n",
    "      \n",
    "      ub <- emprical_pd %>% \n",
    "        filter(q_beta > 0.05) %>% \n",
    "        pull(p_beta) %>% \n",
    "        sort()\n",
    "      \n",
    "      if (length(lb) > 0) {\n",
    "        lb_val <- tail(lb, 1)\n",
    "        threshold <- if (length(ub) > 0) (lb_val + head(ub, 1)) / 2 else lb_val\n",
    "        message(sprintf(\"min p-value threshold @ FDR 0.05: %g\", threshold))\n",
    "        \n",
    "        emprical_pd <- emprical_pd %>% \n",
    "          mutate(p_nominal_threshold = qbeta(threshold, beta_shape1, beta_shape2))\n",
    "      }\n",
    "    }\n",
    "\n",
    "    summary = tibble(\"fdr_perm_0.05\" =  sum(emprical_pd[\"fdr_perm\"] < 0.05), \n",
    "                      \"fdr_beta_0.05\" = sum(emprical_pd[\"fdr_beta\"] < 0.05),\n",
    "                      \"q_perm_0.05\" = sum(emprical_pd[\"q_perm\"] < 0.05),\n",
    "                      \"q_beta_0.05\" = sum(emprical_pd[\"q_beta\"] < 0.05),\n",
    "                      \"fdr_perm_0.01\" =  sum(emprical_pd[\"fdr_perm\"] < 0.01), \n",
    "                      \"fdr_beta_0.01\" = sum(emprical_pd[\"fdr_beta\"] < 0.01),\n",
    "                      \"q_perm_0.01\" = sum(emprical_pd[\"q_perm\"] < 0.01),\n",
    "                      \"q_beta_0.01\" = sum(emprical_pd[\"q_beta\"] < 0.01)  )\n",
    "    emprical_pd%>%write_delim(\"$[_output[0]]\",\"\\t\")\n",
    "    summary%>%write_delim(\"$[_output[1]]\",\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Trans-xQTL association testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "For transQTL analysis, if you output all the p-values for many genes (default setting) it is suggested to provide the largest memory and CPU threads available on a compute node. eg 250G and >32 threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[trans]\n",
    "\n",
    "parameter: batch_size = 10000\n",
    "parameter: pval_threshold = 1.0\n",
    "# Permutation testing is incorrect when the analysis is done by chrom\n",
    "parameter: permutation = False\n",
    "parameter: pval = 0.0\n",
    "\n",
    "input: input_files, group_by = len(input_files[0]), group_with = \"input_chroms\"\n",
    "output: nominal = f'{cwd:a}/{_input[0]:bnn}{\"_%s\" % input_chroms[_index] if input_chroms[_index] != 0 else \"\"}.trans_qtl{\"_p_%.0e\" % pval if pval > 0.0 else \"\"}.pairs.tsv.gz'\n",
    "\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "python: expand= \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',container =container\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import tensorqtl\n",
    "    from tensorqtl import genotypeio, trans\n",
    "    from scipy.stats import chi2\n",
    "    import gc\n",
    "    import os\n",
    "    from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "    ## Define paths\n",
    "    plink_prefix_path = $[_input[1]:nar]\n",
    "    expression_bed = $[_input[0]:ar]\n",
    "    covariates_file = \"$[covariate_file:a]\"\n",
    "    window = $[window]\n",
    "    current_chrom = \"$[input_chroms[_index]]\" if \"$[input_chroms[_index]]\" != \"0\" else None\n",
    "    \n",
    "    print(f\"Processing with output name: {current_chrom}\")\n",
    "    phenotype_df, phenotype_pos_df = tensorqtl.read_phenotype_bed(expression_bed)\n",
    "    phenotype_id = phenotype_pos_df.index.name\n",
    "\n",
    "\n",
    "    ## Analyze only the regions listed\n",
    "    if $[region_list.is_file()]:\n",
    "        region = pd.read_csv(\"$[region_list:a]\")\n",
    "        phenotype_column = 1 if len(region.columns) == 1 else $[region_list_phenotype_column]\n",
    "        keep_region = region.iloc[:, phenotype_column-1].astype(str).str.strip().to_list()\n",
    "        phenotype_df = phenotype_df[phenotype_df.index.isin(keep_region)]\n",
    "        phenotype_pos_df = phenotype_pos_df[phenotype_pos_df.index.isin(keep_region)]\n",
    "\n",
    "\n",
    "    ## use custom cis windows\n",
    "    if $[customized_cis_windows.is_file()]:\n",
    "        cis_list = pd.read_csv(\"$[customized_cis_windows:a]\", comment=\"#\", header=None, names=[\"chr\",\"start\",\"end\",phenotype_id], sep=\"\\t\")\n",
    "        phenotype_pos_df_reset = phenotype_pos_df.reset_index()\n",
    "        phenotype_pos_df = phenotype_pos_df_reset.merge(cis_list, left_on=[\"chr\",phenotype_id], right_on=[cis_list.columns[0],cis_list.columns[3]])\n",
    "        if len(phenotype_df.index) - phenotype_pos_df_reset[~phenotype_pos_df_reset[phenotype_id].isin(cis_list[phenotype_id])].shape[0]!= len(phenotype_pos_df.index):\n",
    "            raise ValueError(\"cannot uniquely match all the phentoype data in the input to the customized cis windows provided\")\n",
    "        phenotype_pos_df = phenotype_pos_df.set_index(phenotype_id)[[\"chr\",\"start\",\"end\"]]\n",
    "        window = 0\n",
    "        if phenotype_pos_df_reset[~phenotype_pos_df_reset[phenotype_id].isin(cis_list[phenotype_id])].shape[0] != 0:\n",
    "            phenotype_df = phenotype_df.loc[phenotype_df.index.isin(cis_list[phenotype_id])]\n",
    "\n",
    "    covariates_df = pd.read_csv(covariates_file, sep='\\t', index_col=0).T\n",
    "\n",
    "\n",
    "    ## Filter covariates based on covariate_pattern if provided\n",
    "    covariate_pattern_list = $[covariate_pattern]\n",
    "    if covariate_pattern_list:\n",
    "        print(f\"Filtering covariates using pattern: {covariate_pattern_list}\")\n",
    "        pattern_mapping = {\n",
    "            \"pheno_PC\": [\"Hidden_Factor_PC\"],  # Map pheno_PC to columns starting with Hidden_Factor_PC\n",
    "            \"geno_PC\": [\"PC\"]                 # Map geno_PC to columns starting with PC\n",
    "        }\n",
    "        \n",
    "        keep_cols = []\n",
    "        for col in covariates_df.columns:\n",
    "            if col in covariate_pattern_list:\n",
    "                keep_cols.append(col)\n",
    "                continue\n",
    "        \n",
    "            for pattern in covariate_pattern_list:\n",
    "                if pattern in pattern_mapping:\n",
    "                    # For special patterns like pheno_PC and geno_PC, check their mappings\n",
    "                    for mapped_pattern in pattern_mapping[pattern]:\n",
    "                        if col.startswith(mapped_pattern):\n",
    "                            keep_cols.append(col)\n",
    "                            break\n",
    "        \n",
    "        if not keep_cols:\n",
    "            print(\"Warning: No covariate columns match the provided pattern!\")\n",
    "        else:\n",
    "            print(f\"Keeping {len(keep_cols)} covariates: {keep_cols}\")\n",
    "            covariates_df = covariates_df[keep_cols]\n",
    "       \n",
    "\n",
    "    genotype_df, variant_df = genotypeio.load_genotypes(plink_prefix_path, dosages = True) \n",
    "    ## use custom sample list to subset the covariates data\n",
    "    if $[keep_sample.is_file()]:\n",
    "        sample_list = pd.read_csv(\"$[keep_sample:a]\", comment=\"#\", header=None, names=[\"sample_id\"], sep=\"\\t\")\n",
    "        covariates_df = covariates_df.loc[sample_list.sample_id]\n",
    "\n",
    "    ## Retaining only common samples\n",
    "    phenotype_df = phenotype_df[np.intersect1d(phenotype_df.columns, covariates_df.index)]\n",
    "    phenotype_df = phenotype_df[np.intersect1d(phenotype_df.columns, genotype_df.columns)] \n",
    "    covariates_df = covariates_df.transpose()[np.intersect1d(phenotype_df.columns, covariates_df.index)].transpose()\n",
    "    pr = genotypeio.PlinkReader(plink_prefix_path)\n",
    "    bim_df = pr.bim\n",
    "    bim_df['chrom'] = bim_df['chrom'].str.replace(\"chr\", \"\")\n",
    "\n",
    "    \n",
    "    ## Get all chromosomes from genotype and phenotype data\n",
    "    ## To simplify things, there should really not be \"chr\" prefix \n",
    "    phenotype_pos_df.chr = phenotype_pos_df.chr.astype(str).str.replace(\"chr\", \"\")\n",
    "    variant_df.chrom = variant_df.chrom.astype(\"str\").str.replace(\"chr\", \"\") \n",
    "    \n",
    "    pheno_chroms = sorted(phenotype_pos_df.chr.unique().tolist())\n",
    "    print(f\"Phenotype data contains chromosomes: {pheno_chroms}\")\n",
    "\n",
    "    geno_chroms = sorted(variant_df.chrom.unique().tolist())\n",
    "    print(f\"Genotype data contains chromosomes: {geno_chroms}\")\n",
    "\n",
    "    # If current chromosome specified, only process that phenotype chromosome\n",
    "    if current_chrom and current_chrom in pheno_chroms:\n",
    "        pheno_chroms_to_process = [current_chrom]\n",
    "        print(f\"Processing only phenotype chromosome: {current_chrom}\")\n",
    "    else:\n",
    "        pheno_chroms_to_process = pheno_chroms\n",
    "        print(f\"Processing all phenotype chromosomes: {pheno_chroms_to_process}\")\n",
    "    \n",
    "    # Determine genotype chromosomes to process\n",
    "    geno_chroms_to_process = geno_chroms\n",
    "    print(f\"Processing all genotype chromosomes: {geno_chroms_to_process}\")\n",
    "    \n",
    "    # Calculate total combinations\n",
    "    total_combinations = len(pheno_chroms_to_process) * len(geno_chroms_to_process)\n",
    "    print(f\"Total combinations to process: {total_combinations}\")\n",
    "    all_results = []\n",
    "    \n",
    "\n",
    "    # Process each combination\n",
    "    combination_count = 0\n",
    "    for pheno_chrom in pheno_chroms_to_process:\n",
    "        # Filter phenotype data to keep only current chromosome\n",
    "        phenotype_pos_df_filtered = phenotype_pos_df[phenotype_pos_df.chr == pheno_chrom]\n",
    "        phenotype_df_filtered = phenotype_df[phenotype_df.index.isin(phenotype_pos_df_filtered.index)]\n",
    "        \n",
    "        print(f\"Filtered phenotypes for chromosome {pheno_chrom}: {len(phenotype_df_filtered)} remaining\")\n",
    "        \n",
    "        if len(phenotype_df_filtered) == 0:\n",
    "            print(f\"No phenotypes found for chromosome {pheno_chrom}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        for geno_chrom in geno_chroms_to_process:\n",
    "            combination_count += 1\n",
    "            print(f\"Processing combination {combination_count}/{total_combinations}: phenotype chr{pheno_chrom} x genotype chr{geno_chrom}\")\n",
    "            \n",
    "            # Filter genotype data to keep only current chromosome\n",
    "            chrom_variants = variant_df[variant_df.chrom == geno_chrom].index.tolist()\n",
    "            \n",
    "            if len(chrom_variants) == 0:\n",
    "                print(f\"No variants found for chromosome {geno_chrom}, skipping\")\n",
    "                continue\n",
    "            \n",
    "            # Load genotype data\n",
    "            print(f\"Loading genotypes for chromosome {geno_chrom}...\")\n",
    "            genotype_df = pr.load_genotypes()\n",
    "            variant_df = bim_df.set_index('snp')[['chrom', 'pos', 'a0', 'a1']]\n",
    "            \n",
    "            # Keep only current chromosome variants\n",
    "            genotype_df_chr = genotype_df.loc[chrom_variants]\n",
    "            variant_df_chr = variant_df.loc[chrom_variants]\n",
    "\n",
    "            del genotype_df\n",
    "            gc.collect()\n",
    "            # Find common samples\n",
    "            common_samples = np.intersect1d(phenotype_df_filtered.columns, genotype_df_chr.columns)\n",
    "            common_samples = np.intersect1d(common_samples, covariates_df.index)\n",
    "            \n",
    "            if len(common_samples) == 0:\n",
    "                print(f\"No common samples between phenotypes, genotypes, and covariates, skipping\")\n",
    "                del genotype_df_chr\n",
    "                gc.collect()\n",
    "                continue\n",
    "            \n",
    "            phenotype_df_final = phenotype_df_filtered[common_samples]\n",
    "            genotype_df_final = genotype_df_chr[common_samples]\n",
    "            covariates_df_final = covariates_df.loc[common_samples]\n",
    "            \n",
    "            print(f\"Final analysis dimensions:\")\n",
    "            print(f\"  Samples: {len(common_samples)}\")\n",
    "            print(f\"  Phenotypes: {len(phenotype_df_final)}\")\n",
    "            print(f\"  Variants: {len(genotype_df_final)}\")\n",
    "            \n",
    "            # Trans analysis\n",
    "            print(f\"Running trans analysis for pheno chr{pheno_chrom} x geno chr{geno_chrom}...\")\n",
    "            try:\n",
    "                trans_df = trans.map_trans(genotype_df_final, \n",
    "                                        phenotype_df_final,\n",
    "                                        covariates_df_final, \n",
    "                                        batch_size=$[batch_size],\n",
    "                                        return_sparse=True, \n",
    "                                        return_r2=True,\n",
    "                                        pval_threshold=$[pval_threshold], \n",
    "                                        maf_threshold=$[maf_threshold])\n",
    "                \n",
    "                del genotype_df_chr, genotype_df_final\n",
    "                gc.collect()\n",
    "\n",
    "                # Filter out cis signal\n",
    "                if trans_df is not None and not trans_df.empty:\n",
    "                    print(f\"Filtering cis signals...\")\n",
    "                    trans_df = trans.filter_cis(trans_df, phenotype_pos_df_filtered, variant_df_chr, window=window)\n",
    "\n",
    "                    if trans_df is not None and not trans_df.empty:\n",
    "                        print(f\"Found {len(trans_df)} trans-QTLs\")\n",
    "                        trans_df.rename(columns={\"phenotype_id\": \"molecular_trait_id\", \n",
    "                                            \"pval\": \"pvalue\", \n",
    "                                            \"b\": \"bhat\", \"b_se\": \"sebhat\"}, inplace=True)\n",
    "                        trans_df[\"n\"] = len(common_samples)\n",
    "                        \n",
    "                        # Merge variant information\n",
    "                        trans_df = variant_df_chr.merge(trans_df, right_on='variant_id', left_index=True)\n",
    "                        trans_df.rename(columns={'a1': 'a2', 'a0': 'a1'}, inplace=True)\n",
    "                        trans_df['pheno_chrom'] = pheno_chrom\n",
    "                        trans_df['geno_chrom'] = geno_chrom\n",
    "                        all_results.append(trans_df)\n",
    "                    else:\n",
    "                        print(f\"No trans-QTLs found after cis filtering\")\n",
    "                else:\n",
    "                    print(f\"No trans-QTLs found\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error during trans analysis: {e}\")\n",
    "                continue\n",
    "    \n",
    "    if all_results:\n",
    "        print(f\"Merging {len(all_results)} result sets...\")\n",
    "        combined_results = pd.concat(all_results, ignore_index=True)\n",
    "        print(f\"Total trans-QTLs found: {len(combined_results)}\")\n",
    "        \n",
    "        # Calculate genomic inflation factor\n",
    "        lambda_col = combined_results.groupby(\"molecular_trait_id\").apply(\n",
    "            lambda x: chi2.ppf(1. - np.median(x.pvalue), 1)/chi2.ppf(0.5,1)\n",
    "        )\n",
    "        lambda_col = lambda_col.reset_index()\n",
    "        lambda_col.columns = ['molecular_trait_id', 'genomic_inflation_lambda']\n",
    "        lambda_col.to_csv(\"$[_output:nnn].genomic_inflation.tsv.gz\", sep='\\t', index=None, \n",
    "                        compression={'method': 'gzip', 'compresslevel': 9})\n",
    "        combined_results = combined_results.sort_values(by=['chrom', 'pos', 'molecular_trait_id'])\n",
    "\n",
    "        # Output information\n",
    "        print('Output Information:')\n",
    "        print(f\"Output Rows: {len(combined_results)}\")\n",
    "        print(f\"Output Columns: {combined_results.columns.tolist()}\")\n",
    "        if len(combined_results) > 0:\n",
    "            print(f\"Output Preview (first 5 rows):\")\n",
    "            print(combined_results.iloc[0:min(5, len(combined_results)), 0:10])\n",
    "        \n",
    "        if $[pval] > 0:\n",
    "            # Record initial number of variants\n",
    "            initial_n = len(combined_results)\n",
    "\n",
    "            # Calculate p-value distribution by each 10th percentile (before filtering)\n",
    "            pval_percentiles = np.percentile(combined_results['pvalue'], np.arange(0, 110, 10))\n",
    "\n",
    "            # Filter combined_results by p-value threshold\n",
    "            combined_results = combined_results[combined_results['pvalue'] < $[pval]]\n",
    "\n",
    "            # Print summary\n",
    "            print(f\"Number of variants initially: {initial_n}\")\n",
    "            print(f\"Number of variants after filtering: {len(combined_results)}\")\n",
    "            print(\"P-value distribution by each 10th percentile (before filtering):\")\n",
    "            print(dict(zip([f\"{i}%\" for i in range(0, 110, 10)], pval_percentiles)))\n",
    "\n",
    "            # Save summary to TSV\n",
    "            summary_df = pd.DataFrame({\n",
    "                'metric': ['initial_n', 'after_filtering'] + [f\"{i}%\" for i in range(0, 110, 10)],\n",
    "                'value': [initial_n, len(combined_results)] + list(pval_percentiles)\n",
    "            })\n",
    "\n",
    "            summary_df.to_csv(f\"$[_output['nominal']:nn].summary.tsv\", sep=\"\\t\", index=False)\n",
    "            \n",
    "        output_file = \"$[_output['nominal']:n]\"\n",
    "        combined_results.to_csv(output_file, sep='\\t', index=None)\n",
    "        print(f\"Results saved to {output_file}\")\n",
    "    else:\n",
    "        print(\"No trans-QTLs found across all chromosome combinations\")\n",
    "        with open(\"$[_output['nominal']:n]\", 'w') as f:\n",
    "            f.write(\"No trans-QTLs found across any chromosome combinations\\n\")\n",
    "\n",
    "R: expand= \"$[ ]\", stderr = f'{_output[\"nominal\"]:nnn}.stderr', stdout = f'{_output[\"nominal\"]:nnn}.stdout', container = container\n",
    "    library(purrr)\n",
    "    library(tidyr)\n",
    "    library(readr)\n",
    "    library(dplyr)\n",
    "    library(qvalue)\n",
    "\n",
    "    compute_qvalues <- function(pvalues) {\n",
    "        tryCatch({\n",
    "            if(length(pvalues) < 2) {\n",
    "                return(pvalues)\n",
    "            } else {\n",
    "                return(qvalue(pvalues)$qvalues)\n",
    "            }\n",
    "        }, error = function(e) {\n",
    "            message(\"Too few p-values to calculate qvalue, fall back to BH\")\n",
    "            qvalue(pvalues, pi0 = 1)$qvalues\n",
    "        })\n",
    "    }\n",
    "    \n",
    "    pairs_df <- read.table(\"$[_output['nominal']:n]\", header = TRUE, sep = '\\t', stringsAsFactors = FALSE)\n",
    "\n",
    "    if (nrow(pairs_df) <= 1) {\n",
    "        message(\"File is empty or has only header. No qvalues to calculate.\")\n",
    "    } else {\n",
    "        unique_traits <- unique(pairs_df$molecular_trait_id)\n",
    "        for(trait in unique_traits) {\n",
    "            trait_rows <- pairs_df$molecular_trait_id == trait\n",
    "            pairs_df$qvalue[trait_rows] <- compute_qvalues(pairs_df$pvalue[trait_rows])\n",
    "        }\n",
    "        \n",
    "        write.table(pairs_df, \"$[_output['nominal']:n]\", sep = '\\t', row.names = FALSE, quote = FALSE)\n",
    "    }\n",
    "\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output[\"nominal\"]:nnn}.stderr', stdout = f'{_output[\"nominal\"]:nnn}.stdout', container = container\n",
    "        bgzip --compress-level 9 $[_output[\"nominal\"]:n]\n",
    "        tabix -S 1 -s 1 -b 2 -e 2 $[_output[\"nominal\"]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.23.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
