{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# QTL Association Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "We perform QTL association testing using TensorQTL [[cf. Taylor-Weiner et al (2019)](https://doi.org/10.1186/s13059-019-1836-7)]. An additional protocol was added to test for quantile QTL associations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input\n",
    "\n",
    "- List of molecular phenotype files: a list of `bed.gz` files containing the table for the molecular phenotype. It should have a companion index file in `tbi` format. It is the output of gene_annotation or phenotype_by_chorm\n",
    "\n",
    "### Example phenotype list\n",
    "\n",
    "```\n",
    "#chr    start   end ID  path\n",
    "chr12   752578  752579  ENSG00000060237  /home/gw/GIT/github/fungen-xqtl-analysis/analysis/Wang_Columbia/ROSMAP/MWE/output/phenotype/protocol_example.protein.bed.gz\n",
    "chr12   990508  990509  ENSG00000082805  /home/gw/GIT/github/fungen-xqtl-analysis/analysis/Wang_Columbia/ROSMAP/MWE/output/phenotype/protocol_example.protein.bed.gz\n",
    "chr12   2794969 2794970 ENSG00000004478  /home/gw/GIT/github/fungen-xqtl-analysis/analysis/Wang_Columbia/ROSMAP/MWE/output/phenotype/protocol_example.protein.bed.gz\n",
    "chr12   4649113 4649114 ENSG00000139180  /home/gw/GIT/github/fungen-xqtl-analysis/analysis/Wang_Columbia/ROSMAP/MWE/output/phenotype/protocol_example.protein.bed.gz\n",
    "chr12   6124769 6124770 ENSG00000110799  /home/gw/GIT/github/fungen-xqtl-analysis/analysis/Wang_Columbia/ROSMAP/MWE/output/phenotype/protocol_example.protein.bed.gz\n",
    "chr12   6534516 6534517 ENSG00000111640  /home/gw/GIT/github/fungen-xqtl-analysis/analysis/Wang_Columbia/ROSMAP/MWE/output/phenotype/protocol_example.protein.bed.gz\n",
    "```\n",
    "\n",
    "\n",
    "    The header of the bed.gz is per the [TensorQTL](https://github.com/broadinstitute/tensorqtl) convention:\n",
    "\n",
    "    >    Phenotypes must be provided in BED format, with a single header line starting with # and the first four columns corresponding to: chr, start, end, phenotype_id, with the remaining columns corresponding to samples (the identifiers must match those in the genotype input). The BED file should specify the center of the cis-window (usually the TSS), with start == end-1.\n",
    "\n",
    "\n",
    "- List of genotypes in PLINK binary format (`bed`/`bim`/`fam`) for each chromosome, previously processed through our genotype QC pipelines.\n",
    "- Covariate file, a file with #id + samples name as colnames and each row a covariate: fixed and known covariates as well as hidden covariates recovered from factor analysis.\n",
    "- Optionally, a list of traits (genes, regions of molecular features etc) to analyze.\n",
    "\n",
    "\n",
    "For cis-analysis:\n",
    "\n",
    "- Optionally, a list of genomic regions associate with each molecular features to analyze. The default cis-analysis will use a window around TSS. This can be customized to take given start and end genomic coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Output\n",
    "\n",
    "For each chromosome, several of summary statistics files are generated, including both nominal test statistics for each test, as well as region (gene) level association evidence.\n",
    "\n",
    "The columns of nominal association result are as follows:\n",
    "\n",
    "- phenotype_id: Molecular trait identifier.(gene)\n",
    "- variant_id: ID of the variant (rsid or chr:position:ref:alt)\n",
    "- tss_distance: Distance of the SNP to the gene transcription start site (TSS)\n",
    "- af: The allele frequency of this SNPs\n",
    "- ma_samples: Number of samples carrying the minor allele\n",
    "- ma_count: Total number of minor alleles across individuals\n",
    "- pval: Nominal P-value from linear regression\n",
    "- beta: Slope of the linear regression\n",
    "- se: Standard error of beta\n",
    "- chr : Variant chromosome.\n",
    "- pos : Variant chromosomal position (basepairs).\n",
    "- ref : Variant reference allele (A, C, T, or G).\n",
    "- alt : Variant alternate allele.\n",
    "\n",
    "\n",
    "The column specification of region (gene) level association evidence are as follows:\n",
    "\n",
    "- phenotype_id - Molecular trait identifier. (gene)\n",
    "- num_var - Total number of variants tested in cis\n",
    "- beta_shape1 - First parameter value of the fitted beta distribution\n",
    "- beta_shape2 - Second parameter value of the fitted beta distribution\n",
    "- true_df - Effective degrees of freedom the beta distribution approximation\n",
    "- pval_true_df - Empirical P-value for the beta distribution approximation\n",
    "- variant_id - ID of the top variant (rsid or chr:position:ref:alt)\n",
    "- tss_distance - Distance of the SNP to the gene transcription start site (TSS)\n",
    "- ma_samples - Number of samples carrying the minor allele\n",
    "- ma_count - Total number of minor alleles across individuals\n",
    "- af - Alternative allele frequency in MiGA cohort\n",
    "- ref_factor - Flag indicating if the alternative allele is the minor allele in the cohort (1 if AF <= 0.5, -1 if not)\n",
    "- pval_nominal - Nominal P-value from linear regression\n",
    "- slope - Slope of the linear regression\n",
    "- slope_se - Standard error of the slope\n",
    "- pval_perm - First permutation P-value directly obtained from the permutations with the direct method\n",
    "- pval_beta - Second permutation P-value obtained via beta approximation. This is the one to use for downstream analysis\n",
    "\n",
    "The columns of nominal association results for quantile regression are as follows:\n",
    "- phenotype_id: Molecular trait identifier.(gene)\n",
    "- variant_id: ID of the variant (rsid or chr:position:ref:alt)\n",
    "- chr : Variant chromosome.\n",
    "- pos : Variant chromosomal position (basepairs).\n",
    "- ref : Variant reference allele (A, C, T, or G).\n",
    "- alt : Variant alternate allele.\n",
    "- af: Alternative allele frequency in MiGA cohort\n",
    "- combined_pval(composite-p value using cauchy combination method): the integrated QR p-value across multiple quantile levels.    \n",
    "- qr_0.1_pval to qr_0.9_pval: quantile-specific QR p-values for the quantile levels 0.1, 0.2, ..., 0.9.   \n",
    "- qr_0.1_slope to qr_0.9_slope: quantile-specific QR coefficients for the quantile levels 0.1, 0.2, ..., 0.9.  \n",
    "- qr_0.1_tval to qr_0.9_tval: quantile-specific QR t-values for the quantile levels 0.1, 0.2, ..., 0.9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Minimal Working Example Steps\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "The data can be found on [Synapse](https://www.synapse.org/#!Synapse:syn36416559/files/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### i. Cis TensorQTL Command "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sos run pipeline/TensorQTL.ipynb cis \\\n",
    "    --genotype-file output/genotype_by_chrom/protocol_example.genotype.chr21_22.genotype_by_chrom_files.txt \\\n",
    "    --phenotype-file  output/phenotype_by_chrom/protocol_example.protein.bed.phenotype_by_chrom_files.region_list.txt \\\n",
    "    --covariate-file output/covariate/protocol_example.protein.protocol_example.samples.protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.Marchenko_PC.gz \\\n",
    "    --customized_cis_windows prototype_example/protocol_example/protocol_example.protein.enhanced_cis_chr21_chr22.bed \\\n",
    "    --cwd output/cis_association/ \\\n",
    "    --MAC 5 \\\n",
    "    --container containers/TensorQTL.sif "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### ii. Trans TensorQTL Command \n",
    "\n",
    "Note: Some protein is not in the customized cis windows list. There we will need to remove them from the analysis by create a region_list. Noted that the region list need to be a actual file. So `<()` file is not acceptable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "zcat output/protocol_example.protein.bed.gz | cut -f 1,2,3,4 | grep -v -e ENSG00000163554 \\\n",
    "    -e ENSG00000171564 -e ENSG00000171560 -e ENSG00000171557 > output/protocol_example.protein.region_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "The following will take more than 180G of memory to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sos run xqtl-protocol/pipeline/TensorQTL.ipynb trans \\\n",
    "    --genotype-file output/genotype_by_chrom/protocol_example.genotype.chr21_22.genotype_by_chrom_files.txt \\\n",
    "    --phenotype-file  output/phenotype_by_chrom/protocol_example.protein.bed.phenotype_by_chrom_files.region_list.txt \\\n",
    "    --region-list output/protocol_example.protein.region_list \\\n",
    "    --covariate-file output/protocol_example.protein.protocol_example.samples.protocol_example.genotype.chr21_22.pQTL.unrelated.plink_qc.prune.pca.Marchenko_PC.gz \\\n",
    "    --customized-cis-windows input/protocol_example.protein.enhanced_cis_chr21_chr22.bed \\\n",
    "    --cwd output/association/trans/ \\\n",
    "    --MAC 5 --numThreads 8 -J 1 -q csg --mem 240G -c /mnt/vast/hpc/csg/molecular_phenotype_calling/csg.yml \\\n",
    "    --container containers/TensorQTL.sif "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "| Step | Substep | Problem | Possible Reason | Solution |\n",
    "|------|---------|---------|------------------|---------|\n",
    "|  |  |  |  |  |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Command Interface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run TensorQTL.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  cis\n",
      "  trans\n",
      "\n",
      "Global Workflow Options:\n",
      "  --cwd output (as path)\n",
      "                        Path to the work directory of the analysis.\n",
      "  --phenotype-file VAL (as path, required)\n",
      "                        Phenotype file, or a list of phenotype per region.\n",
      "  --genotype-file VAL (as path, required)\n",
      "                        A genotype file in PLINK binary format (bed/bam/fam)\n",
      "                        format, or a list of genotype per chrom\n",
      "  --covariate-file VAL (as path, required)\n",
      "                        Covariate file\n",
      "  --name  f\"{phenotype_file:bn}_{covariate_file:bn}\"\n",
      "\n",
      "                        Prefix for the analysis output\n",
      "  --region-list . (as path)\n",
      "                        An optional subset of regions of molecular features to\n",
      "                        analyze. The last column is the gene names\n",
      "  --region-list-phenotype-column 4 (as int)\n",
      "  --keep-sample . (as path)\n",
      "                        Set list of sample to be keep\n",
      "  --interaction ''\n",
      "                        FIXME: please document\n",
      "  --customized-cis-windows . (as path)\n",
      "                        An optional list documenting the custom cis window for\n",
      "                        each region to analyze, with four column, chr, start,\n",
      "                        end, region ID (eg gene ID). If this list is not\n",
      "                        provided, the default `window` parameter (see below)\n",
      "                        will be used.\n",
      "  --phenotype-group . (as path)\n",
      "                        The phenotype group file to group molecule_trait into\n",
      "                        molecule_trait_object This applies to multiple molecular\n",
      "                        events in the same region, such as sQTL analysis.\n",
      "  --chromosome  (as list)\n",
      "                        The name of phenotype corresponding to gene_id or\n",
      "                        gene_name in the region\n",
      "  --MAC 0 (as int)\n",
      "                        Minor allele count cutoff\n",
      "  --window 1000000 (as int)\n",
      "                        Specify the cis window for the up and downstream radius\n",
      "                        to analyze around the region of interest in units of bp\n",
      "                        This parameter will be set to zero if\n",
      "                        `customized_cis_windows` is provided.\n",
      "  --numThreads 8 (as int)\n",
      "                        Number of threads\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "  --walltime 12h\n",
      "  --mem 16G\n",
      "  --container ''\n",
      "                        Container option for software to run the analysis:\n",
      "                        docker or singularity\n",
      "  --entrypoint  ('micromamba run -a \"\" -n' + ' ' + re.sub(r'(_apptainer:latest|_docker:latest|\\.sif)$', '', container.split('/')[-1])) if container else \"\"\n",
      "\n",
      "  --maf-threshold  MAC/(2.0*N) \n",
      "\n",
      "                        Minor allele frequency cutoff. It will overwrite minor\n",
      "                        allele cutoff. You may consider setting it to higher for\n",
      "                        interaction analysis if you have statistical power\n",
      "                        concerns\n",
      "\n",
      "Sections\n",
      "  cis_1:\n",
      "    Workflow Options:\n",
      "      --[no-]skip-nominal-if-exist (default to False)\n",
      "                        parse input file lists skip nominal association results\n",
      "                        if the files exists already This is false by default\n",
      "                        which means to recompute everything This is only\n",
      "                        relevant when the `parquet` files for nominal results\n",
      "                        exist but not the other files and you want to avoid\n",
      "                        computing the nominal results again\n",
      "      --[no-]permutation (default to True)\n",
      "  cis_2:\n",
      "  trans_1:\n",
      "    Workflow Options:\n",
      "      --batch-size 50000 (as int)\n",
      "      --pval-threshold 1.0 (as float)\n",
      "      --[no-]permutation (default to False)\n",
      "                        Permutation testing is incorrect when the analysis is\n",
      "                        done by chrom\n"
     ]
    }
   ],
   "source": [
    "sos run TensorQTL.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## Old Minimal working example\n",
    "\n",
    "An MWE is uploaded to [google drive](https://drive.google.com/drive/folders/1yjTwoO0DYGi-J9ouMsh9fHKfDmsXJ_4I?usp=sharing).\n",
    "The singularity image (sif) for running this MWE is uploaded to [google drive](https://drive.google.com/drive/folders/1mLOS3AVQM8yTaWtCbO8Q3xla98Nr5bZQ)\n",
    "\n",
    "FIXME: need to update these links. \n",
    "\n",
    "FIXME: Also need to update the example commands below using our new example dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/TensorQTL.ipynb cis \\\n",
    "    --genotype-file plink_files_list.txt \\\n",
    "    --phenotype-file MWE.bed.recipe \\\n",
    "    --covariate-file ALL.covariate.pca.BiCV.cov.gz \\\n",
    "    --cwd ./output/ \\\n",
    "    --container containers/TensorQTL.sif --MAC 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/TensorQTL.ipynb trans \\\n",
    "    --genotype-file plink_files_list.txt \\\n",
    "    --phenotype-file MWE.bed.recipe \\\n",
    "    --covariate-file ALL.covariate.pca.BiCV.cov.gz \\\n",
    "    --cwd ./output/ \\\n",
    "    --container containers/TensorQTL.sif --MAC 5 --region-name  gene_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/TensorQTL.ipynb trans \\\n",
    "    --genotype-file plink_files_list.txt \\\n",
    "    --phenotype-file MWE.bed.recipe \\\n",
    "    --covariate-file /mnt/vast/hpc/csg/snuc_pseudo_bulk/eight_tissue_analysis/output/data_preprocessing/ALL/covariates/ALL.log2cpm.ALL.covariate.pca.resid.PEER.cov.gz \\\n",
    "    --cwd ./output/trans_tensorQTL/ \\\n",
    "    --region-list /mnt/vast/hpc/csg/snuc_pseudo_bulk/eight_tissue_analysis/reference_data/AD_genes.region_list \\\n",
    "    --customized-cis-windows TADB_enhanced_cis.bed \\\n",
    "    --container containers/TensorQTL.sif --MAC 5 --region-name ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Setup and global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Path to the work directory of the analysis.\n",
    "parameter: cwd = path('output')\n",
    "# Phenotype file, or a list of phenotype per region.\n",
    "parameter: phenotype_file = path\n",
    "# A genotype file in PLINK binary format (bed/bam/fam) format, or a list of genotype per chrom\n",
    "parameter: genotype_file = path\n",
    "# Covariate file\n",
    "parameter: covariate_file = path\n",
    "# Prefix for the analysis output\n",
    "parameter: name = f\"{phenotype_file:bn}_{covariate_file:bn}\"\n",
    "# An optional subset of regions of molecular features to analyze. The last column is the gene names\n",
    "parameter: region_list = path()\n",
    "parameter: region_list_phenotype_column = 4\n",
    "# Set list of sample to be keep\n",
    "parameter: keep_sample = path()\n",
    "# FIXME: please document\n",
    "parameter: interaction = \"\"\n",
    "\n",
    "# An optional list documenting the custom cis window for each region to analyze, with four column, chr, start, end, region ID (eg gene ID).\n",
    "# If this list is not provided, the default `window` parameter (see below) will be used.\n",
    "parameter: customized_cis_windows = path()\n",
    "\n",
    "# The phenotype group file to group molecule_trait into molecule_trait_object\n",
    "# This applies to multiple molecular events in the same region, such as sQTL analysis.\n",
    "parameter: phenotype_group = path() \n",
    "\n",
    "# The name of phenotype corresponding to gene_id or gene_name in the region\n",
    "parameter: chromosome = []\n",
    "# Minor allele count cutoff\n",
    "parameter: MAC = 0\n",
    "\n",
    "# Specify the cis window for the up and downstream radius to analyze around the region of interest in units of bp\n",
    "# This parameter will be set to zero if `customized_cis_windows` is provided.\n",
    "parameter: window = 1000000\n",
    "\n",
    "# Number of threads\n",
    "parameter: numThreads = 8\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "parameter: walltime = '12h'\n",
    "parameter: mem = '16G'\n",
    "# Container option for software to run the analysis: docker or singularity\n",
    "parameter: container = ''\n",
    "import re\n",
    "parameter: entrypoint= ('micromamba run -a \"\" -n' + ' ' + re.sub(r'(_apptainer:latest|_docker:latest|\\.sif)$', '', container.split('/')[-1])) if container else \"\"\n",
    "\n",
    "# Use the header of the covariate file to decide the sample size\n",
    "import pandas as pd\n",
    "N = len(pd.read_csv(covariate_file, sep = \"\\t\",nrows = 1).columns) - 1\n",
    "\n",
    "# Minor allele frequency cutoff. It will overwrite minor allele cutoff.\n",
    "# You may consider setting it to higher for interaction analysis if you have statistical power concerns\n",
    "parameter: maf_threshold = MAC/(2.0*N) \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def adapt_file_path(file_path, reference_file):\n",
    "    \"\"\"\n",
    "    Adapt a single file path based on its existence and a reference file's path.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): The file path to adapt.\n",
    "    - reference_file (str): File path to use as a reference for adaptation.\n",
    "\n",
    "    Returns:\n",
    "    - str: Adapted file path.\n",
    "\n",
    "    Raises:\n",
    "    - FileNotFoundError: If no valid file path is found.\n",
    "    \"\"\"\n",
    "    reference_path = os.path.dirname(reference_file)\n",
    "\n",
    "    # Check if the file exists\n",
    "    if os.path.isfile(file_path):\n",
    "        return file_path\n",
    "\n",
    "    # Check file name without path\n",
    "    file_name = os.path.basename(file_path)\n",
    "    if os.path.isfile(file_name):\n",
    "        return file_name\n",
    "\n",
    "    # Check file name in reference file's directory\n",
    "    file_in_ref_dir = os.path.join(reference_path, file_name)\n",
    "    if os.path.isfile(file_in_ref_dir):\n",
    "        return file_in_ref_dir\n",
    "\n",
    "    # Check original file path prefixed with reference file's directory\n",
    "    file_prefixed = os.path.join(reference_path, file_path)\n",
    "    if os.path.isfile(file_prefixed):\n",
    "        return file_prefixed\n",
    "\n",
    "    # If all checks fail, raise an error\n",
    "    raise FileNotFoundError(f\"No valid path found for file: {file_path}\")\n",
    "\n",
    "def adapt_file_path_all(df, column_name, reference_file):\n",
    "    return df[column_name].apply(lambda x: adapt_file_path(x, reference_file))\n",
    "\n",
    "\n",
    "if str(genotype_file).endswith(\"bed\") and str(phenotype_file).endswith(\"bed.gz\"):\n",
    "    input_files = [[phenotype_file, genotype_file]]\n",
    "    if len(chromosome) > 0:\n",
    "        input_chroms = [int(x) for x in chromosome]\n",
    "    else:\n",
    "        input_chroms = [0]\n",
    "else:\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    molecular_pheno_files = pd.read_csv(phenotype_file, sep = \"\\t\")\n",
    "    if \"#chr\" in molecular_pheno_files.columns:\n",
    "        molecular_pheno_files = molecular_pheno_files.groupby(['#chr', '#dir']).size().reset_index(name='count').drop(\"count\",axis = 1).rename(columns = {\"#chr\":\"#id\"})\n",
    "    genotype_files = pd.read_csv(genotype_file,sep = \"\\t\")\n",
    "    genotype_files[\"#id\"] = [x.replace(\"chr\",\"\") for x in genotype_files[\"#id\"].astype(str)] # e.g. remove chr1 to 1\n",
    "    genotype_files[\"#path\"] = genotype_files[\"#path\"].apply(lambda x: adapt_file_path(x, genotype_file))\n",
    "    molecular_pheno_files[\"#id\"] = [x.replace(\"chr\",\"\") for x in molecular_pheno_files[\"#id\"].astype(str)]\n",
    "    input_files = molecular_pheno_files.merge(genotype_files, on = \"#id\")\n",
    "    # Only keep chromosome specified in --chromosome\n",
    "    if len(chromosome) > 0:\n",
    "        input_files = input_files[input_files['#id'].isin(chromosome)]\n",
    "    input_files = input_files.values.tolist()\n",
    "    input_chroms = [x[0] for x in input_files]\n",
    "    input_files = [x[1:] for x in input_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## cis-xQTL association testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[cis_1]\n",
    "# parse input file lists\n",
    "# skip nominal association results if the files exists already\n",
    "# This is false by default which means to recompute everything\n",
    "# This is only relevant when the `parquet` files for nominal results exist but not the other files\n",
    "# and you want to avoid computing the nominal results again\n",
    "parameter: skip_nominal_if_exist = False\n",
    "parameter: permutation = True\n",
    "parameter: quantile_regression = False\n",
    "parameter: qr_vcov= 'robust'\n",
    "parameter: qr_kernel= 'epa'\n",
    "parameter: qr_bandwidth= 'hsheather'\n",
    "parameter: qr_max_iter=200\n",
    "parameter: qr_p_tol=0.000001\n",
    "parameter: qr_regress_covariates = True\n",
    "parameter: qr_add_intercept = False\n",
    "parameter: qr_scale = False\n",
    "# use -1 to set the maximum number of cores available\n",
    "parameter: qr_threads = -1\n",
    "if quantile_regression:\n",
    "    permutation = False\n",
    "\n",
    "# Extract interaction name\n",
    "var_interaction = interaction\n",
    "if os.path.isfile(interaction):\n",
    "    interaction_s = pd.read_csv(interaction, sep='\\t', index_col=0)\n",
    "    var_interaction = interaction_s.columns[0] # interaction name\n",
    "test_regional_association = permutation and len(var_interaction) == 0\n",
    "\n",
    "input: input_files, group_by = len(input_files[0]), group_with = \"input_chroms\"\n",
    "output_files = dict([(\"parquet\", f'{cwd:a}/{_input[0]:bnn}{\"_%s\" % var_interaction if interaction else \"\"}.cis_qtl_pairs.{\"\" if input_chroms[_index] == 0 else input_chroms[_index]}.parquet'), # This convention is necessary to match the pattern of map_norminal output\n",
    "                     (\"nominal\", f'{cwd:a}/{_input[0]:bnn}{\"\" if input_chroms[_index] == 0 else \"_chr%s\" % input_chroms[_index]}{\"_%s\" % var_interaction if interaction else \"\"}.cis_{\"quantile_\" if quantile_regression else \"\"}qtl.pairs.tsv.gz')])\n",
    "if test_regional_association:\n",
    "    output_files[\"regional\"] = f'{cwd:a}/{_input[0]:bnn}{\"\" if input_chroms[_index] == 0 else \"_chr%s\" % input_chroms[_index]}{\"_%s\" % var_interaction if interaction else \"\"}.cis_qtl.regional.tsv.gz'\n",
    "output: output_files\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[\"nominal\"]:bnnn}'\n",
    "python: expand= \"$[ ]\", stderr = f'{_output[\"nominal\"]:nnn}.stderr', stdout = f'{_output[\"nominal\"]:nnn}.stdout' , container = container, entrypoint = entrypoint\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import tensorqtl\n",
    "    from tensorqtl import genotypeio, cis\n",
    "    from scipy.stats import chi2\n",
    "    import multiprocessing as mp\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    ## Define paths\n",
    "    plink_prefix_path = $[_input[1]:nar]\n",
    "    expression_bed = $[_input[0]:ar]\n",
    "    covariates_file = \"$[covariate_file:a]\"\n",
    "    window = $[window]\n",
    "    interaction = \"$[interaction]\"\n",
    "    ## Load Data\n",
    "    phenotype_df, phenotype_pos_df = tensorqtl.read_phenotype_bed(expression_bed)\n",
    "    phenotype_id = phenotype_pos_df.index.name\n",
    "\n",
    "    ## Analyze only the regions listed\n",
    "    if $[region_list.is_file()]:\n",
    "        region = pd.read_csv(\"$[region_list:a]\", comment=\"#\", header=None, sep=\"\\t\" )\n",
    "        phenotype_column = 1 if len(region.columns) == 1 else  $[region_list_phenotype_column]\n",
    "        keep_region = region.iloc[:,phenotype_column-1].to_list()\n",
    "        phenotype_df = phenotype_df[phenotype_df.index.isin(keep_region)]\n",
    "        phenotype_pos_df = phenotype_pos_df[phenotype_pos_df.index.isin(keep_region)]\n",
    "    covariates_df = pd.read_csv(covariates_file, sep='\\t', index_col=0).T\n",
    "    pr = genotypeio.PlinkReader(plink_prefix_path)\n",
    "    genotype_df = pr.load_genotypes()\n",
    "    variant_df = pr.bim.set_index('snp')[['chrom', 'pos','a0','a1']]\n",
    "    \n",
    "    ## use custom sample list to subset the covariates data\n",
    "    if $[keep_sample.is_file()]:\n",
    "        sample_list = pd.read_csv(\"$[keep_sample:a]\", comment=\"#\", header=None, names=[\"sample_id\"], sep=\"\\t\")\n",
    "        covariates_df.loc[sample_list.sample_id]\n",
    "\n",
    "    # Read interaction files or extract from covariates file.\n",
    "    var_interaction = interaction\n",
    "    interaction_s = []\n",
    "    if os.path.isfile(interaction):\n",
    "        # update var_interaction and interaction_s\n",
    "        interaction_s = pd.read_csv(interaction, sep='\\t', index_col=0)\n",
    "        interaction_s = interaction_s[interaction_s.index.isin(covariates_df.index)] \n",
    "        var_interaction = interaction_s.columns[0] # interaction name\n",
    "    # check if the interaction term in interaction table is in covariates file, if yes and interaction_s not yet loaded then, extract it out from covariates file\n",
    "    if var_interaction in covariates_df.columns:\n",
    "        # only load from covariate if it has not been loaded yet\n",
    "        if len(interaction_s) == 0:\n",
    "            interaction_s = covariates_df[var_interaction].to_frame()\n",
    "        covariates_df = covariates_df.drop(columns=[var_interaction])\n",
    "    if len(interaction) and len(interaction_s) == 0:\n",
    "        raise ValueError(f\"Cannot find interaction variable or file {interaction}\")\n",
    "\n",
    "    # drop samples that with missing value in iteraction\n",
    "    if len(interaction_s):\n",
    "        interaction_s = interaction_s.dropna() \n",
    "\n",
    "    ## Retaining only common samples\n",
    "    phenotype_df = phenotype_df[np.intersect1d(phenotype_df.columns, covariates_df.index)]\n",
    "    phenotype_df = phenotype_df[np.intersect1d(phenotype_df.columns, genotype_df.columns)] \n",
    "    if len(interaction_s):\n",
    "        phenotype_df = phenotype_df[np.intersect1d(phenotype_df.columns, interaction_s.index)]\n",
    "        interaction_s = interaction_s[interaction_s.index.isin(phenotype_df.columns)]    \n",
    "        interaction_s = interaction_s.loc[phenotype_df.columns]\n",
    "\n",
    "    covariates_df = covariates_df.transpose()[np.intersect1d(phenotype_df.columns, covariates_df.index)].transpose()\n",
    "   \n",
    "    ## To simplify things, there should really not be \"chr\" prefix\n",
    "    phenotype_pos_df.chr = phenotype_pos_df.chr.astype(str).str.replace(\"chr\", \"\")\n",
    "    variant_df.chrom =  variant_df.chrom.astype(\"str\").str.replace(\"chr\", \"\") \n",
    "\n",
    "    ## use custom cis windows list\n",
    "    if $[customized_cis_windows.is_file()]:\n",
    "        cis_list = pd.read_csv(\"$[customized_cis_windows:a]\", comment=\"#\", header=None, names=[\"chr\",\"start\",\"end\",phenotype_id], sep=\"\\t\")\n",
    "        cis_list.chr = cis_list.chr.astype(str).str.replace(\"chr\", \"\")  ## Again to simplify things for chr format concordance.\n",
    "        phenotype_pos_df = phenotype_pos_df.reset_index() #move the phenotype id index to a new column of the dataframe\n",
    "        phenotype_pos_df = phenotype_pos_df.merge(cis_list, left_on = [\"chr\",phenotype_id],right_on = [cis_list.columns[0],cis_list.columns[3]])#in some cases (gene expression for eQTLs) the phenotype_id may be in the cis_list file\n",
    "        phenotype_pos_df = phenotype_pos_df.set_index(phenotype_id)[[\"chr\",\"start\",\"end\"]] # The final phenotype_pos_df will have three columns(chr, start, end) and index is the phenotype ID\n",
    "        if len(phenotype_df.index) != len(phenotype_pos_df.index):\n",
    "            raise ValueError(\"cannot uniquely match all the phentoype data in the input to the customized cis windows provided\")\n",
    "        window = 0 # In the updated tensorQTL, by default if there is a customized cis window, the actual cis window will be start - window & end + window, so it is necessary to change the window parameter to 0\n",
    "\n",
    "    ## Read phenotype group if availble\n",
    "    if $[phenotype_group.is_file()]:\n",
    "        group_s = pd.read_csv($[phenotype_group:r], sep='\\t', header=None, index_col=0, squeeze=True)\n",
    "    else:\n",
    "        group_s = None\n",
    "\n",
    "    if $[\"True\" if quantile_regression else \"False\"]:\n",
    "        import statsmodels.api as sm\n",
    "        import scipy.stats as ss\n",
    "        from scipy.stats import cauchy\n",
    "        import time\n",
    "        import warnings\n",
    "        import torch\n",
    "        # Perform quantile regression\n",
    "        start_time = time.time()\n",
    "        def filter_maf_with_numpy(genotypes, variant_ids, maf_threshold, alleles=2):\n",
    "            af = genotypes.sum(axis=1) / (alleles * genotypes.shape[1])\n",
    "            maf = np.where(af > 0.5, 1 - af, af)\n",
    "            if maf_threshold > 0:\n",
    "                mask = maf >= maf_threshold\n",
    "                #mask = mask.astype(bool)\n",
    "                genotypes = genotypes[mask]\n",
    "                variant_ids = np.array(variant_ids)[mask]\n",
    "                af = af[mask]\n",
    "                maf = maf[mask]\n",
    "            return genotypes, variant_ids, af, maf\n",
    "\n",
    "        def remove_covariate_effects_np(X, Z, y, scale=False):\n",
    "            # for X,Z,y, rows are samples\n",
    "            if not np.all(Z[:, 0] == 1):\n",
    "                Z = np.hstack([np.ones((Z.shape[0], 1)), Z])\n",
    "            \n",
    "            A = np.linalg.inv(Z.T @ Z)\n",
    "            SZy = A @ Z.T @ y\n",
    "            SZX = A @ Z.T @ X\n",
    "            \n",
    "            # Adjust y and X based on calculated effects\n",
    "            y_adjusted = y - Z @ SZy\n",
    "            X_adjusted = X - Z @ SZX\n",
    "            \n",
    "            if scale:\n",
    "                # Standardize y and X\n",
    "                y_scaled = (y_adjusted - y_adjusted.mean()) / y_adjusted.std()\n",
    "                X_scaled = (X_adjusted - X_adjusted.mean(axis=0)) / X_adjusted.std(axis=0)\n",
    "                return X_scaled, y_scaled\n",
    "            else:\n",
    "                return X_adjusted, y_adjusted\n",
    "\n",
    "        def impute_mean(genotypes_t, missing=-1):#for torch tensor genotypes_t,cols are samples\n",
    "            m = genotypes_t == missing\n",
    "            ix = torch.nonzero(m, as_tuple=True)[0]\n",
    "            if len(ix) > 0:\n",
    "                a = genotypes_t.sum(1)\n",
    "                b = m.sum(1).float()\n",
    "                mu = (a - missing*b) / (genotypes_t.shape[1] - b)\n",
    "                genotypes_t[m] = mu[ix]\n",
    "\n",
    "        def drop_zero_variance_rows(genotypes, variant_ids):\n",
    "            # Calculate the variance of each row\n",
    "            variances = np.var(genotypes, axis=1)\n",
    "            # Find the indices of rows with non-zero variance\n",
    "            non_zero_variance_indices = np.where(variances != 0)[0]\n",
    "            # Select rows with non-zero variance in genotypes and corresponding variant_ids\n",
    "            genotypes_updated = genotypes[non_zero_variance_indices, :]\n",
    "            variant_ids_updated = [variant_ids[i] for i in non_zero_variance_indices.tolist()]\n",
    "            return genotypes_updated, variant_ids_updated\n",
    "\n",
    "        def cauchy_meta(pvals):\n",
    "            # Check input\n",
    "            pvals = np.array(pvals)\n",
    "            pvals = pvals[~np.isnan(pvals)]\n",
    "            if len(pvals) == 0:\n",
    "                return np.nan\n",
    "            # pvals[pvals == 0] = 2.2e-308\n",
    "            # Convert to Cauchy\n",
    "            cauchy_vals = np.zeros(pvals.shape)\n",
    "            valid_indices = pvals >= 1e-15\n",
    "            cauchy_vals[valid_indices] = np.tan(np.pi * (0.5 - pvals[valid_indices]))\n",
    "            stats = np.mean(cauchy_vals)\n",
    "            p = cauchy.sf(stats)\n",
    "            return p\n",
    "\n",
    "        def fit_quantreg(phenotype_id, phenotype_array, genotype_matrix, variant_ids, af, covar_df, taus=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], vcov='$[qr_vcov]', kernel='$[qr_kernel]', bandwidth='$[qr_bandwidth]', max_iter=$[qr_max_iter], p_tol=$[qr_p_tol]):\n",
    "            results = []\n",
    "            variant_pvals = {vid: [] for vid in variant_ids}\n",
    "            \n",
    "            if covar_df is not None:\n",
    "                if genotype_matrix.shape[1] != covar_df.shape[0]:\n",
    "                    raise ValueError(\"Mismatch in the number of samples between genotype matrix and covariates DataFrame\")\n",
    "            \n",
    "            for tau in taus:\n",
    "                for idx, genotype_row in enumerate(genotype_matrix):\n",
    "                    current_af = af[idx]\n",
    "                    if covar_df is not None:\n",
    "                        X = np.c_[covar_df.values, genotype_row]\n",
    "\n",
    "                    else:\n",
    "                        # If covar_df is None, just use the genotype_row\n",
    "                        X = genotype_row.reshape(-1, 1)\n",
    "                        \n",
    "                    if $[\"True\" if qr_add_intercept else \"False\"]:\n",
    "                        X = sm.add_constant(X).astype('float')\n",
    "                    \n",
    "                    model = sm.QuantReg(phenotype_array, X)\n",
    "                    try:\n",
    "                        res = model.fit(q=tau, vcov=vcov, kernel=kernel, bandwidth=bandwidth, max_iter=max_iter, p_tol=p_tol)\n",
    "                        pval = res.pvalues[-1]\n",
    "                        variant_pvals[variant_ids[idx]].append(pval)\n",
    "                        results.append({\n",
    "                            'phenotype_id': phenotype_id,\n",
    "                            'variant_id': variant_ids[idx],\n",
    "                            'af': current_af, \n",
    "                            'tau': tau,\n",
    "                            'pval': pval,\n",
    "                            'slope': res.params[-1],\n",
    "                            'tval': res.tvalues[-1]\n",
    "        \n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        raise RuntimeError(f\"Error fitting model for variant {variant_ids[idx]} at tau {tau}: {e}\")\n",
    "\n",
    "            # Calculate combined p-values for each variant\n",
    "            start_time_for_combined_p = time.time()\n",
    "            for vid in variant_ids:\n",
    "                combined_pval = cauchy_meta(variant_pvals[vid])\n",
    "                for result in filter(lambda r: r['variant_id'] == vid, results):\n",
    "                    result['combined_pval'] = combined_pval\n",
    "            \n",
    "            results_df = pd.DataFrame(results)\n",
    "            end_time_for_combined_p = time.time()\n",
    "            wide_df = pd.pivot_table(results_df, values=['pval', 'slope', 'tval'], index=['phenotype_id', 'variant_id', 'af','combined_pval'], columns='tau')\n",
    "            wide_df.columns = ['qr_{}_{}'.format(col[1], col[0]) for col in wide_df.columns]\n",
    "            wide_df.reset_index(inplace=True)\n",
    "\n",
    "            variant_split = wide_df['variant_id'].str.extract(r'chr(\\d+):(\\d+)_([A-Z*]+)_([A-Z*]+)')\n",
    "            variant_split.columns = ['chr', 'pos', 'ref', 'alt']\n",
    "            final_df = pd.concat([variant_split, wide_df], axis=1)\n",
    "            return final_df\n",
    "\n",
    "        # get same order and common samples of phenotype_df, genotype_df, and covariates_df\n",
    "        covariates_df.index = covariates_df.index.astype(str)\n",
    "        common_samples = np.intersect1d(phenotype_df.columns, genotype_df.columns)\n",
    "        genotype_df = genotype_df[common_samples]          \n",
    "        sample_order = covariates_df.index\n",
    "        phenotype_df = phenotype_df[sample_order]\n",
    "        genotype_df = genotype_df[sample_order]\n",
    "\n",
    "        # quantile qtl mapping:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        chrom = None\n",
    "        igc = genotypeio.InputGeneratorCis(genotype_df, variant_df, phenotype_df, phenotype_pos_df, group_s=group_s, window=window)\n",
    "        results_list = [] \n",
    "\n",
    "        def quantile_regression_wrapper(args):\n",
    "            phenotype, genotypes, genotype_range, phenotype_id = args\n",
    "            genotypes = torch.tensor(genotypes, dtype=torch.float).to(device)\n",
    "            impute_mean(genotypes)\n",
    "            if genotypes.is_cuda:\n",
    "                genotypes = genotypes.cpu()\n",
    "            genotypes = genotypes.numpy()\n",
    "            # drop_zero_variance_rows\n",
    "            variant_ids = variant_df.index[genotype_range[0]:genotype_range[-1]+1].tolist()\n",
    "            genotypes, variant_ids = drop_zero_variance_rows(genotypes, variant_ids)   \n",
    "            # filter_maf_with_numpy  \n",
    "            genotypes, variant_ids, af, maf = filter_maf_with_numpy(genotypes, variant_ids, $[maf_threshold])\n",
    "        \n",
    "            # regress out covariates from y and X\n",
    "            if $[\"True\" if qr_regress_covariates else \"False\"]:\n",
    "                covar_np = covariates_df.to_numpy()\n",
    "                X_adj, phenotype = remove_covariate_effects_np(genotypes.T, covar_np, phenotype, scale = '$[qr_scale]')\n",
    "                genotypes = X_adj.T    \n",
    "                quantqtl_start_time = time.time()\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\")\n",
    "                    results_df = fit_quantreg(phenotype_id=phenotype_id,phenotype_array=phenotype,genotype_matrix=genotypes,covar_df=None,variant_ids=variant_ids,af=af\n",
    "                    )                \n",
    "            else:\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\")\n",
    "                    results_df = fit_quantreg(phenotype_id=phenotype_id,phenotype_array=phenotype,genotype_matrix=genotypes,covar_df=covariates_df,variant_ids=variant_ids,af=af\n",
    "                    ) \n",
    "        \n",
    "            quantqtl_end_time = time.time()\n",
    "            runtime = quantqtl_end_time - quantqtl_start_time\n",
    "            return results_df, runtime\n",
    "\n",
    "        # quantile regression main function\n",
    "        qr_threads = $[qr_threads]\n",
    "        max_cores = mp.cpu_count()\n",
    "        \n",
    "        if qr_threads <= 0:\n",
    "            qr_threads = max_cores\n",
    "        else:\n",
    "            qr_threads = min(qr_threads, max_cores)\n",
    "\n",
    "        results_list = []\n",
    "        runtime_list = []\n",
    "        if qr_threads == 1:\n",
    "            for phenotype, genotypes, genotype_range, phenotype_id in igc.generate_data(chrom=chrom, verbose=True):\n",
    "                results_df, runtime = quantile_regression_wrapper((phenotype, genotypes, genotype_range, phenotype_id))\n",
    "                results_list.append(results_df)\n",
    "                runtime_list.append(runtime)\n",
    "        else:\n",
    "            pool = mp.Pool(processes=qr_threads)       \n",
    "            phenotype_args = [(phenotype, genotypes, genotype_range, phenotype_id)\n",
    "                              for phenotype, genotypes, genotype_range, phenotype_id in igc.generate_data(chrom=chrom, verbose=True)]\n",
    "        \n",
    "            with tqdm(total=len(phenotype_args), desc=\"Quantile Regression\") as progress_bar:\n",
    "                for results_df, runtime in pool.imap_unordered(quantile_regression_wrapper, phenotype_args):\n",
    "                    results_list.append(results_df)\n",
    "                    runtime_list.append(runtime)\n",
    "                    progress_bar.update(1)\n",
    "        \n",
    "            pool.close()\n",
    "            pool.join()       \n",
    "\n",
    "        quantile_reg_df = pd.concat(results_list, ignore_index=True)\n",
    "        # sort the table if chrom and pos is not in ascending order\n",
    "        quantile_reg_df['pos'] = pd.to_numeric(quantile_reg_df['pos'])\n",
    "        if not all(quantile_reg_df['pos'].iloc[i] <= quantile_reg_df['pos'].iloc[i+1] for i in range(len(quantile_reg_df)-1)):\n",
    "            quantile_reg_df = quantile_reg_df.sort_values(by=['chr', 'pos'])        \n",
    "        end_time = time.time()  \n",
    "        print(f\"Total execution time from the beginning to the quantile regression: {end_time - start_time} seconds\")\n",
    "\n",
    "        # save file\n",
    "        quantile_reg_df.to_csv($[_output[\"nominal\"]:nr], sep='\\t', index = None)\n",
    "        # print general information of quantile_reg_df\n",
    "        print('Output Information:')\n",
    "        print(\"Output Rows:\", len(quantile_reg_df))\n",
    "        print(\"Output Columns:\", quantile_reg_df.columns.tolist())\n",
    "        print(\"Output Preview:\", quantile_reg_df.iloc[1:5, 1:10])\n",
    "        pass\n",
    "    else:\n",
    "        ## cis-QTL mapping: nominal associations for all variant-phenotype pairs\n",
    "        if not ($[skip_nominal_if_exist] and $[_output[\"parquet\"].is_file()]):\n",
    "            if len(interaction_s):\n",
    "                cis.map_nominal(genotype_df, variant_df, \n",
    "                        phenotype_df, \n",
    "                        phenotype_pos_df, \n",
    "                        $[_output[\"parquet\"]:nnnr],\n",
    "                        covariates_df=covariates_df,\n",
    "                        interaction_df=interaction_s, \n",
    "                        maf_threshold_interaction=$[maf_threshold],\n",
    "                        window=window,\n",
    "                        group_s=group_s,\n",
    "                        run_eigenmt=True, write_top=True, write_stats=True)\n",
    "            else:\n",
    "                cis.map_nominal(genotype_df, variant_df,\n",
    "                    phenotype_df,\n",
    "                    phenotype_pos_df,\n",
    "                    $[_output[\"parquet\"]:nnnr],\n",
    "                    covariates_df=covariates_df, \n",
    "                    window=window, \n",
    "                    maf_threshold = $[maf_threshold],\n",
    "                    group_s=group_s)\n",
    "\n",
    "        ## Load the parquet and save it as txt\n",
    "        pairs_df = pd.read_parquet($[_output[\"parquet\"]:r])\n",
    "        # print general information of parquet\n",
    "        print('Output Information:')\n",
    "        print(\"This is the file containing the immediate output of TensorQTL's map_nominal function \")\n",
    "        print(os.path.getsize($[_output[\"parquet\"]:r]))\n",
    "\n",
    "        ## Adds the group columns to pairs_df, if there is group_s use group_s, else use phenotype_id\n",
    "        if group_s is not None:\n",
    "            pairs_df = pairs_df.merge(pd.DataFrame( {\"molecular_trait_object_id\": group_s}),left_on = \"phenotype_id\", right_index = True)\n",
    "        else:\n",
    "            pairs_df[\"molecular_trait_object_id\"] = pairs_df.phenotype_id\n",
    "\n",
    "        # rename columns\n",
    "        pairs_df.columns.values[0]  = \"molecular_trait_id\"\n",
    "        pairs_df.columns.values[7]  = \"pvalue\"\n",
    "        pairs_df.columns.values[8]  = \"beta\"\n",
    "        pairs_df.columns.values[9]  = \"se\"\n",
    "        pairs_df.rename(columns={'TSS_D': 'tss_distance'}, inplace=True)\n",
    "        if len(interaction_s):\n",
    "            # calculate genomic inflation factor lambda on interaction \n",
    "            # lambda_col_interaction = pairs_df.groupby(\"molecular_trait_object_id\").apply(lambda x: chi2.ppf(1. - np.median(x.pval_gi), 1)/chi2.ppf(0.5,1))\n",
    "            pairs_df.columns.values[10]  = \"pvalue\" + '_' + var_interaction\n",
    "            pairs_df.columns.values[11]  = \"beta\" + '_' + var_interaction\n",
    "            pairs_df.columns.values[12]  = \"se\" + '_' + var_interaction\n",
    "            pairs_df.columns.values[13]  = \"pvalue\" + '_' + var_interaction + '_' + 'interaction'\n",
    "            pairs_df.columns.values[14]  = \"beta\" + '_' + var_interaction + '_' + 'interaction'\n",
    "            pairs_df.columns.values[15]  = \"se\" + '_' + var_interaction + '_' + 'interaction' \n",
    "\n",
    "        pairs_df[\"n\"] = len(phenotype_df.columns.values)\n",
    "        pairs_df = variant_df.merge(pairs_df, right_on='variant_id', left_index=True)\n",
    "        pairs_df.rename(columns={'a1': 'a2', 'a0': 'a1'}, inplace=True)\n",
    "        # sort the table if chrom and pos is not in ascending order\n",
    "        if not all(pairs_df['pos'].iloc[i] <= pairs_df['pos'].iloc[i+1] for i in range(len(pairs_df)-1)):\n",
    "            pairs_df = pairs_df.sort_values(by=['chrom', 'pos'])\n",
    "        # save file\n",
    "        pairs_df.to_csv($[_output[\"nominal\"]:nr], sep='\\t', index = None)\n",
    "        # print general information of pairs_df\n",
    "        print('Output Information:')\n",
    "        print(\"Output Rows:\", len(pairs_df))\n",
    "        print(\"Output Columns:\", pairs_df.columns.tolist())\n",
    "        print(\"Output Preview:\", pairs_df.iloc[1:5, 1:10])\n",
    "\n",
    "        if $[test_regional_association]:\n",
    "            # calculate genomic inflation factor lambda for main variant effect \n",
    "            lambda_col = pairs_df.groupby(\"molecular_trait_object_id\").apply(lambda x: chi2.ppf(1. - np.median(x.pvalue), 1)/chi2.ppf(0.5,1))\n",
    "            cis_df = cis.map_cis(genotype_df, \n",
    "                                variant_df, \n",
    "                                phenotype_df,\n",
    "                                phenotype_pos_df,\n",
    "                                covariates_df=covariates_df, \n",
    "                                seed=999, \n",
    "                                window=window, \n",
    "                                maf_threshold = $[maf_threshold],\n",
    "                                group_s=group_s)\n",
    "            cis_df.index.name = \"molecular_trait_id\"\n",
    "            ## Add groups columns for eQTL analysis\n",
    "            if \"group_id\" not in cis_df.columns:\n",
    "                cis_df[\"group_id\"] = cis_df.index\n",
    "                cis_df[\"group_size\"] = 1\n",
    "            cis_df = cis_df.rename({\"group_id\":\"molecular_trait_object_id\",\"group_size\":\"n_traits\",\"num_var\" : \"n_variants\",\"pval_perm\":\"p_perm\", \"pval_beta\":\"p_beta\" },axis = 1)\n",
    "            cis_df = cis_df.assign(genomic_inflation = lambda dataframe : dataframe[\"molecular_trait_object_id\"].map(lambda molecular_trait_object_id:lambda_col[molecular_trait_object_id]))\n",
    "            # merge cis_df with variant_df\n",
    "            cis_df = variant_df.merge(cis_df, right_on='variant_id', left_index=True)\n",
    "            cis_df.rename(columns={'a1': 'a2', 'a0': 'a1', 'variant_id': 'variant'}, inplace=True)\n",
    "            # sort the table if chrom and pos is not in ascending order\n",
    "            if not all(cis_df['pos'].iloc[i] <= cis_df['pos'].iloc[i+1] for i in range(len(cis_df)-1)):\n",
    "                cis_df = cis_df.sort_values(by=['chrom', 'pos'])\n",
    "            # save file\n",
    "            cis_df.to_csv(str($[_output[\"nominal\"]:nnnr])+str('.regional.tsv'), sep='\\t', index = None)\n",
    "            # print general information of cis_df\n",
    "            print('Output Information:')\n",
    "            print(\"Output Rows:\", len(cis_df))\n",
    "            print(\"Output Columns:\", cis_df.columns.tolist())\n",
    "            print(\"Output Preview:\", cis_df.iloc[0:5, 0:10])\n",
    "\n",
    "R: expand= \"$[ ]\", stderr = f'{_output[\"nominal\"]:nnn}.stderr', stdout = f'{_output[\"nominal\"]:nnn}.stdout', container = container, entrypoint = entrypoint\n",
    "    library(purrr)\n",
    "    library(tidyr)\n",
    "    library(readr)\n",
    "    library(dplyr)\n",
    "    library(qvalue)\n",
    "  \n",
    "    pairs_df = read_delim($[_output[\"nominal\"]:nr,], delim = '\\t')\n",
    "    compute_qvalues <- function(pvalues) {\n",
    "        tryCatch({\n",
    "            if(length(pvalues) < 2) {\n",
    "                return(pvalues)\n",
    "            } else {\n",
    "                return(qvalue(pvalues)$qvalues)\n",
    "            }\n",
    "        }, error = function(e) {\n",
    "            message(\"Too few p-values to calculate qvalue, fall back to BH\")\n",
    "            qvalue(pvalues, pi0 = 1)$qvalues\n",
    "        })\n",
    "    }\n",
    "    \n",
    "    quantile_regression <- \"$[quantile_regression]\"\n",
    "    if (quantile_regression) {\n",
    "        pairs_df <- pairs_df %>%\n",
    "            group_by(phenotype_id) %>%\n",
    "            mutate(\n",
    "                across(\n",
    "                    .cols = ends_with(\"_pval\"), \n",
    "                    .fns = ~ compute_qvalues(.x),\n",
    "                    .names = \"{sub('_pval$', '_qval', .col)}\"\n",
    "                )\n",
    "            )\n",
    "    } else {\n",
    "        var_interaction <- \"$[interaction]\"\n",
    "        # Check if 'interaction' is a file\n",
    "        if (file.exists(var_interaction)) {\n",
    "            # Read the file into 'interaction_s' dataframe\n",
    "            interaction_s <- read.delim(var_interaction, row.names = 1)\n",
    "            # Update 'var_interaction' to the first column name of 'interaction_s'\n",
    "            var_interaction <- names(interaction_s)[1]\n",
    "        }\n",
    "\n",
    "        if (is.null(var_interaction) || var_interaction == \"\") {\n",
    "            pairs_df = pairs_df %>% group_by(molecular_trait_id) %>% mutate(qvalue = compute_qvalues(pvalue))\n",
    "        } else {\n",
    "            pairs_df = pairs_df %>% group_by(molecular_trait_id) %>% mutate(qvalue_main = compute_qvalues(pvalue), qvalue_interaction = compute_qvalues($[\"pvalue_%s_interaction\" % var_interaction]))         \n",
    "        }\n",
    "    }\n",
    "    pairs_df %>% write_delim($[_output[\"nominal\"]:nr],\"\\t\")\n",
    "  \n",
    "bash: expand= \"$[ ]\", stderr = f'{_output[\"nominal\"]:nnn}.stderr', stdout = f'{_output[\"nominal\"]:nnn}.stdout', container = container, entrypoint = entrypoint\n",
    "        bgzip --compress-level 9 $[_output[\"nominal\"]:n] \n",
    "        tabix -S 1 -s 1 -b 2 -e 2 $[_output[\"nominal\"]]\n",
    "\n",
    "done_if(not test_regional_association)\n",
    "\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output[\"nominal\"]:nnn}.stderr', stdout = f'{_output[\"nominal\"]:nnn}.stdout', container = container, entrypoint = entrypoint\n",
    "        bgzip --compress-level 9 $[_output[\"nominal\"]:nnn].regional.tsv\n",
    "        tabix -S 1 -s 1 -b 2 -e 2 $[_output[\"nominal\"]:nnn].regional.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[cis_2]\n",
    "done_if(\"regional\" not in _input.labels)\n",
    "input: group_by = \"all\"\n",
    "output: f'{cwd}/{_input[\"nominal\"][0]:bnnnn}.cis_qtl_regional.fdr.gz',\n",
    "        f'{cwd}/{_input[\"nominal\"][0]:bnnnn}.cis_qtl_regional.summary.txt'\n",
    "input_files = [str(x) for x in _input[\"regional\"]]\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand= \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',container = container, entrypoint = entrypoint\n",
    "    library(\"purrr\")\n",
    "    library(\"tidyr\")\n",
    "    library(\"dplyr\")\n",
    "    library(\"readr\")\n",
    "    library(\"qvalue\")\n",
    "    emprical_pd = tibble(map(c($[_input[\"regional\"]:r,]), ~read_delim(.x,\"\\t\")))%>%unnest()\n",
    "    emprical_pd[\"q_beta\"] = tryCatch(qvalue(emprical_pd$p_beta)$qvalue, error = function(e){print(\"Too few pvalue to calculate qvalue, fall back to BH\") \n",
    "                                                                                              qvalue(emprical_pd$p_beta,pi0 = 1 )$qvalue})  \n",
    "\n",
    "    emprical_pd[\"q_perm\"] = tryCatch(qvalue(emprical_pd$p_perm)$qvalue, error = function(e){print(\"Too few pvalue to calculate qvalue, fall back to BH\") \n",
    "                                                                                              qvalue(emprical_pd$p_perm,pi0 = 1 )$qvalue})\n",
    "    emprical_pd[\"fdr_beta\"] = p.adjust(emprical_pd$p_beta,\"fdr\")    \n",
    "    emprical_pd[\"fdr_perm\"] = p.adjust(emprical_pd$p_perm,\"fdr\")    \n",
    "    summary = tibble(\"fdr_perm_0.05\" =  sum(emprical_pd[\"fdr_perm\"] < 0.05) , \n",
    "                      \"fdr_beta_0.05\" = sum(emprical_pd[\"fdr_beta\"] < 0.05),\n",
    "                      \"q_perm_0.05\" = sum(emprical_pd[\"q_perm\"] < 0.05) ,\n",
    "                      \"q_beta_0.05\" = sum(emprical_pd[\"q_beta\"] < 0.05) ,\n",
    "                       \"q_perm_0.01\" = sum(emprical_pd[\"q_perm\"] < 0.01) ,\n",
    "                      \"q_beta_0.01\" = sum(emprical_pd[\"q_beta\"] < 0.01)  )\n",
    "    emprical_pd%>%write_delim(\"$[_output[0]]\",\"\\t\")\n",
    "    summary%>%write_delim(\"$[_output[1]]\",\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Trans-xQTL association testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "For transQTL analysis, if you output all the p-values for many genes (default setting) it is suggested to provide the largest memory and CPU threads available on a compute node. eg 250G and >32 threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[trans_1]\n",
    "input: input_files, group_by = len(input_files[0]), group_with = \"input_chroms\"\n",
    "output: nominal = f'{cwd:a}/{_input[0]:bnn}{\"\" if input_chroms[_index] == 0 else \"_%s\" % input_chroms[_index]}.trans_qtl.pairs.tsv.gz'\n",
    "\n",
    "parameter: batch_size = 10000\n",
    "parameter: pval_threshold = 1.0\n",
    "# Permutation testing is incorrect when the analysis is done by chrom\n",
    "parameter: permutation = False\n",
    "\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "python: expand= \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',container =container, entrypoint = entrypoint\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import tensorqtl\n",
    "    from tensorqtl import genotypeio, trans\n",
    "    from scipy.stats import chi2\n",
    "\n",
    "    ## Define paths\n",
    "    plink_prefix_path = $[_input[1]:nar]\n",
    "    expression_bed = $[_input[0]:ar]\n",
    "    covariates_file = \"$[covariate_file:a]\"\n",
    "    window = $[window]\n",
    "    ## Loading Data\n",
    "    phenotype_df, phenotype_pos_df = tensorqtl.read_phenotype_bed(expression_bed)\n",
    "    phenotype_id = phenotype_pos_df.index.name\n",
    "\n",
    "    ## Analyze only the regions listed\n",
    "    if $[region_list.is_file()]:\n",
    "        region = pd.read_csv(\"$[region_list:a]\", comment=\"#\", header=None,sep=\"\\t\")\n",
    "        phenotype_column = 1 if len(region.columns) == 1 else  $[region_list_phenotype_column]\n",
    "        keep_region = region.iloc[:,phenotype_column-1].to_list()\n",
    "        phenotype_df = phenotype_df[phenotype_df.index.isin(keep_region)]\n",
    "        phenotype_pos_df = phenotype_pos_df[phenotype_pos_df.index.isin(keep_region)]\n",
    "\n",
    "    ## use custom cis windows\n",
    "    if $[customized_cis_windows.is_file()]:\n",
    "        cis_list = pd.read_csv(\"$[customized_cis_windows:a]\", comment=\"#\", header=None, names=[\"chr\",\"start\",\"end\",phenotype_id], sep=\"\\t\")\n",
    "        phenotype_pos_df_reset = phenotype_pos_df.reset_index() #move the phenotype id index to a new column of the dataframe\n",
    "        phenotype_pos_df = phenotype_pos_df_reset.merge(cis_list, left_on = [\"chr\",phenotype_id],right_on = [cis_list.columns[0],cis_list.columns[3]])#in some cases (gene expression for eQTLs) the phenotype_id may be in the cis_list file\n",
    "        if len(phenotype_df.index) - phenotype_pos_df_reset[~phenotype_pos_df_reset[phenotype_id].isin(cis_list[phenotype_id])].shape[0]!= len(phenotype_pos_df.index):\n",
    "            raise ValueError(\"cannot uniquely match all the phentoype data in the input to the customized cis windows provided\")\n",
    "        phenotype_pos_df = phenotype_pos_df.set_index(phenotype_id)[[\"chr\",\"start\",\"end\"]] # The final phenotype_pos_df will have three columns(chr, start, end) and index is the phenotype ID\n",
    "        window = 0 # In the updated tensorQTL, by default if there is a customized cis window, the actual cis window will be start - window & end + window, so it is necessary to change the window parameter to 0\n",
    "        ## Retaining only traits in cis_list\n",
    "        if phenotype_pos_df_reset[~phenotype_pos_df_reset[phenotype_id].isin(cis_list[phenotype_id])].shape[0] != 0:\n",
    "            phenotype_df = phenotype_df.loc[phenotype_df.index.isin(cis_list[phenotype_id])]\n",
    "\n",
    "    covariates_df = pd.read_csv(covariates_file, sep='\\t', index_col=0).T\n",
    "    ## use custom sample list to subset the covariates data\n",
    "    if $[keep_sample.is_file()]:\n",
    "        sample_list = pd.read_csv(\"$[keep_sample:a]\", comment=\"#\", header=None, names=[\"sample_id\"], sep=\"\\t\")\n",
    "        covariates_df.loc[sample_list.sample_id]\n",
    "    pr = genotypeio.PlinkReader(plink_prefix_path)\n",
    "    genotype_df = pr.load_genotypes()\n",
    "    variant_df = pr.bim.set_index('snp')[['chrom', 'pos','a0','a1']]\n",
    "\n",
    "    ## Retaining only common samples\n",
    "    phenotype_df = phenotype_df[np.intersect1d(phenotype_df.columns, covariates_df.index)]\n",
    "    phenotype_df = phenotype_df[np.intersect1d(phenotype_df.columns, genotype_df.columns)]\n",
    "    covariates_df = covariates_df.transpose()[np.intersect1d(phenotype_df.columns, covariates_df.index)].transpose()\n",
    "\n",
    "    ## To simplify things, there should really not be \"chr\" prefix\n",
    "    phenotype_pos_df.chr = [x.replace(\"chr\",\"\") for x in phenotype_pos_df.chr]\n",
    "    variant_df.chrom = [x.replace(\"chr\",\"\") for x in variant_df.chrom]\n",
    "\n",
    "    ## Trans analysis\n",
    "    trans_df = trans.map_trans(genotype_df, \n",
    "                            phenotype_df,\n",
    "                            covariates_df, \n",
    "                            batch_size=$[batch_size],\n",
    "                            return_sparse=True, \n",
    "                            return_r2 = True,\n",
    "                            pval_threshold=$[pval_threshold], \n",
    "                            maf_threshold=$[maf_threshold])\n",
    "\n",
    "    ## Filter out cis signal, again if customized cis windows are used, the windows is [start-win,end + win] where win = 0, else it is [start - win, start + win]\n",
    "    trans_df = trans.filter_cis(trans_df, phenotype_pos_df, variant_df, window=window)   \n",
    "\n",
    "    ## Permutation\n",
    "    if $['True' if permutation else 'False']:\n",
    "        perm_df = trans.map_permutations(genotype_df, covariates_df, batch_size=$[batch_size],\n",
    "                             maf_threshold=$[maf_threshold])\n",
    "        trans.apply_permutations(perm_df,trans_df)\n",
    "\n",
    "    ## Output\n",
    "    trans_df.columns.values[1]  = \"molecular_trait_id\"\n",
    "    trans_df.columns.values[2]  = \"pvalue\"\n",
    "    trans_df.columns.values[3]  = \"beta\"\n",
    "    trans_df.columns.values[4]  = \"se\"\n",
    "    trans_df[\"n\"] = len(phenotype_df.columns.values)\n",
    "    trans_df = variant_df.merge(trans_df, right_on='variant_id', left_index=True)\n",
    "    trans_df.rename(columns={'a1': 'a2', 'a0': 'a1'}, inplace=True)\n",
    "    # genomic inflation factor\n",
    "    lambda_col = trans_df.groupby(\"molecular_trait_id\").apply(lambda x: chi2.ppf(1. - np.median(x.pvalue), 1)/chi2.ppf(0.5,1))\n",
    "    # Convert the Series to a DataFrame\n",
    "    lambda_col = lambda_col.reset_index()\n",
    "    lambda_col.columns = ['molecular_trait_id', 'genomic_inflation_lambda']\n",
    "    lambda_col.to_csv(\"$[_output:nnn].genomic_inflation.tsv.gz\", sep='\\t', index = None, compression={'method': 'gzip', 'compresslevel': 9})\n",
    "\n",
    "    # sort the table if chrom and pos is not in ascending order\n",
    "    if not all(trans_df['pos'].iloc[i] <= trans_df['pos'].iloc[i+1] for i in range(len(trans_df)-1)):\n",
    "        trans_df = trans_df.sort_values(by=['chrom', 'pos'])\n",
    " \n",
    "    # print general information of trans_df\n",
    "    print('Output Information:')\n",
    "    print(\"Output Rows:\", len(trans_df))\n",
    "    print(\"Output Columns:\", trans_df.columns.tolist())\n",
    "    print(\"Output Preview:\", trans_df.iloc[0:5, 0:10])\n",
    "    \n",
    "    # save output\n",
    "    trans_df.to_csv($[_output[\"nominal\"]:nr], sep='\\t', index = None)\n",
    "\n",
    "\n",
    "R: expand= \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',container =container, entrypoint = entrypoint   \n",
    "    if ($['FALSE' if permutation and pval_threshold < 1.0 else 'TRUE']){ \n",
    "      library(purrr)\n",
    "      library(tidyr)\n",
    "      library(readr)\n",
    "      library(dplyr)\n",
    "      library(qvalue)\n",
    "      # calculate qvalue\n",
    "      pairs_df = read_delim($[_output[\"nominal\"]:nr,], delim = '\\t')  \n",
    "      pairs_df = pairs_df %>% group_by(molecular_trait_id) %>% mutate(qvalue = qvalue(pvalue)$qvalues)\n",
    "      pairs_df %>% write_delim($[_output[\"nominal\"]:nr],\"\\t\")\n",
    "    } \n",
    "\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output[\"nominal\"]:nnn}.stderr', stdout = f'{_output[\"nominal\"]:nnn}.stdout', container = container, entrypoint = entrypoint\n",
    "        bgzip --compress-level 9 $[_output[\"nominal\"]:n] \n",
    "        tabix -S 1 -s 1 -b 2 -e 2 $[_output[\"nominal\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.23.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
