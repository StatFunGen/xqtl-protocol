{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Quantile regression for QTL association testing\n",
    "This notebook implements a workflow for using [quantile regression of QTL](https://pubmed.ncbi.nlm.nih.gov/37333162/)  and quantile TWAS to perform quantile QTL association testing and get TWAS weight. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Input\n",
    "\n",
    "1. A list of regions to be analyzed (optional); the last column of this file should be region name.\n",
    "2. Either a list of per chromosome genotype files, or one file for genotype data of the entire genome. Genotype data has to be in PLINK `bed` format. \n",
    "3. Vector of lists of phenotype files per region to be analyzed, in UCSC `bed.gz` with index in `bed.gz.tbi` formats.\n",
    "4. Vector of covariate files corresponding to the lists above.\n",
    "5. Customized association windows file for variants (cis or trans). If it is not provided, a fixed sized window will be used around the region (a cis-window)\n",
    "6. Optionally a vector of names of the phenotypic conditions in the form of `cond1 cond2 cond3` separated with whitespace.\n",
    "\n",
    "Input 2 and 3 should be outputs from `genotype_per_region` and `annotate_coord` modules in previous preprocessing steps. 4 should be output of `covariate_preprocessing` pipeline that contains genotype PC, phenotypic hidden confounders and fixed covariates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "### Example genotype data\n",
    "\n",
    "```\n",
    "#chr        path\n",
    "chr21 /mnt/mfs/statgen/xqtl_workflow_testing/protocol_example.genotype.chr21.bed\n",
    "chr22 /mnt/mfs/statgen/xqtl_workflow_testing/protocol_example.genotype.chr22.bed\n",
    "```\n",
    "\n",
    "Alternatively, simply use `protocol_example.genotype.chr21_22.bed` if all chromosomes are in the same file.\n",
    "\n",
    "### Example phenotype list\n",
    "\n",
    "```\n",
    "#chr    start   end ID  path\n",
    "chr12   752578  752579  ENSG00000060237  /home/gw/GIT/github/fungen-xqtl-analysis/analysis/Wang_Columbia/ROSMAP/MWE/output/phenotype/protocol_example.protein.bed.gz\n",
    "chr12   990508  990509  ENSG00000082805  /home/gw/GIT/github/fungen-xqtl-analysis/analysis/Wang_Columbia/ROSMAP/MWE/output/phenotype/protocol_example.protein.bed.gz\n",
    "chr12   2794969 2794970 ENSG00000004478  /home/gw/GIT/github/fungen-xqtl-analysis/analysis/Wang_Columbia/ROSMAP/MWE/output/phenotype/protocol_example.protein.bed.gz\n",
    "chr12   4649113 4649114 ENSG00000139180  /home/gw/GIT/github/fungen-xqtl-analysis/analysis/Wang_Columbia/ROSMAP/MWE/output/phenotype/protocol_example.protein.bed.gz\n",
    "chr12   6124769 6124770 ENSG00000110799  /home/gw/GIT/github/fungen-xqtl-analysis/analysis/Wang_Columbia/ROSMAP/MWE/output/phenotype/protocol_example.protein.bed.gz\n",
    "chr12   6534516 6534517 ENSG00000111640  /home/gw/GIT/github/fungen-xqtl-analysis/analysis/Wang_Columbia/ROSMAP/MWE/output/phenotype/protocol_example.protein.bed.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Example association-window file\n",
    "\n",
    "It should have strictly 4 columns, with the header a commented out line:\n",
    "\n",
    "```\n",
    "#chr    start    end    gene_id\n",
    "chr10   0    6480000    ENSG00000008128\n",
    "chr1    0    6480000    ENSG00000008130\n",
    "chr1    0    6480000    ENSG00000067606\n",
    "chr1    0    7101193    ENSG00000069424\n",
    "chr1    0    7960000    ENSG00000069812\n",
    "chr1    0    6480000    ENSG00000078369\n",
    "chr1    0    6480000    ENSG00000078808\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "The key is that the 4th column ID should match with the 4th column ID in the phenotype list. Otherwise the association-window to analyze will not be found.\n",
    "\n",
    "### About indels\n",
    "\n",
    "Option `--no-indel` will remove indel from analysis. FIXME: Gao need to provide more guidelines how to deal with indels in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Output\n",
    "\n",
    "For each analysis region, the output is quantile qtl model and quantile twas fitted and saved in RDS format.\n",
    "\n",
    "For each gene, several of summary statistics files are generated, including all quantile qtl nominal test statistics for each test.\n",
    "\n",
    "The columns of significant quantile qtl nominal association result are as follows:\n",
    "\n",
    "- chr : Variant chromosome.\n",
    "- pos : Variant chromosomal position (basepairs).\n",
    "- ref : Variant reference allele (A, C, T, or G).\n",
    "- alt : Variant alternate allele.\n",
    "- phenotype_id: Molecular trait identifier.(gene)\n",
    "- variant_id: ID of the variant (rsid or chr:position:ref:alt)\n",
    "- p_qr(composite-p value using cauchy combination method): the integrated QR p-value across multiple quantile levels. \n",
    "- p_qr_0.05 to p_qr_0.95: quantile-specific QR p-values for the quantile levels 0.05, 0.1, ..., 0.95.  \n",
    "- qvalue_qr: the q-value of p_qr. \n",
    "- qvalue_qr_0.05 to qvalue_qr_0.95: quantile-specific QR q-values for the quantile levels 0.05, 0.1, ..., 0.95. \n",
    "- zscore_qr_0.05 to zscore_qr_0.95: quantile-specific QR standard errors for the quantile levels 0.05, 0.1, ..., 0.95. \n",
    "- coef_qr_0.05 to coef_qr_0.95 only for snps after LD clumping: quantile-specific QR coefficients for the quantile levels 0.05, 0.1, ..., 0.95. \n",
    "\n",
    "\n",
    "\n",
    "Additionally, the matrix of quantile TWAS weights and pseudo R-squares is calculated and saved using Koenker and Machado's Pseudo RÂ² method, as described in their [Koenker and Machado, 1999: Inference in Quantile Regression](https://www.maths.usyd.edu.au/u/jchan/GLM/Koenker&Machado1999InferenceQuantileReg.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Minimal Working Example Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Timing [FIXME]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Below we duplicate the examples for phenotype and covariates to demonstrate that when there are multiple phenotypes for the same genotype it is possible to use this pipeline to analyze all of them (more than two is accepted as well).\n",
    "\n",
    "Here using `--region-name` we focus the analysis on 3 genes. In practice if this parameter is dropped, the union of all regions in all phenotype region lists will be analyzed. It is possible for some of the regions there are no genotype data, in which case the pipeline will output RDS files with a warning message to indicate the lack of genotype data to analyze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "**Note:** Suggested output naming convention is cohort_modality, eg ROSMAP_snRNA_pseudobulk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sos run pipeline/quantile_twas.ipynb quantile_qtl_twas_weight  \\\n",
    "    --name protocol_example_protein  \\\n",
    "    --genoFile input/xqtl_association/protocol_example.genotype.chr21_22.bed   \\\n",
    "    --phenoFile output/phenotype/protocol_example.protein.region_list.txt \\\n",
    "                output/phenotype/protocol_example.protein.region_list.txt \\\n",
    "    --covFile output/covariate/protocol_example.protein.protocol_example.samples.protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.Marchenko_PC.gz \\\n",
    "              output/covariate/protocol_example.protein.protocol_example.samples.protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.Marchenko_PC.gz  \\\n",
    "    --customized-association-windows input/xqtl_association/protocol_example.protein.enhanced_cis_chr21_chr22.bed \\\n",
    "    --region-name ENSG00000241973_P42356 ENSG00000160209_O00764 ENSG00000100412_Q99798 \\\n",
    "    --phenotype-names trait_A trait_B \\\n",
    "    --container oras://ghcr.io/cumc/pecotmr_apptainer:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "It is also possible to analyze a selected list of regions using option `--region-list`. The last column of this file will be used for the list to analyze. Here for example use the same list of regions as we used for customized association-window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sos run xqtl-protocol/pipeline/quantile_twas.ipynb quantile_qtl_twas_weight  \\\n",
    "    --name protocol_example_protein  \\\n",
    "    --genoFile xqtl_association/protocol_example.genotype.chr21_22.bed   \\\n",
    "    --phenoFile output/phenotype/protocol_example.protein.region_list.txt \\\n",
    "                output/phenotype/protocol_example.protein.region_list.txt \\\n",
    "    --covFile output/covariate/protocol_example.protein.protocol_example.samples.protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.Marchenko_PC.gz \\\n",
    "              output/covariate/protocol_example.protein.protocol_example.samples.protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.Marchenko_PC.gz  \\\n",
    "    --customized-association-windows xqtl_association/protocol_example.protein.enhanced_cis_chr21_chr22.bed \\\n",
    "    --region-list xqtl_association/protocol_example.protein.enhanced_cis_chr21_chr22.bed \\\n",
    "    --phenotype-names trait_A trait_B \\\n",
    "    --container oras://ghcr.io/cumc/pecotmr_apptainer:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "**Note:** When both `--region-name` and `--region-list` are used, the union of regions from these parameters will be analyzed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "It is also possible to specify a subset of samples to analyze, using `--keep-samples` parameter. For example we create a file to keep the ID of 50 samples,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "zcat output/covariate/protocol_example.protein.protocol_example.samples.protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.Marchenko_PC.gz | head -1 | awk '{for (i=2; i<=51; i++) printf $i \" \"; print \"\"}'> output/keep_samples.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "| Step | Substep | Problem | Possible Reason | Solution |\n",
    "|------|---------|---------|------------------|---------|\n",
    "|  |  |  |  |  |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Command interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run quantile_twas.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Workflow implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# It is required to input the name of the analysis\n",
    "parameter: name = str\n",
    "parameter: cwd = path(\"output\")\n",
    "# A list of file paths for genotype data, or the genotype data itself. \n",
    "parameter: genoFile = path\n",
    "# One or multiple lists of file paths for phenotype data.\n",
    "parameter: phenoFile = paths\n",
    "# One or multiple lists of file paths for phenotype ID mapping file. The first column should be the original ID, the 2nd column should be the ID to be mapped to.\n",
    "parameter: phenoIDFile = paths()\n",
    "# Covariate file path\n",
    "parameter: covFile = paths\n",
    "# Optional: if a region list is provide the analysis will be focused on provided region. \n",
    "# The LAST column of this list will contain the ID of regions to focus on\n",
    "# Otherwise, all regions with both genotype and phenotype files will be analyzed\n",
    "parameter: region_list = path()\n",
    "# Optional: if a region name is provided \n",
    "# the analysis would be focused on the union of provides region list and region names\n",
    "parameter: region_name = []\n",
    "# Only focus on a subset of samples\n",
    "parameter: keep_samples = path()\n",
    "# An optional list documenting the custom association window for each region to analyze, with four column, chr, start, end, region ID (eg gene ID).\n",
    "# If this list is not provided, the default `window` parameter (see below) will be used.\n",
    "parameter: customized_association_windows = path()\n",
    "# Specify the cis window for the up and downstream radius to analyze around the region of interest in units of bp\n",
    "# When this is set to negative, we will rely on using customized_association_windows\n",
    "parameter: cis_window = -1\n",
    "# save data object or not\n",
    "parameter: save_data = False\n",
    "# Name of phenotypes\n",
    "parameter: phenotype_names = [f'{x:bn}' for x in phenoFile]\n",
    "parameter: seed = 999\n",
    "# remove a variant if it has more than imiss missing individual level data\n",
    "parameter: imiss = 1.0\n",
    "# MAF cutoff\n",
    "parameter: maf = 0.0025\n",
    "# MAC cutoff, on top of MAF cutoff\n",
    "parameter: mac = 5\n",
    "# Remove indels if indel = False\n",
    "parameter: indel = True\n",
    "parameter: min_twas_maf = 0.01\n",
    "parameter: screen_threshold = 0.01\n",
    "parameter: ld_reference_meta_file = path()\n",
    "# Analysis environment settings\n",
    "parameter: container = \"\"\n",
    "import re\n",
    "parameter: entrypoint= ('micromamba run -a \"\" -n' + ' ' + re.sub(r'(_apptainer:latest|_docker:latest|\\.sif)$', '', container.split('/')[-1])) if container else \"\"\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 200\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"1h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"20G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 1\n",
    "\n",
    "if len(phenoFile) != len(covFile):\n",
    "    raise ValueError(\"Number of input phenotypes files must match that of covariates files\")\n",
    "if len(phenoFile) != len(phenotype_names):\n",
    "    raise ValueError(\"Number of input phenotypes files must match the number of phenotype names\")\n",
    "if len(phenoIDFile) > 0 and len(phenoFile) != len(phenoIDFile):\n",
    "    raise ValueError(\"Number of input phenotypes files must match the number of phenotype ID mapping files\")\n",
    "\n",
    "def group_by_region(lst, partition):\n",
    "    # from itertools import accumulate\n",
    "    # partition = [len(x) for x in partition]\n",
    "    # Compute the cumulative sums once\n",
    "    # cumsum_vector = list(accumulate(partition))\n",
    "    # Use slicing based on the cumulative sums\n",
    "    # return [lst[(cumsum_vector[i-1] if i > 0 else 0):cumsum_vector[i]] for i in range(len(partition))]\n",
    "    return partition\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def adapt_file_path(file_path, reference_file):\n",
    "    \"\"\"\n",
    "    Adapt a single file path based on its existence and a reference file's path.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): The file path to adapt.\n",
    "    - reference_file (str): File path to use as a reference for adaptation.\n",
    "\n",
    "    Returns:\n",
    "    - str: Adapted file path.\n",
    "\n",
    "    Raises:\n",
    "    - FileNotFoundError: If no valid file path is found.\n",
    "    \"\"\"\n",
    "    reference_path = os.path.dirname(reference_file)\n",
    "\n",
    "    # Check if the file exists\n",
    "    if os.path.isfile(file_path):\n",
    "        return file_path\n",
    "\n",
    "    # Check file name without path\n",
    "    file_name = os.path.basename(file_path)\n",
    "    if os.path.isfile(file_name):\n",
    "        return file_name\n",
    "\n",
    "    # Check file name in reference file's directory\n",
    "    file_in_ref_dir = os.path.join(reference_path, file_name)\n",
    "    if os.path.isfile(file_in_ref_dir):\n",
    "        return file_in_ref_dir\n",
    "\n",
    "    # Check original file path prefixed with reference file's directory\n",
    "    file_prefixed = os.path.join(reference_path, file_path)\n",
    "    if os.path.isfile(file_prefixed):\n",
    "        return file_prefixed\n",
    "\n",
    "    # If all checks fail, raise an error\n",
    "    raise FileNotFoundError(f\"No valid path found for file: {file_path}\")\n",
    "\n",
    "def adapt_file_path_all(df, column_name, reference_file):\n",
    "    return df[column_name].apply(lambda x: adapt_file_path(x, reference_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[get_analysis_regions: shared = \"regional_data\"]\n",
    "# input is genoFile, phenoFile, covFile and optionally region_list. If region_list presents then we only analyze what's contained in the list.\n",
    "# regional_data should be a dictionary like:\n",
    "#{'data': [(\"genotype_1.bed\", \"phenotype_1.bed.gz\", \"covariate_1.gz\"), (\"genotype_2.bed\", \"phenotype_1.bed.gz\", \"phenotype_2.bed.gz\", \"covariate_1.gz\", \"covariate_2.gz\") ... ],\n",
    "# 'meta_info': [(\"chr12:752578-752579\",\"chr12:752577-752580\", \"gene_1\", \"trait_1\"), (\"chr13:852580-852581\",\"chr13:852579-852580\", \"gene_2\", \"trait_1\", \"trait_2\") ... ]}\n",
    "import numpy as np\n",
    "\n",
    "def preload_id_map(id_map_files):\n",
    "    id_maps = {}\n",
    "    for id_map_file in id_map_files:\n",
    "        if id_map_file is not None and os.path.isfile(id_map_file):\n",
    "            df = pd.read_csv(id_map_file, sep='\\s+', header=None, comment='#', names=['old_ID', 'new_ID'])\n",
    "            id_maps[id_map_file] = df.set_index('old_ID')['new_ID'].to_dict()\n",
    "    return id_maps\n",
    "\n",
    "def load_and_apply_id_map(pheno_path, id_map_path, preloaded_id_maps):\n",
    "    pheno_df = pd.read_csv(pheno_path, sep=\"\\s+\", header=0)\n",
    "    pheno_df['Original_ID'] = pheno_df['ID']\n",
    "    if id_map_path in preloaded_id_maps:\n",
    "        id_map = preloaded_id_maps[id_map_path]\n",
    "        pheno_df['ID'] = pheno_df['ID'].map(id_map).fillna(pheno_df['ID'])\n",
    "    return pheno_df\n",
    "\n",
    "def filter_by_region_ids(data, region_ids):\n",
    "    if region_ids is not None and len(region_ids) > 0:\n",
    "        data = data[data['ID'].isin(region_ids)]\n",
    "    return data\n",
    "\n",
    "def custom_join(series):\n",
    "    # Initialize an empty list to hold the processed items\n",
    "    result = []\n",
    "    for item in series:\n",
    "        if ',' in item:\n",
    "            # If the item contains commas, split by comma and convert to tuple\n",
    "            result.append(tuple(item.split(',')))\n",
    "        else:\n",
    "            # If the item does not contain commas, add it directly\n",
    "            result.append(item)\n",
    "    # Convert the list of items to a tuple and return\n",
    "    return tuple(result)\n",
    "\n",
    "def aggregate_phenotype_data(accumulated_pheno_df):\n",
    "    if not accumulated_pheno_df.empty:\n",
    "        accumulated_pheno_df = accumulated_pheno_df.groupby(['#chr','ID','cond','path','cov_path'], as_index=False).agg({\n",
    "            '#chr': lambda x: np.unique(x).astype(str)[0],\n",
    "            'ID': lambda x: np.unique(x).astype(str)[0],\n",
    "            'Original_ID': ','.join,\n",
    "            'start': 'min',\n",
    "            'end': 'max'\n",
    "        }).groupby(['#chr','ID'], as_index=False).agg({\n",
    "            'cond': ','.join,\n",
    "            'path': ','.join,\n",
    "            'Original_ID': custom_join,\n",
    "            'cov_path': ','.join,\n",
    "            'start': 'min',\n",
    "            'end': 'max'\n",
    "        })\n",
    "    return accumulated_pheno_df\n",
    "\n",
    "def process_cis_files(pheno_files, cov_files, phenotype_names, pheno_id_files, region_ids, preloaded_id_maps):\n",
    "    '''\n",
    "    Example output:\n",
    "    #chr    start      end    ID  Original_ID   path     cov_path             cond\n",
    "    chr12   752578   752579  ENSG00000060237  Q9H4A3,P62873  protocol_example.protein_1.bed.gz,protocol_example.protein_2.bed.gz  covar_1.gz,covar_2.gz  trait_A,trait_B\n",
    "    '''\n",
    "    accumulated_pheno_df = pd.DataFrame()\n",
    "    pheno_id_files = [None] * len(pheno_files) if len(pheno_id_files) == 0 else pheno_id_files\n",
    "    for pheno_path, cov_path, phenotype_name, id_map_path in zip(pheno_files, cov_files, phenotype_names, pheno_id_files):\n",
    "        if not os.path.isfile(cov_path):\n",
    "            raise FileNotFoundError(f\"No valid path found for file: {cov_path}\")\n",
    "        pheno_df = load_and_apply_id_map(pheno_path, id_map_path, preloaded_id_maps)\n",
    "        pheno_df = filter_by_region_ids(pheno_df, region_ids)\n",
    "        if not pheno_df.empty:\n",
    "            pheno_df.iloc[:, 4] = adapt_file_path_all(pheno_df, pheno_df.columns[4], f\"{pheno_path:a}\")\n",
    "            pheno_df = pheno_df.assign(cov_path=str(cov_path), cond=phenotype_name)           \n",
    "            accumulated_pheno_df = pd.concat([accumulated_pheno_df, pheno_df], ignore_index=True)\n",
    "\n",
    "    accumulated_pheno_df = aggregate_phenotype_data(accumulated_pheno_df)\n",
    "    return accumulated_pheno_df\n",
    "\n",
    "def process_trans_files(pheno_files, cov_files, phenotype_names, pheno_id_files, region_ids, customized_association_windows):\n",
    "    '''\n",
    "    Example output:\n",
    "    #chr    start      end    ID  Original_ID   path     cov_path             cond\n",
    "    chr21   0   0  chr21_18133254_19330300  carnitine,benzoate,hippurate  metabolon_1.bed.gz,metabolon_2.bed.gz  covar_1.gz,covar_2.gz  trait_A,trait_B\n",
    "    '''\n",
    "    \n",
    "    if not os.path.isfile(customized_association_windows):\n",
    "        raise ValueError(\"Customized association analysis window must be specified for trans analysis.\")\n",
    "    accumulated_pheno_df = pd.DataFrame()\n",
    "    pheno_id_files = [None] * len(pheno_files) if len(pheno_id_files) == 0 else pheno_id_files\n",
    "    genotype_windows = pd.read_csv(customized_association_windows, comment=\"#\", header=None, names=[\"#chr\",\"start\",\"end\",\"ID\"], sep=\"\\t\")\n",
    "    genotype_windows = filter_by_region_ids(genotype_windows, region_ids)\n",
    "    if genotype_windows.empty:\n",
    "        return accumulated_pheno_df\n",
    "    \n",
    "    for pheno_path, cov_path, phenotype_name, id_map_path in zip(pheno_files, cov_files, phenotype_names, pheno_id_files):\n",
    "        if not os.path.isfile(cov_path):\n",
    "            raise FileNotFoundError(f\"No valid path found for file: {cov_path}\")\n",
    "        pheno_df = pd.read_csv(pheno_path, sep=\"\\s+\", header=0, names=['Original_ID', 'path'])\n",
    "        if not pheno_df.empty:\n",
    "            pheno_df.iloc[:, -1] = adapt_file_path_all(pheno_df, pheno_df.columns[-1], f\"{pheno_path:a}\")\n",
    "            pheno_df = pheno_df.assign(cov_path=str(cov_path), cond=phenotype_name)\n",
    "            # Here we combine genotype_windows which contains \"#chr\" and \"ID\" to pheno_df by creating a cartesian product\n",
    "            pheno_df = pd.merge(genotype_windows.assign(key=1), pheno_df.assign(key=1), on='key').drop('key', axis=1)\n",
    "            # then set start and end columns to zero\n",
    "            pheno_df['start'] = 0\n",
    "            pheno_df['end'] = 0\n",
    "            if id_map_path is not None:\n",
    "                # Filter pheno_df by specific association-window and phenotype pairs\n",
    "                association_analysis_pair = pd.read_csv(id_map_path, sep='\\s+', header=None, comment='#', names=['ID', 'Original_ID'])\n",
    "                pheno_df = pd.merge(pheno_df, association_analysis_pair, on=['ID', 'Original_ID'])\n",
    "            accumulated_pheno_df = pd.concat([accumulated_pheno_df, pheno_df], ignore_index=True)\n",
    "\n",
    "    accumulated_pheno_df = aggregate_phenotype_data(accumulated_pheno_df)\n",
    "    return accumulated_pheno_df\n",
    "\n",
    "# Load genotype meta data\n",
    "if f\"{genoFile:x}\" == \".bed\":\n",
    "    geno_meta_data = pd.DataFrame([(\"chr\"+str(x), f\"{genoFile:a}\") for x in range(1,23)] + [(\"chrX\", f\"{genoFile:a}\")], columns=['#chr', 'geno_path'])\n",
    "else:\n",
    "    geno_meta_data = pd.read_csv(f\"{genoFile:a}\", sep = \"\\s+\", header=0)\n",
    "    geno_meta_data.iloc[:, 1] = adapt_file_path_all(geno_meta_data, geno_meta_data.columns[1], f\"{genoFile:a}\")\n",
    "    geno_meta_data.columns = ['#chr', 'geno_path']\n",
    "    geno_meta_data['#chr'] = geno_meta_data['#chr'].apply(lambda x: str(x) if str(x).startswith('chr') else f'chr{x}')\n",
    "\n",
    "# Checking the DataFrame\n",
    "valid_chr_values = [f'chr{x}' for x in range(1, 23)] + ['chrX']\n",
    "if not all(value in valid_chr_values for value in geno_meta_data['#chr']):\n",
    "    raise ValueError(\"Invalid chromosome values found. Allowed values are chr1 to chr22 and chrX.\")\n",
    "\n",
    "region_ids = []\n",
    "# If region_list is provided, read the file and extract IDs\n",
    "if region_list.is_file():\n",
    "    region_list_df = pd.read_csv(region_list, delim_whitespace=True, header=None, comment = \"#\")\n",
    "    region_ids = region_list_df.iloc[:, -1].unique()  # Extracting the last column for IDs\n",
    "# If region_name is provided, include those IDs as well\n",
    "# --region-name A B C will result in a list of [\"A\", \"B\", \"C\"] here\n",
    "if len(region_name) > 0:\n",
    "    region_ids = list(set(region_ids).union(set(region_name)))\n",
    "\n",
    "trans_analysis = False\n",
    "if trans_analysis:\n",
    "    meta_data = process_trans_files(phenoFile, covFile, phenotype_names, phenoIDFile, region_ids, customized_association_windows)\n",
    "else:\n",
    "    meta_data = process_cis_files(phenoFile, covFile, phenotype_names, phenoIDFile, region_ids, preload_id_map(phenoIDFile))\n",
    "\n",
    "if not meta_data.empty:\n",
    "    meta_data = meta_data.merge(geno_meta_data, on='#chr', how='inner')\n",
    "    # Adjust association-window\n",
    "    if os.path.isfile(customized_association_windows):\n",
    "        print(f\"Loading customized association analysis window from {customized_association_windows}\")\n",
    "        association_windows_list = pd.read_csv(customized_association_windows, comment=\"#\", header=None, names=[\"#chr\",\"start\",\"end\",\"ID\"], sep=\"\\t\")\n",
    "        meta_data = pd.merge(meta_data, association_windows_list, on=['#chr', 'ID'], how='left', suffixes=('', '_association'))\n",
    "        mismatches = meta_data[meta_data['start_association'].isna()]\n",
    "        if not mismatches.empty:\n",
    "            raise ValueError(f\"{len(mismatches)} regions to analyze cannot be found in ``{customized_association_windows}``. Please check your ``{customized_association_windows}`` database to make sure it contains all association-window definitions. \")\n",
    "    else:\n",
    "        if cis_window < 0 :\n",
    "            raise ValueError(\"Please either input valid path to association-window file via ``--customized-association-windows``, or set ``--cis-window`` to a non-negative integer.\")\n",
    "        if cis_window == 0:\n",
    "            print(\"Warning: only variants within the range of start and end of molecular phenotype will be considered since cis_window is set to zero and no customized association window file was found. Please make sure this is by design.\")\n",
    "        meta_data['start_association'] = meta_data['start'].apply(lambda x: max(x - cis_window, 0))\n",
    "        meta_data['end_association'] = meta_data['end'] + cis_window\n",
    "\n",
    "    # Example meta_data:\n",
    "    # #chr    start      end    start_association       end_association           ID  Original_ID   path     cov_path             cond             coordinate     geno_path\n",
    "    # 0  chr12   752578   752579  652578   852579  ENSG00000060237  Q9H4A3,P62873  protocol_example.protein_1.bed.gz,protocol_example.protein_2.bed.gz  covar_1.gz,covar_2.gz  trait_A,trait_B    chr12:752578-752579  protocol_example.genotype.chr21_22.bed       \n",
    "    # Create the final dictionary\n",
    "    regional_data = {\n",
    "        'data': [(row['geno_path'], *row['path'].split(','), *row['cov_path'].split(',')) for _, row in meta_data.iterrows()],\n",
    "        'meta_info': [(f\"{row['#chr']}:{row['start']}-{row['end']}\", # this is the phenotypic region to extract data from\n",
    "                       f\"{row['#chr']}:{row['start_association']}-{row['end_association']}\", # this is the association window region\n",
    "                       row['ID'], row['Original_ID'], *row['cond'].split(',')) for _, row in meta_data.iterrows()]\n",
    "    }\n",
    "else:\n",
    "    regional_data = {'data':[], 'meta_info':[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Quantile QTL and quantile TWAS weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[quantile_qtl_twas_weight]\n",
    "depends: sos_variable(\"regional_data\")\n",
    "# Check if both 'data' and 'meta_info' are empty lists\n",
    "stop_if(len(regional_data['data']) == 0, f'Either genotype or phenotype data are not available for region {\", \".join(region_name)}.')\n",
    "\n",
    "meta_info = regional_data['meta_info']\n",
    "input: regional_data[\"data\"], group_by = lambda x: group_by_region(x, regional_data[\"data\"]), group_with = \"meta_info\"\n",
    "output: f'{cwd:a}/{step_name}/{name}.{_meta_info[0].split(\":\")[0]}_{_meta_info[2]}.univariate_qr_twas_weights.rds'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output:n}.stdout\", stderr = f\"{_output:n}.stderr\", container = container, entrypoint = entrypoint\n",
    "    options(warn=1)\n",
    "    library(pecotmr)\n",
    "    start_time_total <- proc.time()\n",
    "    \n",
    "    phenotype_files = c(${\",\".join(['\"%s\"' % x.absolute() for x in _input[1:len(_input)//2+1]])})\n",
    "    covariate_files = c(${\",\".join(['\"%s\"' % x.absolute() for x in _input[len(_input)//2+1:]])})\n",
    "    conditions = c(${\",\".join(['\"%s\"' % x for x in _meta_info[4:]])})\n",
    "    region = ${(\"'%s'\" % _meta_info[0]) if int(_meta_info[0].split('-')[-1])>0 else 'NULL'} # if the end position is zero return NULL\n",
    "    association_window = \"${_meta_info[1]}\"\n",
    "    extract_region_name = list(${\",\".join([(\"c('\"+x+\"')\") if isinstance(x, str) else (\"c\"+ str(x)) for x in _meta_info[3]])})\n",
    "    phenotype_header = ${\"4\" if int(_meta_info[0].split('-')[-1])>0 else \"1\"}\n",
    "    region_name_col = ${\"4\" if int(_meta_info[0].split('-')[-1])>0 else \"1\"} \n",
    "\n",
    "\n",
    "    # extract subset of samples\n",
    "    keep_samples = NULL\n",
    "    if (${\"TRUE\" if keep_samples.is_file() else \"FALSE\"}) {\n",
    "      keep_samples = unlist(strsplit(readLines(${keep_samples:ar}), \"\\\\s+\"))\n",
    "      message(paste(length(keep_samples), \"samples are selected to be loaded for analysis\"))\n",
    "    }\n",
    "\n",
    "    # Load regional association data\n",
    "    tryCatch({\n",
    "    fdat = load_regional_association_data(genotype = ${_input[0]:anr},\n",
    "                                          phenotype = phenotype_files,\n",
    "                                          covariate = covariate_files,\n",
    "                                          region = ${(\"'%s'\" % _meta_info[0]) if int(_meta_info[0].split('-')[-1])>0 else 'NULL'}, # if the end position is zero return NULL\n",
    "                                          association_window = \"${_meta_info[1]}\",\n",
    "                                          conditions = conditions,\n",
    "                                          maf_cutoff = ${maf},\n",
    "                                          mac_cutoff = ${mac},\n",
    "                                          imiss_cutoff = ${imiss},\n",
    "                                          keep_indel = ${\"TRUE\" if indel else \"FALSE\"},\n",
    "                                          keep_samples = keep_samples,\n",
    "                                          extract_region_name = list(${\",\".join([(\"c('\"+x+\"')\") if isinstance(x, str) else (\"c\"+ str(x)) for x in _meta_info[3]])}),\n",
    "                                          phenotype_header = ${\"4\" if int(_meta_info[0].split('-')[-1])>0 else \"1\"},\n",
    "                                          region_name_col = ${\"4\" if int(_meta_info[0].split('-')[-1])>0 else \"1\"},\n",
    "                                          scale_residuals = FALSE)\n",
    "    }, NoSNPsError = function(e) {\n",
    "        message(\"Error: \", paste(e$message, \"${_meta_info[2] + '@' + _meta_info[1]}\"))\n",
    "        saveRDS(list(${_meta_info[2]} = e$message), ${_output:ar}, compress='xz')\n",
    "        quit(save=\"no\")\n",
    "    })\n",
    "  \n",
    "    if (${\"TRUE\" if save_data else \"FALSE\"}) {\n",
    "        # save data object for debug purpose\n",
    "        saveRDS(list(${_meta_info[2]} = fdat), \"${_output:ann}.univariate.rds\", compress='xz')\n",
    "    }\n",
    "    \n",
    "    # setup univariate analysis pipeline options\n",
    "    if (\"${_meta_info[2]}\" != \"${_meta_info[3]}\") {\n",
    "        region_name = c(\"${_meta_info[2]}\", c(${\",\".join([(\"c('\"+x+\"')\") if isinstance(x, str) else (\"c\"+ str(x)) for x in _meta_info[3]])}))\n",
    "    } else {\n",
    "        region_name = \"${_meta_info[2]}\"\n",
    "    }\n",
    "  \n",
    "    region_info = list(region_coord=parse_region(\"${_meta_info[0]}\"), grange=parse_region(\"${_meta_info[1]}\"), region_name=region_name)\n",
    "    \n",
    "    fitted = list()\n",
    "    condition_names = vector()\n",
    "    r = 1\n",
    "    while (r<=length(fdat$Y)) {\n",
    "        X <- fdat$X_data[[r]]  \n",
    "        Y <- fdat$Y[[r]]\n",
    "        if (is.null(dim(Y))) {\n",
    "            Y <- matrix(Y, nrow = length(Y), ncol = 1)\n",
    "        }\n",
    "        colnames(Y) <- extract_region_name[[r]] \n",
    "        Z <- fdat$covar[[r]]     \n",
    "        # Update condition names first\n",
    "        new_names = names(fdat$residual_Y)[r]\n",
    "        new_col_names = list(${\",\".join([(\"c('\"+x+\"')\") if isinstance(x, str) else (\"c\"+ str(x)) for x in _meta_info[3]])})[[r]]\n",
    "        if (is.null(new_col_names)) {\n",
    "            new_col_names = 1:ncol(fdat$residual_Y[[r]])\n",
    "        }\n",
    "        if(!(identical(new_names, new_col_names))) {\n",
    "            new_names = paste(new_names, new_col_names, sep=\"_\")\n",
    "        }\n",
    "                \n",
    "        column_results <- lapply(1:ncol(Y), function(i) {\n",
    "            Y_col <- matrix(Y[,i], ncol=1)\n",
    "            colnames(Y_col) <- colnames(Y)[i]\n",
    "            \n",
    "            qr_results = quantile_twas_weight_pipeline(\n",
    "                X = X, \n",
    "                Y = Y_col,\n",
    "                Z = Z, \n",
    "                ld_reference_meta_file=${('\"%s\"' % ld_reference_meta_file) if not ld_reference_meta_file.is_dir() else \"NULL\"},\n",
    "                maf = fdat$maf[[r]],\n",
    "                twas_maf_cutoff = ${min_twas_maf},                                            \n",
    "                region_id = paste0(colnames(Y_col), \"_\", names(fdat$residual_Y)[r]),\n",
    "                quantile_qtl_tau_list = seq(0.05, 0.95, by = 0.05),\n",
    "                quantile_twas_tau_list = seq(0.01, 0.99, by = 0.01),\n",
    "                screen_threshold = ${screen_threshold}\n",
    "            )\n",
    "            \n",
    "            if (!is.null(qr_results$message)) {\n",
    "                message(qr_results$message)\n",
    "            }\n",
    "            \n",
    "            qr_results$region_info = region_info\n",
    "            qr_results$maf = fdat$maf[[r]]\n",
    "            \n",
    "            return(qr_results)\n",
    "        })\n",
    "        \n",
    "        fitted <- c(fitted, column_results)\n",
    "        condition_names <- c(condition_names, new_names)\n",
    "        \n",
    "        if (length(new_names) > 0) {\n",
    "            message(\"Analysis completed for: \", paste(new_names, collapse=\",\"))\n",
    "        }\n",
    "        \n",
    "        # Release memory\n",
    "        fdat$residual_X[[r]] <- NA\n",
    "        fdat$residual_Y[[r]] <- NA      \n",
    "        r = r + 1\n",
    "    }\n",
    "\n",
    "    # Set names for the final results\n",
    "    if (length(fitted) > 0) {\n",
    "        names(fitted) <- condition_names\n",
    "    }\n",
    "\n",
    "    saveRDS(list(\"${_meta_info[2]}\" = fitted), ${_output:ar}, compress='xz')\n",
    "    end_time_total <- proc.time()\n",
    "    total_time <- end_time_total - start_time_total\n",
    "    print(total_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "calysto_bash",
     "Bash",
     "#E6EEFF",
     "shell"
    ],
    [
     "Markdown",
     "markdown",
     "markdown",
     "",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.24.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
