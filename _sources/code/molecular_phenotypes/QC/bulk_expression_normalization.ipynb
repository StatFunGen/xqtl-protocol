{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "healthy-circle",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Bulk RNA-seq counts normalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbb803d-c22f-4817-aba1-a824bf977aef",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41cd73d-f8f3-459c-8d5f-300058765394",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "The normalization step follows steps used by the GTeX pipeline. Genes are first filtered to keep genes where TPM is greater than 10% in at least 20% of the samples. They are also kept if read counts is greater than 6 in at least 20% of the samples. The filtered data is then normalized using the Trimmed Mean of M-value (TMM) method. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7d56e8-4a0e-44a8-93e2-4aff69de2001",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input\n",
    "\n",
    "1. TPM matrix and read count matrix in RNA-SeQC format\n",
    "    - the first two rows should be commented text with `#` prefix.\n",
    "    - the matrix should be tab delimited.\n",
    "    - the matrix files should end with `gct` suffix\n",
    "    - These requirements are satisfied if the inputs are outputs from [`bulk_expression_QC` pipeline](https://cumc.github.io/xqtl-pipeline/code/molecular_phenotypes/QC/bulk_expression_QC.html).\n",
    "2. GTF for collapsed gene model\n",
    "    - the gene names must be consistent with the GCT matrices (eg ENSG00000000003 vs. ENSG00000000003.1 will not work) \n",
    "    - chromosome names must have `chr` prefix (although we can make it an option in the pipeline, currently we assume the `chr` prefix convention)\n",
    "3. Meta-data to match between sample names in expression data and genotype files\n",
    "    - Required input\n",
    "    - Tab delimited with header\n",
    "    - Only 2 columns: first column is sample name in expression data, 2nd column is sample name in genotype data\n",
    "    - **must contains all the sample name in expression matrices even if they don't existing in genotype data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec85cc20-9341-47b2-9037-916d682d8b29",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Output\n",
    "\n",
    "Normalized expression file in `bed` format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e950d8-94fc-47a3-a159-cd56bdefa6cd",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Minimal Working Example Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea66682e-d383-4b8d-ad11-e5663149f9f5",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### vii. Multi-sample read count normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871339d6-cb92-461f-b783-b0307a277a11",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Timing <10min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513909bd-4c9f-47b1-9c28-76307b42d57d",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "TMM normalization of read counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fc7c5b-1835-43a5-a2e7-94ee4a64b965",
   "metadata": {},
   "source": [
    "**Note:** We recommend using a count-threshold default value of 6. This was changed to 1 below for the MWE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2966f049-22be-4a17-9c0b-77bc61417592",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Running \u001b[32mnormalize\u001b[0m: \n",
      "INFO: t903fc22d31109304 \u001b[32msubmitted\u001b[0m to neurology with job id Your job 2487615 (\"job_t903fc22d31109304\") has been submitted\n",
      "INFO: Waiting for the completion of \u001b[32m1\u001b[0m task.\n",
      "INFO: Waiting for the completion of \u001b[32m1\u001b[0m task.\n",
      "INFO: Waiting for the completion of \u001b[32m1\u001b[0m task.\n",
      "INFO: \u001b[32mnormalize\u001b[0m output:   \u001b[32m/restricted/projectnb/xqtl/xqtl_protocol/output_test/normalize/PCC_sample_list_subset.rnaseqc.low_expression_filtered.outlier_removed.tmm.expression.bed.gz\u001b[0m\n",
      "INFO: Workflow normalize (ID=wc742b6df800ede96) is executed successfully with 1 completed step and 1 completed task.\n"
     ]
    }
   ],
   "source": [
    "!sos run bulk_expression_normalization.ipynb normalize \\\n",
    "    --cwd ../../output_test/normalize \\\n",
    "    --tpm-gct ../../output_test/rnaseqc_qc/PCC_sample_list_subset.rnaseqc.low_expression_filtered.outlier_removed.tpm.gct.gz \\\n",
    "    --counts-gct ../../output_test/rnaseqc_qc/PCC_sample_list_subset.rnaseqc.low_expression_filtered.outlier_removed.geneCount.gct.gz \\\n",
    "    --annotation-gtf ../../reference_data/Homo_sapiens.GRCh38.103.chr.reformatted.collapse_only.gene.ERCC.gtf \\\n",
    "    --sample-participant-lookup ../../PCC_sample_subset_map_test \\\n",
    "    --count-threshold 1 \\\n",
    "    --tpm_threshold 0.1 \\\n",
    "    --sample_frac_threshold 0.2 \\\n",
    "    --normalization_method tmm  \\\n",
    "    --container oras://ghcr.io/cumc/rna_quantification_apptainer:latest \\\n",
    "    -s force -c ../csg.yml -q neurology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67cdc65-1f9e-4e49-ba17-27fd1a275009",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d8301a-ba7c-430c-bdd6-67d7d63088f8",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "| Step | Substep | Problem | Possible Reason | Solution |\n",
    "|------|---------|---------|------------------|---------|\n",
    "|  |  |  |  |  |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-diagnosis",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## Command interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fewer-niagara",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run bulk_expression_normalization.ipynb\n",
      "               [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  normalize\n",
      "\n",
      "Global Workflow Options:\n",
      "  --cwd output (as path)\n",
      "                        Work directory & output directory\n",
      "  --counts-gct VAL (as path, required)\n",
      "                        gene count table\n",
      "  --tpm-gct VAL (as path, required)\n",
      "                        gene TPM table\n",
      "  --annotation-gtf VAL (as path, required)\n",
      "                        gene gtf annotation table\n",
      "  --sample-participant-lookup VAL (as path, required)\n",
      "                        A file to map sample ID from expression to genotype,must\n",
      "                        contain two columns, sample_id and participant_id,\n",
      "                        mapping IDs in the expression files to IDs in the\n",
      "                        genotype (these can be the same).\n",
      "  --tpm-threshold 0.1 (as float)\n",
      "  --count-threshold 6 (as int)\n",
      "  --sample-frac-threshold 0.2 (as float)\n",
      "  --normalization-method tmm\n",
      "                        Normalization method: TMM (tmm) or quantile\n",
      "                        normalization (qn)\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "  --walltime 5h\n",
      "                        Wall clock time expected\n",
      "  --mem 16G\n",
      "                        Memory expected\n",
      "  --numThreads 20 (as int)\n",
      "                        Number of threads\n",
      "  --container ''\n",
      "  --entrypoint  ('micromamba run -a \"\" -n' + ' ' + re.sub(r'(_apptainer:latest|_docker:latest|\\.sif)$', '', container.split('/')[-1])) if container else \"\"\n",
      "\n",
      "\n",
      "Sections\n",
      "  normalize:\n"
     ]
    }
   ],
   "source": [
    "!sos run bulk_expression_normalization.ipynb -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aggressive-edgar",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Work directory & output directory\n",
    "parameter: cwd = path(\"output\")\n",
    "#  gene count table\n",
    "parameter: counts_gct = path\n",
    "#  gene TPM table\n",
    "parameter: tpm_gct = path\n",
    "#  gene gtf annotation table\n",
    "parameter: annotation_gtf = path\n",
    "# A file to map sample ID from expression to genotype,must contain two columns, sample_id and participant_id, mapping IDs in the expression files to IDs in the genotype (these can be the same).\n",
    "parameter: sample_participant_lookup = path\n",
    "parameter: tpm_threshold = 0.1\n",
    "parameter: count_threshold = 6\n",
    "parameter: sample_frac_threshold = 0.2\n",
    "# Normalization method: TMM (tmm) or quantile normalization (qn)\n",
    "parameter: normalization_method = 'tmm'\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"5h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 20\n",
    "parameter: container = \"\"\n",
    "import re\n",
    "parameter: entrypoint= ('micromamba run -a \"\" -n' + ' ' + re.sub(r'(_apptainer:latest|_docker:latest|\\.sif)$', '', container.split('/')[-1])) if container else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "front-jaguar",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[normalize]\n",
    "# Path to the input molecular phenotype data, should be a processd and indexed bed.gz file, with tabix index.\n",
    "input: tpm_gct, counts_gct, annotation_gtf, sample_participant_lookup\n",
    "output: f'{cwd:a}/{_input[0]:bnnn}.{normalization_method}.expression.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output[0]:bn}'  \n",
    "python: expand = \"${ }\", stderr = f'{_output[0]:nn}.stderr', stdout = f'{_output[0]:nn}.stdout',container = container, entrypoint = entrypoint\n",
    "    import pandas as pd    \n",
    "    #read the sample map file\n",
    "    sample_map = pd.read_table(\"${_input[3]}\")\n",
    "    duplicated = sample_map.loc[sample_map.duplicated(subset=['participant_id'])]\n",
    "\n",
    "    if duplicated.shape[0] > 0:\n",
    "        print(\"Duplicate samples found. Please remove duplicates from ${_input[3]} before normalizing.\")\n",
    "        print(\"Duplicates:\")\n",
    "        print(duplicated)\n",
    "        raise ValueError\n",
    "    else:\n",
    "        print(\"No duplicates found. Proceeding with normalization...\")\n",
    "\n",
    "bash: expand = \"${ }\", stderr = f'{_output[0]:nn}.stderr', stdout = f'{_output[0]:nn}.stdout',container = container, entrypoint = entrypoint\n",
    "    for i in {1..22} X Y MT; do echo chr$i; done > ${_output[0]:bnnn}.vcf_chr_list\n",
    "    eqtl_prepare_expression.py ${_input[0]} ${_input[1]} ${_input[2]} \\\n",
    "        ${_input[3]} ${_output[0]:nnn} \\\n",
    "        --chrs  ${_output[0]:bnnn}.vcf_chr_list \\\n",
    "        --tpm_threshold ${tpm_threshold} \\\n",
    "        --count_threshold ${count_threshold} \\\n",
    "        --sample_frac_threshold ${sample_frac_threshold} \\\n",
    "        --normalization_method ${normalization_method} && \\\n",
    "    rm -f ${_output[0]:bnnn}.vcf_chr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b887bc9-1438-442a-9d5b-057975c930ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.24.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
