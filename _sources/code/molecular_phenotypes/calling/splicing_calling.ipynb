{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "binding-ottawa",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Quantifying alternative splicing from RNA-seq data\n",
    "\n",
    "This pipeline implements our pipeline to call alternative splicing events from RNA-seq data, using [`leafcutter`](https://www.nature.com/articles/s41588-017-0004-9) and [`psichomics`](https://academic.oup.com/nar/article/47/2/e7/5114259) to call the RNA-seq data from original `fastq.gz` data. It implements the GTEx pipeline for GTEx/TOPMed project. Please refer to [this page](https://github.com/broadinstitute/gtex-pipeline/blob/master/TOPMed_RNAseq_pipeline.md) for detail. The choice of pipeline modules in this project is supported by internal (unpublished) benchmarks from GTEx group.\n",
    "\n",
    "**Various reference data needs to be prepared before using this workflow**. [Here we provide a module](https://cumc.github.io/xqtl-pipeline/code/data_preprocessing/reference_data.html) to download and prepare the reference data. \n",
    "\n",
    "The product of this workflow can be used in generating phenotype tables using /molecular_phenotyles/QC/splicing_normalization.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-indie",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Methods overview\n",
    "\n",
    "There are many types of alternative splicing events. See [Wang et al (2008)](https://pubmed.ncbi.nlm.nih.gov/18978772/) and [Park et al (2018)](https://pubmed.ncbi.nlm.nih.gov/29304370/) for an illustration on different events and how splicings are controlled. We will apply two methods to quantify alternative splicing:\n",
    "\n",
    "1. [`psichomics`](https://academic.oup.com/nar/article/47/2/e7/5114259) that quantifies each specific event. In particular the exon skipping event which is used also in GTEx sQTL analysis.\n",
    "2. [`leafcutter`](https://www.nature.com/articles/s41588-017-0004-9) to quantify the usage of alternatively excised introns. This collectively captures skipped exons, 5’ and 3’ alternative splice site usage and other complex events. The method was previously applied to ROSMAP data as part of the Brain xQTL version 2.0. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-bathroom",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input\n",
    "\n",
    "### `leafcutter`\n",
    "\n",
    "The bam file can be generated by `the STAR_align` workflow from our RNA_calling.ipynb module. \n",
    "\n",
    "A meta-data file, white space delimited without header, containing 3 columns: sample ID, RNA strandness and path to the BAM file:\n",
    "\n",
    "```\n",
    "sample_1 rf samp1.bam\n",
    "sample_2 fr samp2.bam\n",
    "sample_3 unstranded samp3.bam\n",
    "```\n",
    "\n",
    "All the BAM files should be available under specified folder (default assumes the same folder as where the meta-data file is).\n",
    "\n",
    "If intend to blacklist some chromosomes and not analyze it, add one text file named black_list.txt with one chromosome name per line in the same directory of the meta-data file.\n",
    "\n",
    "\n",
    "### `psichomics`\n",
    "\n",
    "A meta-data file, white space delimited without header, containing 3 columns: sample ID, RNA strandness and path to the SJ.out.tab files:\n",
    "\n",
    "```\n",
    "sample_1 rf samp1SJ.out.tab\n",
    "sample_2 fr samp2SJ.out.tab\n",
    "sample_3 unstranded samp3SJ.out.tab\n",
    "```\n",
    "\n",
    "All the SJ.out.tab files should be available under specified folder (default assumes the same folder as where the meta-data file is).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-costs",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Output\n",
    "\n",
    "### `leafcutter`\n",
    "\n",
    "`{sample_list}` below refers to the name of the meta-data file input.\n",
    "\n",
    "Main output include: \n",
    "\n",
    "- `{sample_list}_intron_usage_perind.counts.gz` file with row id in format: \"chromosome:intron_start:intron_end:cluster_id\", column labeled as input sample names and each type of intron usage ratio under each sample (i.e. #particular intron in a sample / #total introns classified in the same cluster in a sample) in each cells. \n",
    "- `{sample_list}_intron_usage_perind_numers.counts.gz` file with the same row and column label but the count of each intron in each cells.\n",
    "\n",
    "### `psichomics`\n",
    "\n",
    "- `psi_output.tsv` A dataframe of PSI values (quantification of the alternative splicing events) with first column splicing event identifier (for instance, SE_1_-_2125078_2124414_2124284_2121220_C1orf86) is composed of:\n",
    "\n",
    "                   Event type (SE stands for skipped exon)\n",
    "                   Chromosome (1)\n",
    "                   Strand (-)\n",
    "                   Relevant coordinates depending on event type (in this case, the first constitutive exon’s end, the                            alternative exon’ start and end and the second constitutive exon’s start)\n",
    "                   Associated gene (C1orf86)\n",
    "\n",
    "| Splicing Event Type | Abbreviation | [Coordinates](https://bioconductor.org/packages/release/bioc/manuals/psichomics/man/psichomics.pdf) |\n",
    "| --- | --- | --- |\n",
    "| Skipped Exon | SE | constitutive exon 1 end, alternative exon (start and end) and constitutive exon 2 start |\n",
    "| Mutually exclusive exon | MXE | constitutive exon 1 end, alternative exon 1 and 2 (start and end) and constitutive exon 2 start |\n",
    "| Alternative 5' splice site | A5SS | constitutive exon 1 end, alternative exon 1 end and constitutive exon 2 start |\n",
    "| Alternative 3' splice site | A3SS | constitutive exon 1 end, alternative exon 1 start and constitutive exon 2 start |\n",
    "| Alternative first exon | AFE | constitutive exon 1 end, alternative exon 1 end and constitutive exon 2 start |\n",
    "| Alternative last exon | ALE | constitutive exon 1 end, alternative exon 1 start and constitutive exon 2 start |\n",
    "| Alternative first exon (exon-centered - less reliable) | AFE_exon | constitutive exon 1 end, alternative exon 1 end and constitutive exon 2 start |\n",
    "| Alternative last exon (exon-centered - less reliable) | ALE_exon | constitutive exon 1 end, alternative exon 1 start and constitutive exon 2 start |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-lighting",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Minimal working example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-recruitment",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "### For `leafcutter`\n",
    "A minimal working example is uploaded in the [google drive](https://drive.google.com/drive/folders/1lpcx3eKG2UpauntLUuJ6bMBjHyIhWW_R?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-craft",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/splicing_calling.ipynb leafcutter \\\n",
    "    --cwd output/ \\\n",
    "    --samples sample_bam.list \\\n",
    "    --container containers/leafcutter.sif "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-handbook",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### For `psichomics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-stocks",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run splicing_calling.ipynb psichomics \\\n",
    "    --cwd psidata/output/ \\\n",
    "    --samples psidata/sample_SJ.list \\\n",
    "    --container container/psichomics.sif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-member",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## Command interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "mineral-motorcycle",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run splicing_calling.ipynb\n",
      "               [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  leafcutter\n",
      "  psichomics\n",
      "\n",
      "Global Workflow Options:\n",
      "  --cwd output (as path)\n",
      "                        The output directory for generated files.\n",
      "  --samples VAL (as path, required)\n",
      "                        Sample meta data list\n",
      "  --data-dir  path(f\"{samples:d}\")\n",
      "\n",
      "                        Raw data directory, default to the same directory as\n",
      "                        sample list\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "  --walltime 5h\n",
      "                        Wall clock time expected\n",
      "  --mem 16G\n",
      "                        Memory expected\n",
      "  --numThreads 8 (as int)\n",
      "                        Number of threads\n",
      "  --container ''\n",
      "                        Software container option\n",
      "\n",
      "Sections\n",
      "  leafcutter_1:\n",
      "    Workflow Options:\n",
      "      --anchor-len 8 (as int)\n",
      "                        anchor length (default 8)\n",
      "      --min-intron-len 50 (as int)\n",
      "                        minimum intron length to be analyzed (default 50)\n",
      "      --max-intron-len 500000 (as int)\n",
      "                        maximum intron length to be analyzed (default 500000)\n",
      "  leafcutter_2:\n",
      "    Workflow Options:\n",
      "      --min-clu-reads 50 (as int)\n",
      "                        minimum reads in a cluster (default 50 reads)\n",
      "      --max-intron-len 500000 (as int)\n",
      "                        maximum intron length to be analyzed (default 500000)\n",
      "  psichomics_1:\n",
      "  psichomics_2:\n"
     ]
    }
   ],
   "source": [
    "sos run splicing_calling.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-ontario",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Setup and global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "australian-declaration",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# The output directory for generated files. \n",
    "parameter: cwd = path(\"output\")\n",
    "# Sample meta data list\n",
    "parameter: samples = path\n",
    "# Raw data directory, default to the same directory as sample list\n",
    "parameter: data_dir = path(f\"{samples:d}\")\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"5h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 8\n",
    "# Software container option\n",
    "parameter: container = \"\"\n",
    "from sos.utils import expand_size\n",
    "cwd = path(f'{cwd:a}')\n",
    "\n",
    "def get_samples(fn, dr):\n",
    "    import os\n",
    "    samples = [x.strip().split() for x in open(fn).readlines()]\n",
    "    names = []\n",
    "    strandness = []\n",
    "    files = []\n",
    "    datas = []\n",
    "    \n",
    "    for i, x in enumerate(samples):\n",
    "        if len(x)<3:\n",
    "            raise ValueError(f\"Line {i+1} of file {fn} must have 3 columns\")\n",
    "        names.append(x[0])\n",
    "        strandness.append(x[1])\n",
    "        files.append(x[2])\n",
    "        \n",
    "    for j in range(len(strandness)):\n",
    "        # for regtools command usage, replace 0 = unstranded/XS, 1 = first-strand/RF, 2 = second-strand/FR\n",
    "        if strandness[i] == 'rf':\n",
    "            strandness[i] = 1\n",
    "        if strandness[i] == 'fr':\n",
    "            strandness[i] = 2\n",
    "        if strandness[i] == 'unstranded':\n",
    "            strandness[i] = 0\n",
    "            \n",
    "    for y in files:\n",
    "        y = os.path.join(dr, y)\n",
    "        if not os.path.isfile(y):\n",
    "            raise ValueError(f\"File {y} does not exist\")\n",
    "        datas.append(y)\n",
    "        \n",
    "    if len(files) != len(set(files)):\n",
    "        raise ValueError(\"Duplicated files are found (but should not be allowed) in BAM file list\")\n",
    "        \n",
    "    return names, datas, strandness\n",
    "\n",
    "sample_id, data, strandness = get_samples(samples, data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-leisure",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## `leafcutter`\n",
    "\n",
    "Documentation: [`leafcutter`](https://davidaknowles.github.io/leafcutter/index.html). The choices of regtool parameters are [discussed here](https://github.com/davidaknowles/leafcutter/issues/127).\n",
    "\n",
    "### Other clustering options:\n",
    "\n",
    "*   \"-q\", \"--quiet\" : don't print status messages to stdout, default=True.\n",
    "\n",
    "*   \"-p\", \"--mincluratio\" : minimum fraction of reads in a cluster that support a junction, default 0.001. \n",
    "\n",
    "*   \"-c\", \"--cluster\" : refined cluster file when clusters are already made, default = None.\n",
    "\n",
    "*   \"-k\", \"--nochromcheck\" : Don't check that the chromosomes are well formated e.g. chr1, chr2, ..., or 1, 2, ..., default = False.\n",
    "\n",
    "*    \"-C\", \"--includeconst\" : also include constitutive introns, default = False.\n",
    "\n",
    "To use these options add them at the end of the \"python leafcutter_cluster_regtools.py\" line.\n",
    "\n",
    "### Things to keep in mind:\n",
    "\n",
    "* If .bam.bai index files of the .bam input are ready before using leafCutter, it can be placed in the same directory with input .bam files and the \"samtools index ${_input}\" line can be skipped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aerial-temperature",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[leafcutter_1]\n",
    "# anchor length (default 8)\n",
    "parameter: anchor_len = 8\n",
    "# minimum intron length to be analyzed (default 50)\n",
    "parameter: min_intron_len = 50\n",
    "# maximum intron length to be analyzed (default 500000)\n",
    "parameter: max_intron_len = 500000\n",
    "input: data, group_by = 1, group_with = \"strandness\"\n",
    "output: f'{cwd}/{_input:bn}.junc' \n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container\n",
    "    samtools index ${_input}\n",
    "    regtools junctions extract -a ${anchor_len} -m ${min_intron_len} -M ${max_intron_len} -s ${_strandness} ${_input} -o ${_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "going-history",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[leafcutter_2]\n",
    "# minimum reads in a cluster (default 50 reads)\n",
    "parameter: min_clu_reads = 50 \n",
    "# maximum intron length to be analyzed (default 500000)\n",
    "parameter: max_intron_len = 500000\n",
    "input: group_by = 'all'\n",
    "output: f'{cwd}/{samples:bn}_intron_usage_perind.counts.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads\n",
    "bash: expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', container=container\n",
    "    rm -f ${_output:nn}.junc\n",
    "    for i in ${_input:r}; do\n",
    "    echo $i >> ${_output:nn}.junc ; done\n",
    "    python /opt/leafcutter/clustering/leafcutter_cluster_regtools.py -j ${_output:nn}.junc -o ${f'{_output:bnn}'.replace(\"_perind\",\"\")} -m ${min_clu_reads} -l ${max_intron_len} -r ${cwd}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-reception",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## `psichomics`\n",
    "\n",
    "Documentation: [`psichomics`](http://bioconductor.org/packages/release/bioc/html/psichomics.html)\n",
    "\n",
    "### Other options\n",
    "\n",
    "quantifySplicing( annotation,\n",
    "                  junctionQuant,\n",
    "                  eventType = c(\"SE\", \"MXE\", \"ALE\", \"AFE\", \"A3SS\", \"A5SS\"),\n",
    "                  minReads = 10,\n",
    "                  genes = NULL\n",
    ")\n",
    "\n",
    "In function quantifySplicing, arguments eventType (Character: splicing event types to quantify), minReads (Integer: values whose number of total supporting read counts is below minReads are returned as NA) and genes (Character: gene symbols for which to quantify splicing events. If NULL, events from all genes are quantified.) can be specified. Usage and default values are shown above.\n",
    "\n",
    "### Things to keep in mind\n",
    "\n",
    "* The default annotation used in psichomics is from [`vasttools`](https://github.com/vastgroup/vast-tools#vastdb-libraries) , still need to check if their definition of gene coordinate with this project. Current default is their hg38.\n",
    "* The current .out.tab outputs in upstream workflow is in .gz format, if that is kept some more zcat command might be added at the begining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc82853-5f6d-412b-9b36-d595d4dfe958",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[psichomics_1]\n",
    "input: data\n",
    "output: f'{cwd}/psi_output.tsv'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads\n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container\n",
    "    library(psichomics)\n",
    "    setwd(\"${samples:d}/output/\")\n",
    "    prepareJunctionQuant(${_input:r,})\n",
    "    data <- loadLocalFiles(\"${cwd}\")\n",
    "    junctionQuant <- data[[1]]$`Junction quantification`\n",
    "    annotation <- loadAnnotation(\"AH95570\")\n",
    "    psi <- quantifySplicing(annotation, junctionQuant)\n",
    "    write.table(psi, file='${cwd}/psi_output.tsv', quote=FALSE, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     "shell"
    ],
    [
     "R",
     "ir",
     "R",
     "#DCDCDA",
     "r"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.23.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
