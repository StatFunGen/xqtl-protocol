{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "authorized-highland",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Phenotype Data Imputation\n",
    "\n",
    "This workflow contains a collection of methods on imputation of missing omics data values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63211b7-54b4-4df8-b639-e06a159c1daf",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d17a53-5fe1-4842-809b-ed38a1375561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3cffb67c",
   "metadata": {},
   "source": [
    "## Input\n",
    "* A molecular phenotype data with missing where first four columns are chr, start, end, and ID. The rest columns are samples."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dcd6c9a4",
   "metadata": {},
   "source": [
    "## Output\n",
    "* A complete molecular phenotype data where first four columns are chr, start, end, and ID. The rest columns are samples."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba1c7c5a",
   "metadata": {},
   "source": [
    "## Minimal Working Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae58c9e7-9d0a-4de9-9914-4c737d699967",
   "metadata": {},
   "source": [
    "### a. Phenotype Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21933f3c-b52a-463f-8c7e-dd6be6050e69",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d80d6672-1189-452c-9d75-19afc5a4f09c",
   "metadata": {},
   "source": [
    "Timing: X min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-locking",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run xqtl-pipeline/pipeline/phenotype_imputation.ipynb flash \\\n",
    "    --phenoFile /phenotype/protocol_example.protein.bed.gz \\\n",
    "    --cwd output/phenotype \\\n",
    "    --prior ebnm_point_normal --varType 1 \\\n",
    "    --container oras://ghcr.io/cumc/omics_imputation_apptainer:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e616ed-e73f-4962-9262-b1a609861e46",
   "metadata": {},
   "source": [
    "## Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88385288-72fa-415b-8233-621638520fde",
   "metadata": {},
   "source": [
    "| Step | Substep | Problem | Possible Reason | Solution |\n",
    "|------|---------|---------|------------------|---------|\n",
    "|  |  |  |  |  |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891a01cc",
   "metadata": {},
   "source": [
    "## Command Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a1bc863",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run phenotype_imputation.ipynb\n",
      "               [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  flash\n",
      "  missforest\n",
      "  missxgboost\n",
      "  knn\n",
      "  soft\n",
      "  mean\n",
      "  lod\n",
      "  bed_filter_na\n",
      "\n",
      "Global Workflow Options:\n",
      "  --cwd output (as path)\n",
      "                        Work directory & output directory\n",
      "  --phenoFile VAL (as path, required)\n",
      "                        Molecular phenotype matrix\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "  --walltime 72h\n",
      "                        Wall clock time expected\n",
      "  --mem 16G\n",
      "                        Memory expected\n",
      "  --numThreads 20 (as int)\n",
      "                        Number of threads\n",
      "  --container ''\n",
      "  --entrypoint  ('micromamba run -a \"\" -n' + ' ' + re.sub(r'(_apptainer:latest|_docker:latest|\\.sif)$', '', container.split('/')[-1])) if container else \"\"\n",
      "\n",
      "\n",
      "Sections\n",
      "  flash:\n",
      "    Workflow Options:\n",
      "      --prior  ebnm_point_normal\n",
      "\n",
      "                        prior distribution of loadings and factors\n",
      "  missforest:\n",
      "  missxgboost:\n",
      "  knn:\n",
      "  soft:\n",
      "  mean:\n",
      "  lod:\n",
      "  bed_filter_na:\n",
      "    Workflow Options:\n",
      "      --rank-max 50 (as int)\n",
      "      --lambda-hyp 30 (as int)\n",
      "      --impute-method soft\n",
      "      --tol-missing 0.05 (as float)\n",
      "                        Tolerance of missingness rows with missing rate larger\n",
      "                        than tol_missing will be removed, with missing rate\n",
      "                        smaller than tol_missing will be mean_imputed. Say if we\n",
      "                        want to keep rows with less than 5% missing, then we use\n",
      "                        0.05 as tol_missing.\n"
     ]
    }
   ],
   "source": [
    "!sos run phenotype_imputation.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cf71c7-67f6-4df4-b3bc-c9fc9c795ae2",
   "metadata": {},
   "source": [
    "## Setup and global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nuclear-tumor",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Work directory & output directory\n",
    "parameter: cwd = path(\"output\")\n",
    "# Molecular phenotype matrix\n",
    "parameter: phenoFile = path\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"72h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 20\n",
    "parameter: container = \"\"\n",
    "import re\n",
    "parameter: entrypoint= ('micromamba run -a \"\" -n' + ' ' + re.sub(r'(_apptainer:latest|_docker:latest|\\.sif)$', '', container.split('/')[-1])) if container else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-kitty",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[flash]\n",
    "# prior distribution of loadings and factors\n",
    "parameter: prior = \"ebnm_point_normal\"\n",
    "# type of estimated variance: 1 is a estimated variance for each row.\n",
    "parameter: varType = '1'\n",
    "input: phenoFile\n",
    "output: f'{cwd:a}/{_input:bn}.imputed.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "   library(flashier)\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   library(\"dplyr\")\n",
    "    \n",
    "    pheno <- read_delim(${_input:ar}, delim = \"\\t\")\n",
    "    pheno_NAs <- pheno[, 5:ncol(pheno)]\n",
    "    f <- flashier::flash(as.matrix(pheno_NAs), ebnm_fn = ${prior}, var_type = ${varType})\n",
    "    Yfill <- ifelse(is.na(as.matrix(pheno_NAs)), fitted(f), as.matrix(pheno_NAs))\n",
    "    pheno_imp <- as.data.frame(cbind(pheno[, 1:4], Yfill))\n",
    "    write_delim(pheno_imp, ${_output:r}, delim = \"\\t\" )\n",
    "\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}\n",
    "\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output:n].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `cat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `cat $i | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `cat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        cat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wireless-draft",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[missforest]\n",
    "input: phenoFile\n",
    "output: f'{cwd:a}/{_input:bn}.imputed.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "   library(missForest)\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   library(\"dplyr\")\n",
    "    \n",
    "    pheno <- read_delim(${_input:ar}, delim = \"\\t\")\n",
    "    pheno_NAs <- pheno[, 5:ncol(pheno)]\n",
    "    Yfill <- missForest(as.matrix(pheno_NAs), parallelize = 'variables')$ximp\n",
    "    pheno_imp <- as.data.frame(cbind(pheno[, 1:4], Yfill))\n",
    "    write_delim(pheno_imp, ${_output:r}, delim = \"\\t\" )\n",
    "\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}\n",
    "\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output:n].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `cat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `cat $i | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `cat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        cat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-hypothetical",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[missxgboost]\n",
    "input: phenoFile\n",
    "output: f'{cwd:a}/{_input:bn}.imputed.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "   source('/mnt/vast/hpc/csg/zq2209/xgb_imp.R')\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   library(\"dplyr\")\n",
    "    \n",
    "    pheno <- read_delim(${_input:ar}, delim = \"\\t\")\n",
    "    pheno_NAs <- pheno[, 5:ncol(pheno)]\n",
    "    Yfill <- xgboost_imputation(as.matrix(pheno_NAs))\n",
    "    pheno_imp <- as.data.frame(cbind(pheno[, 1:4], Yfill))\n",
    "    write_delim(pheno_imp, ${_output:r}, delim = \"\\t\" )\n",
    "\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output:n].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `cat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `cat $i | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `cat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        cat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-complaint",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[knn]\n",
    "input: phenoFile\n",
    "output: f'{cwd:a}/{_input:bn}.imputed.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "   library(impute)\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   library(\"dplyr\")\n",
    "    \n",
    "    pheno <- read_delim(${_input:ar}, delim = \"\\t\")\n",
    "    pheno_NAs <- pheno[, 5:ncol(pheno)]\n",
    "    Yfill <- impute.knn(as.matrix(pheno_NAs), rowmax = 1)$data\n",
    "    pheno_imp <- as.data.frame(cbind(pheno[, 1:4], Yfill))\n",
    "    write_delim(pheno_imp, ${_output:r}, delim = \"\\t\" )\n",
    "\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output:n].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `cat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `cat $i | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `cat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        cat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-legislation",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[soft]\n",
    "input: phenoFile\n",
    "output: f'{cwd:a}/{_input:bn}.imputed.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "   library(softImpute)\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   library(\"dplyr\")\n",
    "    \n",
    "    pheno <- read_delim(${_input:ar}, delim = \"\\t\")\n",
    "    pheno_NAs <- pheno[, 5:ncol(pheno)]\n",
    "    X_mis_C <- as(as.matrix(pheno_NAs), \"Incomplete\")\n",
    "    ###uses \"svd\" algorithm\n",
    "    fit <- softImpute(X_mis_C,rank = 50,lambda = 30,type = \"svd\")\n",
    "    Yfill <- complete(as.matrix(pheno_NAs),fit)\n",
    "    pheno_imp <- as.data.frame(cbind(pheno[, 1:4], Yfill))\n",
    "    write_delim(pheno_imp, ${_output:r}, delim = \"\\t\" )\n",
    "\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output:n].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `cat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `cat $i | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `cat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        cat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-smoke",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[mean]\n",
    "input: phenoFile\n",
    "output: f'{cwd:a}/{_input:bn}.imputed.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   library(\"dplyr\")\n",
    "    \n",
    "    pheno <- read_delim(${_input:ar}, delim = \"\\t\")\n",
    "    pheno_NAs <- pheno[, 5:ncol(pheno)]\n",
    "    Yfill <- as.matrix(pheno_NAs)\n",
    "    for (t.row in 1:nrow(pheno_NAs)) {\n",
    "        Yfill[t.row, is.na(Yfill[t.row,])] <- rowMeans(Yfill, na.rm = TRUE)[t.row] \n",
    "    }    \n",
    "    pheno_imp <- as.data.frame(cbind(pheno[, 1:4], Yfill))\n",
    "    write_delim(pheno_imp, ${_output:r}, delim = \"\\t\" )\n",
    "\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output:n].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `cat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `cat $i | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `cat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        cat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-kidney",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[lod]\n",
    "input: phenoFile\n",
    "output: f'{cwd:a}/{_input:bn}.imputed.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   library(\"dplyr\")\n",
    "    \n",
    "    pheno <- read_delim(${_input:ar}, delim = \"\\t\")\n",
    "    pheno_NAs <- pheno[, 5:ncol(pheno)]\n",
    "    Yfill <- as.matrix(pheno_NAs)\n",
    "    for (t.row in 1:nrow(pheno_NAs)) {\n",
    "        Yfill[t.row, is.na(Yfill[t.row,])] <- min(Yfill[t.row, ], na.rm = TRUE)\n",
    "    }\n",
    "    pheno_imp <- as.data.frame(cbind(pheno[, 1:4], Yfill))\n",
    "    write_delim(pheno_imp, ${_output:r}, delim = \"\\t\" )\n",
    "\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output:n].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `cat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `cat $i | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `cat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        cat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-audit",
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "[bed_filter_na]\n",
    "parameter: rank_max = 50 # max rank estimated in the per-chr methyl matrix\n",
    "parameter: lambda_hyp = 30 # hyper par, indicating the importance of the nuclear norm\n",
    "parameter: impute_method = \"soft\"\n",
    "# Tolerance of missingness rows with missing rate larger than tol_missing will be removed,\n",
    "# with missing rate smaller than tol_missing will be mean_imputed. Say if we want to keep rows with less than 5% missing, then we use 0.05 as tol_missing.\n",
    "parameter: tol_missing = 0.05\n",
    "input: phenoFile\n",
    "output: f'{_input:nn}.filter_na.{impute_method}.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads\n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "   library(\"dplyr\")\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   library(softImpute)\n",
    "   compute_missing <- function(mtx){\n",
    "          miss <- sum(is.na(mtx))/length(mtx)\n",
    "          return(miss)\n",
    "        }\n",
    "\n",
    "        mean_impute <- function(mtx){\n",
    "          f <- apply(mtx, 2, function(x) mean(x,na.rm = TRUE))\n",
    "          for (i in 1:length(f)) mtx[,i][which(is.na(mtx[,i]))] <- f[i]\n",
    "          return(mtx)\n",
    "        }\n",
    "    \n",
    "        soft_impute <- function(){\n",
    "          f <- apply(mtx, 2, function(x) mean(x,na.rm = TRUE))\n",
    "          for (i in 1:length(f)) mtx[,i][which(is.na(mtx[,i]))] <- f[i]\n",
    "          return(mtx)\n",
    "        }\n",
    "  \n",
    "  \n",
    "        filter_mtx <- function(X, missing_rate_thresh) {\n",
    "            rm_col <- which(apply(X, 2, compute_missing) > missing_rate_thresh)\n",
    "            if (length(rm_col)) X <- X[, -rm_col]\n",
    "            return((X))\n",
    "        }  \n",
    "  \n",
    "    bed = read_delim(\"${_input}\")\n",
    "    mtx = bed[,5:ncol(bed)]%>%as.matrix\n",
    "    rownames(mtx) = bed[,4]%>%unlist()\n",
    "    tbl_filtered = filter_mtx(mtx%>%t(),${tol_missing})\n",
    "    if ( \"${impute_method}\" == \"mean\" ){\n",
    "    tbl_filtered = tbl_filtered%>%mean_impute()%>%t()\n",
    "     } else if (\"${impute_method}\" == \"soft\"){ \n",
    "      tbl_filtered_C= as(t(tbl_filtered),\"Incomplete\")\n",
    "      fit=softImpute(tbl_filtered_C,rank=${rank_max},lambda=${lambda_hyp},type=\"svd\")\n",
    "      tbl_filtered = complete(t(tbl_filtered),fit)\n",
    "    }\n",
    "    tbl_filtered = tbl_filtered%>%as_tibble(rownames = colnames(bed)[4])  \n",
    "    bed_filtered = inner_join(bed[,1:4],tbl_filtered)\n",
    "    bed_filtered%>%write_delim(\"${_output:n}\", \"\\t\" )\n",
    "  \n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `zcat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `zcat $i | grep -v \"##\"   | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `zcat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        zcat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-minnesota",
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "The resource usage for softimputing 450K methylation data are as followed:\n",
    "\n",
    "``` \n",
    "time elapsed: 880.90s\n",
    "peak first occurred: 152.11s\n",
    "peak last occurred: 175.41s\n",
    "max vms_memory: 38.95GB\n",
    "max rss_memory: 34.35GB\n",
    "memory check interval: 1s\n",
    "return code: 0\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.23.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
