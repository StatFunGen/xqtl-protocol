{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "authorized-highland",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Phenotype data imputation\n",
    "\n",
    "This workflow contains a collection of methods on imputation of missing omics data values. The imputation methods are benchmarked in [Multi-Omics Imputation Benchmark Paper](https://www.medrxiv.org/content/10.1101/2023.11.29.23299181v1). Refer to this paper, we select a low-rank approximation method, EBMF(flashier), as our primary imputation method for imputation on molecular phenotype data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cffb67c",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input\n",
    "* A molecular phenotype data with missing where first four columns are chr, start, end, and ID. The rest columns are samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd6c9a4",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Output\n",
    "* A complete molecular phenotype data where first four columns are chr, start, end, and ID. The rest columns are samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1c7c5a",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Minimal Working Example\n",
    "FIXME: will update this after container is done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-locking",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run phenotype_imputation.ipynb EBMF \\\n",
    "    --phenoFile protocol_example.protein.bed.gz \\\n",
    "    --cwd ./test \\\n",
    "    --prior ebnm_point_laplace --varType 1 \\\n",
    "    --container containers/factor_analysis.sif \\\n",
    "    --mem 40G \\\n",
    "    --walltime 100h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d911ca-26f8-42a3-9b95-1211287dd057",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run xqtl-protocol/pipeline/phenotype_imputation.ipynb gEBMF \\\n",
    "    --phenoFile xqtl_association/protocol_example.protein.bed.gz \\\n",
    "    --cwd ./test \\\n",
    "    --nCores 12 \\\n",
    "    --container containers/factor_analysis.sif \\\n",
    "    --mem 40G \\\n",
    "    --walltime 100h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nuclear-tumor",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Work directory & output directory\n",
    "parameter: cwd = path(\"output\")\n",
    "# Molecular phenotype matrix\n",
    "parameter: phenoFile = path\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"72h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 20\n",
    "parameter: container = \"\"\n",
    "import re\n",
    "parameter: entrypoint= ('micromamba run -a \"\" -n' + ' ' + re.sub(r'(_apptainer:latest|_docker:latest|\\.sif)$', '', container.split('/')[-1])) if container else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-kitty",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[EBMF]\n",
    "# prior distribution of loadings and factors\n",
    "parameter: prior = \"ebnm_point_laplace\"\n",
    "parameter: varType = '1'\n",
    "parameter: num_factor = '60'\n",
    "input: phenoFile\n",
    "output: f'{cwd:a}/{_input:bn}.imputed.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}', cores = numThreads  \n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "   library(\"flashier\")\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   library(\"dplyr\")\n",
    "   #library(\"irlba\")\n",
    "   library(\"softImpute\")\n",
    "  \n",
    "    pheno <- read_delim(${_input:ar}, delim = \"\\t\")\n",
    "    pheno_NAs <- pheno[, 5:ncol(pheno)]\n",
    "    # Tunning the parameter\n",
    "    lambda <- 30\n",
    "    rank <- 50\n",
    "    if (nrow(pheno_NAs) < 1500) {\n",
    "      lambda <- 5\n",
    "    } else {\n",
    "      lambda <- 30\n",
    "    }  \n",
    "    # Impute\n",
    "    X_mis_C <- as(as.matrix(pheno_NAs), \"Incomplete\")\n",
    "    ###uses \"svd\" algorithm\n",
    "    fit1 <- softImpute::softImpute(X_mis_C,rank = rank,lambda = lambda,type = \"svd\")\n",
    "    pheno_soft <- softImpute::complete(as.matrix(pheno_NAs),fit1)\n",
    "    min_sd <- min(apply(pheno_soft, 1, sd))\n",
    "    pca_res <- irlba::irlba(pheno_soft, nv = ${num_factor})\n",
    "    pca_res <- list(pca_res$d, pca_res$u, pca_res$v)\n",
    "    names(pca_res) <- c('d', 'u', 'v')\n",
    "    fl_pca <- flash_init(as.matrix(pheno_NAs), S = min_sd, var_type = ${varType}) |>\n",
    "      flash_factors_init(pca_res, ebnm_fn = ${prior}) |>\n",
    "      flash_backfit(maxiter = 300)\n",
    "    pheno.imp <- ifelse(is.na(as.matrix(pheno_NAs)), fitted(fl_pca), as.matrix(pheno_NAs))\n",
    "    write_delim(cbind(pheno[, 1:4], pheno.imp), \"${_output:n}\", delim = \"\\t\" )\n",
    "\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}\n",
    "\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output:n].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `cat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `cat $i | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `cat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        cat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caee8619-9b8a-425e-be00-924644c4fdc2",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[gEBMF]\n",
    "parameter: nCores = '1'\n",
    "parameter: num_factor = '60'\n",
    "parameter: backfit_iter = '3'\n",
    "parameter: save_flash = True\n",
    "parameter: null_check = False\n",
    "input: phenoFile\n",
    "output: f'{cwd:a}/{_input:bn}.imputed.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}', cores = numThreads  \n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "   library(\"flashier\")\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   library(\"dplyr\")\n",
    "   library(\"snow\")\n",
    "   library(\"softImpute\")\n",
    "  \n",
    "    pheno <- read_delim(${_input:ar}, delim = \"\\t\")\n",
    "    pheno_NAs <- pheno[, 5:ncol(pheno)]\n",
    "    dat <- qnorm(pheno_NAs)\n",
    "    rm(pheno_NAs)\n",
    "    groups <- pheno$`#chr`\n",
    "    null_check <- ${\"TRUE\" if null_check else \"FALSE\"}\n",
    "    cl <- flash_init_cluster_for_grouped_data(dat, groups, ${nCores} , K = ${num_factor})\n",
    "    for (i in seq_len(${backfit_iter})) {\n",
    "        flash_backfit_grouped_data(cl, maxiter = 10)\n",
    "        flash_impute_grouped_data(cl)\n",
    "\n",
    "      }\n",
    "    fl <- flash_recover_fl_object_from_cluster(cl)\n",
    "    snow::stopCluster(cl)\n",
    "    rm(cl)\n",
    "\n",
    "    if(${\"TRUE\" if null_check else \"FALSE\"}){\n",
    "        fl <- flash_nullcheck(fl)\n",
    "\n",
    "      }\n",
    "\n",
    "    if(${\"TRUE\" if save_flash else \"FALSE\"}){\n",
    "        saveRDS(fl,save_flash)\n",
    "      }\n",
    "\n",
    "\n",
    "    x_imp <- ifelse(is.na(dat), fitted(fl), dat)\n",
    "    #message('done.')\n",
    "    pheno_imp<-pnorm(x_imp)\n",
    "  \n",
    "    write_delim(cbind(pheno[, 1:4], pheno_imp), \"${_output:n}\", delim = \"\\t\")\n",
    "\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}\n",
    "\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output:n].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `cat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `cat $i | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `cat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        cat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wireless-draft",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[missforest]\n",
    "input: phenoFile\n",
    "output: f'{cwd:a}/{_input:bn}.imputed.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "   library(flashier)\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   library(\"dplyr\")\n",
    "    \n",
    "    pheno <- read_delim(${_input:ar}, delim = \"\\t\")\n",
    "    pheno_NAs <- pheno[, 5:ncol(pheno)]\n",
    "    pheno_imp <- missForest(as.matrix(pheno_NAs), parallelize = 'variables')$ximp\n",
    "    write_delim(cbind(pheno[, 1:4], pheno_imp), ${_output:r}, delim = \"\\t\" )\n",
    "\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}\n",
    "\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output:n].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `cat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `cat $i | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `cat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        cat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-hypothetical",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[missxgboost]\n",
    "input: phenoFile\n",
    "output: f'{cwd:a}/{_input:bn}.imputed.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "   source('/mnt/vast/hpc/csg/zq2209/xgb_imp.R')\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   library(\"dplyr\")\n",
    "    \n",
    "    pheno <- read_delim(${_input:ar}, delim = \"\\t\")\n",
    "    pheno_NAs <- pheno[, 5:ncol(pheno)]\n",
    "    pheno_imp <- xgboost_imputation(as.matrix(pheno_NAs))\n",
    "    write_delim(cbind(pheno[, 1:4], pheno_imp), ${_output:r}, delim = \"\\t\" )\n",
    "\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output:n].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `cat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `cat $i | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `cat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        cat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-complaint",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[knn]\n",
    "input: phenoFile\n",
    "output: f'{cwd:a}/{_input:bn}.imputed.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "   library(impute)\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   library(\"dplyr\")\n",
    "    \n",
    "    pheno <- read_delim(${_input:ar}, delim = \"\\t\")\n",
    "    pheno_NAs <- pheno[, 5:ncol(pheno)]\n",
    "    pheno_imp <- impute.knn(as.matrix(pheno_NAs), rowmax = 1)$data\n",
    "    write_delim(cbind(pheno[, 1:4], pheno_imp), ${_output:r}, delim = \"\\t\" )\n",
    "\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output:n].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `cat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `cat $i | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `cat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        cat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-legislation",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[soft]\n",
    "input: phenoFile\n",
    "output: f'{cwd:a}/{_input:bn}.imputed.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "   library(softImpute)\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   library(\"dplyr\")\n",
    "    \n",
    "    pheno <- read_delim(${_input:ar}, delim = \"\\t\")\n",
    "    pheno_NAs <- pheno[, 5:ncol(pheno)]\n",
    "    X_mis_C <- as(as.matrix(pheno_NAs), \"Incomplete\")\n",
    "    ###uses \"svd\" algorithm\n",
    "    fit <- softImpute(X_mis_C,rank = 50,lambda = 30,type = \"svd\")\n",
    "    pheno_imp <- complete(as.matrix(pheno_NAs),fit)\n",
    "    write_delim(cbind(pheno[, 1:4], pheno_imp), ${_output:r}, delim = \"\\t\" )\n",
    "\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output:n].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `cat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `cat $i | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `cat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        cat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-smoke",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[mean]\n",
    "input: phenoFile\n",
    "output: f'{cwd:a}/{_input:bn}.imputed.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   library(\"dplyr\")\n",
    "    \n",
    "    pheno <- read_delim(${_input:ar}, delim = \"\\t\")\n",
    "    pheno_NAs <- pheno[, 5:ncol(pheno)]\n",
    "    Yfill <- as.matrix(pheno_NAs)\n",
    "    for (t.row in 1:nrow(pheno_NAs)) {\n",
    "        Yfill[t.row, is.na(Yfill[t.row,])] <- rowMeans(Yfill, na.rm = TRUE)[t.row] \n",
    "    }    \n",
    "    write_delim(cbind(pheno[, 1:4], Yfill), ${_output:r}, delim = \"\\t\" )\n",
    "\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output:n].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `cat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `cat $i | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `cat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        cat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-kidney",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[lod]\n",
    "input: phenoFile\n",
    "output: f'{cwd:a}/{_input:bn}.imputed.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   library(\"dplyr\")\n",
    "    \n",
    "    pheno <- read_delim(${_input:ar}, delim = \"\\t\")\n",
    "    pheno_NAs <- pheno[, 5:ncol(pheno)]\n",
    "    Yfill <- as.matrix(pheno_NAs)\n",
    "    for (t.row in 1:nrow(pheno_NAs)) {\n",
    "        Yfill[t.row, is.na(Yfill[t.row,])] <- min(Yfill[t.row, ], na.rm = TRUE)\n",
    "    }\n",
    "    write_delim(cbind(pheno[, 1:4], Yfill), ${_output:r}, delim = \"\\t\" )\n",
    "\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output:n].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `cat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `cat $i | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `cat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        cat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-audit",
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "[bed_filter_na]\n",
    "parameter: rank_max = 50 # max rank estimated in the per-chr methyl matrix\n",
    "parameter: lambda_hyp = 30 # hyper par, indicating the importance of the nuclear norm\n",
    "parameter: impute_method = \"soft\"\n",
    "# Tolerance of missingness rows with missing rate larger than tol_missing will be removed,\n",
    "# with missing rate smaller than tol_missing will be mean_imputed. Say if we want to keep rows with less than 5% missing, then we use 0.05 as tol_missing.\n",
    "parameter: tol_missing = 0.05\n",
    "input: phenoFile\n",
    "output: f'{_input:nn}.filter_na.{impute_method}.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads\n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "   library(\"dplyr\")\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   library(softImpute)\n",
    "   compute_missing <- function(mtx){\n",
    "          miss <- sum(is.na(mtx))/length(mtx)\n",
    "          return(miss)\n",
    "        }\n",
    "\n",
    "        mean_impute <- function(mtx){\n",
    "          f <- apply(mtx, 2, function(x) mean(x,na.rm = TRUE))\n",
    "          for (i in 1:length(f)) mtx[,i][which(is.na(mtx[,i]))] <- f[i]\n",
    "          return(mtx)\n",
    "        }\n",
    "    \n",
    "        soft_impute <- function(){\n",
    "          f <- apply(mtx, 2, function(x) mean(x,na.rm = TRUE))\n",
    "          for (i in 1:length(f)) mtx[,i][which(is.na(mtx[,i]))] <- f[i]\n",
    "          return(mtx)\n",
    "        }\n",
    "  \n",
    "  \n",
    "        filter_mtx <- function(X, missing_rate_thresh) {\n",
    "            rm_col <- which(apply(X, 2, compute_missing) > missing_rate_thresh)\n",
    "            if (length(rm_col)) X <- X[, -rm_col]\n",
    "            return((X))\n",
    "        }  \n",
    "  \n",
    "    bed = read_delim(\"${_input}\")\n",
    "    mtx = bed[,5:ncol(bed)]%>%as.matrix\n",
    "    rownames(mtx) = bed[,4]%>%unlist()\n",
    "    tbl_filtered = filter_mtx(mtx%>%t(),${tol_missing})\n",
    "    if ( \"${impute_method}\" == \"mean\" ){\n",
    "    tbl_filtered = tbl_filtered%>%mean_impute()%>%t()\n",
    "     } else if (\"${impute_method}\" == \"soft\"){ \n",
    "      tbl_filtered_C= as(t(tbl_filtered),\"Incomplete\")\n",
    "      fit=softImpute(tbl_filtered_C,rank=${rank_max},lambda=${lambda_hyp},type=\"svd\")\n",
    "      tbl_filtered = complete(t(tbl_filtered),fit)\n",
    "    }\n",
    "    tbl_filtered = tbl_filtered%>%as_tibble(rownames = colnames(bed)[4])  \n",
    "    bed_filtered = inner_join(bed[,1:4],tbl_filtered)\n",
    "    bed_filtered%>%write_delim(\"${_output:n}\", \"\\t\" )\n",
    "  \n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `zcat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `zcat $i | grep -v \"##\"   | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `zcat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        zcat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-minnesota",
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "The resource usage for softimputing 450K methylation data are as followed:\n",
    "\n",
    "``` \n",
    "time elapsed: 880.90s\n",
    "peak first occurred: 152.11s\n",
    "peak last occurred: 175.41s\n",
    "max vms_memory: 38.95GB\n",
    "max rss_memory: 34.35GB\n",
    "memory check interval: 1s\n",
    "return code: 0\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.23.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
