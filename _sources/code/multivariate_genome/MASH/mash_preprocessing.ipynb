{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "outside-vatican",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Extract genome-wide data for multivariate analysis\n",
    "\n",
    "## Description\n",
    "\n",
    "This notebook prepares input data for Utimate Decomposition to generate mixture prior (for mvSuSiE) or to use for MASH analysis. It outputs 3 sets of data: $Z_s$, $Z_n$ and $Z_r$ (strong, null and random)\n",
    "\n",
    "* $Z_s$: **this is now extracted from genome-wide cis analysis fine-mapping results**. We extract the top loci data frame of each condition, where the CS threshold is set to be 0.7. Then we merge the z-scores of them into one data frame.\n",
    "* $Z_n$: (null $Z$-scores): we first extract up to $M$ candidate SNPs from each region which satisify $|z| \\le 2$, then overlap it with the list of independent SNPs to keep only independent variants, then finally take the union of the extracted.\n",
    "* $Z_r$: we randomly extract variants based on input independent list of variants.\n",
    "\n",
    "**FIXME: We need to apply the independent list of variants Anqi developed and use it here to filter and get $Z_n$ and $Z_r$. This logic shoud be added to `processing_1`. Also, it might be a good idea we take some of these utility functions into pecotmr package for better maintenance. For example `processing_1` the function to load regional summary stats from tensorQTL into a matrix should be packed into pecotmr; plus this one function `handle_nan_etc`. processing_2 can stay as is; the `susie_signal` step can also go into `pecotmr` as a way for users to summarize signals from SuSiE for other purposes**\n",
    "\n",
    "## Input\n",
    "1. **Marginal summary statistics files**: Bgzipped summary statistics for chromosomes 1-22, generated by tensorQTL cis-analysis and indexed by `tabix`.\n",
    "2. **Fine-mapping results file index**: Path to lists of fine-mapped RDS files from finemapping output.\n",
    "2. **Genome region partition** (optional): Defines genomic regions for each gene as enhanced cis regions where we should extract $Z_n$ and $Z_r$ from. This list is used for fine-mapping, so if the complete list of fine-mapping RDS (rather than a handful of it) is already avaiable (#2 above) then there is no need to provide this file. Otherwise, it's going to be limited to only certaion regions, which is also good for testing purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-wisdom",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Output\n",
    "A list of 10 elements:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-sperm",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "```\n",
    "List of 10\n",
    " $ strong.b:'data.frame':\t62 obs. of  16 variables:\n",
    "  ..$ Mic_De_Jager_eQTL  : num [1:62] 0.0402 0.0177 0.1852 -0.2188 0.1352 ...\n",
    "  ..$ Ast_De_Jager_eQTL  : num [1:62] -0.74 -0.215 0.165 -0.263 0.113 ...\n",
    "  ..$ Oli_De_Jager_eQTL  : num [1:62] -0.0564 0.195 0.1379 -0.1245 -0.061 ...\n",
    "  ..$ OPC_De_Jager_eQTL  : num [1:62] 0.1748 0.2064 0.1182 -0.0751 0.1023 ...\n",
    "  ..$ Exc_De_Jager_eQTL  : num [1:62] -0.56004 0.04682 0.2279 -0.13765 0.00667 ...\n",
    "  ..$ Inh_De_Jager_eQTL  : num [1:62] -0.6306 0.1502 0.1777 -0.2118 -0.0562 ...\n",
    "  ..$ DLPFC_De_Jager_eQTL: num [1:62] -0.0379 0.1315 0.0361 -0.315 -0.1005 ...\n",
    "  ..$ PCC_De_Jager_eQTL  : num [1:62] -0.0403 0.0209 0.0614 -0.1755 0.0422 ...\n",
    "  ..$ AC_De_Jager_eQTL   : num [1:62] -0.13649 -0.00365 0.08409 -0.19717 0.08202 ...\n",
    "  ..$ Mic_Kellis_eQTL    : num [1:62] -0.396 0 0 0 0 ...\n",
    "  ..$ Ast_Kellis_eQTL    : num [1:62] -0.9948 0.1155 0.0732 -0.2074 -0.044 ...\n",
    "  ..$ Oli_Kellis_eQTL    : num [1:62] -0.559 0.387 0.1339 -0.3099 -0.0334 ...\n",
    "  ..$ OPC_Kellis_eQTL    : num [1:62] -0.11556 0.17907 0.06332 0.06868 0.00266 ...\n",
    "  ..$ Exc_Kellis_eQTL    : num [1:62] -0.5978 0.0797 0.1463 -0.1659 0.049 ...\n",
    "  ..$ Inh_Kellis_eQTL    : num [1:62] -0.40719 0.04581 0.12052 -0.2968 0.00677 ...\n",
    "  ..$ Ast.10_Kellis_eQTL : num [1:62] 0 0 0 0 0 0 0 0 0 0 ...\n",
    " $ random.b:'data.frame':\t200 obs. of  16 variables:\n",
    "  ..$ Mic_De_Jager_eQTL  : num [1:200] -0.014 -0.0691 -0.0426 -0.1391 0.1639 ...\n",
    "  ..$ Ast_De_Jager_eQTL  : num [1:200] -0.006636 -0.051634 0.064082 0.000642 -0.040912 ...\n",
    "  ..$ Oli_De_Jager_eQTL  : num [1:200] -0.0702 -0.0912 0.0985 -0.0492 0.0375 ...\n",
    "  ..$ OPC_De_Jager_eQTL  : num [1:200] 0.0517 0.0577 -0.0443 0.0677 0.019 ...\n",
    "  ..$ Exc_De_Jager_eQTL  : num [1:200] 0.0404 -0.02711 0.02452 -0.01076 0.00808 ...\n",
    "  ..$ Inh_De_Jager_eQTL  : num [1:200] -0.09783 -0.0174 0.01247 0.00424 0.0561 ...\n",
    "  ..$ DLPFC_De_Jager_eQTL: num [1:200] -0.005966 0.006705 0.000253 -0.004673 0.001346 ...\n",
    "  ..$ PCC_De_Jager_eQTL  : num [1:200] -0.0113 -0.0248 -0.0239 0.0113 0.0307 ...\n",
    "  ..$ AC_De_Jager_eQTL   : num [1:200] -0.01516 0.00196 -0.05586 0.01852 0.0188 ...\n",
    "  ..$ Mic_Kellis_eQTL    : num [1:200] 0.0641 -0.1708 -0.0346 -0.0661 0.0293 ...\n",
    "  ..$ Ast_Kellis_eQTL    : num [1:200] 0.05854 -0.03466 -0.03777 -0.00221 -0.01986 ...\n",
    "  ..$ Oli_Kellis_eQTL    : num [1:200] -0.01408 0.02196 0.02674 0.00619 -0.03527 ...\n",
    "  ..$ OPC_Kellis_eQTL    : num [1:200] -0.018068 -0.026661 -0.051184 0.000499 -0.018648 ...\n",
    "  ..$ Exc_Kellis_eQTL    : num [1:200] 0.00046 -0.08625 0.02572 0.00127 -0.07891 ...\n",
    "  ..$ Inh_Kellis_eQTL    : num [1:200] -0.07466 -0.03319 -0.00879 0.06033 -0.02189 ...\n",
    "  ..$ Ast.10_Kellis_eQTL : num [1:200] 0 0 0 0 0 0 0 0 0 0 ...\n",
    " $ null.b  :'data.frame':\t200 obs. of  16 variables:\n",
    "  ..$ Mic_De_Jager_eQTL  : num [1:200] -0.0252 -0.0296 -0.1086 -0.0394 -0.2567 ...\n",
    "  ..$ Ast_De_Jager_eQTL  : num [1:200] -0.0597 0.0402 -0.03 0.0394 -0.1582 ...\n",
    "  ..$ Oli_De_Jager_eQTL  : num [1:200] -0.0376 0.0668 0.1072 0.0819 -0.3407 ...\n",
    "  ..$ OPC_De_Jager_eQTL  : num [1:200] 0.058 0.0907 -0.0941 0.0193 -0.0585 ...\n",
    "  ..$ Exc_De_Jager_eQTL  : num [1:200] 0.01518 -0.00338 0.01137 -0.03883 -0.02836 ...\n",
    "  ..$ Inh_De_Jager_eQTL  : num [1:200] 0.00196 -0.05773 0.06773 -0.08281 0.29775 ...\n",
    "  ..$ DLPFC_De_Jager_eQTL: num [1:200] 0.000521 -0.004139 -0.010968 -0.019917 0.081309 ...\n",
    "  ..$ PCC_De_Jager_eQTL  : num [1:200] -0.0193 0.0273 -0.0237 0.0212 -0.0884 ...\n",
    "  ..$ AC_De_Jager_eQTL   : num [1:200] 0.001409 0.016122 -0.049309 -0.000438 -0.045112 ...\n",
    "  ..$ Mic_Kellis_eQTL    : num [1:200] 0.0506 0.0105 0.0444 0.0287 0.4847 ...\n",
    "  ..$ Ast_Kellis_eQTL    : num [1:200] 1.18e-02 1.34e-06 1.17e-01 1.28e-01 -5.49e-01 ...\n",
    "  ..$ Oli_Kellis_eQTL    : num [1:200] 0.0742 0.0675 -0.025 -0.0363 0.2675 ...\n",
    "  ..$ OPC_Kellis_eQTL    : num [1:200] -0.0333 -0.0226 -0.0231 0.0717 -0.0915 ...\n",
    "  ..$ Exc_Kellis_eQTL    : num [1:200] 0.03593 0.00316 0.01524 -0.0089 0.08042 ...\n",
    "  ..$ Inh_Kellis_eQTL    : num [1:200] -0.043 -0.0471 0.0418 0.0791 -0.0831 ...\n",
    "  ..$ Ast.10_Kellis_eQTL : num [1:200] 0 0 0 0 0 0 0 0 0 0 ...\n",
    " $ strong.s:'data.frame':\t62 obs. of  16 variables:\n",
    "  ..$ Mic_De_Jager_eQTL  : num [1:62] 0.3036 0.0925 0.0569 0.095 0.0626 ...\n",
    "  ..$ Ast_De_Jager_eQTL  : num [1:62] 0.2298 0.0777 0.0476 0.08 0.053 ...\n",
    "  ..$ Oli_De_Jager_eQTL  : num [1:62] 0.2397 0.0912 0.0556 0.0944 0.0623 ...\n",
    "  ..$ OPC_De_Jager_eQTL  : num [1:62] 0.3184 0.1084 0.0672 0.1122 0.0741 ...\n",
    "  ..$ Exc_De_Jager_eQTL  : num [1:62] 0.1051 0.0577 0.0336 0.0586 0.039 ...\n",
    "  ..$ Inh_De_Jager_eQTL  : num [1:62] 0.198 0.0861 0.0513 0.0872 0.0581 ...\n",
    "  ..$ DLPFC_De_Jager_eQTL: num [1:62] 0.0511 0.0366 0.0225 0.0349 0.0249 ...\n",
    "  ..$ PCC_De_Jager_eQTL  : num [1:62] 0.0844 0.0551 0.0326 0.0543 0.0367 ...\n",
    "  ..$ AC_De_Jager_eQTL   : num [1:62] 0.0729 0.0483 0.0302 0.0484 0.0343 ...\n",
    "  ..$ Mic_Kellis_eQTL    : num [1:62] 0.319 1000 1000 1000 1000 ...\n",
    "  ..$ Ast_Kellis_eQTL    : num [1:62] 0.3174 0.0941 0.054 0.0926 0.0604 ...\n",
    "  ..$ Oli_Kellis_eQTL    : num [1:62] 0.2342 0.0776 0.0471 0.0783 0.0527 ...\n",
    "  ..$ OPC_Kellis_eQTL    : num [1:62] 0.3137 0.0972 0.0568 0.0953 0.0631 ...\n",
    "  ..$ Exc_Kellis_eQTL    : num [1:62] 0.1788 0.0754 0.0442 0.0756 0.0495 ...\n",
    "  ..$ Inh_Kellis_eQTL    : num [1:62] 0.2481 0.0783 0.0454 0.0762 0.0506 ...\n",
    "  ..$ Ast.10_Kellis_eQTL : num [1:62] 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...\n",
    " $ null.s  :'data.frame':\t200 obs. of  16 variables:\n",
    "  ..$ Mic_De_Jager_eQTL  : num [1:200] 0.0633 0.0667 0.0866 0.0795 0.3139 ...\n",
    "  ..$ Ast_De_Jager_eQTL  : num [1:200] 0.0486 0.0502 0.0665 0.0603 0.2429 ...\n",
    "  ..$ Oli_De_Jager_eQTL  : num [1:200] 0.0498 0.0522 0.0671 0.0621 0.2443 ...\n",
    "  ..$ OPC_De_Jager_eQTL  : num [1:200] 0.0663 0.0688 0.0905 0.0842 0.3302 ...\n",
    "  ..$ Exc_De_Jager_eQTL  : num [1:200] 0.0225 0.0234 0.0308 0.0282 0.1132 ...\n",
    "  ..$ Inh_De_Jager_eQTL  : num [1:200] 0.0421 0.044 0.0577 0.0529 0.2107 ...\n",
    "  ..$ DLPFC_De_Jager_eQTL: num [1:200] 0.0127 0.0133 0.0181 0.0163 0.0726 ...\n",
    "  ..$ PCC_De_Jager_eQTL  : num [1:200] 0.0201 0.0213 0.0289 0.0259 0.104 ...\n",
    "  ..$ AC_De_Jager_eQTL   : num [1:200] 0.0183 0.0191 0.0269 0.0237 0.1017 ...\n",
    "  ..$ Mic_Kellis_eQTL    : num [1:200] 0.0602 0.0619 0.0864 0.078 0.305 ...\n",
    "  ..$ Ast_Kellis_eQTL    : num [1:200] 0.0543 0.0565 0.0765 0.0707 0.2917 ...\n",
    "  ..$ Oli_Kellis_eQTL    : num [1:200] 0.0421 0.0444 0.0597 0.0545 0.2213 ...\n",
    "  ..$ OPC_Kellis_eQTL    : num [1:200] 0.0539 0.0566 0.077 0.0708 0.2842 ...\n",
    "  ..$ Exc_Kellis_eQTL    : num [1:200] 0.0329 0.0344 0.0457 0.0427 0.1859 ...\n",
    "  ..$ Inh_Kellis_eQTL    : num [1:200] 0.0461 0.047 0.0634 0.0589 0.2358 ...\n",
    "  ..$ Ast.10_Kellis_eQTL : num [1:200] 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...\n",
    " $ random.s:'data.frame':\t200 obs. of  16 variables:\n",
    "  ..$ Mic_De_Jager_eQTL  : num [1:200] 0.0603 0.096 0.0694 0.0657 0.0769 ...\n",
    "  ..$ Ast_De_Jager_eQTL  : num [1:200] 0.0466 0.074 0.0521 0.0507 0.0578 ...\n",
    "  ..$ Oli_De_Jager_eQTL  : num [1:200] 0.048 0.0752 0.0526 0.0517 0.0585 ...\n",
    "  ..$ OPC_De_Jager_eQTL  : num [1:200] 0.0635 0.1011 0.0711 0.0693 0.0789 ...\n",
    "  ..$ Exc_De_Jager_eQTL  : num [1:200] 0.0219 0.0345 0.0243 0.0237 0.0266 ...\n",
    "  ..$ Inh_De_Jager_eQTL  : num [1:200] 0.0405 0.0648 0.0457 0.0439 0.0501 ...\n",
    "  ..$ DLPFC_De_Jager_eQTL: num [1:200] 0.0125 0.0196 0.0145 0.0139 0.016 ...\n",
    "  ..$ PCC_De_Jager_eQTL  : num [1:200] 0.0198 0.0305 0.0234 0.021 0.0251 ...\n",
    "  ..$ AC_De_Jager_eQTL   : num [1:200] 0.0176 0.0284 0.0209 0.0196 0.0229 ...\n",
    "  ..$ Mic_Kellis_eQTL    : num [1:200] 0.0598 0.0894 0.065 0.0641 0.0709 ...\n",
    "  ..$ Ast_Kellis_eQTL    : num [1:200] 0.0523 0.0838 0.0587 0.0559 0.0625 ...\n",
    "  ..$ Oli_Kellis_eQTL    : num [1:200] 0.041 0.0651 0.0453 0.0444 0.0509 ...\n",
    "  ..$ OPC_Kellis_eQTL    : num [1:200] 0.053 0.0829 0.0582 0.0571 0.0627 ...\n",
    "  ..$ Exc_Kellis_eQTL    : num [1:200] 0.033 0.0506 0.0348 0.0343 0.0387 ...\n",
    "  ..$ Inh_Kellis_eQTL    : num [1:200] 0.045 0.0694 0.0492 0.0481 0.0545 ...\n",
    "  ..$ Ast.10_Kellis_eQTL : num [1:200] 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...\n",
    " $ strong.z:'data.frame':\t62 obs. of  16 variables:\n",
    "  ..$ Mic_De_Jager_eQTL  : num [1:62] 0.132 0.191 3.253 -2.304 2.161 ...\n",
    "  ..$ Ast_De_Jager_eQTL  : num [1:62] -3.22 -2.77 3.46 -3.28 2.13 ...\n",
    "  ..$ Oli_De_Jager_eQTL  : num [1:62] -0.235 2.139 2.48 -1.319 -0.98 ...\n",
    "  ..$ OPC_De_Jager_eQTL  : num [1:62] 0.549 1.905 1.759 -0.67 1.38 ...\n",
    "  ..$ Exc_De_Jager_eQTL  : num [1:62] -5.33 0.811 6.79 -2.35 0.171 ...\n",
    "  ..$ Inh_De_Jager_eQTL  : num [1:62] -3.185 1.744 3.466 -2.428 -0.967 ...\n",
    "  ..$ DLPFC_De_Jager_eQTL: num [1:62] -0.741 3.598 1.601 -9.025 -4.042 ...\n",
    "  ..$ PCC_De_Jager_eQTL  : num [1:62] -0.477 0.379 1.885 -3.231 1.151 ...\n",
    "  ..$ AC_De_Jager_eQTL   : num [1:62] -1.8726 -0.0757 2.7865 -4.0712 2.3891 ...\n",
    "  ..$ Mic_Kellis_eQTL    : num [1:62] -1.24 0 0 0 0 ...\n",
    "  ..$ Ast_Kellis_eQTL    : num [1:62] -3.134 1.227 1.355 -2.239 -0.729 ...\n",
    "  ..$ Oli_Kellis_eQTL    : num [1:62] -2.386 4.987 2.843 -3.956 -0.634 ...\n",
    "  ..$ OPC_Kellis_eQTL    : num [1:62] -0.3683 1.8424 1.1147 0.7209 0.0422 ...\n",
    "  ..$ Exc_Kellis_eQTL    : num [1:62] -3.343 1.056 3.308 -2.194 0.991 ...\n",
    "  ..$ Inh_Kellis_eQTL    : num [1:62] -1.641 0.585 2.653 -3.893 0.134 ...\n",
    "  ..$ Ast.10_Kellis_eQTL : num [1:62] 0 0 0 0 0 0 0 0 0 0 ...\n",
    " $ random.z:'data.frame':\t200 obs. of  16 variables:\n",
    "  ..$ Mic_De_Jager_eQTL  : num [1:200] -0.232 -0.72 -0.614 -2.116 2.132 ...\n",
    "  ..$ Ast_De_Jager_eQTL  : num [1:200] -0.1425 -0.6982 1.2298 0.0127 -0.7073 ...\n",
    "  ..$ Oli_De_Jager_eQTL  : num [1:200] -1.463 -1.214 1.873 -0.953 0.641 ...\n",
    "  ..$ OPC_De_Jager_eQTL  : num [1:200] 0.813 0.571 -0.624 0.976 0.24 ...\n",
    "  ..$ Exc_De_Jager_eQTL  : num [1:200] 1.844 -0.786 1.009 -0.455 0.304 ...\n",
    "  ..$ Inh_De_Jager_eQTL  : num [1:200] -2.4158 -0.2683 0.273 0.0964 1.1196 ...\n",
    "  ..$ DLPFC_De_Jager_eQTL: num [1:200] -0.4757 0.3416 0.0175 -0.3357 0.084 ...\n",
    "  ..$ PCC_De_Jager_eQTL  : num [1:200] -0.572 -0.813 -1.023 0.536 1.221 ...\n",
    "  ..$ AC_De_Jager_eQTL   : num [1:200] -0.8634 0.0689 -2.6709 0.9463 0.8218 ...\n",
    "  ..$ Mic_Kellis_eQTL    : num [1:200] 1.073 -1.91 -0.533 -1.03 0.413 ...\n",
    "  ..$ Ast_Kellis_eQTL    : num [1:200] 1.1182 -0.4138 -0.6432 -0.0395 -0.3177 ...\n",
    "  ..$ Oli_Kellis_eQTL    : num [1:200] -0.343 0.337 0.59 0.139 -0.693 ...\n",
    "  ..$ OPC_Kellis_eQTL    : num [1:200] -0.34097 -0.32177 -0.8792 0.00874 -0.29735 ...\n",
    "  ..$ Exc_Kellis_eQTL    : num [1:200] 0.0139 -1.705 0.7393 0.0371 -2.0365 ...\n",
    "  ..$ Inh_Kellis_eQTL    : num [1:200] -1.658 -0.478 -0.179 1.255 -0.402 ...\n",
    "  ..$ Ast.10_Kellis_eQTL : num [1:200] 0 0 0 0 0 0 0 0 0 0 ...\n",
    " $ null.z  :'data.frame':\t200 obs. of  16 variables:\n",
    "  ..$ Mic_De_Jager_eQTL  : num [1:200] -0.398 -0.444 -1.254 -0.495 -0.818 ...\n",
    "  ..$ Ast_De_Jager_eQTL  : num [1:200] -1.229 0.8 -0.452 0.654 -0.651 ...\n",
    "  ..$ Oli_De_Jager_eQTL  : num [1:200] -0.755 1.28 1.597 1.319 -1.394 ...\n",
    "  ..$ OPC_De_Jager_eQTL  : num [1:200] 0.876 1.318 -1.039 0.229 -0.177 ...\n",
    "  ..$ Exc_De_Jager_eQTL  : num [1:200] 0.675 -0.145 0.37 -1.379 -0.251 ...\n",
    "  ..$ Inh_De_Jager_eQTL  : num [1:200] 0.0466 -1.3118 1.1748 -1.5654 1.4129 ...\n",
    "  ..$ DLPFC_De_Jager_eQTL: num [1:200] 0.041 -0.31 -0.605 -1.221 1.121 ...\n",
    "  ..$ PCC_De_Jager_eQTL  : num [1:200] -0.962 1.283 -0.819 0.82 -0.85 ...\n",
    "  ..$ AC_De_Jager_eQTL   : num [1:200] 0.077 0.8421 -1.835 -0.0184 -0.4436 ...\n",
    "  ..$ Mic_Kellis_eQTL    : num [1:200] 0.841 0.17 0.514 0.368 1.589 ...\n",
    "  ..$ Ast_Kellis_eQTL    : num [1:200] 2.17e-01 2.37e-05 1.53 1.81 -1.88 ...\n",
    "  ..$ Oli_Kellis_eQTL    : num [1:200] 1.762 1.519 -0.418 -0.665 1.209 ...\n",
    "  ..$ OPC_Kellis_eQTL    : num [1:200] -0.619 -0.4 -0.3 1.013 -0.322 ...\n",
    "  ..$ Exc_Kellis_eQTL    : num [1:200] 1.091 0.092 0.333 -0.208 0.433 ...\n",
    "  ..$ Inh_Kellis_eQTL    : num [1:200] -0.932 -1.002 0.659 1.344 -0.353 ...\n",
    "  ..$ Ast.10_Kellis_eQTL : num [1:200] 0 0 0 0 0 0 0 0 0 0 ...\n",
    " $ ZtZ     : num [1:16, 1:16] 2.182 1.09 1.481 0.759 2.405 ...\n",
    "  ..- attr(*, \"dimnames\")=List of 2\n",
    "  .. ..$ : chr [1:16] \"Mic_De_Jager_eQTL\" \"Ast_De_Jager_eQTL\" \"Oli_De_Jager_eQTL\" \"OPC_De_Jager_eQTL\" ...\n",
    "  .. ..$ : chr [1:16] \"Mic_De_Jager_eQTL\" \"Ast_De_Jager_eQTL\" \"Oli_De_Jager_eQTL\" \"OPC_De_Jager_eQTL\" ...\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-tolerance",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-modeling",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# generate random and null only\n",
    "# sos run pipeline/mash_preprocessing.ipynb processing \\\n",
    "#     --name protocol_example_protein \\\n",
    "#     --sum_files test_pQTL_asso_list \\\n",
    "#                test_pQTL_asso_list \\\n",
    "#     --region_file test.region \\\n",
    "#     --traits A B \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-constitutional",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# generate strong only\n",
    "# sos run pipeline/mash_preprocessing.ipynb susie_signal \\\n",
    "#     --name protocol_example_protein \\\n",
    "#     --susie_list protocol_example_protein.susie_output.txt \\\n",
    "#     --traits A B \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-intranet",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# generate mashr input directly\n",
    "sos run pipeline/mash_preprocessing.ipynb susie_to_mash \\\n",
    "        --name mash_example \\\n",
    "        --coverage \"cs_coverage_0.7\" \\\n",
    "        --per_chunk 100 \\\n",
    "        --independent_variant_list ld_pruned_variants.txt.gz \\\n",
    "        --susie_list susie_list.tsv \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "attractive-manor",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "parameter: name = str\n",
    "# Path to work directory where output locates\n",
    "parameter: cwd = path(\"./output\")\n",
    "parameter: seed = 999\n",
    "parameter: n_random = 10\n",
    "parameter: n_null = 10\n",
    "parameter: exclude_condition = []\n",
    "# Containers that contains the necessary packages\n",
    "parameter: container = \"\"\n",
    "import re\n",
    "parameter: entrypoint= ('micromamba run -a \"\" -n' + ' ' + re.sub(r'(_apptainer:latest|_docker:latest|\\.sif)$', '', container.split('/')[-1])) if container else \"\"\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"1h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 1\n",
    "# This is in principle required; but in practice it can be optional if we are not exactly stringent about getting independent SNPs\n",
    "parameter: independent_variant_list = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "macro-collect",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# extract data for MASH from summary stats\n",
    "[susie_to_mash_1]\n",
    "parameter: per_chunk = 100\n",
    "parameter: fine_mapping_meta = path\n",
    "parameter: coverage = \"cs_coverage_0.7\"\n",
    "# first 3 col are chr start end, 4th column is region ID, 5th col are file names, 6 col is all the condition names comma split\n",
    "import pandas as pd\n",
    "df = pd.read_csv(fine_mapping_meta, sep='\\t', na_filter=False)\n",
    "meta_data = [\n",
    "    \"c(\" + \",\".join(f\"'NA'\" if y == '' else f\"'{y}'\" for y in row) + \")\"\n",
    "    for index, row in df.iterrows()\n",
    "]\n",
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))  \n",
    "# Desired group size\n",
    "grouped_meta_data = list(chunker(meta_data, per_chunk))\n",
    "input:  for_each = \"grouped_meta_data\"\n",
    "output: f\"{cwd}/{name}_cache/{name}_batch{_index+1}.rds\"\n",
    "task: trunk_workers = job_size, walltime = walltime, trunk_size = 1, mem = mem, cores = numThreads, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\",stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "\n",
    "    library(pecotmr)\n",
    "    converted_sub_meta_data <- c(${','.join([repr(item) for item in _grouped_meta_data])})\n",
    "    data_to_combined <- list()\n",
    "    \n",
    "    # Loop through _grouped_meta_data, evaluate each string as R code, and append the result\n",
    "    for (item in converted_sub_meta_data) {\n",
    "      data_to_combined <- c(data_to_combined, list(eval(parse(text = noquote(item)))))\n",
    "    }\n",
    "    # Combine evaluated data into a data frame\n",
    "    meta_df <- do.call(rbind, data_to_combined)\n",
    "    exclude_condition = c(${\",\".join([repr(x) for x in exclude_condition])})\n",
    "\n",
    "    res <- list()\n",
    "    for (i in 1:nrow(meta_df)) {\n",
    "      line <- meta_df[i,]\n",
    "      region_file <- line[7]\n",
    "      sumstats_db_file <- line[8]\n",
    "      region_id <- line[4]\n",
    "      conditions <- line[9]\n",
    "      if (conditions!=\"NA\") {\n",
    "         strong_file <- load_multitrait_R_sumstat(readRDS(region_file), readRDS(sumstats_db_file), coverage = \"${coverage}\", top_loci=TRUE, exclude_condition = exclude_condition)\n",
    "         ran_null_file <- load_multitrait_R_sumstat(readRDS(region_file), readRDS(sumstats_db_file), filter_file=${independent_variant_list:r}, exclude_condition = exclude_condition)\n",
    "         ran_null <- mash_rand_null_sample(ran_null_file, ${n_random}, ${n_null}, exclude_condition = exclude_condition, seed=${seed})\n",
    "         strong <- list(strong = list(bhat = strong_file$bhat, sbhat = strong_file$sbhat))\n",
    "         res[[region_id]] <- c(strong, ran_null)\n",
    "        } \n",
    "     }\n",
    "    saveRDS(res,${_output:r}, compress=\"xz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-document",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[susie_to_mash_2]\n",
    "input: group_by = \"all\"\n",
    "output: f\"{cwd}/{name}.mash_input.rds\" \n",
    "task: trunk_workers = job_size, walltime = walltime, trunk_size = 1, mem = mem, cores = numThreads, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", container = container, stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', entrypoint=entrypoint\n",
    "  library(pecotmr)\n",
    "  # Function to reformat data\n",
    "  reformat_data <- function(dat) { \n",
    "      res <- list(strong.b = dat$strong$bhat,\n",
    "                   random.b = dat$random$bhat,\n",
    "                   null.b = dat$null$bhat,\n",
    "                   strong.s = dat$strong$sbhat,\n",
    "                   null.s = dat$null$sbhat,\n",
    "                   random.s = dat$random$sbhat)\n",
    "    return(res)\n",
    "  }\n",
    "  # Function to rename rownames of dat\n",
    "  rename_rownames <- function(dat){\n",
    "  renamed_data <- lapply(names(dat), function(name) {\n",
    "    # Retrieve the data frame from the list\n",
    "    sublist <- dat[[name]]\n",
    "  \n",
    "    renamed_sublist <- lapply(sublist, function(df) {\n",
    "    if(length(df)!=0&&!is.null(df)){\n",
    "     # Check if nrow of df is zero\n",
    "      if(nrow(df) > 0) {\n",
    "        # Only rename rownames if df has more than 0 rows\n",
    "        rownames(df) <- paste(rownames(df), name, sep = \"_\")\n",
    "      }\n",
    "     }\n",
    "      return(df)\n",
    "    })\n",
    "  \n",
    "  return(renamed_sublist)\n",
    "  })\n",
    "  # Set the names of the modified list to match the original list\n",
    "  names(renamed_data) <- names(dat)\n",
    "  return(renamed_data)\n",
    "  }\n",
    "  batch_combined_data <- list()\n",
    "   for (batch in c(${_input:r,})){\n",
    "      res_reformatted <- lapply(readRDS(batch), reformat_data)\n",
    "      renamed_res_reformatted <- rename_rownames(res_reformatted)\n",
    "      merged_data <- list()\n",
    "      for(region in names(renamed_res_reformatted)){\n",
    "        merged_data <- merge_mash_data(merged_data, renamed_res_reformatted[[region]])\n",
    "      }\n",
    "      batch_combined_data <- merge_mash_data(batch_combined_data,merged_data)\n",
    "    } \n",
    "   saveRDS(batch_combined_data, \"${_output:n}.with_na.rds\", compress=\"xz\")\n",
    "   conditions = c(\"strong\", \"random\", \"null\")\n",
    "   for (cond in conditions){\n",
    "     batch_combined_data <- handle_invalid_summary_stat(batch_combined_data, bhat = paste0(cond,\".b\"), sbhat = paste0(cond,\".s\"),z = TRUE)\n",
    "   }\n",
    "   batch_combined_data$ZtZ = t(as.matrix(batch_combined_data$strong.z)) %*% as.matrix(batch_combined_data$strong.z) / nrow(batch_combined_data$strong.z)\n",
    "   saveRDS(batch_combined_data, ${_output:r}, compress=\"xz\")\n",
    " \n",
    "bash: expand = \"${ }\", container = container, stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', entrypoint=entrypoint\n",
    "    rm -rf ${cwd}/${name}_cache/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-values",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Get the random and null effects per analysis unit\n",
    "\n",
    "**FIXME: notice that we no longer rely on tensorQTL results for MASH analysis. Our new protocol uses SuSiE output. We keep this piece of code to extract from tensorQTL which may still be relevant for trans-analysis. But currently it is limited to random and null variants extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-kernel",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[random_null_tensorqtl_1]\n",
    "parameter: sum_files = paths\n",
    "parameter: region_file = path\n",
    "parameter: traits = paths\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "def find_matching_files_for_region(chr_id):\n",
    "    chr_number = chr_id[3:]  # subset 1 from chr1\n",
    "    pattern_str = r\"\\.{chr_number}\\.\"\n",
    "    pattern = re.compile(pattern_str.format(chr_number=chr_number))\n",
    "    paths = []\n",
    "    for sum_file in sum_files:\n",
    "        with open(sum_file, 'r') as af:\n",
    "            for aline in af:\n",
    "                if pattern.search(aline):\n",
    "                    paths.append(aline.strip())\n",
    "    return \",\".join(paths)\n",
    "\n",
    "updated_regions = []\n",
    "with open(region_file, 'r') as regions:\n",
    "    header = regions.readline().strip()\n",
    "    updated_regions.append(header + \"\\tpath\\tregion\")\n",
    "    for line in regions:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        chr_id, start, end, gene_id = parts\n",
    "        paths = find_matching_files_for_region(chr_id)\n",
    "        updated_regions.append(f\"{chr_id}\\t{start}\\t{end}\\t{gene_id}\\t{paths}\\t{chr_id}:{start}-{end}\")\n",
    "\n",
    "meta_df = pd.DataFrame([line.split(\"\\t\") for line in updated_regions[1:]], columns=updated_regions[0].split(\"\\t\"))\n",
    "meta = meta_df[['gene_id', 'path', 'region']].to_dict(orient='records')\n",
    "\n",
    "input: for_each='meta'\n",
    "output: f'{cwd:a}/{name}_cache/{name}.{_meta[\"gene_id\"]}.rds'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand = \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container, entrypoint=entrypoint\n",
    "    region <- \"${_meta['region']}\"\n",
    "    # FIXME I am sure there is a more elegant way to put together the path, via SoS\n",
    "    phenotype_path <- unlist(strsplit(\"${_meta['path']}\", \",\"))\n",
    "    dat <- tryCatch(\n",
    "      {\n",
    "        # Try to run the function\n",
    "         pecotmr::load_multitrait_tensorqtl_sumstat(phenotype_path = phenotype_path, region = region, \n",
    "          trait_names = c(${traits:r,}), filter_file = NULL, remove_any_missing = TRUE, max_rows_selected = 300, na_remove = ${\"T\" if na_remove else \"F\"})\n",
    "      },\n",
    "      error = function(e) {\n",
    "        warning(\"Attempt remove chr in region ID to load the data.\")\n",
    "        # If an error occurs, modify the region and try again\n",
    "        pecotmr::load_multitrait_tensorqtl_sumstat(phenotype_path = phenotype_path, region =  gsub(\"chr\", \"\", region), \n",
    "          trait_names = c(${traits:r,}), filter_file = NULL, remove_any_missing = TRUE, max_rows_selected = 300, na_remove = ${\"T\" if na_remove else \"F\"})\n",
    "      }\n",
    "    )\n",
    "    exclude_condition = c(${\",\".join([repr(x) for x in exclude_condition])})\n",
    "    dat <- pecotmr::mash_ran_null_sample(dat, ${n_random}, ${n_null}, ${expected_ncondition}, exclude_condition, z_only = ${\"TRUE\" if z_only else \"FALSE\"}, seed=${seed})\n",
    "    saveRDS(dat, ${_output:r}, compress=\"xz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "R",
     "ir",
     "R",
     "#DCDCDA",
     "r"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.24.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
