{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "plain-league",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# APA calling Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-letter",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Aim\n",
    "The purpose of this notebook is to call APA-based information (PDUI) based on DAPARS2 method\n",
    "(https://github.com/3UTR/DaPars2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-journalism",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Methods overview\n",
    "(Optional) 3UTR Generation:\n",
    "* _gtf2bed12.py_ : Covert gtf to bed format (Source from in-house codes from Li Lab: https://github.com/Xu-Dong/Exon_Intron_Extractor/blob/main/scripts/gtf2bed12.py)  \n",
    "\n",
    "    `wget https://raw.githubusercontent.com/seriousbamboo/Exon_Intron_Extractor/main/scripts/gtf2bed12.py`\n",
    "\n",
    "* _DaPars_Extract_Anno.py_ : extract the 3UTR regions in bed formats from the whole genome bed (Source from Dapars 2: https://github.com/3UTR/DaPars2/blob/master/src/DaPars_Extract_Anno.py)\n",
    "\n",
    "    `wget https://raw.githubusercontent.com/3UTR/DaPars2/master/src/DaPars_Extract_Anno.py`\n",
    "\n",
    "1 - Config files Generation:  \n",
    "* _Python 3_ loops to read line by line the sum of reads coverage of all chromosome.\n",
    "\n",
    "2 - Dapars2 Main Function:\n",
    "* _Dapars2_Multi_Sample.py_: use the least sqaures methods to calculate the usage of long isoforms (https://github.com/3UTR/DaPars2/blob/master/src/Dapars2_Multi_Sample.py)  \n",
    "\n",
    "    `wget https://raw.githubusercontent.com/seriousbamboo/DaPars2/master/src/Dapars2_Multi_Sample.py`\n",
    "    \n",
    "    Note: this part of code have been modified from source to deal with some formatting discrepancy in wig file\n",
    "\n",
    "3 - Impute missing values in Dapars result\n",
    "\n",
    "#### Dependence\n",
    "* _Python2_ (Note: codes in python2 can be update to Python 3 easily)\n",
    "* _Python3_\n",
    "* _R_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-connectivity",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "### Input for the whole Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-apple",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Required input: \n",
    "*  The path to the directory where the wig files are stored (denoted as bfile, please refer to further sessions for more detailed requirment)\n",
    "*  The 3'UTR annotation file\n",
    "\n",
    "If you do not have 3'UTR annotation file, please generate it following step 1. The input of generation is:\n",
    "*  GTF(served as the reference) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-terror",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-lesson",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "*  Dapars config files (in the current directory)\n",
    "*  PUDI (Raw) information saved in txt (in the specified output directory)\n",
    "*  PDUI (Imputed) information saved in txt. This can be used for further analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-nightlife",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "inclusive-white",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "parameter: walltime = '36h'\n",
    "parameter: mem = '100G'\n",
    "parameter: ncore = 22\n",
    "# the output directory for generated files\n",
    "parameter: cwd = path\n",
    "# path to GTF file \n",
    "parameter: thread = 8\n",
    "parameter: job_size = 22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-stations",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 0: Generate 3UTR regions based on GTF "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-planning",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "The 3UTR regions (saved in bed format) could be use __repeatly__ for different samples. It only served as the reference region, such that you __should not__ run it if given generated hg19/hg38 3UTR regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "union-style",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Generate the 3UTR region according to the gtf file\n",
    "[UTR_generation_1]\n",
    "# gtf file\n",
    "parameter: gtf = path\n",
    "input: gtf\n",
    "output: [f'{cwd}/gene_annotation.bed', f'{cwd}/transcript_to_geneName.txt']\n",
    "bash: expand = '${ }'\n",
    "    python2 Scripts/gtf2bed12.py --gtf \"${_input}\" --out \"${cwd}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "divided-approval",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[UTR_generation_2]\n",
    "parameter: gtf = path\n",
    "input: [f'{cwd}/gene_annotation.bed', f'{cwd}/transcript_to_geneName.txt']\n",
    "output: f'{cwd}/{gtf:bn}_3UTR.bed'\n",
    "bash: expand = '${ }'\n",
    "    python2 Scripts/DaPars_Extract_Anno.py -b \"${_input[0]}\" -s \"${_input[1]}\" -o \"${_output}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-aside",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### Step 1: Generating config files and calculating sample depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-edmonton",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "#### Notes on input file format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-morgan",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "For the input file, it has the following format. Additional notes are:\n",
    "* The first line is the information of file. If you do not have them, please add any content on first line\n",
    "* The file must end with \".wig\". It will not cause any problem if you directly change from \".bedgraph\"\n",
    "* If your input wig file did not have the characters __\"chr\"__ in the first column, please set `no_chr_prefix = T`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "worse-edward",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track type=bedGraph\n",
      "chr1\t10000\t10812\t0\n",
      "chr1\t10812\t10820\t1\n",
      "chr1\t10820\t11094\t0\n",
      "chr1\t11094\t11170\t1\n",
      "chr1\t11170\t11404\t0\n",
      "chr1\t11404\t11480\t1\n",
      "chr1\t11480\t11504\t0\n",
      "chr1\t11504\t11517\t1\n",
      "chr1\t11517\t11625\t0\n"
     ]
    }
   ],
   "source": [
    "head -n 10 Sample_Input/Wigfiles/Sample1.wig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "retained-highlight",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculcate total depth and configuration file\n",
    "[APAconfig]\n",
    "parameter: bfile = path\n",
    "parameter: annotation = path\n",
    "parameter: job_size = 1\n",
    "# Default parameters for Dapars2:\n",
    "parameter: least_pass_coverage_percentage = 0.3\n",
    "parameter: coverage_threshold = 10\n",
    "\n",
    "parameter: no_chr_prefix = \"F\"\n",
    "output: [f'{cwd}/sample_mapping_files.txt',f'{cwd}/sample_configuration_file.txt']\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = walltime, mem = mem, cores = ncore\n",
    "python3: expand = \"${ }\"\n",
    "    import re\n",
    "    import os\n",
    "    target_all_sample = os.listdir(\"${bfile}\")\n",
    "    target_all_sample = list(filter(lambda v: re.match('.*wig$', v), target_all_sample))\n",
    "    target_all_sample = [\"${bfile}\" + \"/\" + w for w in target_all_sample]\n",
    "    #print(target_all_sample)\n",
    "    print(\"INFO: Total\",len(target_all_sample),\"samples found in provided dirctory!\")\n",
    "    # Total depth file:\n",
    "    chr = []\n",
    "    for i in range(22):\n",
    "        chr.append(str(i+1))\n",
    "    chr = chr + [\"X\",\"Y\"]\n",
    "    if \"${no_chr_prefix}\" == \"F\":\n",
    "        chr = ['chr' + str(a) for a in chr]\n",
    "    mapping_file = open(\"${_output[0]}\", \"w\")\n",
    "    for current_sample in target_all_sample:\n",
    "        current_sample_total_depth = 0\n",
    "        # skip the default type = bedgraph line\n",
    "        for line in open(current_sample,'r'):\n",
    "            if line[0] != '#' and line[0] != 't':\n",
    "                fields = line.strip('\\n').split('\\t')\n",
    "                curr_chr = fields[0]\n",
    "                region_start = int(fields[1])\n",
    "                region_end = int(fields[2])\n",
    "                current_sample_total_depth += (curr_chr in chr) * int(float(fields[-1])) * (region_end - region_start)\n",
    "        field_out = [current_sample, str(current_sample_total_depth)]\n",
    "        mapping_file.writelines('\\t'.join(field_out) + '\\n')\n",
    "\n",
    "        print(\"Coverage of sample \", current_sample, \": \", current_sample_total_depth)\n",
    "    mapping_file.close()\n",
    "\n",
    "    # Configuration file:\n",
    "\n",
    "    config_file = open(${_output[1]:r},\"w\")\n",
    "    config_file.writelines(f\"Annotated_3UTR=${annotation}\\n\")\n",
    "    config_file.writelines( \"Aligned_Wig_files=%s\\n\" % \",\".join(target_all_sample))\n",
    "    config_file.writelines(f\"Output_directory=${cwd:bn}/${bfile:bn}\\n\")\n",
    "    config_file.writelines(f\"Output_result_file=Dapars_result\\n\")\n",
    "    config_file.writelines(f\"Least_pass_coverage_percentage=${least_pass_coverage_percentage}\\n\")\n",
    "    config_file.writelines( \"Coverage_threshold=${coverage_threshold}\\n\")\n",
    "    config_file.writelines( \"Num_Threads=${thread}\\n\")\n",
    "    config_file.writelines(f\"sequencing_depth_file=${_output[0]}\") \n",
    "    config_file.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-discipline",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step2: Run Dapars2 main to calculate PDUIs\n",
    "#### Tip: modified Dapars2_Multi_Sample.py\n",
    "Default input of Dapars2_Multi_Sample.py did not consider the situation that first column did not contain \"chr\" (shown in _Step 2_).   \n",
    "* We add a new argument no_chr_prefix (default is FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "registered-contrary",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Call Dapars2 multi_chromosome\n",
    "[APAmain]\n",
    "parameter: no_chr_prefix = False\n",
    "parameter: chrlist = list\n",
    "input: for_each = 'chrlist'\n",
    "output: [f'{cwd}/Wigfiles_{x}/Dapars_result_result_temp.{x}.txt' for x in chrlist], group_by = 1\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = ncore\n",
    "bash: expand = True\n",
    "    python2 Scripts/Dapars2_Multi_Sample.py {cwd}/sample_configuration_file.txt {_chrlist} {no_chr_prefix}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-requirement",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Step3: Inpute the result:\n",
    "This step impute the missing value in PDUI matrix and return the Imputed one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "advanced-allah",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Dapars result Imputation \n",
    "[APAimpute]\n",
    "# Input path\n",
    "# parameter: dapars_raw = \n",
    "parameter: chrlist = list\n",
    "# Default k neighbours. Set k = 0 will train the k in a data-driven manner\n",
    "parameter: knn = 5\n",
    "input: [f'{cwd}/Wigfiles_{x}/Dapars_result_result_temp.{x}.txt' for x in chrlist], group_by = 1\n",
    "output: [f'{cwd}/Dapars_result_imputed_{x}.txt' for x in chrlist], group_by = 1\n",
    "R: expand= \"${ }\"\n",
    "\n",
    "\n",
    "suppressPackageStartupMessages(require(dplyr))\n",
    "suppressPackageStartupMessages(require(tidyr))\n",
    "suppressPackageStartupMessages(require(doParallel))\n",
    "suppressPackageStartupMessages(require(VIM))\n",
    "suppressPackageStartupMessages(require(preprocessCore))\n",
    "  \n",
    "  \n",
    "# KNN impute\n",
    "\n",
    "# Decide the optimal n if possible. Set the k to 2:#sample \n",
    "# and train a best k. The idea is that, randomly remove \n",
    "# 20% numbers in the full value subset 5 times, calculate \n",
    "# MSE of imputed value by VIM and true value to decide which \n",
    "# k is the optimal one. (an analog from 5 fold CV)\n",
    "  \n",
    "  \n",
    "knn_train_sample <- function(input_df, k_nb){\n",
    "      # Sample data and remove entries\n",
    "      # We must keep 1 full col for impute\n",
    "      dim_df <- dim(input_df)\n",
    "      sample_size <-  round(dim_df[1] * dim_df[2] * 0.2, 0)\n",
    "      row_index <- sample(1:nrow(input_df), sample_size)\n",
    "      col_index <- sample(1:ncol(input_df), sample_size, replace = T)\n",
    "      val_list <- c()\n",
    "      for(i in 1:length(row_index)){\n",
    "        val_list <- c(val_list, input_df[row_index[i], col_index[i]])\n",
    "        input_df[row_index[i], col_index[i]] <- NA\n",
    "      }\n",
    "\n",
    "      # Impute value\n",
    "\n",
    "      impute_data <- VIM::kNN(input_df, k = k_nb)\n",
    "      impute_data <- impute_data[,1:ncol(input_df)]\n",
    "\n",
    "      # Calculate the MSE:\n",
    "      predict_list <- c()\n",
    "      for(i in 1:length(row_index)){\n",
    "        predict_list <- c(predict_list, impute_data[row_index[i], col_index[i]])\n",
    "      }\n",
    "      tss <- sum((predict_list - val_list)^2)\n",
    "      return(tss)\n",
    "}\n",
    "  \n",
    " # Read the data\n",
    "    input_dir <- ${_input:r}\n",
    "  \n",
    "\n",
    "    dapars_result <- \n",
    "      read.table(input_dir,\n",
    "                 header = T) \n",
    "    \n",
    "    dapars_names <- \n",
    "      dapars_result %>% \n",
    "      select(1:3)\n",
    "  \n",
    "    dapars_result <-\n",
    "      dapars_result %>% \n",
    "      select(-1:-3) \n",
    " \n",
    "  if(${knn} == 0){\n",
    "    \n",
    "\n",
    "    dapars_train_data <- dapars_result %>% drop_na()\n",
    "\n",
    "    # Train the model\n",
    "    no_cores <- detectCores() - 1\n",
    "    cl <- makeCluster(no_cores)\n",
    "    registerDoParallel(cl)\n",
    "\n",
    "    index <- seq(2, ncol(dapars_train_data), by = 1)  # Change by = x for precision, for large dataset, please make it bigger\n",
    "    result_list <- c()\n",
    "    for(i in 1:length(index)){\n",
    "        print(paste0(\"Train k = \",index[i]))\n",
    "        re <- foreach(j=1:5,.combine = c) %dopar% \n",
    "          knn_train_sample(dapars_train_data, index[i])\n",
    "        result_list <- c(result_list, mean(re))\n",
    "      }\n",
    "\n",
    "    optimal_k <- index[which.min(result_list)]\n",
    "    print(paste0(\"Optimal k selected is \", optimal_k))\n",
    "    }else{\n",
    "      optimal_k <- ${knn} \n",
    "      print(paste0(\"Use k = \", optimal_k, \" for imputation\"))\n",
    "    }\n",
    "      \n",
    "    \n",
    "  \n",
    "    # Train the whole dataset:\n",
    "    imputed_full_data <- VIM::kNN(dapars_result, k = optimal_k)\n",
    "    imputed_full_data <- imputed_full_data[,1:ncol(dapars_result)]\n",
    "  \n",
    "    qnorm_full_data <- \n",
    "      preprocessCore::normalize.quantiles(as.matrix(imputed_full_data), \n",
    "                                          copy = F)\n",
    "  \n",
    "    final_data <- cbind(dapars_names, qnorm_full_data)\n",
    "    write.table(final_data, file = ${_output:r}, quote = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-afghanistan",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "# Minimum working example\n",
    "### Step 0: 3UTR generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "banner-shanghai",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Running \u001b[32mUTR_generation_1\u001b[0m: Generate the 3UTR region according to the gtf file\n",
      "Done!\n",
      "INFO: \u001b[32mUTR_generation_1\u001b[0m is \u001b[32mcompleted\u001b[0m.\n",
      "INFO: \u001b[32mUTR_generation_1\u001b[0m output:   \u001b[32m/Users/albert29/Documents/Xqtl/Call_Dapars/Output/gene_annotation.bed /Users/albert29/Documents/Xqtl/Call_Dapars/Output/transcript_to_geneName.txt\u001b[0m\n",
      "INFO: Running \u001b[32mUTR_generation_2\u001b[0m: \n",
      "Generating regions ...\n",
      "Total extracted 3' UTR: 140563\n",
      "Finished\n",
      "INFO: \u001b[32mUTR_generation_2\u001b[0m is \u001b[32mcompleted\u001b[0m.\n",
      "INFO: \u001b[32mUTR_generation_2\u001b[0m output:   \u001b[32m/Users/albert29/Documents/Xqtl/Call_Dapars/Output/gencode.v19.annotation_3UTR.bed\u001b[0m\n",
      "INFO: Workflow UTR_generation (ID=wbdda56e90fddc24c) is executed successfully with 2 completed steps.\n"
     ]
    }
   ],
   "source": [
    "sos run apacalling.ipynb UTR_generation \\\n",
    "    --cwd /Users/albert29/Documents/Xqtl/Call_Dapars/Output \\\n",
    "    --gtf /Users/albert29/Documents/Xqtl/Call_Dapars/Sample_Input/gencode.v19.annotation.gtf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "answering-crawford",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/Users/albert29/Documents/Xqtl/Call_Dapars/Output\u001b[00m\n",
      "├── gencode.v19.annotation_3UTR.bed\n",
      "├── gene_annotation.bed\n",
      "├── sample_configuration_file.txt\n",
      "├── sample_mapping_files.txt\n",
      "└── transcript_to_geneName.txt\n",
      "\n",
      "0 directories, 5 files\n"
     ]
    }
   ],
   "source": [
    "tree /Users/albert29/Documents/Xqtl/Call_Dapars/Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-picnic",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### Step 1: Generating config files and calculating sample depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "accepted-premises",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Running \u001b[32mAPAconfig\u001b[0m: Calculcate total depth and configuration file\n",
      "INFO: Total 4 samples found in provided dirctory!\n",
      "Coverage of sample  /Users/albert29/Documents/Xqtl/Call_Dapars/Sample_Input/Wigfiles/Sample3.wig :  859989694\n",
      "Coverage of sample  /Users/albert29/Documents/Xqtl/Call_Dapars/Sample_Input/Wigfiles/Sample2.wig :  1017641808\n",
      "Coverage of sample  /Users/albert29/Documents/Xqtl/Call_Dapars/Sample_Input/Wigfiles/Sample1.wig :  851834461\n",
      "Coverage of sample  /Users/albert29/Documents/Xqtl/Call_Dapars/Sample_Input/Wigfiles/Sample4.wig :  890005265\n",
      "INFO: \u001b[32mAPAconfig\u001b[0m is \u001b[32mcompleted\u001b[0m.\n",
      "INFO: \u001b[32mAPAconfig\u001b[0m output:   \u001b[32m/Users/albert29/Documents/Xqtl/Call_Dapars/Output/sample_mapping_files.txt /Users/albert29/Documents/Xqtl/Call_Dapars/Output/sample_configuration_file.txt\u001b[0m\n",
      "INFO: Workflow APAconfig (ID=wbeede41b336d4ece) is executed successfully with 1 completed step.\n"
     ]
    }
   ],
   "source": [
    "sos run apacalling.ipynb APAconfig \\\n",
    "    --cwd /Users/albert29/Documents/Xqtl/Call_Dapars/Output \\\n",
    "    --bfile /Users/albert29/Documents/Xqtl/Call_Dapars/Sample_Input/Wigfiles \\\n",
    "    --annotation /Users/albert29/Documents/Xqtl/Call_Dapars/Output/gencode.v19.annotation_3UTR.bed \\\n",
    "    --no_chr_prefix F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "selective-bridge",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/Users/albert29/Documents/Xqtl/Call_Dapars/Output\u001b[00m\n",
      "├── gencode.v19.annotation_3UTR.bed\n",
      "├── gene_annotation.bed\n",
      "├── sample_configuration_file.txt\n",
      "├── sample_mapping_files.txt\n",
      "└── transcript_to_geneName.txt\n",
      "\n",
      "0 directories, 5 files\n"
     ]
    }
   ],
   "source": [
    "tree /Users/albert29/Documents/Xqtl/Call_Dapars/Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-reunion",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 2: Dapars2 Main\n",
    "Note: the example is a truncated version, which just have coverage in chr1,chr11 and chr12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "young-intro",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Running \u001b[32mAPAmain\u001b[0m: Call Dapars2 multi_chromosome\n",
      "[Thu Dec 16 15:41:29 2021] Start Analysis ...\n",
      "All samples Joint Processing chr10 ...\n",
      "[Thu Dec 16 15:41:29 2021] Loading Coverage ...\n",
      "[Thu Dec 16 15:41:29 2021] Start Analysis ...\n",
      "[Thu Dec 16 15:41:29 2021] Start Analysis ...\n",
      "All samples Joint Processing chr1 ...\n",
      "[Thu Dec 16 15:41:29 2021] Loading Coverage ...\n",
      "All samples Joint Processing chr11 ...\n",
      "[Thu Dec 16 15:41:29 2021] Loading Coverage ...\n",
      "/Users/albert29/Documents/Xqtl/Call_Dapars/Sample_Input/Wigfiles/Sample3.wig\n",
      "/Users/albert29/Documents/Xqtl/Call_Dapars/Sample_Input/Wigfiles/Sample2.wig\n",
      "/Users/albert29/Documents/Xqtl/Call_Dapars/Sample_Input/Wigfiles/Sample1.wig\n",
      "/Users/albert29/Documents/Xqtl/Call_Dapars/Sample_Input/Wigfiles/Sample4.wig\n",
      "/Users/albert29/Documents/Xqtl/Call_Dapars/Sample_Input/Wigfiles/Sample2.wig\n",
      "/Users/albert29/Documents/Xqtl/Call_Dapars/Sample_Input/Wigfiles/Sample3.wig\n",
      "/Users/albert29/Documents/Xqtl/Call_Dapars/Sample_Input/Wigfiles/Sample1.wig\n",
      "/Users/albert29/Documents/Xqtl/Call_Dapars/Sample_Input/Wigfiles/Sample4.wig\n",
      "/Users/albert29/Documents/Xqtl/Call_Dapars/Sample_Input/Wigfiles/Sample3.wig\n",
      "/Users/albert29/Documents/Xqtl/Call_Dapars/Sample_Input/Wigfiles/Sample2.wig\n",
      "/Users/albert29/Documents/Xqtl/Call_Dapars/Sample_Input/Wigfiles/Sample1.wig\n",
      "/Users/albert29/Documents/Xqtl/Call_Dapars/Sample_Input/Wigfiles/Sample4.wig\n",
      "[ 859989694 1017641808  851834461  890005265]\n",
      "[Thu Dec 16 15:41:51 2021] Loading Coverage Finished ...\n",
      "#assigned events:\n",
      "478\n",
      "478\n",
      "478\n",
      "477\n",
      "477\n",
      "477\n",
      "477\n",
      "477\n",
      "[ 859989694 1017641808  851834461  890005265]\n",
      "[Thu Dec 16 15:42:00 2021] Loading Coverage Finished ...\n",
      "#assigned events:\n",
      "1379\n",
      "1379\n",
      "1379\n",
      "1379\n",
      "1379\n",
      "1378\n",
      "1378\n",
      "1378\n",
      "[ 859989694 1017641808  851834461  890005265]\n",
      "[Thu Dec 16 15:42:01 2021] Loading Coverage Finished ...\n",
      "#assigned events:\n",
      "988\n",
      "988\n",
      "988\n",
      "988\n",
      "987\n",
      "987\n",
      "987\n",
      "987\n",
      "[Thu Dec 16 15:45:00 2021] Finished!\n",
      "INFO: \u001b[32mAPAmain\u001b[0m (index=1) is \u001b[32mcompleted\u001b[0m.\n",
      "[Thu Dec 16 15:45:59 2021] Finished!\n",
      "INFO: \u001b[32mAPAmain\u001b[0m (index=2) is \u001b[32mcompleted\u001b[0m.\n",
      "[Thu Dec 16 15:46:51 2021] Finished!\n",
      "INFO: \u001b[32mAPAmain\u001b[0m (index=0) is \u001b[32mcompleted\u001b[0m.\n",
      "INFO: \u001b[32mAPAmain\u001b[0m output:   \u001b[32m/Users/albert29/Documents/Xqtl/Call_Dapars/Output/Wigfiles_chr1/Dapars_result_result_temp.chr1.txt /Users/albert29/Documents/Xqtl/Call_Dapars/Output/Wigfiles_chr10/Dapars_result_result_temp.chr10.txt... (3 items in 3 groups)\u001b[0m\n",
      "INFO: Workflow APAmain (ID=wd6b3f69cde79c5b0) is executed successfully with 1 completed step and 3 completed substeps.\n"
     ]
    }
   ],
   "source": [
    "sos run apacalling.ipynb APAmain \\\n",
    "    --cwd /Users/albert29/Documents/Xqtl/Call_Dapars/Output \\\n",
    "    --no_chr_prefix F \\\n",
    "    --chrlist chr1 chr10 chr11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bigger-width",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/Users/albert29/Documents/Xqtl/Call_Dapars/Output\u001b[00m\n",
      "├── \u001b[01;34mWigfiles_chr1\u001b[00m\n",
      "│   ├── Dapars_result_result_temp.chr1.txt\n",
      "│   └── \u001b[01;34mtmp\u001b[00m\n",
      "│       ├── Each_processor_3UTR_Result_1.txt\n",
      "│       ├── Each_processor_3UTR_Result_2.txt\n",
      "│       ├── Each_processor_3UTR_Result_3.txt\n",
      "│       ├── Each_processor_3UTR_Result_4.txt\n",
      "│       ├── Each_processor_3UTR_Result_5.txt\n",
      "│       ├── Each_processor_3UTR_Result_6.txt\n",
      "│       ├── Each_processor_3UTR_Result_7.txt\n",
      "│       └── Each_processor_3UTR_Result_8.txt\n",
      "├── \u001b[01;34mWigfiles_chr10\u001b[00m\n",
      "│   ├── Dapars_result_result_temp.chr10.txt\n",
      "│   └── \u001b[01;34mtmp\u001b[00m\n",
      "│       ├── Each_processor_3UTR_Result_1.txt\n",
      "│       ├── Each_processor_3UTR_Result_2.txt\n",
      "│       ├── Each_processor_3UTR_Result_3.txt\n",
      "│       ├── Each_processor_3UTR_Result_4.txt\n",
      "│       ├── Each_processor_3UTR_Result_5.txt\n",
      "│       ├── Each_processor_3UTR_Result_6.txt\n",
      "│       ├── Each_processor_3UTR_Result_7.txt\n",
      "│       └── Each_processor_3UTR_Result_8.txt\n",
      "├── \u001b[01;34mWigfiles_chr11\u001b[00m\n",
      "│   ├── Dapars_result_result_temp.chr11.txt\n",
      "│   └── \u001b[01;34mtmp\u001b[00m\n",
      "│       ├── Each_processor_3UTR_Result_1.txt\n",
      "│       ├── Each_processor_3UTR_Result_2.txt\n",
      "│       ├── Each_processor_3UTR_Result_3.txt\n",
      "│       ├── Each_processor_3UTR_Result_4.txt\n",
      "│       ├── Each_processor_3UTR_Result_5.txt\n",
      "│       ├── Each_processor_3UTR_Result_6.txt\n",
      "│       ├── Each_processor_3UTR_Result_7.txt\n",
      "│       └── Each_processor_3UTR_Result_8.txt\n",
      "├── gencode.v19.annotation_3UTR.bed\n",
      "├── gene_annotation.bed\n",
      "├── sample_configuration_file.txt\n",
      "├── sample_mapping_files.txt\n",
      "└── transcript_to_geneName.txt\n",
      "\n",
      "6 directories, 32 files\n"
     ]
    }
   ],
   "source": [
    "tree /Users/albert29/Documents/Xqtl/Call_Dapars/Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-museum",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### Step 3: Impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "russian-essay",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Running \u001b[32mAPAimpute\u001b[0m: Dapars result Imputation\n",
      "[1] \"Use k = 5 for imputation\"\n",
      "[1] \"Use k = 5 for imputation\"\n",
      "[1] \"Use k = 5 for imputation\"\n",
      "Warning message:\n",
      "In preprocessCore::normalize.quantiles(as.matrix(imputed_full_data),  :\n",
      "  NAs introduced by coercion\n",
      "INFO: \u001b[32mAPAimpute\u001b[0m (index=1) is \u001b[32mcompleted\u001b[0m.\n",
      "Warning message:\n",
      "In preprocessCore::normalize.quantiles(as.matrix(imputed_full_data),  :\n",
      "  NAs introduced by coercion\n",
      "INFO: \u001b[32mAPAimpute\u001b[0m (index=2) is \u001b[32mcompleted\u001b[0m.\n",
      "Warning message:\n",
      "In preprocessCore::normalize.quantiles(as.matrix(imputed_full_data),  :\n",
      "  NAs introduced by coercion\n",
      "INFO: \u001b[32mAPAimpute\u001b[0m (index=0) is \u001b[32mcompleted\u001b[0m.\n",
      "INFO: \u001b[32mAPAimpute\u001b[0m output:   \u001b[32m/Users/albert29/Documents/Xqtl/Call_Dapars/Output/Dapars_result_imputed_chr1.txt /Users/albert29/Documents/Xqtl/Call_Dapars/Output/Dapars_result_imputed_chr10.txt... (3 items in 3 groups)\u001b[0m\n",
      "INFO: Workflow APAimpute (ID=wc04627bf743db81f) is executed successfully with 1 completed step and 3 completed substeps.\n"
     ]
    }
   ],
   "source": [
    "sos run apacalling.ipynb APAimpute \\\n",
    "    --cwd /Users/albert29/Documents/Xqtl/Call_Dapars/Output \\\n",
    "    --chrlist chr1 chr10 chr11 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-generic",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     "shell"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
