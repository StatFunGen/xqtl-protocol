{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ceef0cf-b55d-44f6-883e-bef7642aeff1",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Replication study\n",
    "This notebook is trying to validate the eQTLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e0b819-dd0c-49bc-802f-c3a9f3883f49",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run Replication-study.ipynb replication \\\n",
    "        --cwd ./ \\\n",
    "        --analysis_1_path analysis_1_path.txt \\\n",
    "        --analysis_2_path analysis_2_path.txt \\\n",
    "        --ID_keys  ID_keys.txt \\\n",
    "        --container containers/bioinfo.sif \\\n",
    "        --specify the cluster running parameters if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9a3f4c-430d-438c-a3dc-025c0e78781b",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Methods overview\n",
    "* Goal: Because of the different normalization and covariates extraction procedure, QTL calling result from the same data set might still have inconsistency. We aim to compare the difference bertween two calling results from two pipelines\n",
    "\n",
    "* Settings and notations:\n",
    "\n",
    "  * Outcome: $Y_{ir}, i=1,2,\\cdots,n; r = 1,2,\\cdots,R$\n",
    "  * SNP: $X_{ij}, i=1,2,...,n, j = 1,2,\\cdots, J$\n",
    "  * P value for the outcome-r and SNP j pair in test k $p^{(k)}_{jr}$\n",
    "  * test result for the outcome-r and SNP j pair in test k $I^{(k)}_{jr}$\n",
    "  * We should compare the test result coming from the same multiple testing procedure to make sure the results comparable, For example, BH adjustment: $I_{jr}^{(k)} = I\\{P_{ir}^{(k)}\\leq \\text{cutoff}_{jr}\\}$, where cutoff is the BH adjusted cutoff for each pair of features\n",
    "\n",
    "* Contingency table\n",
    "\n",
    "  |                                            | Test 2 is significant for pair $(j,r)$ | Test 2 is non-significant for pair $(j,r)$ |      |\n",
    "  | ------------------------------------------ | -------------------------------------- | ------------------------------------------ | ---- |\n",
    "  | Test 1 is significant for pair $(j,r)$     | TP                                     | FN                                         | m0   |\n",
    "  | Test 1 is non-significant for pair $(j,r)$ | FP                                     | TN                                         | m1   |\n",
    "  |                                            | S                                      | N                                          | m    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4375d744-5ff6-43bd-a0b3-2002f3b214dd",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Data input\n",
    "newly generated sumstats: /mnt/vast/hpc/csg/ROSMAP_methy_QTL_beta/association_scan/methyl_QTL_2/TensorQTL/emprical.cis_sumstats.txt\n",
    "\n",
    "original sumstats: \"/mnt/vast/hpc/csg/jt3386/original_data/mQTLs.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba251baa-3fd0-4933-be1f-418b9e9bd7a5",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "parameter: cwd = path\n",
    "# current working directory\n",
    "parameter: analysis_1_path = path\n",
    "# Containing qvalue result from the first analysis, this is used to specify the significant pairs in analysis 1, the file should contain molecular_feature name, snp_id and the qvalue of the pair from analysis 1\n",
    "parameter: analysis_2_path = path\n",
    "# Containing pvalue result from the second analysis, this is used to estimate pi1 statistics in analysis 2, the file should contain molecular_feature name, snp_id and the pvalue of the pair from analysis 2\n",
    "parameter: ID_keys = path\n",
    "# Used to specify the ID difference and match the pairs from the 2 analysis\n",
    "parameter: name = path\n",
    "\n",
    "# The following are the cluster submission parameters, might be useful;\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"5h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"2G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 8\n",
    "# Software container option\n",
    "parameter: container = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35a5907b-f43e-4106-b589-3441f86ae27e",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[replication]\n",
    "output: f'{cwd}/{name}.txt'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand= \"$[ ]\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', container=container\n",
    "    # set up\n",
    "    library(tidyverse)\n",
    "    library(qvalue)\n",
    "    analysis1_data = read.delim(\"$[analysis_1_path]\")\n",
    "    analysis2_data = read.delim(\"$[analysis_2_path]\")\n",
    "    # ? where did you match the snp id? how did you match them? can this be more generalize?\n",
    "    # fixme: this step can be select out to match the ids, we might need to make this more generalize\n",
    "    sig1 = analysis1_data %>% filter(qvalue <= 0.05)\n",
    "    p2_sig1 = analysis2_data %>% filter(pair %in% sig1$pair)\n",
    "    # output\n",
    "    pi0 = pi0est(p2_sig1$pValue)\n",
    "    pi1 = 1-pi0$pi0\n",
    "    output_tib = tibble(name = \"$[name]\",\n",
    "                        pi1 = pi1)\n",
    "    output_tib %>% readr::write_delim(\"$[cwd]/$[name].txt\",\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af63e384-ef02-4d62-8be8-bbab37f1053b",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Please finish the following steps:\n",
    "\n",
    "1. fixme refine and discussion with Gao\n",
    "2. Create 2 result files with the qvalue and pvalue randomly sampled from a uniform distribution as the input file specified as mwe, run the sos pipeline out;\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.23.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
