{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# MASH analysis pipeline with posterior computation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Compute MASH posteriors\n",
    "\n",
    "In the GTEx V6 paper we assumed one eQTL per gene and applied the model learned above to those SNPs. Under that assumption, the input data for posterior calculation will be the `dat$strong.*` matrices.\n",
    "It is a fairly straightforward procedure as shown in [this vignette](https://stephenslab.github.io/mashr/articles/eQTL_outline.html).\n",
    "\n",
    "But it is often more interesting to apply MASH to given list of eQTLs, eg, from those from fine-mapping results. In GTEx V8 analysis we obtain such gene-SNP pairs from DAP-G fine-mapping analysis. See [this notebook](https://stephenslab.github.io/gtex-eqtls/analysis/Independent_eQTL_Results.html) for how the input data is prepared. The workflow below takes a number of input chunks (each chunk is a list of matrices `dat$Bhat` and `dat$Shat`) \n",
    "and computes posterior for each chunk. It is therefore suited for running in parallel posterior computation for all gene-SNP pairs, if input data chunks are provided.\n",
    "\n",
    "\n",
    "```\n",
    "JOB_OPT=\"-c midway2.yml -q midway2\"\n",
    "DATA_DIR=/project/compbio/GTEx_eQTL/independent_eQTL\n",
    "sos run workflows/mashr_flashr_workflow.ipynb posterior \\\n",
    "    $JOB_OPT \\\n",
    "    --posterior-input $DATA_DIR/DAPG_pip_gt_0.01-AllTissues/DAPG_pip_gt_0.01-AllTissues.*.rds \\\n",
    "                      $DATA_DIR/ConditionalAnalysis_AllTissues/ConditionalAnalysis_AllTissues.*.rds\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "group recipe \n",
    "```\n",
    "Ast,Exc\n",
    "Mic,MiGA_GFM,MiGA_GTS\n",
    "Oli,DLPFC_pQTL\n",
    "# ... add more groups as needed, separated by commas\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "##### posterior: works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#no slice\n",
    "sos run /home/rf2872/codes/xqtl-pipeline/code/multivariate/MASH/mash_posterior.ipynb posterior  \\\n",
    "    --container /mnt/vast/hpc/csg/containers/xqtl_archive/stephenslab.sif \\\n",
    "    --analysis-units <(cat  MWE.list| cut -f 2) \\\n",
    "    --cwd MWE_udr  \\\n",
    "    --output_prefix  MWE_udr \\\n",
    "    --vhat mle \\\n",
    "    --mash_model MWE_udr/MWE_udr.EZ.V_mle.mash_model.rds -n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#slice\n",
    "sos run /home/rf2872/codes/xqtl-pipeline/code/multivariate/MASH/mash_posterior.ipynb posterior  \\\n",
    "    --container /mnt/vast/hpc/csg/containers/xqtl_archive/stephenslab.sif \\\n",
    "    --analysis-units <(cat  MWE.list| cut -f 2) \\\n",
    "    --cwd MWE_udr  \\\n",
    "    --output_prefix  MWE_udr \\\n",
    "    --vhat mle \\\n",
    "    --mash_model MWE_udr/MWE_udr.EZ.V_mle.mash_model.rds \\\n",
    "    --slice_method True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "##### contrast analysis: works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# 0 group\n",
    "sos run /home/rf2872/codes/xqtl-pipeline/code/multivariate/MASH/mash_posterior.ipynb mash_posterior_contrast   \\\n",
    "    --posterior_file test.list \\\n",
    "    --sum_file /mnt/vast/hpc/csg/rf2872/Work/Multivariate/MASH/From_SuSiE/2023.5_new/ep_MiGA/output/ROSMAP_Pseudo_eQTL_DLPFC_pQTL_MiGA.merged_rds.list  \\\n",
    "    --cwd test \\\n",
    "    --cells \"Ast\",\"Exc\",\"Inh\",\"Mic\",\"OPC\",\"Oli\",\"DLPFC_pQTL\",\"MiGA_GFM\",\"MiGA_GTS\",\"MiGA_SVZ\",\"MiGA_THA\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# 1 group\n",
    "sos run /home/rf2872/codes/xqtl-pipeline/code/multivariate/MASH/mash_posterior.ipynb mash_posterior_contrast   \\\n",
    "    --posterior_file test.list \\\n",
    "    --sum_file /mnt/vast/hpc/csg/rf2872/Work/Multivariate/MASH/From_SuSiE/2023.5_new/ep_MiGA/output/ROSMAP_Pseudo_eQTL_DLPFC_pQTL_MiGA.merged_rds.list  \\\n",
    "    --cwd test \\\n",
    "    --cells \"Ast\",\"Exc\",\"Inh\",\"Mic\",\"OPC\",\"Oli\",\"DLPFC_pQTL\",\"MiGA_GFM\",\"MiGA_GTS\",\"MiGA_SVZ\",\"MiGA_THA\" \\\n",
    "    --group1 \"Mic\",\"MiGA_GFM\",\"MiGA_GTS\",\"MiGA_SVZ\",\"MiGA_THA\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# 2 group\n",
    "sos run /home/rf2872/codes/xqtl-pipeline/code/multivariate/MASH/mash_posterior.ipynb mash_posterior_contrast   \\\n",
    "    --posterior_file test.list \\\n",
    "    --sum_file /mnt/vast/hpc/csg/rf2872/Work/Multivariate/MASH/From_SuSiE/2023.5_new/ep_MiGA/output/ROSMAP_Pseudo_eQTL_DLPFC_pQTL_MiGA.merged_rds.list  \\\n",
    "    --cwd test \\\n",
    "    --cells \"Ast\",\"Exc\",\"Inh\",\"Mic\",\"OPC\",\"Oli\",\"DLPFC_pQTL\",\"MiGA_GFM\",\"MiGA_GTS\",\"MiGA_SVZ\",\"MiGA_THA\" \\\n",
    "    --group1 \"Mic\",\"MiGA_GFM\",\"MiGA_GTS\",\"MiGA_SVZ\",\"MiGA_THA\" \\\n",
    "    --group2 \"Ast\",\"Exc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# recipe with 2 group\n",
    "sos run /home/rf2872/codes/xqtl-pipeline/code/multivariate/MASH/mash_posterior.ipynb mash_posterior_contrast   \\\n",
    "    --posterior_file test.list \\\n",
    "    --sum_file /mnt/vast/hpc/csg/rf2872/Work/Multivariate/MASH/From_SuSiE/2023.5_new/ep_MiGA/output/ROSMAP_Pseudo_eQTL_DLPFC_pQTL_MiGA.merged_rds.list  \\\n",
    "    --cwd test \\\n",
    "    --cells \"Ast\",\"Exc\",\"Inh\",\"Mic\",\"OPC\",\"Oli\",\"DLPFC_pQTL\",\"MiGA_GFM\",\"MiGA_GTS\",\"MiGA_SVZ\",\"MiGA_THA\" \\\n",
    "    --grouping_recipe recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "import os\n",
    "# Work directory & output directory\n",
    "parameter: cwd = path('./')\n",
    "# The filename prefix for output data\n",
    "parameter: name=\"test\"\n",
    "parameter: cells = [\"Ast\",\"Exc\",\"Inh\",\"Mic\",\"OPC\",\"Oli\",\"DLPFC_pQTL\"]#order is important\n",
    "parameter: group1 = []\n",
    "parameter: group2 = []\n",
    "parameter: group3 = []\n",
    "parameter: job_size = 1\n",
    "parameter: container = ''\n",
    "parameter: table_name = \"\"\n",
    "parameter: posterior_file_list = \"w\"\n",
    "#parameter: orig_file = path\n",
    "parameter: orig_file_list = \"/mnt/vast/hpc/csg/rf2872/Work/MASH_test_csg/output/ALL_Ast_End_Exc_Inh_Mic_OPC_Oli.merged_rds.list\"\n",
    "#parameter:contrast_dir = \"/home/rf2872/Work/MASH_test_csg/MASH_6_celltypes_Dan/contrast/\"\n",
    "##  conditions can be excluded if needs arise. If nothing to exclude keep the default 0\n",
    "parameter: datadir = \"\"\n",
    "import pandas as pd\n",
    "#parameter: analysis_units = path\n",
    "# handle N = per_chunk data-set in one job\n",
    "parameter: per_chunk = 1\n",
    "###add for test\n",
    "parameter: output_prefix = ''\n",
    "parameter: output_suffix = 'all'\n",
    "# Exchangable effect (EE) or exchangable z-scores (EZ)\n",
    "parameter: effect_model = 'EZ'\n",
    "# Identifier of $\\hat{V}$ estimate file\n",
    "# Options are \"identity\", \"simple\", \"mle\", \"vhat_corshrink_xcondition\", \"vhat_simple_specific\"\n",
    "parameter: vhat = 'simple'\n",
    "parameter: data = path(\"fastqtl_to_mash_output/FastQTLSumStats.mash.rds\")\n",
    "data = data.absolute()\n",
    "cwd = cwd.absolute()\n",
    "if len(output_prefix) == 0:\n",
    "    output_prefix = f\"{data:bn}\"\n",
    "vhat_data = file_target(f\"{cwd:a}/{output_prefix}.{effect_model}.V_{vhat}.rds\")\n",
    "mash_model = file_target(f\"{cwd:a}/{output_prefix}.{effect_model}.V_{vhat}.mash_model.rds\")\n",
    "posterior_list = file_target(f\"{cwd:a}/{output_prefix}.{effect_model}.{output_suffix}.posterior_list\")\n",
    "\n",
    "def sort_uniq(seq):\n",
    "    seen = set()\n",
    "    return [x for x in seq if not (x in seen or seen.add(x))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Posterior results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "1. The outcome of the `[posterior]` step should produce a number of serialized R objects `*.batch_*.posterior.rds` (can be loaded to R via `readRDS()`) -- I chopped data to batches to take advantage of computing in multiple cluster nodes. It should be self-explanary but please let me know otherwise.\n",
    "2. Other posterior related files are:\n",
    "    1. `*.batch_*.yaml`: gene-SNP pairs of interest, identified elsewhere (eg. fine-mapping analysis). \n",
    "    2. The corresponding univariate analysis summary statistics for gene-SNPs from `*.batch_*.yaml` are extracted and saved to `*.batch_*.rds`, creating input to the `[posterior]` step.\n",
    "    3. Note the `*.batch_*.stdout` file documents some SNPs found in fine-mapping results but not found in the original `fastqtl` output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Slice Posterior \n",
    "\n",
    "take all the 13K genes, and for those with missing conditions we just drop those corresponding rows and cols in the prior model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Apply posterior calculations with slice NA and set NaN/Inf 0/1E3, output_posterior_cov = T \n",
    "[posterior_1]\n",
    "parameter: analysis_units = path\n",
    "regions = [x.replace(\"\\\"\",\"\").strip().split() for x in open(analysis_units).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "parameter: mash_model = path()\n",
    "parameter: posterior_input = [path(x[0]) for x in regions]\n",
    "parameter: posterior_vhat_files = paths()\n",
    "# eg, if data is saved in R list as data$strong, then\n",
    "# when you specify `--data-table-name strong` it will read the data as\n",
    "# readRDS('{_input:r}')$strong\n",
    "parameter: data_table_name = ''\n",
    "parameter: bhat_table_name = 'bhat'\n",
    "parameter: shat_table_name = 'sbhat'\n",
    "parameter: per_chunk = '100'\n",
    "##  conditions can be excluded if needs arise. If nothing to exclude keep the default 0\n",
    "parameter: exclude_condition = [\"1\",\"3\"]\n",
    "parameter: output_prefix = \"ROSMAP\"\n",
    "parameter: effect_model = 'EZ'\n",
    "# Options are \"identity\", \"simple\", \"mle\", \"vhat_corshrink_xcondition\", \"vhat_simple_specific\"\n",
    "parameter: vhat = 'simple'\n",
    "parameter: slice_method = False \n",
    "skip_if(len(posterior_input) == 0, msg = \"No posterior input data to compute on. Please specify it using --posterior-input.\")\n",
    "fail_if(len(posterior_vhat_files) > 1 and len(posterior_vhat_files) != len(posterior_input), msg = \"length of --posterior-input and --posterior-vhat-files do not agree.\")\n",
    "for p in posterior_input:\n",
    "    fail_if(not p.is_file(), msg = f'Cannot find posterior input file ``{p}``')\n",
    "vhat_data = file_target(f\"{cwd:a}/{output_prefix}.{effect_model}.V_{vhat}.rds\")\n",
    "mash_model = file_target(f\"{cwd:a}/{output_prefix}.{effect_model}.V_{vhat}.mash_model.rds\")\n",
    "input: posterior_input, group_by = per_chunk\n",
    "output: f\"{cwd}/cache/mash_output_list_{_index+1}\"\n",
    "task: trunk_workers = 1, walltime = '20h', trunk_size = 1, mem = '20G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", workdir = cwd, stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\", container = container\n",
    "    library(mashr)\n",
    "    library(dplyr)\n",
    "    library(stringr)\n",
    "    #library(ttt)\n",
    "    handle_nan_etc = function(x) {\n",
    "      x$bhat[which(is.nan(x$bhat))] = 0\n",
    "      x$sbhat[which(is.nan(x$sbhat) | is.infinite(x$sbhat))] = 1E3\n",
    "      return(x)\n",
    "    }\n",
    "    # Slice matrices\n",
    "    slice_and_update_data <- function(data, vhat, snps, samples) {\n",
    "        data$bhat <- data$bhat[snps, samples] %>% as.matrix\n",
    "        data$sbhat <- data$sbhat[snps, samples] %>% as.matrix\n",
    "        data$Z <- data$Z[snps, samples] %>% as.matrix\n",
    "        vhat <- vhat[samples, samples] %>% as.matrix\n",
    "\n",
    "        # Filter SNPs and update column names\n",
    "        data$snp <- data$snp[data$snp %in% snps]\n",
    "        colnames(data$bhat) <- colnames(data$sbhat) <- colnames(data$Z) <- colnames(vhat) <- samples\n",
    "\n",
    "        return(list(data = data, vhat = vhat))\n",
    "    }\n",
    "  \n",
    "    # Remove covariance matrices that are not needed\n",
    "    remove_unnecessary_cov_matrices <- function(cov, all_samples, samples) {\n",
    "      unwanted_samples <- setdiff(all.samples, samples)\n",
    "      for (d in names(cov)) {\n",
    "        if (d %in% unwanted_samples || d %in% paste0(\"ED_\", unwanted_samples)) {\n",
    "          cov[[d]] <- NULL\n",
    "        }\n",
    "      }\n",
    "      return(cov)\n",
    "    }\n",
    "\n",
    "    # Update or adjust the covariance matrices\n",
    "    adjust_cov_matrices <- function(cov, samples) {\n",
    "      for (d in names(cov)) {\n",
    "        if (d %in% samples) {\n",
    "          cov[[d]] <- matrix(0, length(samples), length(samples))\n",
    "          cov[[d]][which(samples == d), which(samples == d)] <- 1\n",
    "        } else if (d == \"identity\") {\n",
    "          cov[[d]] <- matrix(0, length(samples), length(samples))\n",
    "          cov[[d]][1, 1] <- 1  \n",
    "        } else if (is.null(colnames(cov[[d]]))) {\n",
    "          cov[[d]] <- cov[[d]][1:length(samples), 1:length(samples)]\n",
    "        } else {\n",
    "          cov[[d]] <- cov[[d]][samples, samples]\n",
    "        }\n",
    "        cov[[d]] <- as.matrix(cov[[d]])\n",
    "      }\n",
    "      return(cov)\n",
    "    }\n",
    "\n",
    "    # Main function to update the covariance in the MASH model\n",
    "    update_mash_model_cov <- function(mash_model, all_samples, samples) {\n",
    "      cov <- mash_model$fitted_g$Ulist\n",
    "\n",
    "      # Remove matrices that are not required\n",
    "      cov <- remove_unnecessary_cov_matrices(cov, all_samples, samples)\n",
    "\n",
    "      # Update or reshape the covariance matrices\n",
    "      cov <- adjust_cov_matrices(cov, samples)\n",
    "\n",
    "      # Update the covariance matrices in the model\n",
    "      mash_model$fitted_g$Ulist <- cov\n",
    "\n",
    "      # Update the 'pi' attribute of the model\n",
    "      unwanted_samples <- setdiff(all.samples, samples)\n",
    "      for (s in unwanted_samples) {\n",
    "        mash_model$fitted_g$pi <- mash_model$fitted_g$pi[-grep(s, names(mash_model$fitted_g$pi))]\n",
    "      }\n",
    "\n",
    "      return(mash_model)\n",
    "    }\n",
    "  \n",
    "    #slice = TRUE  # Set this to either TRUE or FALSE\n",
    "\n",
    "    outlist = data.frame()\n",
    "    for (f in c(${_input:r,})) try({\n",
    "\n",
    "      data = readRDS(f)${('$' + data_table_name) if data_table_name else ''}\n",
    "      data <- handle_nan_etc(data)\n",
    "\n",
    "      if(c(${\",\".join(exclude_condition)})[1] > 0 ){\n",
    "        message(paste(\"Excluding condition ${exclude_condition} from the analysis\"))\n",
    "        data$bhat = data$bhat[,-c(${\",\".join(exclude_condition)})]\n",
    "        data$sbhat = data$sbhat[,-c(${\",\".join(exclude_condition)})]\n",
    "        data$Z = data$Z[,-c(${\",\".join(exclude_condition)})]\n",
    "      }\n",
    "\n",
    "      vhat = readRDS(\"${vhat_data if len(posterior_vhat_files) == 0 else posterior_vhat_files[_index]}\")\n",
    "      mash_model <- readRDS(\"${mash_model}\")\n",
    "  \n",
    "      slice_method <- ${'TRUE' if slice_method else 'FALSE'}\n",
    "      if(slice_method){\n",
    "        # All additional operations from the second script go here\n",
    "\n",
    "        all.samples <- colnames(data$bhat)\n",
    "        all.snps <- rownames(data$bhat)    \n",
    "\n",
    "        #remove the rows and cols containing NA\n",
    "        na.test <- data$bhat %>% as.data.frame %>% select_if(~any(!is.na(.))) %>% na.omit %>% as.matrix\n",
    "\n",
    "        #recording meaningful rows and cols\n",
    "        samples <- colnames(na.test)\n",
    "        snps <- rownames(na.test)\n",
    "\n",
    "        if(length(all.snps)!=length(snps) | length(all.samples)!=length(samples)){\n",
    "            # slice data matrix\n",
    "            data <- slice_and_update_data(data, vhat, snps, samples)\n",
    "\n",
    "            if(length(all.samples)!=length(samples)){\n",
    "                ##slice the prior\n",
    "                mash_model <- update_mash_model_cov(mash_model, all_samples, samples)\n",
    "            }\n",
    "        }\n",
    "      }\n",
    "\n",
    "      mash_data = mash_set_data(data$${bhat_table_name}, Shat=data$${shat_table_name}, alpha=${1 if effect_model == 'EZ' else 0}, V=vhat, zero_Bhat_Shat_reset = 1E3)\n",
    "      mash_output = mash_compute_posterior_matrices(mash_model, mash_data, output_posterior_cov=TRUE)\n",
    "      mash_output$snps = data$snps\n",
    "      samplename <- str_split(f, \"/\", simplify = T) %>% .[length(.)] %>% gsub('.rds', '', .)\n",
    "      saveRDS(mash_output, paste0(\"${_output:d}\", \"/\", samplename, \".posterior.rds\"))\n",
    "      outlist <- rbind(outlist, paste0(\"${_output:d}\", \"/\", samplename, \".posterior.rds\"))\n",
    "\n",
    "    })\n",
    "    write.table(outlist, ${_output:r}, col.names=F, row.names=F, quote=F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[*posterior_2]\n",
    "input: group_by = \"all\"\n",
    "output:f\"{cwd}/mash_output_list_{output_suffix}\"\n",
    "bash: expand ='${ }', workdir = cwd, stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\"\n",
    "     cd ${_input[0]:d}\n",
    "     cat mash_output_list_*[0-9] >> posterior_file_list\n",
    "     awk -F 'cis_long_table.' '{print $2}' posterior_file_list| awk -F '.posterior.rds' '{print $1}'|paste - posterior_file_list > ${_output:r}\n",
    "     rm posterior_file_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Posterior contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# perform mash posterior contrast for sliced data\n",
    "[mash_posterior_contrast_1]\n",
    "parameter: grouping_recipe = \"\"\n",
    "parameter: posterior_file = path\n",
    "parameter: sum_file = path\n",
    "\n",
    "# Extract data from posterior_file\n",
    "paths_posterior = [x.replace(\"\\\"\",\"\").strip().split()[1] for x in open(posterior_file).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "\n",
    "# Create a dictionary from sum_file for quick lookup\n",
    "dict_sum = dict([(x.replace(\"\\\"\",\"\").strip().split()[0], x.replace(\"\\\"\",\"\").strip().split()[1]) for x in open(sum_file).readlines() if x.strip() and not x.strip().startswith('#')])\n",
    "\n",
    "# Use genes from posterior_file to fetch corresponding paths from sum_file\n",
    "paths_sum = [dict_sum[x.replace(\"\\\"\",\"\").strip().split()[0]] for x in open(posterior_file).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "\n",
    "input: paths_posterior, paired_with='paths_sum', group_by=1\n",
    "output: f\"{cwd}/{_input:bnn}_posterior_contrast.rds\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '24h',  mem = '10G', tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\",stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout' \n",
    "    # Load necessary libraries\n",
    "    library(mashr)\n",
    "    library(RhpcBLASctl)\n",
    "    library(magrittr)\n",
    "    library(tidyverse)\n",
    "    #library(ttt)\n",
    "\n",
    "    # Set number of threads for BLAS operations\n",
    "    blas_set_num_threads(1)\n",
    "\n",
    "    # Create a function for pairwise contrast columns\n",
    "    MakePairwiseContrastCols <- function(contrast_left, orig_vector) {\n",
    "        orig_vector[contrast_left[1]] <- 1\n",
    "        orig_vector[contrast_left[2]] <- -1\n",
    "        orig_vector\n",
    "    }\n",
    "\n",
    "    # Function to fit contrast data\n",
    "    FitContrast <- function(index, orig_mean, posterior_mean, posterior_vcov) {\n",
    "            population_names <- colnames(posterior_mean) %>% str_remove_all(\"BETA_\")\n",
    "\n",
    "            orig_mean_vector <- orig_mean[index,]\n",
    "            names(orig_mean_vector) <- population_names\n",
    "            orig_mean_nonzero <- as.vector(orig_mean_vector != 0)\n",
    "            orig_mean_tested <- names(orig_mean_vector[orig_mean_nonzero])\n",
    "            n_populations <- length(orig_mean_tested)\n",
    "\n",
    "            pairwise_vector <- rep(0, n_populations)\n",
    "            names(pairwise_vector) <- orig_mean_tested\n",
    "\n",
    "            grouping <- grouping_all[orig_mean_tested]\n",
    "            if (n_populations > 1) {\n",
    "                if (n_populations > 2) {\n",
    "                    #####1. deviation contrast\n",
    "                    deviation_contrasts <- rep(-1, n_populations^2) %>% matrix(nrow = n_populations, ncol = n_populations)\n",
    "                    diag(deviation_contrasts) <- n_populations - 1\n",
    "                    rownames(deviation_contrasts) <- orig_mean_tested\n",
    "                    colnames(deviation_contrasts) <- orig_mean_tested\n",
    "                    deviation_contrasts_tested <- deviation_contrasts[, orig_mean_tested]\n",
    "                    \n",
    "                    unique_groups <- unique(grouping)\n",
    "                    for (grp in unique_groups[unique_groups > 0]) {\n",
    "                       #same celltype (e.g. MIC) with different populations would get 1/n for their weight, \n",
    "                        diag(deviation_contrasts_tested)[grouping == grp] <- (n_populations - 1) / length(grouping[grouping == grp])\n",
    "                        deviation_contrasts_tested[grouping == grp, grouping == grp] <- (n_populations - 1) / length(grouping[grouping == grp])\n",
    "                    }\n",
    "                    \n",
    "                    colnames(deviation_contrasts_tested) %<>% str_c(\"_deviation\")\n",
    "\n",
    "                    ####2. pairwise contrast\n",
    "                    two_combn <- combn(orig_mean_tested, m = 2)\n",
    "                    pairwise_names <- apply(two_combn, 2, str_c, collapse = \"_vs_\")\n",
    "                    pairwise_contrast <- apply(two_combn, 2, MakePairwiseContrastCols, pairwise_vector)\n",
    "                \n",
    "                    colnames(pairwise_contrast) <- pairwise_names\n",
    "                    \n",
    "                    # Create a new matrix to store the adjusted values\n",
    "                    pairwise_contrast_new <- pairwise_contrast\n",
    "\n",
    "                    # Loop through each column to archieve such goal: e.g.\n",
    "                    # microglia populations would get 1/n_Mic for their weight, \n",
    "                    # and Mic vs Mic would still be 1 vs -1 to estimate the internal difference among microglia datasets\n",
    "                    for (col in colnames(pairwise_contrast)) {\n",
    "                      # Split column names to get group names\n",
    "                      groups <- strsplit(col, \"_vs_\")[[1]]\n",
    "\n",
    "                      # Get the grouping values for the two groups\n",
    "                      group_values <- grouping[names(grouping) %in% groups]\n",
    "\n",
    "                      # Identify groups with non-zero grouping values\n",
    "                      relevant_groups <- names(group_values[group_values > 0])\n",
    "\n",
    "                      # Check if there are multiple distinct groups\n",
    "                      if (length(unique(group_values)) > 1 && length(relevant_groups) > 0) {\n",
    "                        distinct_groups <- unique(group_values[group_values > 0])\n",
    "\n",
    "                        for (distinct_grp in distinct_groups) {\n",
    "                          # Identify rows belonging to the current group\n",
    "                          rows_in_group <- names(grouping[grouping == distinct_grp])\n",
    "\n",
    "                          # Adjust the pairwise_contrast values for each row in the group\n",
    "                          pairwise_contrast_new[rows_in_group, col] <- pairwise_contrast[rows_in_group[rows_in_group %in% groups], col] / length(rows_in_group)\n",
    "                        }\n",
    "                      }\n",
    "                    }\n",
    "\n",
    "                    # Replace the original matrix with the new one\n",
    "                    pairwise_contrast <- pairwise_contrast_new\n",
    "\n",
    "                    #### 3. combine them \n",
    "                    contrast_design <- cbind(deviation_contrasts_tested / (n_populations - 1), pairwise_contrast)\n",
    "\n",
    "                } else {\n",
    "                    pairwise_vector[orig_mean_tested[1]] <- 1\n",
    "                    pairwise_vector[orig_mean_tested[2]] <- -1\n",
    "                    contrast_design <- as.matrix(pairwise_vector)\n",
    "                    colnames(contrast_design) <- str_c(orig_mean_tested[1], \"_vs_\", orig_mean_tested[2])\n",
    "                }\n",
    "\n",
    "                posterior_mean_subset <- posterior_mean[index,]\n",
    "                posterior_mean_subset2 <- posterior_mean_subset[orig_mean_tested]\n",
    "                posterior_vcov_subset <- posterior_vcov[,,index]\n",
    "                posterior_vcov_subset2 <- posterior_vcov_subset[orig_mean_tested,orig_mean_tested]\n",
    "\n",
    "                contrast_diff <- t(contrast_design) %*% posterior_mean_subset2\n",
    "                contrast_vcov <- t(contrast_design) %*% posterior_vcov_subset2 %*% contrast_design\n",
    "                contrast_se <- diag(contrast_vcov) %>% sqrt\n",
    "\n",
    "                contrast_p <- 2 * (1 - pnorm(abs(contrast_diff) / contrast_se))\n",
    "\n",
    "                contrast_diff_df <- t(contrast_diff) %>% as_tibble\n",
    "                colnames(contrast_diff_df) %<>% str_c(\"mean_contrast_\", .)\n",
    "                contrast_se_df <- t(contrast_se) %>% as_tibble\n",
    "                colnames(contrast_se_df) %<>% str_c(\"se_contrast_\", .)\n",
    "                contrast_p_df <- t(contrast_p) %>% as_tibble\n",
    "                colnames(contrast_p_df) %<>% str_c(\"p_contrast_\", .)\n",
    "\n",
    "                contrast_df <- bind_cols(contrast_diff_df, contrast_se_df, contrast_p_df)\n",
    "            } else if(grouping[orig_mean_tested][1]!=grouping[orig_mean_tested][2]){\n",
    "                contrast_vector <- rep(NA, length(population_names))\n",
    "                names(contrast_vector) <- str_c(\"mean_contrast_\", population_names, \"_deviation\")\n",
    "                contrast_df <- t(contrast_vector) %>% as_tibble\n",
    "            }\n",
    "            contrast_df\n",
    "        }\n",
    "\n",
    "    if(length(\"${cells}\") > 0){\n",
    "        # All the cells\n",
    "        cells <- c(\"${\", \".join(cells)}\") %>% str_split(., \",\", simplify = TRUE) %>% as.character \n",
    "\n",
    "        # Automatically set grouping categories based on the recipe， set0 for the celltypes without multiple populations\n",
    "        grouping_all <- rep(0, length(cells))\n",
    "        names(grouping_all) <- cells\n",
    "        \n",
    "  \n",
    "        # Read groupings from the recipe\n",
    "        if(length(\"${group1}\") > 0){\n",
    "            cell_groups <- list(\n",
    "              ${\"group1 = c(\" + \", \".join([\"'\" + item + \"'\" for item in group1]) + \")\" if len(group1) > 0 else \"\"} \n",
    "              ${\", group2 = c(\" + \", \".join([\"'\" + item + \"'\" for item in group2]) + \")\" if len(group2) > 0 else \"\"} \n",
    "              ${\", group3 = c(\" + \", \".join([\"'\" + item + \"'\" for item in group3]) + \")\" if len(group3) > 0 else \"\"}\n",
    "            )\n",
    "            if(!is.null(cell_groups)) {\n",
    "              cell_groups <- map(cell_groups, ~str_split(.x, \",\", simplify = TRUE) %>% as.character())\n",
    "            }\n",
    "        }\n",
    "  \n",
    "        if(\"${grouping_recipe}\" != \"\"){\n",
    "            cell_groups <- readLines(\"${grouping_recipe}\")\n",
    "            cell_groups <- lapply(cell_groups, function(g) strsplit(g, \",\")[[1]])\n",
    "        }\n",
    "\n",
    "        if(!is.null(cell_groups)){\n",
    "            for(i in seq_along(cell_groups)) {\n",
    "              grouping_all[cell_groups[[i]]] <- i\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Read the data files\n",
    "    orig_data <- read_rds(\"${_paths_sum[0]}\")$bhat\n",
    "    posterior_data <- read_rds(\"${_input}\")\n",
    "    posterior_mean <- posterior_data$PosteriorMean\n",
    "    posterior_cov <- posterior_data$PosteriorCov\n",
    "\n",
    "    # Align data and clean-up NaN values\n",
    "    orig_data <- orig_data[, colnames(posterior_mean), drop = FALSE]\n",
    "    orig_data[which(is.nan(orig_data))] <- 0 # Placeholder for NaNs\n",
    "\n",
    "    # Apply the FitContrast function and consolidate results\n",
    "    contrast_result <- map(1:nrow(posterior_mean), FitContrast, orig_data, posterior_mean, posterior_cov) %>% bind_rows %>%\n",
    "        select(matches(\"mean_contrast.*deviation\"), matches(\"mean_contrast.*_vs_\"), \n",
    "               matches(\"se_contrast.*deviation\"), matches(\"se_contrast.*_vs_\"), \n",
    "               matches(\"p_contrast.*deviation\"), matches(\"p_contrast.*_vs_\"))\n",
    "    rownames(contrast_result) <- rownames(posterior_mean)\n",
    "\n",
    "    write_rds(contrast_result,  ${_output:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# merge the contrast data with slice data\n",
    "[mash_posterior_contrast_2]\n",
    "input: group_by = \"all\"\n",
    "output: f\"{cwd}/posterior_sum.csv\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '24h',  mem = '10G', tags = f'{_output:bn}'  \n",
    "\n",
    "R: expand = \"${ }\",stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout' \n",
    "        library(dplyr)\n",
    "        library(tidyverse)\n",
    "        library(ggnewscale)\n",
    "        \n",
    "        all.list <- stringr::str_split(\"${_input}\", \" \", simplify = T)\n",
    "       \n",
    "        p_cut <- 1E-05\n",
    "\n",
    "        cells<-c(\"${\",\".join(cells)}\")%>%str_split(.,\",\",simplify = T)%>%as.character #ggnewscale cannot use a specified order, I can not find a good way to order them by category for now\n",
    "        conditions <-combn(cells, m = 2) %>%apply(., 2, str_c, collapse = \"_vs_\") \n",
    "        \n",
    "\n",
    "        df <- matrix(ncol = length(conditions), nrow = 4) %>% as.data.frame()\n",
    "        colnames(df) <- conditions\n",
    "        rownames(df) <- c( \"n_sig_snp\", \"n_snp\",\"n_sig_feature\",\"n_all_feature\")\n",
    "        for (con in conditions) {\n",
    "            n.all.sig.snp <- n.all.snp <- n.all.sig.feature <- n.all.feature <- 0\n",
    "\n",
    "            for (i in 1:length(all.list)) {\n",
    "                print(i)\n",
    "                tmp <- readRDS(all.list[i])\n",
    "                p.mtx <- tmp %>% select(matches(\"p_contrast.*_vs_\"))\n",
    "                p.mtx.con <- p.mtx %>% select(matches(con))\n",
    "                n.sig.snp <- sum(p.mtx.con < p_cut)\n",
    "                # print(n.sig.snp)\n",
    "                if(ncol(p.mtx.con)>0){\n",
    "                    p.mtx.con<-na.omit(p.mtx.con)\n",
    "                    n.sig.snp <- sum(p.mtx.con < p_cut)\n",
    "                    n.snp <- nrow(p.mtx.con)\n",
    "                } else {\n",
    "                    n.sig.snp <- n.snp <-0\n",
    "                }\n",
    "                # print(n.snp)\n",
    "                n.sig.feature <- ifelse(n.sig.snp > 0, 1, 0)\n",
    "                n.feature<- ifelse (n.snp > 0 , 1, 0)\n",
    "\n",
    "                n.all.sig.snp <- n.sig.snp + n.all.sig.snp\n",
    "                n.all.snp <- n.all.snp + n.snp\n",
    "                n.all.sig.feature <- n.all.sig.feature + n.sig.feature\n",
    "                n.all.feature <- n.all.feature + n.feature\n",
    "            }\n",
    "            df[, con] <- c( n.all.sig.snp,n.all.snp, n.all.sig.feature,n.all.feature)\n",
    "        }\n",
    "        write.csv(df, \"${_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot contrast result\n",
    "[mash_posterior_contrast_3, posterior_cntrast_plot]\n",
    "input: group_by = \"all\"\n",
    "output: f\"{cwd}/posterior_sum.png\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '24h',  mem = '10G', tags = f'{_output:bn}'  \n",
    "\n",
    "R: expand = \"${ }\",stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout' \n",
    "        library(dplyr)\n",
    "        library(tidyverse)\n",
    "        library(ggnewscale)\n",
    "        df <- read.csv(\"${_input:a}\",row.names=1)\n",
    "        colnames(df)<-gsub(\"DLPFC_\",\"\",colnames(df))\n",
    "        for (i in 1:ncol(df)) {\n",
    "            con1 <- stringr::str_split(colnames(df)[i], \"_vs_\", simplify = T)[, 1]\n",
    "            con2 <- stringr::str_split(colnames(df)[i], \"_vs_\", simplify = T)[, 2]\n",
    "\n",
    "            if (con1 > con2) {\n",
    "                new.name <- paste0(con2, \"_vs_\", con1)\n",
    "                colnames(df)[i] <- new.name\n",
    "            }\n",
    "        }\n",
    "\n",
    "        ## summarizxse with approach 1: snp-feature pair\n",
    "        snp.ratio <- df[\"n_sig_snp\", ] / df[\"n_snp\", ]\n",
    "        snp.ratio <- snp.ratio %>%\n",
    "            t() %>%\n",
    "            as.data.frame()\n",
    "        colnames(snp.ratio) <- \"ratio\"\n",
    "        snp.ratio$group <- \"snp\"\n",
    "\n",
    "        ## summarize with approach 2: feature\n",
    "        fet.ratio <- df[\"n_sig_feature\", ] / df[\"n_all_feature\", ]\n",
    "        fet.ratio <- fet.ratio %>%\n",
    "            t() %>%\n",
    "            as.data.frame()\n",
    "        rownames(fet.ratio) <- paste0(stringr::str_split(rownames(fet.ratio), \"_vs_\", simplify = T)[, 2], \"_vs_\", stringr::str_split(rownames(fet.ratio), \"_vs_\", simplify = T)[, 1])\n",
    "        colnames(fet.ratio) <- \"ratio\"\n",
    "        fet.ratio$group <- \"feature\"\n",
    "        ratio <- rbind(snp.ratio, fet.ratio)\n",
    "\n",
    "        ## I need to add the below to make it Simmetrie\n",
    "\n",
    "        cons <- rownames(ratio) %>%\n",
    "            str_split(., \"_vs_\", simplify = T) %>%\n",
    "            .[, 1] %>%\n",
    "            unique()\n",
    "        for (i in 1:length(cons)) {\n",
    "            new.name <- paste0(cons[i], \"_vs_\", cons[i])\n",
    "            ratio[new.name, ] <- 0\n",
    "        }\n",
    "\n",
    "        ratio$con1 <- stringr::str_split(rownames(ratio), \"_vs_\", simplify = T)[, 1]\n",
    "        ratio$con2 <- stringr::str_split(rownames(ratio), \"_vs_\", simplify = T)[, 2]\n",
    "\n",
    "        ## prepare for the plot, score1 is for snp-feature pair, score2 is for feature only\n",
    "        ratio$score1 <- ratio$score2 <- 0\n",
    "        ratio$score1[ratio$group == \"snp\"] <- ratio$ratio[ratio$group == \"snp\"]\n",
    "        ratio$score2[ratio$group == \"feature\"] <- ratio$ratio[ratio$group == \"feature\"]\n",
    "        ratio$label <- paste0(round(ratio$ratio, 4) * 100, \"%\")\n",
    "        ratio$label[ratio$group == 0] <- NA\n",
    "\n",
    "        # plot\n",
    "        num_cols <- length(cons)\n",
    "        height <- width <- 4 + num_cols * 0.5 \n",
    "        ggplot(ratio[ratio$group == \"snp\", ], aes(x = con1, y = con2)) +\n",
    "            geom_tile(aes(fill = score1)) +\n",
    "            scale_fill_gradient2(\"SNP_Feature pair\",\n",
    "                low = \"#762A83\", mid = \"white\", high = \"#1B7837\"\n",
    "            ) +\n",
    "            new_scale(\"fill\") +\n",
    "            geom_tile(aes(fill = score2), data = subset(ratio, group != \"snp\")) +\n",
    "            scale_fill_gradient2(\"Feature\",\n",
    "                low = \"#1B7837\", mid = \"white\", high = \"#762A83\"\n",
    "            ) +\n",
    "            geom_text(data = ratio, aes(label = label)) +\n",
    "            theme_bw()\n",
    "        #geom_text(data=ratio, aes(label = label, color = factor(group))) +theme_bw()\n",
    "        #ggsave(gsub(\".csv\",\".png\",filename))\n",
    "\n",
    "        ggsave(\"${_output}\",width = width, height = height)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0,
    "style": "side"
   },
   "version": "0.24.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
