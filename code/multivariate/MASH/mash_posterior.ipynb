{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# MASH analysis pipeline with posterior computation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "In the GTEx V6 paper we assumed one eQTL per gene and applied the model learned above to those SNPs. Under that assumption, the input data for posterior calculation will be the `dat$strong.*` matrices.\n",
    "It is a fairly straightforward procedure as shown in [this vignette](https://stephenslab.github.io/mashr/articles/eQTL_outline.html).\n",
    "\n",
    "But it is often more interesting to apply MASH to given list of eQTLs, eg, from those from fine-mapping results. In GTEx V8 analysis we obtain such gene-SNP pairs from DAP-G fine-mapping analysis. See [this notebook](https://stephenslab.github.io/gtex-eqtls/analysis/Independent_eQTL_Results.html) for how the input data is prepared. The workflow below takes a number of input chunks (each chunk is a list of matrices `dat$Bhat` and `dat$Shat`) \n",
    "and computes posterior for each chunk. It is therefore suited for running in parallel posterior computation for all gene-SNP pairs, if input data chunks are provided.\n",
    "\n",
    "\n",
    "```\n",
    "JOB_OPT=\"-c midway2.yml -q midway2\"\n",
    "DATA_DIR=/project/compbio/GTEx_eQTL/independent_eQTL\n",
    "sos run workflows/mashr_flashr_workflow.ipynb posterior \\\n",
    "    $JOB_OPT \\\n",
    "    --posterior-input $DATA_DIR/DAPG_pip_gt_0.01-AllTissues/DAPG_pip_gt_0.01-AllTissues.*.rds \\\n",
    "                      $DATA_DIR/ConditionalAnalysis_AllTissues/ConditionalAnalysis_AllTissues.*.rds\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd /mnt/vast/hpc/csg/rf2872/Work/Multivariate/MASH/MWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#slice\n",
    "sos run pipeline/mash_posterior.ipynb posterior  \\\n",
    "    --analysis-units <(cat  MWE.list| cut -f 2) \\\n",
    "    --cwd MWE_udr  \\\n",
    "    --output_prefix  MWE_udr \\\n",
    "    --vhat mle \\\n",
    "    --mash_model MWE_udr/MWE_udr.EZ.V_mle.mash_model.rds \\\n",
    "    --slice_method True \\\n",
    "    --container containers/stephenslab.sif "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### contrast analysis: works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# no group\n",
    "sos run pipeline/mash_posterior.ipynb mash_posterior_contrast   \\\n",
    "    --posterior_file MWE_udr/mash_output_list_all \\\n",
    "    --sum_file MWE.list  \\\n",
    "    --cwd test \\\n",
    "    --cells \"Ast\",\"Exc\",\"Inh\",\"Mic\",\"OPC\",\"Oli\",\"DLPFC_pQTL\",\"MiGA_GFM\",\"MiGA_GTS\",\"MiGA_SVZ\",\"MiGA_THA\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# 2 group\n",
    "sos run pipeline/mash_posterior.ipynb mash_posterior_contrast   \\\n",
    "    --posterior_file MWE_udr/mash_output_list_all \\\n",
    "    --sum_file MWE.list  \\\n",
    "    --cwd test_2group \\\n",
    "    --cells \"Ast\",\"Exc\",\"Inh\",\"Mic\",\"OPC\",\"Oli\",\"DLPFC_pQTL\",\"MiGA_GFM\",\"MiGA_GTS\",\"MiGA_SVZ\",\"MiGA_THA\" \\\n",
    "    --group1 \"Mic\",\"MiGA_GFM\",\"MiGA_GTS\",\"MiGA_SVZ\",\"MiGA_THA\" \\\n",
    "    --group2 \"Ast\",\"Exc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# recipe with 2 group\n",
    "sos run pipeline/mash_posterior.ipynb mash_posterior_contrast   \\\n",
    "    --posterior_file MWE_udr/mash_output_list_all \\\n",
    "    --sum_file MWE.list  \\\n",
    "    --cwd test_2group_recipe \\\n",
    "    --cells \"Ast\",\"Exc\",\"Inh\",\"Mic\",\"OPC\",\"Oli\",\"DLPFC_pQTL\",\"MiGA_GFM\",\"MiGA_GTS\",\"MiGA_SVZ\",\"MiGA_THA\" \\\n",
    "    --grouping_recipe recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "group recipe looks like:\n",
    "```\n",
    "Ast,Exc\n",
    "Mic,MiGA_GFM,MiGA_GTS\n",
    "Oli,DLPFC_pQTL\n",
    "# ... add more groups as needed, separated by commas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "import os\n",
    "# Work directory & output directory\n",
    "parameter: cwd = path('./')\n",
    "# The filename prefix for output data\n",
    "parameter: name=\"test\"\n",
    "parameter: cells = [\"Ast\",\"Exc\",\"Inh\",\"Mic\",\"OPC\",\"Oli\",\"DLPFC_pQTL\"]#order is important\n",
    "parameter: group1 = []\n",
    "parameter: group2 = []\n",
    "parameter: group3 = []\n",
    "parameter: job_size = 1\n",
    "parameter: container = ''\n",
    "# handle N = per_chunk data-set in one job\n",
    "parameter: per_chunk = 1\n",
    "###add for test\n",
    "parameter: output_prefix = ''\n",
    "parameter: output_suffix = 'all'\n",
    "# Exchangable effect (EE) or exchangable z-scores (EZ)\n",
    "parameter: effect_model = 'EZ'\n",
    "# Identifier of $\\hat{V}$ estimate file\n",
    "# Options are \"identity\", \"simple\", \"mle\", \"vhat_corshrink_xcondition\", \"vhat_simple_specific\"\n",
    "parameter: vhat = 'simple'\n",
    "parameter: data = path(\"fastqtl_to_mash_output/FastQTLSumStats.mash.rds\")\n",
    "parameter: p_cut=0.00001\n",
    "import re\n",
    "parameter: entrypoint= ('micromamba run -a \"\" -n' + ' ' + re.sub(r'(_apptainer:latest|_docker:latest|\\.sif)$', '', container.split('/')[-1])) if container else \"\"\n",
    "\n",
    "import pandas as pd\n",
    "data = data.absolute()\n",
    "cwd = cwd.absolute()\n",
    "\n",
    "if len(output_prefix) == 0:\n",
    "    output_prefix = f\"{data:bn}\"\n",
    "vhat_data = file_target(f\"{cwd:a}/{output_prefix}.{effect_model}.V_{vhat}.rds\")\n",
    "mash_model = file_target(f\"{cwd:a}/{output_prefix}.{effect_model}.V_{vhat}.mash_model.rds\")\n",
    "posterior_list = file_target(f\"{cwd:a}/{output_prefix}.{effect_model}.{output_suffix}.posterior_list\")\n",
    "\n",
    "def sort_uniq(seq):\n",
    "    seen = set()\n",
    "    return [x for x in seq if not (x in seen or seen.add(x))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Posterior results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "1. The outcome of the `[posterior]` step should produce a number of serialized R objects `*.batch_*.posterior.rds` (can be loaded to R via `readRDS()`) -- I chopped data to batches to take advantage of computing in multiple cluster nodes. It should be self-explanary but please let me know otherwise.\n",
    "2. Other posterior related files are:\n",
    "    1. `*.batch_*.yaml`: gene-SNP pairs of interest, identified elsewhere (eg. fine-mapping analysis). \n",
    "    2. The corresponding univariate analysis summary statistics for gene-SNPs from `*.batch_*.yaml` are extracted and saved to `*.batch_*.rds`, creating input to the `[posterior]` step.\n",
    "    3. Note the `*.batch_*.stdout` file documents some SNPs found in fine-mapping results but not found in the original `fastqtl` output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Posterior \n",
    "take all the 13K genes,\n",
    "if `slice_method = True` for those with missing conditions we just drop those corresponding rows and cols in the prior model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Apply posterior calculations with slice NA and set NaN/Inf 0/1E3, output_posterior_cov = T \n",
    "[posterior_1]\n",
    "parameter: analysis_units = path\n",
    "regions = [x.replace(\"\\\"\",\"\").strip().split() for x in open(analysis_units).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "parameter: mash_model = path()\n",
    "mash_model = mash_model.absolute()\n",
    "parameter: posterior_input = [path(x[0]) for x in regions]\n",
    "parameter: posterior_vhat_files = paths()\n",
    "# eg, if data is saved in R list as data$strong, then\n",
    "# when you specify `--data-table-name strong` it will read the data as\n",
    "# readRDS('{_input:r}')$strong\n",
    "parameter: data_table_name = ''\n",
    "parameter: bhat_table_name = 'bhat'\n",
    "parameter: shat_table_name = 'sbhat'\n",
    "parameter: per_chunk = '100'\n",
    "##  conditions can be excluded if needs arise. If nothing to exclude keep the default 0\n",
    "parameter: exclude_condition = [\"1\",\"3\"]\n",
    "\n",
    "parameter: slice_method = False \n",
    "skip_if(len(posterior_input) == 0, msg = \"No posterior input data to compute on. Please specify it using --posterior-input.\")\n",
    "fail_if(len(posterior_vhat_files) > 1 and len(posterior_vhat_files) != len(posterior_input), msg = \"length of --posterior-input and --posterior-vhat-files do not agree.\")\n",
    "for p in posterior_input:\n",
    "    fail_if(not p.is_file(), msg = f'Cannot find posterior input file ``{p}``')\n",
    "\n",
    "input: posterior_input, group_by = per_chunk\n",
    "output: f\"{cwd}/cache/mash_output_list_{_index+1}\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand = \"${ }\", workdir = cwd, stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\", container = container, entrypoint=entrypoint\n",
    "    library(mashr)\n",
    "    library(dplyr)\n",
    "    library(stringr)\n",
    "    #library(ttt)\n",
    "    handle_nan_etc = function(x) {\n",
    "      x$bhat[which(is.nan(x$bhat))] = 0\n",
    "      x$sbhat[which(is.nan(x$sbhat) | is.infinite(x$sbhat))] = 1E3\n",
    "      return(x)\n",
    "    }\n",
    "    # Slice matrices\n",
    "    slice_and_update_data <- function(data, vhat, snps, samples) {\n",
    "        data$bhat <- data$bhat[snps, samples] %>% as.matrix\n",
    "        data$sbhat <- data$sbhat[snps, samples] %>% as.matrix\n",
    "        data$Z <- data$Z[snps, samples] %>% as.matrix\n",
    "        vhat <- vhat[samples, samples] %>% as.matrix\n",
    "\n",
    "        # Filter SNPs and update column names\n",
    "        data$snp <- data$snp[data$snp %in% snps]\n",
    "        colnames(data$bhat) <- colnames(data$sbhat) <- colnames(data$Z) <- colnames(vhat) <- samples\n",
    "\n",
    "        return(list(data = data, vhat = vhat))\n",
    "    }\n",
    "  \n",
    "    # Remove covariance matrices that are not needed\n",
    "    remove_unnecessary_cov_matrices <- function(cov, all_samples, samples) {\n",
    "      unwanted_samples <- setdiff(all.samples, samples)\n",
    "      for (d in names(cov)) {\n",
    "        if (d %in% unwanted_samples || d %in% paste0(\"ED_\", unwanted_samples)) {\n",
    "          cov[[d]] <- NULL\n",
    "        }\n",
    "      }\n",
    "      return(cov)\n",
    "    }\n",
    "\n",
    "    # Update or adjust the covariance matrices\n",
    "    adjust_cov_matrices <- function(cov, samples) {\n",
    "      for (d in names(cov)) {\n",
    "        if (d %in% samples) {\n",
    "          cov[[d]] <- matrix(0, length(samples), length(samples))\n",
    "          cov[[d]][which(samples == d), which(samples == d)] <- 1\n",
    "        } else if (d == \"identity\") {\n",
    "          cov[[d]] <- matrix(0, length(samples), length(samples))\n",
    "          cov[[d]][1, 1] <- 1  \n",
    "        } else if (is.null(colnames(cov[[d]]))) {\n",
    "          cov[[d]] <- cov[[d]][1:length(samples), 1:length(samples)]\n",
    "        } else {\n",
    "          cov[[d]] <- cov[[d]][samples, samples]\n",
    "        }\n",
    "        cov[[d]] <- as.matrix(cov[[d]])\n",
    "      }\n",
    "      return(cov)\n",
    "    }\n",
    "\n",
    "    # Main function to update the covariance in the MASH model\n",
    "    update_mash_model_cov <- function(mash_model, all_samples, samples) {\n",
    "      cov <- mash_model$fitted_g$Ulist\n",
    "      # Remove matrices that are not required\n",
    "      cov <- remove_unnecessary_cov_matrices(cov, all_samples, samples)\n",
    "  \n",
    "      # Update or reshape the covariance matrices\n",
    "      cov <- adjust_cov_matrices(cov, samples)\n",
    "  \n",
    "      # Update the covariance matrices in the model\n",
    "      mash_model$fitted_g$Ulist <- cov\n",
    "  \n",
    "      # Update the 'pi' attribute of the model\n",
    "      unwanted_samples <- setdiff(all.samples, samples)\n",
    "      for (s in unwanted_samples) {\n",
    "        mash_model$fitted_g$pi <- mash_model$fitted_g$pi[-grep(s, names(mash_model$fitted_g$pi))]\n",
    "      }\n",
    "\n",
    "      return(mash_model)\n",
    "    }\n",
    "  \n",
    "    outlist = data.frame()\n",
    "    for (f in c(${_input:r,})) try({\n",
    "\n",
    "      data = readRDS(f)${('$' + data_table_name) if data_table_name else ''}\n",
    "      data <- handle_nan_etc(data)\n",
    "\n",
    "      if(c(${\",\".join(exclude_condition)})[1] > 0 ){\n",
    "        message(paste(\"Excluding condition ${exclude_condition} from the analysis\"))\n",
    "        data$bhat = data$bhat[,-c(${\",\".join(exclude_condition)})]\n",
    "        data$sbhat = data$sbhat[,-c(${\",\".join(exclude_condition)})]\n",
    "        data$Z = data$Z[,-c(${\",\".join(exclude_condition)})]\n",
    "      }\n",
    "\n",
    "      vhat = readRDS(\"${vhat_data if len(posterior_vhat_files) == 0 else posterior_vhat_files[_index]}\")\n",
    "      mash_model <- readRDS(\"${mash_model}\")\n",
    "  \n",
    "      slice_method <- ${'TRUE' if slice_method else 'FALSE'}\n",
    "      if(slice_method){\n",
    "        # All additional operations from the second script go here\n",
    "\n",
    "        all.samples <- colnames(data$bhat)\n",
    "        all.snps <- rownames(data$bhat)    \n",
    "\n",
    "        #remove the rows and cols containing NA\n",
    "        na.test <- data$bhat %>% as.data.frame %>% select_if(~any(!is.na(.))) %>% na.omit %>% as.matrix\n",
    "\n",
    "        #recording meaningful rows and cols\n",
    "        samples <- colnames(na.test)\n",
    "        snps <- rownames(na.test)\n",
    "\n",
    "        if(length(all.snps)!=length(snps) | length(all.samples)!=length(samples)){\n",
    "            # slice data matrix\n",
    "            data <- slice_and_update_data(data, vhat, snps, samples)\n",
    "\n",
    "            if(length(all.samples)!=length(samples)){\n",
    "                ##slice the prior\n",
    "                mash_model <- update_mash_model_cov(mash_model, all_samples, samples)\n",
    "            }\n",
    "        }\n",
    "      }\n",
    "\n",
    "      mash_data = mash_set_data(data$${bhat_table_name}, Shat=data$${shat_table_name}, alpha=${1 if effect_model == 'EZ' else 0}, V=vhat, zero_Bhat_Shat_reset = 1E3)\n",
    "      mash_output = mash_compute_posterior_matrices(mash_model, mash_data, output_posterior_cov=TRUE)\n",
    "      mash_output$snps = data$snps\n",
    "      samplename <- str_split(f, \"/\", simplify = T) %>% .[length(.)] %>% gsub('.rds', '', .)\n",
    "      saveRDS(mash_output, paste0(\"${_output:d}\", \"/\", samplename, \".posterior.rds\"))\n",
    "      outlist <- rbind(outlist, paste0(\"${_output:d}\", \"/\", samplename, \".posterior.rds\"))\n",
    "\n",
    "    })\n",
    "    write.table(outlist, ${_output:r}, col.names=F, row.names=F, quote=F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[posterior_2]\n",
    "input: group_by = \"all\"\n",
    "output:f\"{cwd}/mash_output_list_{output_suffix}\"\n",
    "bash: expand ='${ }', workdir = cwd, stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\"\n",
    "     cd ${_input[0]:d}\n",
    "     cat mash_output_list_*[0-9] >> posterior_file_list\n",
    "     awk -F 'cis_long_table.' '{print $2}' posterior_file_list| awk -F '.posterior.rds' '{print $1}'|paste - posterior_file_list > ${_output:r}\n",
    "     rm posterior_file_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Posterior contrast\n",
    "- Add group in this module\n",
    "    \n",
    "    e.g. add MiGA-Microglia-scRNA data to this analysis to supplement the Mic cell count shortage, but the MiGA data comes from four sites with four datasets, and here I handled it in such a way that the different Mic's were always in the same state during the deviation contrast analysis. If Mic is the one be compared, each Mic sample would be set as (n_populations - 1)/n_Mic instead of n_populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# perform mash posterior contrast for sliced data\n",
    "[mash_posterior_contrast_1]\n",
    "parameter: grouping_recipe = \"\"\n",
    "parameter: posterior_file = path\n",
    "parameter: sum_file = path\n",
    "\n",
    "# Extract data from posterior_file\n",
    "paths_posterior = [x.replace(\"\\\"\",\"\").strip().split()[1] for x in open(posterior_file).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "# Create a dictionary from sum_file for quick lookup\n",
    "dict_sum = dict([(x.replace(\"\\\"\",\"\").strip().split()[0], x.replace(\"\\\"\",\"\").strip().split()[1]) for x in open(sum_file).readlines() if x.strip() and not x.strip().startswith('#')])\n",
    "# Use genes from posterior_file to fetch corresponding paths from sum_file\n",
    "paths_sum = [dict_sum[x.replace(\"\\\"\",\"\").strip().split()[0]] for x in open(posterior_file).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "\n",
    "input: paths_posterior, paired_with='paths_sum', group_by=1\n",
    "output: f\"{cwd}/{_input:bnn}_posterior_contrast.rds\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand = \"${ }\", workdir = cwd, stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\", container = container, entrypoint=entrypoint\n",
    "    # Load necessary libraries\n",
    "    library(mashr)\n",
    "    library(RhpcBLASctl)\n",
    "    library(magrittr)\n",
    "    library(tidyverse)\n",
    "    #library(ttt)\n",
    "\n",
    "    # Set number of threads for BLAS operations\n",
    "    blas_set_num_threads(1)\n",
    "\n",
    "    # Create a function for pairwise contrast columns\n",
    "    MakePairwiseContrastCols <- function(contrast_left, orig_vector) {\n",
    "        orig_vector[contrast_left[1]] <- 1\n",
    "        orig_vector[contrast_left[2]] <- -1\n",
    "        orig_vector\n",
    "    }\n",
    "\n",
    "    # Function to fit contrast data\n",
    "    FitContrast <- function(index, orig_mean, posterior_mean, posterior_vcov) {\n",
    "        population_names <- colnames(posterior_mean) %>% str_remove_all(\"BETA_\")\n",
    "\n",
    "        orig_mean_vector <- orig_mean[index,]\n",
    "        names(orig_mean_vector) <- population_names\n",
    "        orig_mean_nonzero <- as.vector(orig_mean_vector != 0)\n",
    "        orig_mean_tested <- names(orig_mean_vector[orig_mean_nonzero])\n",
    "        \n",
    "        if(length(orig_mean_tested)>0){\n",
    "            n_populations <- length(orig_mean_tested)\n",
    "\n",
    "            pairwise_vector <- rep(0, n_populations)\n",
    "            names(pairwise_vector) <- orig_mean_tested\n",
    "\n",
    "            grouping <- grouping_all[orig_mean_tested]\n",
    "            if (n_populations > 1) {\n",
    "                if (n_populations > 2) {\n",
    "                    #####1. deviation contrast\n",
    "                    deviation_contrasts <- rep(-1, n_populations^2) %>% matrix(nrow = n_populations, ncol = n_populations)\n",
    "                    diag(deviation_contrasts) <- n_populations - 1\n",
    "                    rownames(deviation_contrasts) <- orig_mean_tested\n",
    "                    colnames(deviation_contrasts) <- orig_mean_tested\n",
    "                    deviation_contrasts_tested <- deviation_contrasts[, orig_mean_tested]\n",
    "\n",
    "                    unique_groups <- unique(grouping)\n",
    "                    for (grp in unique_groups[unique_groups > 0]) {\n",
    "                       #same celltype (e.g. MIC) with different populations would get 1/n for their weight,\n",
    "                        diag(deviation_contrasts_tested)[grouping == grp] <- (n_populations - 1) / length(grouping[grouping == grp])\n",
    "                        deviation_contrasts_tested[grouping == grp, grouping == grp] <- (n_populations - 1) / length(grouping[grouping == grp])\n",
    "                    }\n",
    "\n",
    "                    colnames(deviation_contrasts_tested) %<>% str_c(\"_deviation\")\n",
    "\n",
    "                    ####2. pairwise contrast\n",
    "                    two_combn <- combn(orig_mean_tested, m = 2)\n",
    "                    pairwise_names <- apply(two_combn, 2, str_c, collapse = \"_vs_\")\n",
    "                    pairwise_contrast <- apply(two_combn, 2, MakePairwiseContrastCols, pairwise_vector)\n",
    "\n",
    "                    colnames(pairwise_contrast) <- pairwise_names\n",
    "\n",
    "                    # Create a new matrix to store the adjusted values\n",
    "                    pairwise_contrast_new <- pairwise_contrast\n",
    "\n",
    "                    # Loop through each column to archieve such goal: e.g.\n",
    "                    # microglia populations would get 1/n_Mic for their weight,\n",
    "                    # and Mic vs Mic would still be 1 vs -1 to estimate the internal difference among microglia datasets\n",
    "                    for (col in colnames(pairwise_contrast)) {\n",
    "                      # Split column names to get group names\n",
    "                      groups <- strsplit(col, \"_vs_\")[[1]]\n",
    "\n",
    "                      # Get the grouping values for the two groups\n",
    "                      group_values <- grouping[names(grouping) %in% groups]\n",
    "\n",
    "                      # Identify groups with non-zero grouping values\n",
    "                      relevant_groups <- names(group_values[group_values > 0])\n",
    "\n",
    "                      # Check if there are multiple distinct groups\n",
    "                      if (length(unique(group_values)) > 1 && length(relevant_groups) > 0) {\n",
    "                        distinct_groups <- unique(group_values[group_values > 0])\n",
    "\n",
    "                        for (distinct_grp in distinct_groups) {\n",
    "                          # Identify rows belonging to the current group\n",
    "                          rows_in_group <- names(grouping[grouping == distinct_grp])\n",
    "\n",
    "                          # Adjust the pairwise_contrast values for each row in the group\n",
    "                          pairwise_contrast_new[rows_in_group, col] <- pairwise_contrast[rows_in_group[rows_in_group %in% groups], col] / length(rows_in_group)\n",
    "                        }\n",
    "                      }\n",
    "                    }\n",
    "\n",
    "                    # Replace the original matrix with the new one\n",
    "                    pairwise_contrast <- pairwise_contrast_new\n",
    "\n",
    "                    #### 3. combine them\n",
    "                    contrast_design <- cbind(deviation_contrasts_tested / (n_populations - 1), pairwise_contrast)\n",
    "\n",
    "                } else {\n",
    "                    pairwise_vector[orig_mean_tested[1]] <- 1\n",
    "                    pairwise_vector[orig_mean_tested[2]] <- -1\n",
    "                    contrast_design <- as.matrix(pairwise_vector)\n",
    "                    colnames(contrast_design) <- str_c(orig_mean_tested[1], \"_vs_\", orig_mean_tested[2])\n",
    "                }\n",
    "\n",
    "                posterior_mean_subset <- posterior_mean[index,]\n",
    "                posterior_mean_subset2 <- posterior_mean_subset[orig_mean_tested]\n",
    "                posterior_vcov_subset <- posterior_vcov[,,index]\n",
    "                posterior_vcov_subset2 <- posterior_vcov_subset[orig_mean_tested,orig_mean_tested]\n",
    "\n",
    "                contrast_diff <- t(contrast_design) %*% posterior_mean_subset2\n",
    "                contrast_vcov <- t(contrast_design) %*% posterior_vcov_subset2 %*% contrast_design\n",
    "                contrast_se <- diag(contrast_vcov) %>% sqrt\n",
    "\n",
    "                contrast_p <- 2 * (1 - pnorm(abs(contrast_diff) / contrast_se))\n",
    "\n",
    "                contrast_diff_df <- t(contrast_diff) %>% as_tibble\n",
    "                colnames(contrast_diff_df) %<>% str_c(\"mean_contrast_\", .)\n",
    "                contrast_se_df <- t(contrast_se) %>% as_tibble\n",
    "                colnames(contrast_se_df) %<>% str_c(\"se_contrast_\", .)\n",
    "                contrast_p_df <- t(contrast_p) %>% as_tibble\n",
    "                colnames(contrast_p_df) %<>% str_c(\"p_contrast_\", .)\n",
    "\n",
    "                contrast_df <- bind_cols(contrast_diff_df, contrast_se_df, contrast_p_df)\n",
    "            } else if(grouping[orig_mean_tested][1]!=grouping[orig_mean_tested][2]){\n",
    "                contrast_vector <- rep(NA, length(population_names))\n",
    "                names(contrast_vector) <- str_c(\"mean_contrast_\", population_names, \"_deviation\")\n",
    "                contrast_df <- t(contrast_vector) %>% as_tibble\n",
    "            }\n",
    "         \n",
    "        contrast_df <- contrast_df %>% as.data.frame\n",
    "        rownames(contrast_df) <- rownames(posterior_mean)[index]\n",
    "        return(contrast_df)\n",
    "        }\n",
    "    \n",
    "    }\n",
    "\n",
    "    if(length(\"${cells}\") > 0){\n",
    "        # All the cells\n",
    "        cells <- c(\"${\", \".join(cells)}\") %>% str_split(., \",\", simplify = TRUE) %>% as.character \n",
    "\n",
    "        # Automatically set grouping categories based on the recipe， set0 for the celltypes without multiple populations\n",
    "        grouping_all <- rep(0, length(cells))\n",
    "        names(grouping_all) <- cells\n",
    "        \n",
    "  \n",
    "        # Read groupings from the recipe\n",
    "        if(length(\"${group1}\") > 0){\n",
    "            cell_groups <- list(\n",
    "              ${\"group1 = c(\" + \", \".join([\"'\" + item + \"'\" for item in group1]) + \")\" if len(group1) > 0 else \"\"} \n",
    "              ${\", group2 = c(\" + \", \".join([\"'\" + item + \"'\" for item in group2]) + \")\" if len(group2) > 0 else \"\"} \n",
    "              ${\", group3 = c(\" + \", \".join([\"'\" + item + \"'\" for item in group3]) + \")\" if len(group3) > 0 else \"\"}\n",
    "            )\n",
    "            if(!is.null(cell_groups)) {\n",
    "              cell_groups <- map(cell_groups, ~str_split(.x, \",\", simplify = TRUE) %>% as.character())\n",
    "            }\n",
    "        }\n",
    "  \n",
    "        if(\"${grouping_recipe}\" != \"\"){\n",
    "            cell_groups <- readLines(\"${grouping_recipe}\")\n",
    "            cell_groups <- lapply(cell_groups, function(g) strsplit(g, \",\")[[1]])\n",
    "        }\n",
    "\n",
    "        if(!is.null(cell_groups)){\n",
    "            for(i in seq_along(cell_groups)) {\n",
    "              grouping_all[cell_groups[[i]]] <- i\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Read the data files\n",
    "    orig_data <- read_rds(\"${_paths_sum[0]}\")$bhat\n",
    "    posterior_data <- read_rds(\"${_input}\")\n",
    "    posterior_mean <- posterior_data$PosteriorMean\n",
    "    posterior_cov <- posterior_data$PosteriorCov\n",
    "\n",
    "    # Align data and clean-up NaN values\n",
    "    orig_data <- orig_data[, colnames(posterior_mean), drop = FALSE]\n",
    "    orig_data[which(is.nan(orig_data))] <- 0 # Placeholder for NaNs\n",
    "\n",
    "    # Apply the FitContrast function and consolidate results\n",
    "    contrast_result <- map(1:nrow(posterior_mean), FitContrast, orig_data, posterior_mean, posterior_cov) %>% bind_rows %>%\n",
    "        select(matches(\"mean_contrast.*deviation\"), matches(\"mean_contrast.*_vs_\"), \n",
    "               matches(\"se_contrast.*deviation\"), matches(\"se_contrast.*_vs_\"), \n",
    "               matches(\"p_contrast.*deviation\"), matches(\"p_contrast.*_vs_\"))\n",
    "    #rownames(contrast_result) <- rownames(posterior_mean)\n",
    "\n",
    "    write_rds(contrast_result,  ${_output:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# merge the contrast data with slice data\n",
    "[mash_posterior_contrast_2]\n",
    "input: group_by = \"all\"\n",
    "output: f\"{cwd}/posterior_sum.csv\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '24h',  mem = '10G', tags = f'{_output:bn}'  \n",
    "\n",
    "R: expand = \"${ }\",stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout' \n",
    "        library(dplyr)\n",
    "        library(tidyverse)\n",
    "        library(ggnewscale)\n",
    "        \n",
    "        all.list <- stringr::str_split(\"${_input}\", \" \", simplify = T)\n",
    "       \n",
    "        p_cut <- ${p_cut} %>% as.numeric\n",
    "\n",
    "        cells<-c(\"${\",\".join(cells)}\")%>%str_split(.,\",\",simplify = T)%>%as.character #ggnewscale cannot use a specified order, I can not find a good way to order them by category for now\n",
    "        conditions <-combn(cells, m = 2) %>%apply(., 2, str_c, collapse = \"_vs_\") \n",
    "        \n",
    "        df <- matrix(ncol = length(conditions), nrow = 4) %>% as.data.frame()\n",
    "        colnames(df) <- conditions\n",
    "        rownames(df) <- c( \"n_sig_snp\", \"n_snp\",\"n_sig_feature\",\"n_all_feature\")\n",
    "        for (con in conditions) {\n",
    "            n.all.sig.snp <- n.all.snp <- n.all.sig.feature <- n.all.feature <- 0\n",
    "\n",
    "            for (i in 1:length(all.list)) {\n",
    "                tmp <- readRDS(all.list[i])\n",
    "                p.mtx <- tmp %>% select(matches(\"p_contrast.*_vs_\"))\n",
    "                p.mtx.con <- p.mtx %>% select(matches(con))\n",
    "                # print(n.sig.snp)\n",
    "                if(ncol(p.mtx.con)>0){\n",
    "                    p.mtx.con<-na.omit(p.mtx.con)\n",
    "                    n.sig.snp <- sum(p.mtx.con < p_cut)\n",
    "                    n.snp <- nrow(p.mtx.con)\n",
    "                } else {\n",
    "                    n.sig.snp <- n.snp <-0\n",
    "                }\n",
    "                # print(n.snp)\n",
    "                n.sig.feature <- ifelse(n.sig.snp > 0, 1, 0)\n",
    "                n.feature<- ifelse (n.snp > 0 , 1, 0)\n",
    "\n",
    "                n.all.sig.snp <- n.sig.snp + n.all.sig.snp\n",
    "                n.all.snp <- n.all.snp + n.snp\n",
    "                n.all.sig.feature <- n.all.sig.feature + n.sig.feature\n",
    "                n.all.feature <- n.all.feature + n.feature\n",
    "            }\n",
    "            df[, con] <- c( n.all.sig.snp,n.all.snp, n.all.sig.feature,n.all.feature)\n",
    "        }\n",
    "        write.csv(df, \"${_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot contrast result\n",
    "[mash_posterior_contrast_3, posterior_cntrast_plot]\n",
    "input: group_by = \"all\"\n",
    "output: f\"{cwd}/posterior_sum.png\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '24h',  mem = '10G', tags = f'{_output:bn}'  \n",
    "\n",
    "R: expand = \"${ }\",stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout' \n",
    "        library(dplyr)\n",
    "        library(tidyverse)\n",
    "        library(ggnewscale)\n",
    "        df <- read.csv(\"${_input:a}\",row.names=1)\n",
    "        colnames(df)<-gsub(\"DLPFC_\",\"\",colnames(df))\n",
    "        for (i in 1:ncol(df)) {\n",
    "            con1 <- stringr::str_split(colnames(df)[i], \"_vs_\", simplify = T)[, 1]\n",
    "            con2 <- stringr::str_split(colnames(df)[i], \"_vs_\", simplify = T)[, 2]\n",
    "\n",
    "            if (con1 > con2) {\n",
    "                new.name <- paste0(con2, \"_vs_\", con1)\n",
    "                colnames(df)[i] <- new.name\n",
    "            }\n",
    "        }\n",
    "\n",
    "        ## summarizxse with approach 1: snp-feature pair\n",
    "        snp.ratio <- df[\"n_sig_snp\", ] / df[\"n_snp\", ]\n",
    "        snp.ratio <- snp.ratio %>%\n",
    "            t() %>%\n",
    "            as.data.frame()\n",
    "        colnames(snp.ratio) <- \"ratio\"\n",
    "        snp.ratio$group <- \"snp\"\n",
    "\n",
    "        ## summarize with approach 2: feature\n",
    "        fet.ratio <- df[\"n_sig_feature\", ] / df[\"n_all_feature\", ]\n",
    "        fet.ratio <- fet.ratio %>%\n",
    "            t() %>%\n",
    "            as.data.frame()\n",
    "        rownames(fet.ratio) <- paste0(stringr::str_split(rownames(fet.ratio), \"_vs_\", simplify = T)[, 2], \"_vs_\", stringr::str_split(rownames(fet.ratio), \"_vs_\", simplify = T)[, 1])\n",
    "        colnames(fet.ratio) <- \"ratio\"\n",
    "        fet.ratio$group <- \"feature\"\n",
    "        ratio <- rbind(snp.ratio, fet.ratio)\n",
    "\n",
    "        ## I need to add the below to make it Simmetrie\n",
    "\n",
    "        cons <- rownames(ratio) %>%\n",
    "            str_split(., \"_vs_\", simplify = T) %>%\n",
    "            .[, 1] %>%\n",
    "            unique()\n",
    "        for (i in 1:length(cons)) {\n",
    "            new.name <- paste0(cons[i], \"_vs_\", cons[i])\n",
    "            ratio[new.name, ] <- 0\n",
    "        }\n",
    "\n",
    "        ratio$con1 <- stringr::str_split(rownames(ratio), \"_vs_\", simplify = T)[, 1]\n",
    "        ratio$con2 <- stringr::str_split(rownames(ratio), \"_vs_\", simplify = T)[, 2]\n",
    "\n",
    "        ## prepare for the plot, score1 is for snp-feature pair, score2 is for feature only\n",
    "        ratio$score1 <- ratio$score2 <- 0\n",
    "        ratio$score1[ratio$group == \"snp\"] <- ratio$ratio[ratio$group == \"snp\"]\n",
    "        ratio$score2[ratio$group == \"feature\"] <- ratio$ratio[ratio$group == \"feature\"]\n",
    "        ratio$label <- paste0(round(ratio$ratio, 4) * 100, \"%\")\n",
    "        ratio$label[ratio$group == 0] <- NA\n",
    "\n",
    "        # plot\n",
    "        num_cols <- length(cons)\n",
    "        height <- width <- 4 + num_cols * 0.5 \n",
    "        ggplot(ratio[ratio$group == \"snp\", ], aes(x = con1, y = con2)) +\n",
    "            geom_tile(aes(fill = score1)) +\n",
    "            scale_fill_gradient2(\"SNP_Feature pair\",\n",
    "                low = \"#762A83\", mid = \"white\", high = \"#1B7837\"\n",
    "            ) +\n",
    "            new_scale(\"fill\") +\n",
    "            geom_tile(aes(fill = score2), data = subset(ratio, group != \"snp\")) +\n",
    "            scale_fill_gradient2(\"Feature\",\n",
    "                low = \"#1B7837\", mid = \"white\", high = \"#762A83\"\n",
    "            ) +\n",
    "            geom_text(data = ratio, aes(label = label)) +\n",
    "            theme_bw()\n",
    "        #geom_text(data=ratio, aes(label = label, color = factor(group))) +theme_bw()\n",
    "        #ggsave(gsub(\".csv\",\".png\",filename))\n",
    "\n",
    "        ggsave(\"${_output}\",width = width, height = height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Feature score from contrast results\n",
    "\n",
    "**FIXME: Haven't cleaned up yet, need to talk to Gao to decide which one should be kept.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "### feature_score_meta\n",
    "Meta approach: Meta analysis with each cell deviation contrast result of each feature (a loop for each column in deviation results). And then perform meta analysis with pairwise contrasts to get a pvalue to find to understand what the specific differences are. But there is a problem that meta analysis with so many snps would cost too much time to compute, I am trying to downsample for input, Dan suggest to LD prune with a more permissive threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# compute feature score from contrast results\n",
    "[feature_score_meta_1]\n",
    "#regions = [x.replace(\"\\\"\",\"\").strip().split() for x in open(analysis_unit).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "parameter: plink_path = \"/mnt/mfs/cluster/bin/plink1.9.10/plink\"\n",
    "parameter: bfile_path = \"/mnt/vast/hpc/csg/molecular_phenotype_calling/WashU_genotype/genotype_qc/MAP_Brain-xQTL_Gwas_geno_0.1_maf_0.0005.filtered.\"\n",
    "parameter: extract = \"/home/rf2872/Work/Multivariate/MASH/From_SuSiE/2023.5_new/add_pQTL/LDcache/snp.list\"\n",
    "parameter: window_size = '100'\n",
    "parameter: step_size = '10'\n",
    "parameter: r2_threshold = '0.2'\n",
    "parameter: per_chunk = '100'\n",
    "parameter: LD_prune = \"TRUE\"\n",
    "parameter: downsample_ratio = '1'\n",
    "parameter: meta_method = 'REML'\n",
    "parameter: LDcache = \"/home/rf2872/Work/Multivariate/MASH/From_SuSiE/2023.5_new/add_pQTL/LDcache/\"\n",
    "parameter: contrast_input = [path(x[0]) for x in regions]\n",
    "input: contrast_input, group_by = per_chunk\n",
    "output: f\"{cwd}/feature_score_metaLD/cache/mash_posterior_contrast_featurescore{_index+1}.rds\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand = \"${ }\", workdir = cwd, stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\", container = container, entrypoint=entrypoint\n",
    "    # Library Loading\n",
    "    suppressMessages({\n",
    "      library(data.table)\n",
    "      library(tidyverse)\n",
    "      library(metafor)\n",
    "    })\n",
    "\n",
    "    # Environment Configuration\n",
    "    plink_path <- \"${plink_path}\"\n",
    "    bfile_path <- \"${bfile_path}\"\n",
    "    indep_pairwise <- paste(\"${window_size}\", \"${step_size}\", \"${r2_threshold}\")\n",
    "    out <- NULL\n",
    "    set.seed(999)\n",
    "\n",
    "    # Define helper functions\n",
    "\n",
    "    plink_ld_pruning <- function(res, chr, bfile_path, LDcache, gene, plink_path, indep_pairwise) {\n",
    "      extract <- str_c(\"${LDcache}\", gene, \"_snp.list\")\n",
    "      output <- str_c(\"${LDcache}\", gene, \"_output\")\n",
    "      tmp_contrast_results <- readRDS(res) %>% as.matrix()\n",
    "      write.table(rownames(tmp_contrast_results), extract, quote = F)\n",
    "      # system(paste0(\"rm \", output, \"*\"), intern = TRUE)\n",
    "      bfile <- str_c(bfile_path, chr)\n",
    "      command <- paste(plink_path, \"--bfile\", bfile, \"--extract\", extract, \"--indep-pairwise\", indep_pairwise, \"--out\", output)\n",
    "      system(command, intern = TRUE)\n",
    "      ld_output <- read.table(str_c(\"${LDcache}\", gene, \"_output.prune.in\"))\n",
    "      return(tmp_contrast_results[ld_output$V1, ] %>% as.data.table())\n",
    "    }\n",
    "\n",
    "    calculate_feature_scores <- function(tmp_contrast_results, meta_method) {\n",
    "      effect_sizes <- tmp_contrast_results %>% select(matches(\"mean_contrast.*deviation\")) %>% as.matrix()\n",
    "      se_values <- tmp_contrast_results %>% select(matches(\"se_contrast.*deviation\")) %>% as.matrix()\n",
    "      feature_scores <- data.table()\n",
    "      for (i in 1:ncol(effect_sizes)) {\n",
    "        effect_sizes_condition <- effect_sizes[, i]\n",
    "        se_values_condition <- se_values[, i]\n",
    "        absolute_effect_sizes <- abs(as.numeric(effect_sizes_condition))\n",
    "        pairwise_standard_errors <- as.numeric(se_values_condition)\n",
    "        meta_result <- rma(yi = absolute_effect_sizes, sei = pairwise_standard_errors, method = meta_method)\n",
    "        z_scores <- meta_result$b / meta_result$se\n",
    "        feature_scores_condition <- data.table(ZScore = z_scores)\n",
    "        feature_scores <- rbindlist(list(feature_scores, feature_scores_condition))\n",
    "      }\n",
    "      return(feature_scores)\n",
    "    }\n",
    "\n",
    "    # Main Loop\n",
    "    for (res in c(${_input:r,})) try({\n",
    "      chr <- res %>% basename() %>% str_extract(., paste0(\"\\\\.(.*?)\\\\.\")) %>% str_replace_all(\"\\\\.\", \"\") %>% str_replace_all(\"chr\", \"\")\n",
    "      gene <- basename(res) %>% stringr::str_split(., \"norminal.cis_long_table.\", simplify = TRUE) %>% .[, 2] %>% gsub(\"_posterior_contrast.rds\", \"\", .)\n",
    "\n",
    "      tmp_contrast_results <- readRDS(res)\n",
    "\n",
    "      LD_prune <- ${'TRUE' if LD_prune else 'FALSE'}\n",
    "      if (LD_prune) {\n",
    "        tmp_contrast_results <- plink_ld_pruning(res, chr, bfile_path, LDcache, gene, plink_path, indep_pairwise)\n",
    "      }\n",
    "\n",
    "      if (ncol(tmp_contrast_results %>% select(matches(\"mean_contrast.*deviation\"))) > 0) {\n",
    "        feature_scores <- calculate_feature_scores(tmp_contrast_results, \"${meta_method}\")\n",
    "        colnames(feature_scores) <- gene\n",
    "        condition_name <- colnames(effect_sizes) %>% gsub(\"mean_contrast_\", \"\", .) %>% gsub(\"_deviation\", \"\", .)\n",
    "        feature_scores <- feature_scores[, condition := condition_name]\n",
    "        saveRDS(feature_scores, str_c(\"${_output:d}\", \"/\", gsub(\".rds\", \"_featurescore.rds\", basename(res))))\n",
    "      }\n",
    "\n",
    "      if (is.null(out)) {\n",
    "        out <- feature_scores\n",
    "      } else {\n",
    "        out <- merge(out, feature_scores, by = \"condition\", all = TRUE)\n",
    "      }\n",
    "    })\n",
    "    saveRDS(out, \"${_output}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### feature_score_finemap\n",
    "feature score with fine mapped QTL (the top 1 in each CS)\n",
    "\n",
    "Fine-mapped approach(more recommend by Dan). pick the top SNP in each CS from each cell type fine mapped results. Then pick the most significant one from contrast result. Get the z-score from that snp, which should be the score of that cell type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# compute feature score from contrast results with eQTL and pQTL finemapped signals\n",
    "[feature_score_finemap_1]\n",
    "#regions = [x.replace(\"\\\"\",\"\").strip().split() for x in open(analysis_unit).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "parameter: per_chunk = '100'\n",
    "parameter: pfine_path = \"/mnt/vast/hpc/csg/molecular_phenotype_calling/QTL_fine_mapping/pqtl.all_variants.tsv\"\n",
    "parameter: efine_path = \"/mnt/vast/hpc/csg/hs3393/susie_eqtl/Result_new/tsv/\"\n",
    "parameter: efine_suffix = \".unisusie.fit.variant.tsv\"\n",
    "parameter: gene_ref_path = \"/mnt/vast/hpc/csg/molecular_phenotype_calling/reference_data/Homo_sapiens.GRCh38.103.chr.reformatted.collapse_only.gene.region_list\"\n",
    "parameter: contrast_input = [path(x[0]) for x in regions]\n",
    "input: contrast_input, group_by = per_chunk\n",
    "output: f\"{cwd}/feature_score_finemap/cache/mash_posterior_contrast_featurescore{_index+1}.rds\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand = \"${ }\", workdir = cwd, stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\", container = container, entrypoint=entrypoint\n",
    "   # Load necessary libraries\n",
    "    suppressMessages({\n",
    "        library(data.table)\n",
    "        library(tidyverse)\n",
    "    })\n",
    "\n",
    "    # Function to calculate scores from fine-mapping results\n",
    "    score_from_cs <- function(fine.file, contrast_results, con) {\n",
    "        CSs <- unique(fine.file$cs_order) %>% .[. != 0]\n",
    "        max.cs.df <- NULL\n",
    "        for (cs in CSs) {\n",
    "            tmp <- fine.file[fine.file$cs_order == cs, ]\n",
    "            max.cs.df <- rbind(max.cs.df, tmp[tmp$pip == max(tmp$pip), ])\n",
    "        }\n",
    "        snps <- intersect(rownames(contrast_results), max.cs.df$variants)\n",
    "        if (length(snps) == 0) return(NA)\n",
    "\n",
    "        # Extract contrast p-values\n",
    "        contrast_p <- NULL\n",
    "        if (ncol(select(contrast_results %>% as.data.frame(), matches(str_c(\"p_contrast_\", con, \"_deviation\")))) > 0) {\n",
    "            contrast_p <- contrast_results[snps, str_c(\"p_contrast_\", con, \"_deviation\"), drop = F]\n",
    "        } else if (ncol(select(contrast_results %>% as.data.frame(), matches(\"p_contrast.*_vs_*\"))) == 1) {\n",
    "            contrast_p <- contrast_results %>% as.data.frame() %>% select(matches(\"p_contrast.*_vs_*\")) %>% .[snps, , drop = F]\n",
    "        }\n",
    "\n",
    "        if (is.null(contrast_p)) return(NA)\n",
    "\n",
    "        max.snp <- contrast_p[contrast_p[, 1] == max(contrast_p[, 1]), , drop = F] %>% rownames()\n",
    "        score <- max(abs(contrast_results %>% as.data.frame() %>% select(matches(\"mean_contrast.*_vs_*\")) %>% .[max.snp, ]) /\n",
    "                     (contrast_results %>% as.data.frame() %>% select(matches(\"se_contrast.*_vs_*\")) %>% .[max.snp, ]))\n",
    "        return(score)\n",
    "    }\n",
    "\n",
    "    # Read pQTL file\n",
    "    pfine.mapped.result <- fread(\"${pfine_path}\")\n",
    "    pfine.mapped.result$Gene <- str_split(pfine.mapped.result$molecular_trait_id, \"_\", simplify = TRUE)[, 2]\n",
    "    gene.ref <- read.table(\"${gene_ref_path}\")\n",
    "    out <- data.table()\n",
    "\n",
    "    # Loop through each input and compute scores\n",
    "    for (res in c(${_input:r,})) {\n",
    "        tmp_contrast_results <- readRDS(res) %>% as.matrix()\n",
    "\n",
    "        gene <- basename(res) %>%\n",
    "            str_split(., \"norminal.cis_long_table.\", simplify = TRUE) %>%\n",
    "            .[, 2] %>%\n",
    "            gsub(\"_posterior_contrast.rds\", \"\", .)\n",
    "        ensemble <- gene.ref[gene.ref$V5 == gene, ]$V4\n",
    "        efine.mapped.result <- list.files(path = \"${efine_path}\", pattern = paste0(ensemble, \"${efine_suffix}\"), full.names = T)\n",
    "        pfine.file <- pfine.mapped.result[pfine.mapped.result$Gene == gene & pfine.mapped.result$cs_order > 0, ]\n",
    "\n",
    "        df <- data.frame()\n",
    "        if (nrow(pfine.file) > 0) {\n",
    "            message(\"Extracting signal from pQTL in \", gene)\n",
    "            df[gene, \"DLPFC_pQTL\"] <- score_from_cs(pfine.file, tmp_contrast_results, \"DLPFC_pQTL\")\n",
    "        }\n",
    "        if (length(efine.mapped.result) > 0) {\n",
    "            fine.conditions <- basename(efine.mapped.result) %>%\n",
    "                sub(\"demo.\", \"\", .) %>%\n",
    "                sub(paste0(\".\", ensemble, \"${efine_suffix}\"), \"\", .) %>%\n",
    "                .[. != \"ALL\"] %>%\n",
    "                .[. != \"End\"]\n",
    "            for (con in fine.conditions) {\n",
    "                con.file <- efine.mapped.result[grep(con, efine.mapped.result)] %>% fread()\n",
    "                con.fine.file <- con.file[con.file$cs_order > 0, ]\n",
    "                if (nrow(con.fine.file) > 0) {\n",
    "                    df[gene, con] <- score_from_cs(con.fine.file, tmp_contrast_results, con)\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        saveRDS(df, str_c(\"${cwd}\",\"/feature_score_finemap/cache/\",gsub(\".rds\",\"_featurescore.rds\",basename(res))))\n",
    "        out <- rbindlist(list(out, as.data.table(df, keep.rownames = TRUE)), use.names = TRUE, fill = TRUE)\n",
    "    }\n",
    "    saveRDS(out, \"${_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# merge the feature score from contrast results with eQTL and pQTL finemapped signals\n",
    "[feature_score_finemap_2]\n",
    "input: group_by = \"all\"\n",
    "output: f\"{cwd}/feature_score_finemap/posterior_feature_score_sum.csv\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '24h',  mem = '10G', tags = f'{_output:bn}'  \n",
    "\n",
    "R: expand = \"${ }\",stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout' \n",
    "    suppressMessages(library(data.table))\n",
    "    suppressMessages(library(tidyverse))\n",
    "    \n",
    "    out <- data.table()\n",
    "\n",
    "    all.list <- stringr::str_split(\"${_input}\", \" \", simplify = T)\n",
    "    for (i in all.list) {\n",
    "        feature_scores <- readRDS(i)\n",
    "        # Print the feature scores for each condition\n",
    "        if (!is.null(feature_scores)) {\n",
    "           if (is.null(out)) {\n",
    "                out <- as.data.table(feature_scores, keep.rownames = TRUE)\n",
    "              } else {\n",
    "                out <-  rbindlist(list(out, as.data.table(feature_scores, keep.rownames = TRUE)), use.names = TRUE, fill = TRUE)\n",
    "              }\n",
    "        }\n",
    "    }\n",
    "    write.csv(out, \"${_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### feature_score_nsig\n",
    "Calculate the number of meaningful SNPs in each feature of each cell type (actually, ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# compute feature score from contrast results\n",
    "[feature_score_nsig_1]\n",
    "#regions = [x.replace(\"\\\"\",\"\").strip().split() for x in open(analysis_unit).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "parameter: per_chunk = '100'\n",
    "parameter: contrast_input = [path(x[0]) for x in regions]\n",
    "input: contrast_input, group_by = per_chunk\n",
    "output: f\"{cwd}/feature_score_nsig/cache/mash_posterior_contrast_featurescore_nsig{_index+1}.rds\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand = \"${ }\", workdir = cwd, stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\", container = container, entrypoint=entrypoint\n",
    "   # Load required libraries\n",
    "    suppressMessages({\n",
    "        library(data.table)\n",
    "        library(tidyverse)\n",
    "        library(metafor)\n",
    "    })\n",
    "\n",
    "    # Convert p_cut to numeric\n",
    "    p_cut <- ${p_cut} %>% as.numeric\n",
    "\n",
    "    # Initialize the output data table\n",
    "    out <- NULL\n",
    "    set.seed(999)\n",
    "\n",
    "    # Function to extract the gene name from the file path\n",
    "    get_gene_name <- function(file_path) {\n",
    "        basename(file_path) %>%\n",
    "            stringr::str_split(., \"norminal.cis_long_table.\", simplify = TRUE) %>%\n",
    "            .[, 2] %>%\n",
    "            gsub(\"_posterior_contrast.rds\", \"\", .)\n",
    "    }\n",
    "\n",
    "    # Loop through each input RDS file\n",
    "    for (res in c(${_input:r,})) {\n",
    "        try({\n",
    "            # Extract gene name\n",
    "            gene <- get_gene_name(res)\n",
    "            print(gene)\n",
    "\n",
    "            # Load the contrast results and filter columns of interest\n",
    "            tmp_contrast_results <- readRDS(res) %>%\n",
    "                select(matches(\"p_contrast_.*deviation\")) %>%\n",
    "                as.matrix()\n",
    "\n",
    "            # Initialize the feature output data table\n",
    "            feature.out <- data.table()\n",
    "\n",
    "            # Calculate the ratio for each condition\n",
    "            for (i in 1:ncol(tmp_contrast_results)) {\n",
    "                condition_name <- colnames(tmp_contrast_results)[i] %>%\n",
    "                    gsub(\"p_contrast_\", \"\", .) %>%\n",
    "                    gsub(\"_deviation\", \"\", .)\n",
    "\n",
    "                n_sig_snp <- sum(tmp_contrast_results[, i] < p_cut, na.rm = TRUE)\n",
    "                n_snp <- sum(!is.na(tmp_contrast_results[, i]))\n",
    "\n",
    "                ratio <- n_sig_snp / n_snp\n",
    "                feature.out <- rbind(feature.out, data.table(gene = gene, condition = condition_name, ratio = ratio))\n",
    "            }\n",
    "\n",
    "            # Save individual gene results\n",
    "            saveRDS(feature.out, paste0(\"${_output:d}\", \"/\", gsub(\".rds\", \"_n_sig_ratio.rds\", basename(res))))\n",
    "\n",
    "            # Merge with the overall output\n",
    "            if (is.null(out)) {\n",
    "                out <- feature.out\n",
    "            } else {\n",
    "                out <- merge(out, feature.out, by = \"condition\", all = TRUE)\n",
    "            }\n",
    "        }, silent = TRUE) # Error handling to proceed even if one iteration fails\n",
    "    }\n",
    "\n",
    "    # Save the combined output\n",
    "    saveRDS(out, \"${_output}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### feature_pval_pair\n",
    "find the specific different cell type pair\n",
    "\n",
    "perform meta analysis with pairwise contrasts to get a pvalue to find to understand what the specific differences are.\n",
    "\n",
    "metaanalysis return a warning as \"Warning message: “Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.”\"\n",
    "Which is due to the big difference between max(pairwise_standard_errors^2) and min(pairwise_standard_errors^2) So I have delete the snps with small pairwise_standard_errors as Xuewei suggested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# compute feature score from contrast results\n",
    "[feature_pval_pair_1]\n",
    "#regions = [x.replace(\"\\\"\",\"\").strip().split() for x in open(analysis_unit).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "parameter: plink_path = \"/mnt/mfs/cluster/bin/plink1.9.10/plink\"\n",
    "parameter: bfile_path = \"/mnt/vast/hpc/csg/molecular_phenotype_calling/WashU_genotype/genotype_qc/MAP_Brain-xQTL_Gwas_geno_0.1_maf_0.0005.filtered.\"\n",
    "parameter: extract = \"/home/rf2872/Work/Multivariate/MASH/From_SuSiE/2023.5_new/add_pQTL/LDcache/snp.list\"\n",
    "parameter: window_size = '100'\n",
    "parameter: step_size = '10'\n",
    "parameter: r2_threshold = '0.2'\n",
    "parameter: per_chunk = '100'\n",
    "parameter: LD_prune = True\n",
    "parameter: downsample_ratio = '1'\n",
    "parameter: meta_method = 'REML'\n",
    "parameter: se_cutoff = '1E-03'\n",
    "parameter: LDcache = \"/home/rf2872/Work/Multivariate/MASH/From_SuSiE/2023.5_new/add_pQTL/LDcache/\"\n",
    "parameter: contrast_input = [path(x[0]) for x in regions]\n",
    "input: contrast_input, group_by = per_chunk\n",
    "output: f\"{cwd}/feature_pval_pair/cache/mash_posterior_contrast_featurescore{_index+1}.rds\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand = \"${ }\", workdir = cwd, stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\", container = container, entrypoint=entrypoint\n",
    "    # Library Loading\n",
    "    suppressMessages({\n",
    "      library(data.table)\n",
    "      library(tidyverse)\n",
    "      library(metafor)\n",
    "    })\n",
    "\n",
    "    # Initializations\n",
    "    out <- NULL\n",
    "    set.seed(999)\n",
    "\n",
    "    # Helper function: extract gene name from result\n",
    "    extract_gene <- function(res) {\n",
    "      basename(res) %>%\n",
    "        stringr::str_split(., \"norminal.cis_long_table.\", simplify = TRUE) %>%\n",
    "        .[, 2] %>%\n",
    "        gsub(\"_posterior_contrast.rds\", \"\", .)\n",
    "    }\n",
    "\n",
    "    # Helper function: perform meta analysis per cell\n",
    "    meta_analysis_per_cell <- function(effect_sizes, se_values, gene, se_cutoff) {\n",
    "      conditions <- colnames(effect_sizes) %>%\n",
    "        sub(\"mean_contrast_\", \"\", .) %>%\n",
    "        unique()\n",
    "      cells <- c(sub(\"_vs_.*\", \"\", conditions), sub(\".*_vs_\", \"\", conditions)) %>% unique()\n",
    "\n",
    "      df <- data.table()\n",
    "      for (cell in cells) {\n",
    "        cell.b <- effect_sizes[, grep(cell, colnames(effect_sizes)), drop = F]\n",
    "        cell.se <- se_values[, grep(cell, colnames(se_values)), drop = F]\n",
    "        feature_pvals <- data.table()\n",
    "        for (i in 1:ncol(cell.b)) {\n",
    "          effect_sizes_condition <- cell.b[, i]\n",
    "          se_values_condition <- cell.b[, i]\n",
    "          # Filter out based on se cutoff\n",
    "          effect_sizes_condition <- effect_sizes_condition[which(se_values_condition > as.numeric(se_cutoff))]\n",
    "          se_values_condition <- se_values_condition[which(se_values_condition > as.numeric(se_cutoff))]\n",
    "          # Meta-analysis\n",
    "          absolute_effect_sizes <- abs(as.numeric(effect_sizes_condition))\n",
    "          pairwise_standard_errors <- as.numeric(se_values_condition)\n",
    "          meta_result <- rma(yi = absolute_effect_sizes, sei = pairwise_standard_errors, method = \"REML\")\n",
    "          feature_pval_condition <- data.table(pavlue = meta_result$pval)\n",
    "          feature_pvals <- rbindlist(list(feature_pvals, feature_pval_condition))\n",
    "        }\n",
    "        colnames(feature_pvals) <- gene\n",
    "        condition_name <- colnames(cell.b) %>%\n",
    "          gsub(\"mean_contrast_\", \"\", .)\n",
    "        feature_pvals <- feature_pvals[, condition := condition_name]\n",
    "        df <- rbindlist(list(df, feature_pvals))\n",
    "      }\n",
    "      return(df)\n",
    "    }\n",
    "\n",
    "    # Main Loop\n",
    "    for (res in c(${_input:r,})) {\n",
    "      gene <- extract_gene(res)\n",
    "      print(gene)\n",
    "      tmp_contrast_results <- readRDS(res)\n",
    "      ld_output <- read.table(str_c(\"${LDcache}\", gene, \"_output.prune.in\"))\n",
    "      tmp_contrast_results <- tmp_contrast_results[ld_output$V1, ] %>% as.data.table(keep.rownames = T)\n",
    "\n",
    "      effect_sizes <- tmp_contrast_results %>% select(matches(\"mean_contrast.*_vs_*\")) %>% as.matrix()\n",
    "      se_values <- tmp_contrast_results %>% select(matches(\"se_contrast.*_vs_*\")) %>% as.matrix()\n",
    "\n",
    "      df <- meta_analysis_per_cell(effect_sizes, se_values, gene, \"${se_cutoff}\")\n",
    "      saveRDS(df, str_c(\"${_output:d}\", \"/\", gsub(\".rds\", \"_featurescore_pw.rds\", basename(res))))\n",
    "\n",
    "      if (is.null(out)) {\n",
    "        out <- df\n",
    "      } else {\n",
    "        out <- merge(out, df, by = \"condition\", all = TRUE, allow.cartesian = TRUE)\n",
    "      }\n",
    "    }\n",
    "    saveRDS(out, \"${_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# merge the feature score from contrast results\n",
    "[feature_pval_pair_2, feature_score_meta_2, feature_score_nsig_2]\n",
    "input: group_by = \"all\"\n",
    "output: f\"{cwd}/feature_pval_pair/posterior_feature_score_sum.csv\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '24h',  mem = '10G', tags = f'{_output:bn}'  \n",
    "\n",
    "R: expand = \"${ }\",stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout' \n",
    "    library(dplyr)\n",
    "    library(tidyverse)\n",
    "    out <- NULL\n",
    "\n",
    "    all.list <- stringr::str_split(\"${_input}\", \" \", simplify = T)\n",
    "    for (i in all.list) {\n",
    "        feature_scores <- readRDS(i)\n",
    "        # Print the feature scores for each condition\n",
    "        if (!is.null(feature_scores)) {\n",
    "            if (is.null(out)) {\n",
    "                out <- feature_scores\n",
    "            } else {\n",
    "                out <- merge(out, feature_scores, by = \"condition\", all = TRUE)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "      out<-t(out)\n",
    "      #out<-out[-1,]\n",
    "    write.csv(out, \"${_output}\",col.names=F)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     "shell"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0,
    "style": "side"
   },
   "version": "0.24.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
