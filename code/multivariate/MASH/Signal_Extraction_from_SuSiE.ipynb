{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "superior-regard",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Reformat the top signals from SuSiE\n",
    "This notebook is to extract strong and random signals from the SuSie extracted signals so that they can be fed into flashr for mixture prior and mashr.\n",
    "\n",
    "At th momenet, \n",
    "1. the NA would be removed by default:na_remove = TRUE, can be kept with na_remove = FALSE\n",
    "2. nan beta will be set to 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-korean",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "nohup sos run ~/xqtl-pipeline-changed/pipeline/Signal_Extraction_from_SuSiE.V2.ipynb extract_effects_fromsusie    \\\n",
    "#--na_remove FALSE \\\n",
    "--name  Ast_Exc_Inh_Mic_OPC_Oli.with.na  \\\n",
    "--sum_stat '/mnt/vast/hpc/csg/rf2872/Work/MASH_test_csg/output/ALL_Ast_End_Exc_Inh_Mic_OPC_Oli.merged_rds.list'   \\\n",
    "--susie '/mnt/vast/hpc/csg/rf2872/Work/SuSiE_MASH/Extra_signals/SuSiE_output_signals_table.new'  \\\n",
    "--gene_ref '/mnt/vast/hpc/csg/molecular_phenotype_calling/reference_data/Homo_sapiens.GRCh38.103.chr.reformatted.collapse_only.gene.region_list'  \\\n",
    "--exclude_condition 1,3    \\\n",
    "-s force -J 20 -q csg2 -l t_pri -c ~/test/csg2.yml   &> mash_extr_effects.with.na.log &\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-ballet",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-embassy",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "import os\n",
    "# Work directory & output directory\n",
    "parameter: cwd = path('./output')\n",
    "# The filename prefix for output data\n",
    "parameter: name = str\n",
    "parameter: job_size = 1\n",
    "parameter: container = ''\n",
    "parameter: table_name = \"\"\n",
    "parameter: bhat = \"bhat\"\n",
    "parameter: sbhat = \"sbhat\"\n",
    "parameter: expected_ncondition = 0\n",
    "##  conditions can be excluded if needs arise. If nothing to exclude keep the default 0\n",
    "parameter: exclude_condition = [\"1\",\"3\"]\n",
    "parameter: datadir = \"\"\n",
    "parameter: seed = 999\n",
    "parameter: n_random = 4\n",
    "parameter: n_null = 4\n",
    "parameter: z_only = False\n",
    "parameter: na_remove = \"TRUE\"\n",
    "# Analysis units file with 1 column being the cell types\n",
    "import pandas as pd\n",
    "#parameter: analysis_units = path\n",
    "# handle N = per_chunk data-set in one job\n",
    "parameter: per_chunk = 1000\n",
    "#regions = [x.replace(\"\\\"\",\"\").strip().split() for x in open(analysis_units).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "parameter: susie = path\n",
    "parameter: sum_stat = path\n",
    "parameter: gene_ref = ''\n",
    "parameter: gene_ref_ncondition = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-warrant",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Get top, random and null effects per analysis unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-chassis",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# extract data for MASH with Extracted signals from SuSiE output \n",
    "[extract_effects_fromsusie]\n",
    "input: susie,sum_stat\n",
    "output: f\"{cwd}/{name}.rds\"\n",
    "task: trunk_workers = 1, walltime = '1h', trunk_size = 1, mem = '4G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\",stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container\n",
    "    library(org.Hs.eg.db)\n",
    "    library(dplyr)\n",
    "    library(stringr)\n",
    "    set.seed(${seed})\n",
    "    matxMax <- function(mtx) {\n",
    "      return(arrayInd(which.max(mtx), dim(mtx)))\n",
    "    }\n",
    "    remove_rownames = function(x) {\n",
    "        for (name in names(x)) rownames(x[[name]]) = NULL\n",
    "        return(x)\n",
    "    }\n",
    "    handle_nan_etc = function(x) {\n",
    "      x$bhat[which(is.nan(x$bhat))] = 0\n",
    "      x$sbhat[which(is.nan(x$sbhat) | is.infinite(x$sbhat))] = 1E3\n",
    "      return(x)\n",
    "    }\n",
    "    \n",
    "    reformat_data = function(dat, z_only = TRUE) {\n",
    "        # make output consistent in format with \n",
    "        # https://github.com/stephenslab/gtexresults/blob/master/workflows/mashr_flashr_workflow.ipynb      \n",
    "        res = list(random.z = dat$random$bhat/dat$random$sbhat, \n",
    "                  strong.z = dat$strong$bhat/dat$strong$sbhat,  \n",
    "                  null.z = dat$null$bhat/dat$null$sbhat)\n",
    "        if (!z_only) {\n",
    "          res = c(res, list(random.b = dat$random$bhat,\n",
    "           strong.b = dat$strong$bhat,\n",
    "           null.b = dat$null$bhat,\n",
    "           null.s = dat$null$sbhat,\n",
    "           random.s = dat$random$sbhat,\n",
    "           strong.s = dat$strong$sbhat))\n",
    "      }\n",
    "      return(res)\n",
    "    }\n",
    "    merge_data = function(res, one_data) {\n",
    "      if (length(res) == 0) {\n",
    "          return(one_data)\n",
    "      } else if (is.null(one_data)) {\n",
    "          return(res)\n",
    "      } else {\n",
    "          for (d in names(one_data)) {\n",
    "            if (is.null(one_data[[d]])) {\n",
    "              next\n",
    "            } else {\n",
    "                res[[d]] = rbind(res[[d]], one_data[[d]])\n",
    "            }\n",
    "          }\n",
    "          return(res)\n",
    "      }\n",
    "    }\n",
    "  \n",
    "    extract_susiesignal = function(dat, sus.sum,n_random, n_null, infile, na_remove = TRUE) {\n",
    "        if (is.null(dat)) return(NULL)\n",
    "        if(na_remove == TRUE){\n",
    "          dat$bhat = na.omit(dat$bhat)\n",
    "          dat$sbhat = na.omit(dat$sbhat)\n",
    "          }\n",
    "        signals.su<- sus.sum%>%filter(path %in% infile)%>%.[,\"signals\"]\n",
    "        signals<-intersect(signals.su, rownames(dat$bhat))\n",
    "        outlier<-setdiff(signals.su, rownames(dat$bhat))     \n",
    "        strong = list(bhat = dat$bhat[signals,,drop=F], sbhat = dat$sbhat[signals,,drop=F])\n",
    "        sample_idx<-setdiff(rownames(dat$bhat), signals)\n",
    "        random_idx = sample(sample_idx, min(n_random, length(sample_idx)), replace = F)\n",
    "        random = list(bhat = dat$bhat[random_idx,,drop=F], sbhat = dat$sbhat[random_idx,,drop=F])\n",
    "        z = abs(dat$${bhat}/dat$${sbhat})\n",
    "        # null samples defined as |z| < 2\n",
    "        null.id = which(apply(abs(z), 1, max) < 2)\n",
    "        if (length(null.id) == 0) {\n",
    "          warning(paste(\"Null data is empty for input file\", infile))\n",
    "          null = list()\n",
    "        } else {\n",
    "          null_idx = sample(null.id, min(n_null, length(null.id)), replace = F)\n",
    "          null = list(bhat = dat$bhat[null_idx,,drop=F], sbhat = dat$sbhat[null_idx,,drop=F])\n",
    "        }\n",
    "        dat = (list(random = remove_rownames(random), null = remove_rownames(null), strong = remove_rownames(strong)))\n",
    "        dat$random = handle_nan_etc(dat$random)\n",
    "        dat$null = handle_nan_etc(dat$null)\n",
    "        dat$strong = handle_nan_etc(dat$strong)\n",
    "        com.dat<-list(dat=dat,signals=signals,outlier=outlier)\n",
    "        return(com.dat)\n",
    "    }\n",
    "    \n",
    "    # intersect the output from SuSiE with sumstat file. \n",
    "    sus.out<-read.table(${_input[0]:r,},header = T)    \n",
    "    sum.out<-read.table(${_input[1]:r,},header = F)\n",
    "    \n",
    "    if(${gene_ref_ncondition}>0){\n",
    "        \n",
    "    #always get gene_symbol from ensembl ID, instead of convert\n",
    "    colnames(sum.out)<-c(\"gene_symbol\",\"path\")\n",
    "    gene.ref<-read.table(\"${gene_ref}\")\n",
    "    sum.out$gene <- gene.ref[match(sum.out$gene_symbol,gene.ref$V5),\"V4\"]} else {\n",
    "    colnames(sum.out)<-c(\"gene\",\"path\")}\n",
    "  \n",
    "    sus.sum<-merge(sus.out,sum.out,by=\"gene\")\n",
    "    files<-unique(sus.sum$path)\n",
    "    #sus.sum<-sus.sum[-which(duplicated(sus.sum$path)),] \n",
    "    #files<-sus.sum$path\n",
    "    res = list()\n",
    "    signals.df<-NULL\n",
    "    outlier.df<-NULL\n",
    "    for (f in files) {\n",
    "      # If cannot read the input for some reason then we just skip it, assuming we have other enough data-sets to use.\n",
    "      dat = tryCatch(readRDS(f), error = function(e) return(NULL))${(\"$\"+table_name) if table_name != \"\" else \"\"}\n",
    "      if (is.null(dat)) {\n",
    "          message(paste(\"Skip loading file\", f, \"due to load failure.\"))\n",
    "          next\n",
    "      }\n",
    "      if (${expected_ncondition} > 0 && (ncol(dat$${bhat}) != ${expected_ncondition} || ncol(dat$${sbhat}) != ${expected_ncondition})) {\n",
    "          message(paste(\"Skip loading file\", f, \"because it has\", ncol(dat$${bhat}), \"columns different from required\", ${expected_ncondition}))\n",
    "          next\n",
    "      }\n",
    "      if(c(${\",\".join(exclude_condition)})[1] > 0 ){\n",
    "      message(paste(\"Excluding condition ${exclude_condition} from the analysis\"))\n",
    "      dat$bhat = dat$bhat[,-c(${\",\".join(exclude_condition)})]\n",
    "      dat$sbhat = dat$sbhat[,-c(${\",\".join(exclude_condition)})]\n",
    "      dat$Z = dat$Z[,-c(${\",\".join(exclude_condition)})]\n",
    "      }\n",
    "\n",
    "      com.dat<-tryCatch( extract_susiesignal(dat, sus.sum, ${n_random}, ${n_null}, f, ${na_remove})  , error = function(e) return(NULL)) \n",
    "      res = tryCatch(merge_data(res, reformat_data(com.dat$dat, ${\"TRUE\" if z_only else \"FALSE\"})), error = function(e) message(\"Skipping gene due to lack of SNPs\"))\n",
    "\n",
    "      #genename<-str_split(f,\"[.]\")%>%unlist%>%.[(length(.)-1)]\n",
    "      genename<-sum.out[sum.out$path==f,ifelse(${gene_ref_ncondition}>0,\"gene_symbol\",\"gene\")]\n",
    "      signals.df<-rbind(signals.df,data.frame(gene=rep(genename,length(com.dat$signals)),signals=com.dat$signals))\n",
    "      outlier.df<-rbind(outlier.df,data.frame(gene=rep(genename,length(com.dat$outlier)),signals=com.dat$outlier))\n",
    "    }\n",
    "    # compute empirical covariance XtX\n",
    "    X = res$strong.z\n",
    "    X[is.na(X)] = 0\n",
    "    res$XtX = t(as.matrix(X)) %*% as.matrix(X) / nrow(X)\n",
    "    saveRDS(res, ${_output:r})\n",
    "  \n",
    "  \n",
    "    res.sum<-list(signals=signals.df,outlier=outlier.df)  \n",
    "    saveRDS(res, ${_output:r})\n",
    "    saveRDS(res.sum,\"${_output:n}.sum.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-offer",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-premium",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.24.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
