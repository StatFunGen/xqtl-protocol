{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# TensorQTL QTL association testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This pipeline conduct QTL association tests using tensorQTL package. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input\n",
    "- `--molecular-pheno`, The bed.gz file containing the table describing the molecular phenotype. It shall also have a tbi index accompaning it.\n",
    "- `genotype_list` a list of whole genome plink file for each chromosome.\n",
    "- `grm_list` is a file containing list of grm matrixs that generated by the GRM module of this pipeline.\n",
    "- `covariate` is a file with #id + samples name as colnames and each row a covariate: fixed and known covariates as well as hidden covariates recovered from factor analysis.\n",
    "\n",
    "## Output\n",
    "\n",
    "For each chromosome, a sets of summary statistics files , including both nomial test statistics for each test, as well as region (gene) level association evidence.\n",
    "\n",
    "The column specification of nomial result are as followed:\n",
    "\n",
    "- phenotype_id: Molecular trait identifier.(gene)\n",
    "- variant_id: ID of the variant (rsid or chr:position:ref:alt)\n",
    "- tss_distance: Distance of the SNP to the gene transcription start site (TSS)\n",
    "- af: The allele frequency of this SNPs\n",
    "- ma_samples: Number of samples carrying the minor allele\n",
    "- ma_count: Total number of minor alleles across individuals\n",
    "- pval: Nominal P-value from linear regression\n",
    "- beta: Slope of the linear regression\n",
    "- se: Standard error of beta\n",
    "- chr : Variant chromosome.\n",
    "- pos : Variant chromosomal position (basepairs).\n",
    "- ref : Variant reference allele (A, C, T, or G).\n",
    "- alt : Variant alternate allele.\n",
    "\n",
    "\n",
    "The column specification of region (gene) level association evidence are as follows:\n",
    "\n",
    "- phenotype_id - Molecular trait identifier. (gene)\n",
    "- num_var - Total number of variants tested in cis\n",
    "- beta_shape1 - First parameter value of the fitted beta distribution\n",
    "- beta_shape2 - Second parameter value of the fitted beta distribution\n",
    "- true_df - Effective degrees of freedom the beta distribution approximation\n",
    "- pval_true_df - Empirical P-value for the beta distribution approximation\n",
    "- variant_id - ID of the top variant (rsid or chr:position:ref:alt)\n",
    "- tss_distance - Distance of the SNP to the gene transcription start site (TSS)\n",
    "- ma_samples - Number of samples carrying the minor allele\n",
    "- ma_count - Total number of minor alleles across individuals\n",
    "- maf - Minor allele frequency in MiGA cohort\n",
    "- ref_factor - Flag indicating if the alternative allele is the minor allele in the cohort (1 if AF <= 0.5, -1 if not)\n",
    "- pval_nominal - Nominal P-value from linear regression\n",
    "- slope - Slope of the linear regression\n",
    "- slope_se - Standard error of the slope\n",
    "- pval_perm - First permutation P-value directly obtained from the permutations with the direct method\n",
    "- pval_beta - Second permutation P-value obtained via beta approximation. This is the one to use for downstream analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Command interface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run TensorQTL.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  TensorQTL_cis\n",
      "  TensorQTL_trans\n",
      "\n",
      "Global Workflow Options:\n",
      "  --molecular-pheno-list VAL (as path, required)\n",
      "                        Path to the input molecular phenotype file, per chrm, in\n",
      "                        bed.gz format.\n",
      "  --covariate VAL (as path, required)\n",
      "                        Covariate file, in similar format as the molecular_pheno\n",
      "  --genotype-file-list VAL (as path, required)\n",
      "                        Genotype file in plink trio format, per chrm\n",
      "  --region-list . (as path)\n",
      "                        An optional subset of region list containing a column of\n",
      "                        ENSG gene_id to limit the analysis\n",
      "  --cwd . (as path)\n",
      "                        Path to the work directory of the analysis.\n",
      "  --job-size 2 (as int)\n",
      "                        Specify the number of jobs per run.\n",
      "  --container ''\n",
      "                        Container option for software to run the analysis:\n",
      "                        docker or singularity\n",
      "  --window 1000000 (as int)\n",
      "                        Specify the scanning window for the up and downstream\n",
      "                        radius to analyze around the region of interest, in\n",
      "                        units of bp\n",
      "\n",
      "Sections\n",
      "  TensorQTL_cis_1:\n",
      "  TensorQTL_trans_1:\n",
      "    Workflow Options:\n",
      "      --batch-size 10000 (as int)\n",
      "      --pval-threshold 1e-05 (as float)\n",
      "      --maf-threshold 0.05 (as float)\n",
      "  TensorQTL_cis_2:\n",
      "  TensorQTL_trans_2:\n"
     ]
    }
   ],
   "source": [
    "sos run TensorQTL.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/TensorQTL.ipynb TensorQTL_cis --genotype-list plink_files_list.txt \\\n",
    "--phenotype-list MWE.bed.recipe \\\n",
    "--covariate-file ALL.covariate.pca.BiCV.cov.gz \\\n",
    "--cwd ./ \\\n",
    "--container containers/apex.sif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Global parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Path to the input molecular phenotype file, per chrm, in bed.gz format.\n",
    "parameter: phenotype_list = path\n",
    "# covariate_file, in similar format as the molecular_pheno\n",
    "parameter: covariate_file= path\n",
    "# Genotype file in plink trio format, per chrm\n",
    "parameter: genotype_list = path\n",
    "# An optional subset of region list containing a column of ENSG gene_id to limit the analysis\n",
    "parameter: region_list = path(\"./\")\n",
    "# Path to the work directory of the analysis.\n",
    "parameter: cwd = path('./')\n",
    "# Specify the number of jobs per run.\n",
    "parameter: job_size = 2\n",
    "# Container option for software to run the analysis: docker or singularity\n",
    "parameter: container = ''\n",
    "\n",
    "# Specify the scanning window for the up and downstream radius to analyze around the region of interest, in units of bp\n",
    "parameter: window = 1000000\n",
    "\n",
    "import pandas as pd\n",
    "molecular_pheno_chr_inv = pd.read_csv(phenotype_list,sep = \"\\t\")\n",
    "geno_chr_inv = pd.read_csv(genotype_list,sep = \"\\t\")\n",
    "input_inv = molecular_pheno_chr_inv.merge(geno_chr_inv, on = \"#id\")\n",
    "input_inv = input_inv.values.tolist()\n",
    "chr_inv = [x[0] for x in input_inv]\n",
    "file_inv = [x[1:] for x in input_inv ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## cisQTL association testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[TensorQTL_cis_1]\n",
    "input: file_inv,group_by = len(file_inv[0]), group_with = \"chr_inv\"\n",
    "output: f'{cwd:a}/{path(_input[0]):bnnn}.cis_qtl_pairs.{_chr_inv}.parquet', # This design is necessary to match the pattern of map_norminal output\n",
    "        f'{cwd:a}/{path(_input[0]):bnnn}.emprical.cis_sumstats.txt',\n",
    "        long_table = f'{cwd:a}/{path(_input[0]):bnnn}.norminal.cis_long_table.txt'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '12h',  mem = '40G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output[0]}.stderr', container = container,stdout = f'{_output[0]}.stdout'\n",
    "    touch  $[_output[0]].time_stamp\n",
    "python: expand= \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout' , container = container\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import tensorqtl\n",
    "    from tensorqtl import genotypeio, cis, trans\n",
    "    ## Defineing parameter\n",
    "    plink_prefix_path = $[path(_input[1]):nr]\n",
    "    expression_bed = $[path(_input[0]):r]\n",
    "    covariates_file = \"$[covariate_file]\"\n",
    "    Prefix = \"$[_output[0]:nnn]\"\n",
    "    ## Loading Data\n",
    "    phenotype_df, phenotype_pos_df = tensorqtl.read_phenotype_bed(expression_bed)\n",
    "    ### Filter by the optional keep gene\n",
    "    if $[region_list.is_file()]:\n",
    "        region = pd.read_csv(\"$[region_list]\",\"\\t\")\n",
    "        keep_gene = region[\"gene_ID\"].to_list()\n",
    "        phenotype_df = phenotype_df.query('gene_ID  in keep_gene')\n",
    "        phenotype_pos_df = phenotype_pos_df.query('gene_ID  in keep_gene')\n",
    "\n",
    "    covariates_df = pd.read_csv(covariates_file, sep='\\t', index_col=0).T\n",
    "    pr = genotypeio.PlinkReader(plink_prefix_path)\n",
    "    genotype_df = pr.load_genotypes()\n",
    "    variant_df = pr.bim.set_index('snp')[['chrom', 'pos']]\n",
    "    ## Retaining only common samples\n",
    "    phenotype_df = phenotype_df[np.intersect1d(phenotype_df.columns, covariates_df.index)]\n",
    "    phenotype_df = phenotype_df[np.intersect1d(phenotype_df.columns, genotype_df.columns)]\n",
    "    covariates_df = covariates_df.transpose()[np.intersect1d(phenotype_df.columns, covariates_df.index)].transpose()\n",
    "    if \"chr\" not in variant_df.chrom[0]:\n",
    "        phenotype_pos_df.chr = [x.replace(\"chr\",\"\") for x in phenotype_pos_df.chr]\n",
    "    ## cis-QTL mapping: nominal associations for all variant-phenotype pairs\n",
    "    cis.map_nominal(genotype_df, variant_df,\n",
    "                phenotype_df,\n",
    "                phenotype_pos_df,\n",
    "                Prefix, covariates_df=covariates_df, window=$[window] )\n",
    "\n",
    "    ## Load the parquet and save it as txt\n",
    "    pairs_df = pd.read_parquet(\"$[_output[0]]\")\n",
    "    pairs_df.columns.values[6]  = \"pval\"\n",
    "    pairs_df.columns.values[7]  = \"beta\"\n",
    "    pairs_df.columns.values[8]  = \"se\"\n",
    "    pairs_df = pairs_df.assign(\n",
    "    alt = lambda dataframe: dataframe['variant_id'].map(lambda variant_id:variant_id.split(\"_\")[-1])).assign(\n",
    "    ref = lambda dataframe: dataframe['variant_id'].map(lambda variant_id:variant_id.split(\"_\")[-2])).assign(\n",
    "    pos = lambda dataframe: dataframe['variant_id'].map(lambda variant_id:variant_id.split(\"_\")[0].split(\":\")[1])).assign(\n",
    "    chrom = lambda dataframe: dataframe['variant_id'].map(lambda variant_id:variant_id.split(\":\")[0]))\n",
    "    pairs_df.to_csv(\"$[_output[2]]\", sep='\\t',index = None)\n",
    "    cis_df = cis.map_cis(genotype_df, variant_df, \n",
    "                     phenotype_df,\n",
    "                     phenotype_pos_df,\n",
    "                     covariates_df=covariates_df, seed=999, window=$[window] )\n",
    "    cis_df.index.name = \"gene_id\"\n",
    "    cis_df.to_csv(\"$[_output[1]]\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## TransQTL association testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[TensorQTL_trans_1]\n",
    "input: file_inv,group_by = len(file_inv[0]), group_with = \"chr_inv\"\n",
    "output: f'{cwd:a}/{path(_input[0]):bnnn}.trans_sumstats.txt'\n",
    "parameter: batch_size = 10000\n",
    "parameter: pval_threshold = 1e-5\n",
    "parameter: maf_threshold = 0.05\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '12h',  mem = '40G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output[0]}.stderr', container = container,stdout = f'{_output[0]}.stdout'\n",
    "    touch  $[_output[0]].time_stamp\n",
    "python: expand= \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout',container =container \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import tensorqtl\n",
    "    from tensorqtl import genotypeio, cis, trans\n",
    "    ## Defineing parameter\n",
    "    plink_prefix_path = $[path(_input[1]):nr]\n",
    "    expression_bed = $[path(_input[0]):r]\n",
    "    covariates_file = \"$[covariate_file]\"\n",
    "    Prefix = \"$[_output[0]:nnn]\"\n",
    "    ## Loading Data\n",
    "    phenotype_df, phenotype_pos_df = tensorqtl.read_phenotype_bed(expression_bed)\n",
    "\n",
    "\n",
    "    ##### Filter by the optional keep gene\n",
    "    if $[region_list.is_file()]:\n",
    "        region = pd.read_csv(\"$[region_list]\",\"\\t\")\n",
    "        keep_gene = region[\"gene_ID\"].to_list()\n",
    "        phenotype_df = phenotype_df.query('gene_ID  in keep_gene')\n",
    "        phenotype_pos_df = phenotype_pos_df.query('gene_ID  in keep_gene')\n",
    "\n",
    "\n",
    "    covariates_df = pd.read_csv(covariates_file, sep='\\t', index_col=0).T\n",
    "    pr = genotypeio.PlinkReader(plink_prefix_path)\n",
    "    genotype_df = pr.load_genotypes()\n",
    "    variant_df = pr.bim.set_index('snp')[['chrom', 'pos']]\n",
    "    ## Retaining only common samples\n",
    "    phenotype_df = phenotype_df[np.intersect1d(phenotype_df.columns, covariates_df.index)]\n",
    "    covariates_df = covariates_df.transpose()[np.intersect1d(phenotype_df.columns, covariates_df.index)].transpose()\n",
    "    ## Trans analysis\n",
    "    trans_df = trans.map_trans(genotype_df, phenotype_df, covariates_df, batch_size=$[batch_size],\n",
    "                           return_sparse=True, pval_threshold=$[pval_threshold], maf_threshold=$[maf_threshold])\n",
    "    ## Filter out cis signal\n",
    "    trans_df = trans.filter_cis(trans_df, phenotype_pos_df.T.to_dict(), variant_df, window=$[window])\n",
    "    ## Output\n",
    "    trans_df.columns.values[1]  = \"gene_ID\"\n",
    "    trans_df.columns.values[2]  = \"pval\"\n",
    "    trans_df.columns.values[3]  = \"beta\"\n",
    "    trans_df.columns.values[4]  = \"se\"\n",
    "    trans_df = trans_df.assign(\n",
    "    chrom = lambda dataframe: dataframe['variant_id'].map(lambda variant_id:variant_id.split(\":\")[0])).assign(\n",
    "    alt = lambda dataframe: dataframe['variant_id'].map(lambda variant_id:variant_id.split(\"_\")[2])).assign(\n",
    "    ref = lambda dataframe: dataframe['variant_id'].map(lambda variant_id:variant_id.split(\"_\")[1])).assign(\n",
    "    pos = lambda dataframe: dataframe['variant_id'].map(lambda variant_id:variant_id.split(\"_\")[0]))\n",
    "    trans_df.to_csv(\"$[_output]\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Association results processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[TensorQTL_cis_2]\n",
    "input:  group_by = \"all\"\n",
    "output: f'{cwd:a}/TensorQTL_recipe.tsv',f'{cwd:a}/TensorQTL_column_info.txt'\n",
    "python: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    import csv\n",
    "    import pandas as pd \n",
    "    data_tempt = pd.DataFrame({\n",
    "    \"#chr\" : [int(x.split(\".\")[-4].replace(\"chr\",\"\")) for x in  [$[_input[\"long_table\"]:r,]]],\n",
    "    \"sumstat_dir\" : [$[_input[\"long_table\"]:r,]],\n",
    "    \"column_info\" : $[_output[1]:r]\n",
    "    })\n",
    "    column_info_df = pd.DataFrame( pd.Series( {\"ID\": \"GENE,CHR,POS,A0,A1\",\n",
    "          \"CHR\": \"chrom\",\n",
    "          \"POS\": \"pos\",\n",
    "          \"A0\": \"ref\",\n",
    "          \"A1\": \"alt\",\n",
    "          \"SNP\": \"variant_id\",\n",
    "          \"STAT\": \"beta\",\n",
    "          \"SE\": \"se\",\n",
    "          \"P\": \"pval\",\n",
    "          \"TSS_D\": \"tss_distance\",\n",
    "          \"AF\": \"af\",\n",
    "          \"MA_SAMPLES\": \"ma_samples\",\n",
    "          \"MA_COUNT\": \"ma_count\",\n",
    "          \"GENE\": \"phenotype_id\"}), columns = [\"TensorQTL\"] )\n",
    "    data_tempt.to_csv(\"$[_output[0]]\",index = False,sep = \"\\t\" )\n",
    "    column_info_df.to_csv(\"$[_output[1]]\",index = True,sep = \"\\t\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[TensorQTL_trans_2]\n",
    "input: group_by = \"all\"\n",
    "output: f'{cwd:a}/TensorQTL_recipe.tsv',f'{cwd:a}/TensorQTL_column_info.txt'\n",
    "python: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    import csv\n",
    "    import pandas as pd \n",
    "    data_tempt = pd.DataFrame({\n",
    "    \"#chr\" : [int(x.split(\".\")[-3].replace(\"chr\",\"\")) for x in  [$[_input:r,]]],\n",
    "    \"sumstat_dir\" : [$[_input:r,]],\n",
    "    \"column_info\" : $[_output[1]:r]\n",
    "    })\n",
    "    column_info_df = pd.DataFrame( pd.Series( {\"ID\": \"GENE,CHR,POS,A0,A1\",\n",
    "          \"CHR\": \"chrom\",\n",
    "          \"POS\": \"pos\",\n",
    "          \"A0\": \"ref\",\n",
    "          \"A1\": \"alt\",\n",
    "          \"SNP\": \"variant_id\",\n",
    "          \"STAT\": \"beta\",\n",
    "          \"SE\": \"se\",\n",
    "          \"P\": \"pval\",\n",
    "          \"AF\": \"af\",\n",
    "          \"GENE\": \"gene_ID\"}), columns = [\"TensorQTL\"] )\n",
    "    data_tempt.to_csv(\"$[_output[0]]\",index = False,sep = \"\\t\" )\n",
    "    column_info_df.to_csv(\"$[_output[1]]\",index = True,sep = \"\\t\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.22.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
