{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Quantile QTL Association Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "We perform QTL association testing using quantile regression according to [this paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7673343/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input\n",
    "\n",
    "- List of molecular phenotype files: a list of `bed.gz` files containing the table for the molecular phenotype. It should have a companion index file in `tbi` format. It is the output of gene_annotation or phenotype_by_chorm\n",
    "\n",
    "### Example phenotype list\n",
    "\n",
    "```\n",
    "#chr    start   end ID  path\n",
    "chr12   752578  752579  ENSG00000060237  /home/gw/GIT/github/fungen-xqtl-analysis/analysis/Wang_Columbia/ROSMAP/MWE/output/phenotype/protocol_example.protein.bed.gz\n",
    "chr12   990508  990509  ENSG00000082805  /home/gw/GIT/github/fungen-xqtl-analysis/analysis/Wang_Columbia/ROSMAP/MWE/output/phenotype/protocol_example.protein.bed.gz\n",
    "chr12   2794969 2794970 ENSG00000004478  /home/gw/GIT/github/fungen-xqtl-analysis/analysis/Wang_Columbia/ROSMAP/MWE/output/phenotype/protocol_example.protein.bed.gz\n",
    "chr12   4649113 4649114 ENSG00000139180  /home/gw/GIT/github/fungen-xqtl-analysis/analysis/Wang_Columbia/ROSMAP/MWE/output/phenotype/protocol_example.protein.bed.gz\n",
    "chr12   6124769 6124770 ENSG00000110799  /home/gw/GIT/github/fungen-xqtl-analysis/analysis/Wang_Columbia/ROSMAP/MWE/output/phenotype/protocol_example.protein.bed.gz\n",
    "chr12   6534516 6534517 ENSG00000111640  /home/gw/GIT/github/fungen-xqtl-analysis/analysis/Wang_Columbia/ROSMAP/MWE/output/phenotype/protocol_example.protein.bed.gz\n",
    "```\n",
    "\n",
    "\n",
    "    The header of the bed.gz is per the [TensorQTL](https://github.com/broadinstitute/tensorqtl) convention:\n",
    "\n",
    "    >    Phenotypes must be provided in BED format, with a single header line starting with # and the first four columns corresponding to: chr, start, end, phenotype_id, with the remaining columns corresponding to samples (the identifiers must match those in the genotype input). The BED file should specify the center of the cis-window (usually the TSS), with start == end-1.\n",
    "\n",
    "\n",
    "- List of genotypes in PLINK binary format (`bed`/`bim`/`fam`) for each chromosome, previously processed through our genotype QC pipelines.\n",
    "- Covariate file, a file with #id + samples name as colnames and each row a covariate: fixed and known covariates as well as hidden covariates recovered from factor analysis.\n",
    "- Optionally, a list of traits (genes, regions of molecular features etc) to analyze.\n",
    "\n",
    "\n",
    "For cis-analysis:\n",
    "\n",
    "- Optionally, a list of genomic regions associate with each molecular features to analyze. The default cis-analysis will use a window around TSS. This can be customized to take given start and end genomic coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Output\n",
    "\n",
    "For each chromosome, several of summary statistics files are generated, including both nominal test statistics for each test, as well as region (gene) level association evidence.\n",
    "\n",
    "The columns of nominal association result are as follows:\n",
    "- phenotype_id: Molecular trait identifier.(gene)\n",
    "- variant_id_id: ID of the variant (rsid or chr:position:ref:alt)\n",
    "- chr : Variant chromosome.\n",
    "- pos : Variant chromosomal position (basepairs).\n",
    "- ref : Variant reference allele (A, C, T, or G).\n",
    "- alt : Variant alternate allele.\n",
    "- combined_pval(composite-p value using cauchy combination method): the integrated QR p-value across multiple quantile levels.    \n",
    "- qr_0.1_pval to qr_0.9_pval: quantile-specific QR p-values for the quantile levels 0.1, 0.2, ..., 0.9.   \n",
    "- qr_0.1_slope to qr_0.9_slope: quantile-specific QR coefficients for the quantile levels 0.1, 0.2, ..., 0.9.  \n",
    "- qr_0.1_tval to qr_0.9_tval: quantile-specific QR t-values for the quantile levels 0.1, 0.2, ..., 0.9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Minimal Working Example Steps\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "The data can be found on [Synapse](https://www.synapse.org/#!Synapse:syn36416559/files/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### i. Cis TensorQTL Command "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sos run pipeline/quantile_qtl_python.ipynb quant \\\n",
    "    --genotype-file output/genotype_by_chrom/protocol_example.genotype.chr21_22.genotype_by_chrom_files.txt \\\n",
    "    --phenotype-file  output/phenotype_by_chrom/protocol_example.protein.bed.phenotype_by_chrom_files.region_list.txt \\\n",
    "    --covariate-file output/covariate/protocol_example.protein.protocol_example.samples.protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.Marchenko_PC.gz \\\n",
    "    --customized_cis_windows prototype_example/protocol_example/protocol_example.protein.enhanced_cis_chr21_chr22.bed \\\n",
    "    --cwd output/cis_association/ \\\n",
    "    --MAC 5 \\\n",
    "    --container containers/TensorQTL.sif "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "zcat output/protocol_example.protein.bed.gz | cut -f 1,2,3,4 | grep -v -e ENSG00000163554 \\\n",
    "    -e ENSG00000171564 -e ENSG00000171560 -e ENSG00000171557 > output/protocol_example.protein.region_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "| Step | Substep | Problem | Possible Reason | Solution |\n",
    "|------|---------|---------|------------------|---------|\n",
    "|  |  |  |  |  |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Setup and global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Path to the work directory of the analysis.\n",
    "parameter: cwd = path('output')\n",
    "# Phenotype file, or a list of phenotype per region.\n",
    "parameter: phenotype_file = path\n",
    "# A genotype file in PLINK binary format (bed/bam/fam) format, or a list of genotype per chrom\n",
    "parameter: genotype_file = path\n",
    "# Covariate file\n",
    "parameter: covariate_file = path\n",
    "# Prefix for the analysis output\n",
    "parameter: name = f\"{phenotype_file:bn}_{covariate_file:bn}\"\n",
    "# An optional subset of regions of molecular features to analyze. The last column is the gene names\n",
    "parameter: region_list = path()\n",
    "parameter: region_list_phenotype_column = 4\n",
    "# Set list of sample to be keep\n",
    "parameter: keep_sample = path()\n",
    "# FIXME: please document\n",
    "parameter: interaction = \"\"\n",
    "\n",
    "# An optional list documenting the custom cis window for each region to analyze, with four column, chr, start, end, region ID (eg gene ID).\n",
    "# If this list is not provided, the default `window` parameter (see below) will be used.\n",
    "parameter: customized_cis_windows = path()\n",
    "\n",
    "# The phenotype group file to group molecule_trait into molecule_trait_object\n",
    "# This applies to multiple molecular events in the same region, such as sQTL analysis.\n",
    "parameter: phenotype_group = path() \n",
    "\n",
    "# The name of phenotype corresponding to gene_id or gene_name in the region\n",
    "parameter: chromosome = []\n",
    "# Minor allele count cutoff\n",
    "parameter: MAC = 0\n",
    "\n",
    "# Specify the cis window for the up and downstream radius to analyze around the region of interest in units of bp\n",
    "# This parameter will be set to zero if `customized_cis_windows` is provided.\n",
    "parameter: window = 1000000\n",
    "\n",
    "# Number of threads\n",
    "parameter: numThreads = 8\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "parameter: walltime = '12h'\n",
    "parameter: mem = '16G'\n",
    "# Container option for software to run the analysis: docker or singularity\n",
    "parameter: container = ''\n",
    "import re\n",
    "parameter: entrypoint= ('micromamba run -a \"\" -n' + ' ' + re.sub(r'(_apptainer:latest|_docker:latest|\\.sif)$', '', container.split('/')[-1])) if container else \"\"\n",
    "\n",
    "# Use the header of the covariate file to decide the sample size\n",
    "import pandas as pd\n",
    "N = len(pd.read_csv(covariate_file, sep = \"\\t\",nrows = 1).columns) - 1\n",
    "\n",
    "# Minor allele frequency cutoff. It will overwrite minor allele cutoff.\n",
    "# You may consider setting it to higher for interaction analysis if you have statistical power concerns\n",
    "parameter: maf_threshold = MAC/(2.0*N) \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def adapt_file_path(file_path, reference_file):\n",
    "    \"\"\"\n",
    "    Adapt a single file path based on its existence and a reference file's path.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): The file path to adapt.\n",
    "    - reference_file (str): File path to use as a reference for adaptation.\n",
    "\n",
    "    Returns:\n",
    "    - str: Adapted file path.\n",
    "\n",
    "    Raises:\n",
    "    - FileNotFoundError: If no valid file path is found.\n",
    "    \"\"\"\n",
    "    reference_path = os.path.dirname(reference_file)\n",
    "\n",
    "    # Check if the file exists\n",
    "    if os.path.isfile(file_path):\n",
    "        return file_path\n",
    "\n",
    "    # Check file name without path\n",
    "    file_name = os.path.basename(file_path)\n",
    "    if os.path.isfile(file_name):\n",
    "        return file_name\n",
    "\n",
    "    # Check file name in reference file's directory\n",
    "    file_in_ref_dir = os.path.join(reference_path, file_name)\n",
    "    if os.path.isfile(file_in_ref_dir):\n",
    "        return file_in_ref_dir\n",
    "\n",
    "    # Check original file path prefixed with reference file's directory\n",
    "    file_prefixed = os.path.join(reference_path, file_path)\n",
    "    if os.path.isfile(file_prefixed):\n",
    "        return file_prefixed\n",
    "\n",
    "    # If all checks fail, raise an error\n",
    "    raise FileNotFoundError(f\"No valid path found for file: {file_path}\")\n",
    "\n",
    "def adapt_file_path_all(df, column_name, reference_file):\n",
    "    return df[column_name].apply(lambda x: adapt_file_path(x, reference_file))\n",
    "\n",
    "\n",
    "if str(genotype_file).endswith(\"bed\") and str(phenotype_file).endswith(\"bed.gz\"):\n",
    "    input_files = [[phenotype_file, genotype_file]]\n",
    "    input_chroms = [0]\n",
    "else:\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    molecular_pheno_files = pd.read_csv(phenotype_file, sep = \"\\t\")\n",
    "    if \"#chr\" in molecular_pheno_files.columns:\n",
    "        molecular_pheno_files = molecular_pheno_files.groupby(['#chr', '#dir']).size().reset_index(name='count').drop(\"count\",axis = 1).rename(columns = {\"#chr\":\"#id\"})\n",
    "    genotype_files = pd.read_csv(genotype_file,sep = \"\\t\")\n",
    "    genotype_files[\"#id\"] = [x.replace(\"chr\",\"\") for x in genotype_files[\"#id\"].astype(str)] # e.g. remove chr1 to 1\n",
    "    genotype_files[\"#path\"] = genotype_files[\"#path\"].apply(lambda x: adapt_file_path(x, genotype_file))\n",
    "    molecular_pheno_files[\"#id\"] = [x.replace(\"chr\",\"\") for x in molecular_pheno_files[\"#id\"].astype(str)]\n",
    "    input_files = molecular_pheno_files.merge(genotype_files, on = \"#id\")\n",
    "    # Only keep chromosome specified in --chromosome\n",
    "    if len(chromosome) > 0:\n",
    "        input_files = input_files[input_files['#id'].isin(chromosome)]\n",
    "    input_files = input_files.values.tolist()\n",
    "    input_chroms = [x[0] for x in input_files]\n",
    "    input_files = [x[1:] for x in input_files]\n",
    "    print(\"Input Files:\", input_files)\n",
    "    print(\"Input Chromosomes:\", input_chroms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## Quantile qtl cis association testing: by chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# e.g. mega data:exc\n",
    "nohup sos run pipeline/quantile_qtl_python.ipynb quant \\\n",
    "    --name snuc_pseudo_bulk_mega_exc \\\n",
    "    --genotype-file /mnt/vast/hpc/csg/FunGen_xQTL/ROSMAP/Genotype/geno_by_chrom/ROSMAP_NIA_WGS.leftnorm.bcftools_qc.plink_qc.genotype_by_chrom_files.txt \\\n",
    "    --phenotype-file /mnt/vast/hpc/csg/wanggroup/fungen-xqtl-analysis/analysis/Wang_Columbia/ROSMAP/pseudo_bulk_eqtl_mega/Exc/output/data_preprocessing/phenotype_data/phenotype_by_chrom/snuc_pseudo_bulk.Exc.mega.normalized.log2cpm.bed.phenotype_by_chrom_files.txt \\\n",
    "    --region-list /home/al4225/project/quantile_qtl/python_version/combined_AD_genes.csv \\\n",
    "    --covariate-file /mnt/vast/hpc/csg/wanggroup/fungen-xqtl-analysis/analysis/Wang_Columbia/ROSMAP/pseudo_bulk_eqtl_mega/Exc/output/data_preprocessing/covariate_data/snuc_pseudo_bulk.Exc.mega.normalized.log2cpm.rosmap_cov.ROSMAP_NIA_WGS.leftnorm.bcftools_qc.plink_qc.snuc_pseudo_bulk_mega.related.plink_qc.extracted.pca.projected.Marchenko_PC.gz \\\n",
    "    --customized_cis_windows /home/al4225/project/fungen-xqtl-analysis/resource/TADB_enhanced_cis.bed \\\n",
    "    --cwd /home/al4225/project/quantile_qtl/pseudobulk_mega/output/exc/ \\\n",
    "    --container /mnt/vast/hpc/csg/containers_xqtl/TensorQTL.sif --maf-threshold 0.05 \\\n",
    "    --mem 60G -J 50 -c /mnt/vast/hpc/csg/molecular_phenotype_calling/csg.yml -q csg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[quant]\n",
    "# parse input file lists\n",
    "# skip nominal association results if the files exists already\n",
    "# This is false by default which means to recompute everything\n",
    "# This is only relevant when the `parquet` files for nominal results exist but not the other files\n",
    "# and you want to avoid computing the nominal results again\n",
    "#parameter: skip_nominal_if_exist = False\n",
    "#parameter: permutation = True\n",
    "parameter: vcov= 'robust'\n",
    "parameter: kernel='epa'\n",
    "parameter: bandwidth='hsheather'\n",
    "parameter: max_iter=1000\n",
    "parameter: p_tol=0.000001\n",
    "\n",
    "# Extract interaction name\n",
    "var_interaction = interaction\n",
    "if os.path.isfile(interaction):\n",
    "    interaction_s = pd.read_csv(interaction, sep='\\t', index_col=0)\n",
    "    var_interaction = interaction_s.columns[0] # interaction name\n",
    "test_regional_association = permutation and len(var_interaction) == 0\n",
    "\n",
    "input: input_files, group_by = len(input_files[0]), group_with = \"input_chroms\"\n",
    "output_files = dict([(\"parquet\", f'{cwd:a}/{_input[0]:bnn}{\"_%s\" % var_interaction if interaction else \"\"}.cis_qtl_pairs.{\"\" if input_chroms[_index] == 0 else input_chroms[_index]}.parquet'), # This convention is necessary to match the pattern of map_norminal output\n",
    "                     (\"nominal\", f'{cwd:a}/{_input[0]:bnn}{\"\" if input_chroms[_index] == 0 else \"_chr%s\" % input_chroms[_index]}{\"_%s\" % var_interaction if interaction else \"\"}.cis_qtl.pairs.tsv.gz')])\n",
    "if test_regional_association:\n",
    "    output_files[\"regional\"] = f'{cwd:a}/{_input[0]:bnn}{\"\" if input_chroms[_index] == 0 else \"_chr%s\" % input_chroms[_index]}{\"_%s\" % var_interaction if interaction else \"\"}.cis_qtl.regional.tsv.gz'\n",
    "output: output_files, quantileqtl_nominal_results = f'{cwd:a}/{name}.{_input_chroms}.quantileqtl_nominal_results.txt'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[\"nominal\"]:bnnn}'\n",
    "python: expand= \"$[ ]\", stderr = f'{_output[\"nominal\"]:nnn}.stderr', stdout = f'{_output[\"nominal\"]:nnn}.stdout' , container = container, entrypoint = entrypoint\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import tensorqtl\n",
    "    from tensorqtl import genotypeio, cis\n",
    "    from scipy.stats import chi2\n",
    "    import statsmodels.api as sm\n",
    "    import scipy.stats as ss\n",
    "    from scipy.stats import cauchy\n",
    "    import time\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    def calculate_maf(genotype_array, alleles=2):\n",
    "        af_array = genotype_array.sum(axis=1) / (alleles * genotype_array.shape[1])\n",
    "        maf_array = np.where(af_array > 0.5, 1 - af_array, af_array)\n",
    "        return maf_array\n",
    "\n",
    "    def cauchy_meta(pvals):\n",
    "        # Check input\n",
    "        pvals = np.array(pvals)\n",
    "        pvals = pvals[~np.isnan(pvals)]\n",
    "        if len(pvals) == 0:\n",
    "            return np.nan\n",
    "        # pvals[pvals == 0] = 2.2e-308\n",
    "        # Convert to Cauchy\n",
    "        cauchy_vals = np.zeros(pvals.shape)\n",
    "        valid_indices = pvals >= 1e-15\n",
    "        cauchy_vals[valid_indices] = np.tan(np.pi * (0.5 - pvals[valid_indices]))\n",
    "        stats = np.mean(cauchy_vals)\n",
    "        p = cauchy.sf(stats)\n",
    "        return p\n",
    "\n",
    "    def fit_quantreg_with_covariates(phenotype_id, phenotype_array, genotype_matrix, covar_df, variant_ids, taus=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], vcov='$[vcov]', kernel='$[kernel]', bandwidth='$[bandwidth]', max_iter=$[max_iter], p_tol=$[p_tol]):\n",
    "        results = []\n",
    "        variant_pvals = {vid: [] for vid in variant_ids}  # Prepare a dict to store p-values for combined p-value calculation\n",
    "\n",
    "        # Ensure the correct orientation of genotype_matrix to match the samples in covar_df\n",
    "        if genotype_matrix.shape[1] != covar_df.shape[0]: #covar: row: SM, geno: col:SM\n",
    "            raise ValueError(\"Mismatch in the number of samples between genotype matrix and covariates DataFrame\")\n",
    "\n",
    "        for tau in taus:\n",
    "            for idx, genotype_row in enumerate(genotype_matrix): #genotype_matrix is a 2-dimension numpy,iterate over variants\n",
    "                X = np.c_[covar_df.values, genotype_row] \n",
    "                X = sm.add_constant(X).astype('float')\n",
    "                model = sm.QuantReg(phenotype_array, X)\n",
    "                try:\n",
    "                    res = model.fit(q=tau, vcov=vcov, kernel=kernel, bandwidth=bandwidth, max_iter=max_iter, p_tol=p_tol)\n",
    "                    pval = res.pvalues[-1]\n",
    "                    variant_pvals[variant_ids[idx]].append(pval)\n",
    "                    results.append({\n",
    "                        'phenotype_id': phenotype_id,\n",
    "                        'variant_id': variant_ids[idx],\n",
    "                        'tau': tau,\n",
    "                        'pval': pval,\n",
    "                        'slope': res.params[-1],\n",
    "                        'tval': res.tvalues[-1]\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error fitting model for variant {variant_ids[idx]} at tau {tau}: {e}\")\n",
    "                if (idx + 1) % 100 == 0:\n",
    "                    print(f\"{idx+1} pairs, percentage {idx+1}/{len(variant_ids)} for phenotype_id {phenotype_id} finished.\")\n",
    "        # Calculate combined p-values for each variant\n",
    "        for vid in variant_ids:\n",
    "            combined_pval = cauchy_meta(variant_pvals[vid])\n",
    "            for result in filter(lambda r: r['variant_id'] == vid, results):\n",
    "                result['combined_pval'] = combined_pval\n",
    "        results_df = pd.DataFrame(results)\n",
    "        \n",
    "        wide_df = pd.pivot_table(results_df, values=['pval', 'slope', 'tval'], index=['phenotype_id', 'variant_id', 'combined_pval'], columns='tau')\n",
    "        wide_df.columns = ['qr_{}_{}'.format(col[1], col[0]) for col in wide_df.columns]\n",
    "        wide_df.reset_index(inplace=True)\n",
    "        variant_split = wide_df['variant_id'].str.extract(r'chr(\\d+):(\\d+)_([A-Z*]+)_([A-Z*]+)')\n",
    "        variant_split.columns = ['chr', 'pos', 'ref', 'alt']\n",
    "        final_df = pd.concat([variant_split, wide_df], axis=1)\n",
    "        \n",
    "        return final_df\n",
    "\n",
    "        \n",
    "    ## Define paths\n",
    "    plink_prefix_path = $[_input[1]:nar]\n",
    "    expression_bed = $[_input[0]:ar]\n",
    "    covariates_file = \"$[covariate_file:a]\"\n",
    "    window = $[window]\n",
    "    interaction = \"$[interaction]\"\n",
    "    ## Load Data\n",
    "    phenotype_df, phenotype_pos_df = tensorqtl.read_phenotype_bed(expression_bed)\n",
    "\n",
    "    phenotype_id = phenotype_pos_df.index.name\n",
    "    ## Analyze only the regions listed\n",
    "    if $[region_list.is_file()]:\n",
    "        region = pd.read_csv(\"$[region_list:a]\", comment=\"#\", header=None, sep=\",\" )\n",
    "        phenotype_column = 1 if len(region.columns) == 1 else  $[region_list_phenotype_column]\n",
    "        keep_region = region.iloc[:,phenotype_column-1].to_list()\n",
    "        phenotype_df = phenotype_df[phenotype_df.index.isin(keep_region)]\n",
    "        phenotype_pos_df = phenotype_pos_df[phenotype_pos_df.index.isin(keep_region)]\n",
    "\n",
    "    covariates_df = pd.read_csv(covariates_file, sep='\\t', index_col=0).T\n",
    "\n",
    "    pr = genotypeio.PlinkReader(plink_prefix_path)\n",
    "    genotype_df = pr.load_genotypes()\n",
    "\n",
    "    # keep 1st 2k cols\n",
    "    genotype_df = genotype_df.iloc[:10000, :]\n",
    "\n",
    "    variant_df = pr.bim.set_index('snp')[['chrom', 'pos','a0','a1']]\n",
    "    variant_df = variant_df.iloc[:10000, :]\n",
    "    \n",
    "    ## use custom sample list to subset the covariates data\n",
    "    if $[keep_sample.is_file()]:\n",
    "        sample_list = pd.read_csv(\"$[keep_sample:a]\", comment=\"#\", header=None, names=[\"sample_id\"], sep=\"\\t\")\n",
    "        covariates_df.loc[sample_list.sample_id]\n",
    "\n",
    "    # Read interaction files or extract from covariates file.\n",
    "    var_interaction = interaction\n",
    "    interaction_s = []\n",
    "    if os.path.isfile(interaction):\n",
    "        # update var_interaction and interaction_s\n",
    "        interaction_s = pd.read_csv(interaction, sep='\\t', index_col=0)\n",
    "        interaction_s = interaction_s[interaction_s.index.isin(covariates_df.index)] \n",
    "        var_interaction = interaction_s.columns[0] # interaction name\n",
    "    # check if the interaction term in interaction table is in covariates file, if yes and interaction_s not yet loaded then, extract it out from covariates file\n",
    "    if var_interaction in covariates_df.columns:\n",
    "        # only load from covariate if it has not been loaded yet\n",
    "        if len(interaction_s) == 0:\n",
    "            interaction_s = covariates_df[var_interaction].to_frame()\n",
    "        covariates_df = covariates_df.drop(columns=[var_interaction])\n",
    "    if len(interaction) and len(interaction_s) == 0:\n",
    "        raise ValueError(f\"Cannot find interaction variable or file {interaction}\")\n",
    "\n",
    "    # drop samples that with missing value in iteraction\n",
    "    if len(interaction_s):\n",
    "        interaction_s = interaction_s.dropna() \n",
    "\n",
    "    ## Retaining only common samples\n",
    "    phenotype_df.columns = phenotype_df.columns.astype(str)\n",
    "    covariates_df.index = covariates_df.index.astype(str)\n",
    "\n",
    "    phenotype_df = phenotype_df[np.intersect1d(phenotype_df.columns, covariates_df.index)]\n",
    "    phenotype_df = phenotype_df[np.intersect1d(phenotype_df.columns, genotype_df.columns)]\n",
    "    if len(interaction_s):\n",
    "        phenotype_df = phenotype_df[np.intersect1d(phenotype_df.columns, interaction_s.index)]\n",
    "        interaction_s = interaction_s[interaction_s.index.isin(phenotype_df.columns)]    \n",
    "        interaction_s = interaction_s.loc[phenotype_df.columns]\n",
    "\n",
    "    covariates_df = covariates_df.transpose()[np.intersect1d(phenotype_df.columns, covariates_df.index)].transpose()\n",
    "    ## To simplify things, there should really not be \"chr\" prefix\n",
    "    phenotype_pos_df.chr = phenotype_pos_df.chr.astype(str).str.replace(\"chr\", \"\")\n",
    "    variant_df.chrom =  variant_df.chrom.astype(\"str\").str.replace(\"chr\", \"\") \n",
    "    \n",
    "    common_samples = np.intersect1d(phenotype_df.columns, genotype_df.columns)\n",
    "    genotype_df = genotype_df[common_samples]\n",
    "    # same sample order\n",
    "    sample_order = covariates_df.index\n",
    "    phenotype_df = phenotype_df[sample_order]\n",
    "    genotype_df = genotype_df[sample_order]\n",
    "\n",
    "    ## use custom cis windows list\n",
    "    if $[customized_cis_windows.is_file()]:\n",
    "        cis_list = pd.read_csv(\"$[customized_cis_windows:a]\", comment=\"#\", header=None, names=[\"chr\",\"start\",\"end\",phenotype_id], sep=\"\\t\")\n",
    "        cis_list.chr = cis_list.chr.astype(str).str.replace(\"chr\", \"\")  ## Again to simplify things for chr format concordance.\n",
    "        phenotype_pos_df = phenotype_pos_df.reset_index() #move the phenotype id index to a new column of the dataframe\n",
    "        phenotype_pos_df = phenotype_pos_df.merge(cis_list, left_on = [\"chr\",phenotype_id],right_on = [cis_list.columns[0],cis_list.columns[3]])#in some cases (gene expression for eQTLs) the phenotype_id may be in the cis_list file\n",
    "        phenotype_pos_df = phenotype_pos_df.set_index(phenotype_id)[[\"chr\",\"start\",\"end\"]] # The final phenotype_pos_df will have three columns(chr, start, end) and index is the phenotype ID\n",
    "        if len(phenotype_df.index) != len(phenotype_pos_df.index):\n",
    "            raise ValueError(\"cannot uniquely match all the phentoype data in the input to the customized cis windows provided\")\n",
    "        window = 0 \n",
    " \n",
    "    ## Read phenotype group if availble\n",
    "    if $[phenotype_group.is_file()]:\n",
    "        group_s = pd.read_csv($[phenotype_group:r], sep='\\t', header=None, index_col=0, squeeze=True)\n",
    "    else:\n",
    "        group_s = None\n",
    "\n",
    "    # quantile qtl mapping:\n",
    "    igc = genotypeio.InputGeneratorCis(genotype_df, variant_df, phenotype_df, phenotype_pos_df, group_s=group_s, window=window)\n",
    "\n",
    "    results_list = [] \n",
    "\n",
    "    for phenotype, genotypes, genotype_range, phenotype_id in igc.generate_data(chrom=chrom, verbose=True):\n",
    "        variant_ids = variant_df.index[genotype_range[0]:genotype_range[-1]+1].tolist()\n",
    "        if $[maf_threshold] > 0:\n",
    "            maf = calculate_maf(genotypes)\n",
    "            mask = maf >= $[maf_threshold]\n",
    "            genotypes = genotypes[mask]\n",
    "            mask = mask.astype(bool)\n",
    "            variant_ids = np.array(variant_ids)[mask]\n",
    "            print(\"next step is : quantreg\")\n",
    "\n",
    "        results_df = fit_quantreg_with_covariates(phenotype_id, phenotype, genotypes, covariates_df, variant_ids)\n",
    "        results_list.append(results_df)\n",
    "\n",
    "    all_results_df = pd.concat(results_list, ignore_index=True)\n",
    "    all_results_df.to_csv(\"$[_output['quantileqtl_nominal_results']]\", sep=\"\\t\", index=False)\n",
    "    print(f\"quantlie qtl completed\")\n",
    "    end_time = time.time()  \n",
    "    print(f\"Total execution time: {end_time - start_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.23.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
