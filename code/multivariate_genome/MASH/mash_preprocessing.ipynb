{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "outside-vatican",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Extract genome-wide data for multivariate analysis\n",
    "\n",
    "## Description\n",
    "\n",
    "This notebook prepares input data for Utimate Decomposition to generate mixture prior (for mvSuSiE) or to use for MASH analysis. It outputs 3 sets of data: $Z_s$, $Z_n$ and $Z_r$ (strong, null and random)\n",
    "\n",
    "* $Z_s$: **this is now extracted from genome-wide cis analysis fine-mapping results**. We extract the top loci data frame of each condition, where the CS threshold is set to be 0.7. Then we merge the z-scores of them into one data frame.\n",
    "* $Z_n$: (null $Z$-scores): we first extract up to $M$ candidate SNPs from each region which satisify $|z| \\le 2$, then overlap it with the list of independent SNPs to keep only independent variants, then finally take the union of the extracted.\n",
    "* $Z_r$: we randomly extract variants based on input independent list of variants.\n",
    "\n",
    "**FIXME: We need to apply the independent list of variants Anqi developed and use it here to filter and get $Z_n$ and $Z_r$. This logic shoud be added to `processing_1`. Also, it might be a good idea we take some of these utility functions into pecotmr package for better maintenance. For example `processing_1` the function to load regional summary stats from tensorQTL into a matrix should be packed into pecotmr; plus this one function `handle_nan_etc`. processing_2 can stay as is; the `susie_signal` step can also go into `pecotmr` as a way for users to summarize signals from SuSiE for other purposes**\n",
    "\n",
    "## Input\n",
    "1. **Marginal summary statistics files**: Bgzipped summary statistics for chromosomes 1-22, generated by tensorQTL cis-analysis and indexed by `tabix`.\n",
    "2. **Fine-mapping results file index**: Path to lists of fine-mapped RDS files from finemapping output.\n",
    "2. **Genome region partition** (optional): Defines genomic regions for each gene as enhanced cis regions where we should extract $Z_n$ and $Z_r$ from. This list is used for fine-mapping, so if the complete list of fine-mapping RDS (rather than a handful of it) is already avaiable (#2 above) then there is no need to provide this file. Otherwise, it's going to be limited to only certaion regions, which is also good for testing purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-wisdom",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Output\n",
    "A list of 10 elements:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-sperm",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "```\n",
    "List of 10\n",
    " $ random.z: num [1:36, 1:2] -0.785 -0.785 -0.785 -0.785 -0.785 ...\n",
    "  ..- attr(*, \"dimnames\")=List of 2\n",
    "  .. ..$ : chr [1:36] \"1:97960:A:G\" \"1:138565:G:A\" \"1:15112:C:T\" \"1:189947:G:A\" ...\n",
    "  .. ..$ : chr [1:2] \"A\" \"B\"\n",
    " $ null.z  : num [1:36, 1:2] -0.785 -0.785 -0.785 -0.785 -0.785 ...\n",
    "  ..- attr(*, \"dimnames\")=List of 2\n",
    "  .. ..$ : chr [1:36] \"1:93692:C:T\" \"1:273645:A:G\" \"1:10442:CCTA:.\" \"1:198942:A:C\" ...\n",
    "  .. ..$ : chr [1:2] \"A\" \"B\"\n",
    " $ random.b: num [1:36, 1:2] -0.123 -0.123 -0.123 -0.123 -0.123 ...\n",
    "  ..- attr(*, \"dimnames\")=List of 2\n",
    "  .. ..$ : chr [1:36] \"1:97960:A:G\" \"1:138565:G:A\" \"1:15112:C:T\" \"1:189947:G:A\" ...\n",
    "  .. ..$ : chr [1:2] \"A\" \"B\"\n",
    " $ null.b  : num [1:36, 1:2] -0.123 -0.123 -0.123 -0.123 -0.123 ...\n",
    "  ..- attr(*, \"dimnames\")=List of 2\n",
    "  .. ..$ : chr [1:36] \"1:93692:C:T\" \"1:273645:A:G\" \"1:10442:CCTA:.\" \"1:198942:A:C\" ...\n",
    "  .. ..$ : chr [1:2] \"A\" \"B\"\n",
    " $ null.s  : num [1:36, 1:2] 0.157 0.157 0.157 0.157 0.157 ...\n",
    "  ..- attr(*, \"dimnames\")=List of 2\n",
    "  .. ..$ : chr [1:36] \"1:93692:C:T\" \"1:273645:A:G\" \"1:10442:CCTA:.\" \"1:198942:A:C\" ...\n",
    "  .. ..$ : chr [1:2] \"A\" \"B\"\n",
    " $ random.s: num [1:36, 1:2] 0.157 0.157 0.157 0.157 0.157 ...\n",
    "  ..- attr(*, \"dimnames\")=List of 2\n",
    "  .. ..$ : chr [1:36] \"1:97960:A:G\" \"1:138565:G:A\" \"1:15112:C:T\" \"1:189947:G:A\" ...\n",
    "  .. ..$ : chr [1:2] \"A\" \"B\"\n",
    " $ strong.b:Classes ‘data.table’ and 'data.frame':\t1 obs. of  2 variables:\n",
    "  ..$ A: num -0.217\n",
    "  ..$ B: num -0.217\n",
    "  ..- attr(*, \".internal.selfref\")=<externalptr> \n",
    " $ strong.s:Classes ‘data.table’ and 'data.frame':\t1 obs. of  2 variables:\n",
    "  ..$ A: num 0.0481\n",
    "  ..$ B: num 0.0481\n",
    "  ..- attr(*, \".internal.selfref\")=<externalptr> \n",
    " $ strong.z:Classes ‘data.table’ and 'data.frame':\t1 obs. of  2 variables:\n",
    "  ..$ A: num -4.5\n",
    "  ..$ B: num -4.5\n",
    "  ..- attr(*, \".internal.selfref\")=<externalptr> \n",
    " $ XtX     : num [1:2, 1:2] 20.3 20.3 20.3 20.3\n",
    "  ..- attr(*, \"dimnames\")=List of 2\n",
    "  .. ..$ : chr [1:2] \"A\" \"B\"\n",
    "  .. ..$ : chr [1:2] \"A\" \"B\"\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-tolerance",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-modeling",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# generate random and null only\n",
    "sos run pipeline/mash_preprocessing.ipynb processing \\\n",
    "    --name protocol_example_protein \\\n",
    "    --sum_files test_pQTL_asso_list \\\n",
    "               test_pQTL_asso_list \\\n",
    "    --region_file test.region \\\n",
    "    --traits A B \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-constitutional",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# generate strong only\n",
    "sos run pipeline/mash_preprocessing.ipynb susie_signal \\\n",
    "    --name protocol_example_protein \\\n",
    "    --susie_list protocol_example_protein.susie_output.txt \\\n",
    "    --traits A B \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-intranet",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# generate mashr input directly\n",
    "sos run pipeline/mash_preprocessing.ipynb mash_input \\\n",
    "    --name protocol_example_protein \\\n",
    "    --sum_files test_pQTL_asso_list \\\n",
    "               test_pQTL_asso_list \\\n",
    "    --region_file test.region \\\n",
    "    --susie_list protocol_example_protein.susie_output.txt \\\n",
    "    --traits A B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "attractive-manor",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "parameter: name = str\n",
    "# Path to work directory where output locates\n",
    "parameter: cwd = path(\"./output\")\n",
    "parameter: seed = 999\n",
    "parameter: n_random = 10\n",
    "parameter: n_null = 10\n",
    "parameter: expected_ncondition = 0\n",
    "parameter: exclude_condition = []\n",
    "# Containers that contains the necessary packages\n",
    "parameter: container = \"\"\n",
    "import re\n",
    "parameter: entrypoint= ('micromamba run -a \"\" -n' + ' ' + re.sub(r'(_apptainer:latest|_docker:latest|\\.sif)$', '', container.split('/')[-1])) if container else \"\"\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"10min\"\n",
    "# Memory expected\n",
    "parameter: mem = \"8G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 8\n",
    "# This is in principle required; but in practice it can be optional if we are not exactly stringent about getting independent SNPs\n",
    "parameter: independent_variant_list = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-collect",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# extract data for MASH from summary stats\n",
    "[susie_to_mash_1]\n",
    "parameter: per_chunk =100\n",
    "parameter: susie_list = path\n",
    "# first 3 col are chr start end, 4th column is region ID, 5th col are file names, 6 col is all the condition names comma split\n",
    "susie_data = [(\"c(\" + \",\".join(f\"'{y}'\" for y in x.strip().split()) + \")\") for x in open(susie_list).readlines()] \n",
    "input: for_each = susie_data, group_by = per_chunk\n",
    "output: f\"{cwd}/{name}_cache/{name}_batch{_index+1}.rds\"\n",
    "task: trunk_workers = job_size, walltime = walltime, trunk_size = 1, mem = mem, cores = numThreads, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\",stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "    merge_data = function(res, one_data) {\n",
    "      if (length(res) == 0) {\n",
    "          return(one_data)\n",
    "      } else if (is.null(is.null(res$random.b)|is.null(res$null.b))) {\n",
    "          return(one_data)\n",
    "      } else if (is.null(one_data)) {\n",
    "          return(res)\n",
    "      } else {\n",
    "          for (d in names(one_data)) {\n",
    "            if (is.null(one_data[[d]])) {\n",
    "              next\n",
    "            } else {\n",
    "                res[[d]] = as.matrix(rbind(res[[d]],as.data.frame(one_data[[d]])))\n",
    "            }\n",
    "          }\n",
    "          return(res)\n",
    "      }\n",
    "    }\n",
    "    exclude_condition = c(${\",\".join([repr(x) for x in exclude_condition])})\n",
    "    meta_df = rbind(${\",\".join(_susie_data)}}\n",
    "    res = list()\n",
    "    for (i in 1:nrows(meta_df)) {\n",
    "      line = meta_df[i,]\n",
    "      region_files = strsplit(line[5], split=\",\")\n",
    "      traits = strsplit(line[6], split=\",\")\n",
    "      strong <- pecotmr::load_multitrait_R_sumstat(region_files, top_loci=TRUE)\n",
    "      ran_null <- pecotmr::load_multitrait_R_sumstat(region_files, filter_file=${independent_variant_list:r})\n",
    "      if (length(exclude_condition)>0) {\n",
    "          strong = list(strong.z=strong$bhat[,-exclude_condition]/strong$sbhat[,-exclude_condition], strong.b=strong$bhat[,-exclude_condition], strong=strong$sbhat[,-exclude_condition])\n",
    "      } else {\n",
    "          strong = list(strong.z=strong$bhat/strong$sbhat, strong.b=strong$bhat, strong=strong$sbhat)\n",
    "      }\n",
    "      ran_null <- pecotmr::mash_ran_null_sample(dat, ${n_random}, ${n_null}, ${expected_ncondition}, exclude_condition, seed=${seed})\n",
    "      res <- merge_data(res, c(strong, ran_null))\n",
    "    }\n",
    "    \n",
    "    saveRDS(out, ${_output:r}, compress=\"xz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-document",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[susie_to_mash_2]\n",
    "input: group_by = \"all\"\n",
    "output: f\"{cwd}/{name}.mash_input.rds\" \n",
    "task: trunk_workers = 1, walltime = '1h', trunk_size = 1, mem = '16G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", container = container, stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', entrypoint=entrypoint\n",
    "\n",
    "  # Function to merge data\n",
    "  merge_data <- function(res, one_data) {\n",
    "    if (length(res) == 0) {\n",
    "      return(one_data)\n",
    "    } else if (is.null(one_data)) {\n",
    "      return(res)\n",
    "    } else {\n",
    "      for (d in names(one_data)) {\n",
    "        if (is.null(one_data[[d]])) {\n",
    "          next\n",
    "        } else {\n",
    "          res[[d]] <- as.matrix(rbind(res[[d]], as.data.frame(one_data[[d]])))\n",
    "        }\n",
    "      }\n",
    "      return(res)\n",
    "    }\n",
    "  }\n",
    "\n",
    "  dat = list()\n",
    "  for (f in c(${_input:r,})) {\n",
    "    dat = merge_data(dat, readRDS(f))\n",
    "  }\n",
    "  dat$ZtZ = t(as.matrix(dat$strong.z)) %*% as.matrix(dat$strong.z) / nrow(dat$strong.z)\n",
    "  saveRDS(dat, ${_output:r}, compress=\"xz\")\n",
    " \n",
    "bash: expand = \"${ }\", container = container, stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', entrypoint=entrypoint\n",
    "    rm -rf ${cwd}/${name}_cache/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-values",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Get the random and null effects per analysis unit\n",
    "\n",
    "**FIXME: notice that we no longer rely on tensorQTL results for MASH analysis. Our new protocol uses SuSiE output. We keep this piece of code to extract from tensorQTL which may still be relevant for trans-analysis. But currently it is limited to random and null variants extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-kernel",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[random_null_tensorqtl_1]\n",
    "parameter: sum_files = paths\n",
    "parameter: region_file = path\n",
    "parameter: traits = paths\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "def find_matching_files_for_region(chr_id):\n",
    "    chr_number = chr_id[3:]  # subset 1 from chr1\n",
    "    pattern_str = r\"\\.{chr_number}\\.\"\n",
    "    pattern = re.compile(pattern_str.format(chr_number=chr_number))\n",
    "    paths = []\n",
    "    for sum_file in sum_files:\n",
    "        with open(sum_file, 'r') as af:\n",
    "            for aline in af:\n",
    "                if pattern.search(aline):\n",
    "                    paths.append(aline.strip())\n",
    "    return \",\".join(paths)\n",
    "\n",
    "updated_regions = []\n",
    "with open(region_file, 'r') as regions:\n",
    "    header = regions.readline().strip()\n",
    "    updated_regions.append(header + \"\\tpath\\tregion\")\n",
    "    for line in regions:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        chr_id, start, end, gene_id = parts\n",
    "        paths = find_matching_files_for_region(chr_id)\n",
    "        updated_regions.append(f\"{chr_id}\\t{start}\\t{end}\\t{gene_id}\\t{paths}\\t{chr_id}:{start}-{end}\")\n",
    "\n",
    "meta_df = pd.DataFrame([line.split(\"\\t\") for line in updated_regions[1:]], columns=updated_regions[0].split(\"\\t\"))\n",
    "meta = meta_df[['gene_id', 'path', 'region']].to_dict(orient='records')\n",
    "\n",
    "input: for_each='meta'\n",
    "output: f'{cwd:a}/{name}_cache/{name}.{_meta[\"gene_id\"]}.rds'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand = \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container, entrypoint=entrypoint\n",
    "    region <- \"${_meta['region']}\"\n",
    "    # FIXME I am sure there is a more elegant way to put together the path, via SoS\n",
    "    phenotype_path <- unlist(strsplit(\"${_meta['path']}\", \",\"))\n",
    "    dat <- tryCatch(\n",
    "      {\n",
    "        # Try to run the function\n",
    "         pecotmr::load_multitrait_tensorqtl_sumstat(phenotype_path = phenotype_path, region = region, \n",
    "          trait_names = c(${traits:r,}), filter_file = NULL, remove_any_missing = TRUE, max_rows_selected = 300, na_remove = ${\"T\" if na_remove else \"F\"})\n",
    "      },\n",
    "      error = function(e) {\n",
    "        warning(\"Attempt remove chr in region ID to load the data.\")\n",
    "        # If an error occurs, modify the region and try again\n",
    "        pecotmr::load_multitrait_tensorqtl_sumstat(phenotype_path = phenotype_path, region =  gsub(\"chr\", \"\", region), \n",
    "          trait_names = c(${traits:r,}), filter_file = NULL, remove_any_missing = TRUE, max_rows_selected = 300, na_remove = ${\"T\" if na_remove else \"F\"})\n",
    "      }\n",
    "    )\n",
    "    exclude_condition = c(${\",\".join([repr(x) for x in exclude_condition])})\n",
    "    dat <- pecotmr::mash_ran_null_sample(dat, ${n_random}, ${n_null}, ${expected_ncondition}, exclude_condition, z_only = ${\"TRUE\" if z_only else \"FALSE\"}, seed=${seed})\n",
    "    saveRDS(dat, ${_output:r}, compress=\"xz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "R",
     "ir",
     "R",
     "#DCDCDA",
     "r"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.20.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
