{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-e5f6-7890-1234-567890abcdef",
   "metadata": {},
   "source": [
    "# EMS Prediction\n",
    "\n",
    "This notebook demonstrates how to apply trained sc-EMS models to score your own genetic variants for functional impact. After completing [EMS Training](https://statfungen.github.io/xqtl-protocol/code/xqtl_modifier_score/ems_training.html), use your trained model to predict Expression Modifier Scores.\n",
    "\n",
    "## What This Does\n",
    "- **Input**: Your list of genetic variants + trained EMS model\n",
    "- **Output**: Same variants with EMS functional scores (0-1 scale)\n",
    "- **Use Case**: Prioritize variants for experimental validation or clinical follow-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2d3e4-f5a6-7890-1234-567890abcdef",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "**Required Files:**\n",
    "- Trained model: `model_standard_subset_weighted_chr_chr2_NPR_10.joblib`\n",
    "- Your variant list: TSV/CSV with `variant_id` column (format: \"chr:pos:ref:alt\")\n",
    "- Supporting data files from training pipeline\n",
    "\n",
    "**Data Requirements:**\n",
    "- Variants must have matching genomic annotations (handled automatically)\n",
    "- Format: chromosome 2 variants recommended (model was trained on chr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d2e3f4-a5b6-7890-1234-567890abcdef",
   "metadata": {},
   "source": [
    "## Step 1: Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e2f3g4-h5i6-7890-1234-567890abcdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pickle\n",
    "import yaml\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure paths - update for your setup\n",
    "MODEL_PATH = \"../../data/Mic_mega_eQTL/model_results/model_standard_subset_weighted_chr_chr2_NPR_10.joblib\"\n",
    "CONFIG_PATH = \"data_config.yaml\"\n",
    "\n",
    "# Load trained model\n",
    "print(\"Loading trained CatBoost model...\")\n",
    "trained_model = joblib.load(MODEL_PATH)\n",
    "print(f\"✅ Model loaded: {trained_model.__class__.__name__}\")\n",
    "print(f\"Features required: {trained_model.feature_count_}\")\n",
    "print(f\"Training performance: AUC=89.78%, AP=50.5%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2g3h4-i5j6-7890-1234-567890abcdef",
   "metadata": {},
   "source": [
    "### Model Overview\n",
    "\n",
    "**What the model predicts:**\n",
    "- **Score range**: 0.0 - 1.0 (probability variant is functional)\n",
    "- **Functional variant**: Affects gene expression (score > 0.5 typically)\n",
    "- **Non-functional variant**: No detectable expression effect (score < 0.5)\n",
    "\n",
    "**Key technical details:**\n",
    "- **Algorithm**: Feature-weighted CatBoost classifier\n",
    "- **Training data**: 3,056 variants (chr2), 4,839 genomic features\n",
    "- **Top predictor**: Distance to transcription start site\n",
    "- **Cell-type**: Optimized for microglia regulatory effects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1g2h3i4-j5k6-7890-1234-567890abcdef",
   "metadata": {},
   "source": [
    "## Step 2: Load Your Variant List\n",
    "\n",
    "**Expected format:**\n",
    "```\n",
    "variant_id\n",
    "2:12345:A:T\n",
    "2:67890:G:C\n",
    "2:11111:T:A\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g1h2i3j4-k5l6-7890-1234-567890abcdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Use toy example (for testing)\n",
    "toy_variants = pd.DataFrame({\n",
    "    'variant_id': [\n",
    "        '2:12345:A:T',\n",
    "        '2:67890:G:C', \n",
    "        '2:11111:T:A',\n",
    "        '2:22222:C:G',\n",
    "        '2:33333:A:G'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Toy example variants:\")\n",
    "print(toy_variants)\n",
    "\n",
    "# Use toy variants for demonstration\n",
    "user_variants = toy_variants.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h1i2j3k4-l5m6-7890-1234-567890abcdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Load your own variant file (uncomment to use)\n",
    "# YOUR_VARIANT_FILE = \"path/to/your/variants.tsv\"\n",
    "# user_variants = pd.read_csv(YOUR_VARIANT_FILE, sep='\\t')\n",
    "# print(f\"Loaded {len(user_variants)} variants from file\")\n",
    "# print(user_variants.head())\n",
    "\n",
    "print(f\"\\nPreparing to score {len(user_variants)} variants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i1j2k3l4-m5n6-7890-1234-567890abcdef",
   "metadata": {},
   "source": [
    "## Step 3: Feature Preparation\n",
    "\n",
    "The model requires specific genomic features. This step creates the feature matrix matching the training data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j1k2l3m4-n5o6-7890-1234-567890abcdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_variant_features(df):\n",
    "    \"\"\"Create basic variant features from variant_id\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Parse variant_id: chr:pos:ref:alt\n",
    "    df[['chr','pos','ref','alt']] = df['variant_id'].str.split(':', expand=True)\n",
    "    \n",
    "    # Calculate variant type features\n",
    "    df['length_diff'] = df['ref'].str.len() - df['alt'].str.len()\n",
    "    df['is_SNP'] = (df['length_diff'] == 0).astype(int)\n",
    "    df['is_indel'] = (df['length_diff'] != 0).astype(int)\n",
    "    df['is_insertion'] = (df['length_diff'] > 0).astype(int)\n",
    "    df['is_deletion'] = (df['length_diff'] < 0).astype(int)\n",
    "    \n",
    "    # Add placeholder genomic annotations (use training medians)\n",
    "    df['gene_lof'] = -10.0  # Gene constraint score\n",
    "    df['gnomad_MAF'] = 0.1  # Population allele frequency\n",
    "    \n",
    "    # Clean up\n",
    "    df = df.drop(columns=['chr','pos','ref','alt'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create features\n",
    "processed_variants = create_variant_features(user_variants)\n",
    "print(\"✅ Basic variant features created\")\n",
    "print(f\"Features added: {list(processed_variants.columns[1:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k1l2m3n4-o5p6-7890-1234-567890abcdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_prediction_matrix(df, model):\n",
    "    \"\"\"Prepare full feature matrix for model prediction\"\"\"\n",
    "    \n",
    "    # Get required features from trained model\n",
    "    required_features = model.feature_names_\n",
    "    \n",
    "    # Create prediction dataframe with all required features\n",
    "    prediction_df = df.copy()\n",
    "    \n",
    "    # Add missing features with training-informed defaults\n",
    "    for feature in required_features:\n",
    "        if feature not in prediction_df.columns:\n",
    "            if 'distance' in feature.lower() and 'log' in feature.lower():\n",
    "                prediction_df[feature] = 8.5  # Median log distance from training\n",
    "            elif 'abc_score' in feature.lower():\n",
    "                prediction_df[feature] = 0.05  # Median ABC score\n",
    "            elif 'diff' in feature.lower():\n",
    "                prediction_df[feature] = 0.0  # Differential signals\n",
    "            else:\n",
    "                prediction_df[feature] = 0.0  # Default for other features\n",
    "    \n",
    "    # Select and order features to match training\n",
    "    X = prediction_df[required_features]\n",
    "    \n",
    "    # Handle missing/invalid values\n",
    "    X = X.replace([np.inf, -np.inf], 0)\n",
    "    X = X.fillna(0)\n",
    "    \n",
    "    print(f\"✅ Prediction matrix prepared: {X.shape}\")\n",
    "    print(f\"Note: {len(required_features) - len(df.columns) + 1} features imputed with training defaults\")\n",
    "    \n",
    "    return X\n",
    "\n",
    "# Prepare prediction matrix\n",
    "X_prediction = prepare_prediction_matrix(processed_variants, trained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l1m2n3o4-p5q6-7890-1234-567890abcdef",
   "metadata": {},
   "source": [
    "## Step 4: Generate EMS Scores\n",
    "\n",
    "Apply the trained model to generate functional scores for your variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m1n2o3p4-q5r6-7890-1234-567890abcdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "print(\"Generating EMS scores...\")\n",
    "\n",
    "# Get probability scores (0-1) and binary predictions\n",
    "ems_scores = trained_model.predict_proba(X_prediction)[:, 1]\n",
    "binary_predictions = trained_model.predict(X_prediction)\n",
    "\n",
    "# Add results to original dataframe\n",
    "results_df = user_variants.copy()\n",
    "results_df['ems_score'] = ems_scores.round(4)\n",
    "results_df['predicted_functional'] = binary_predictions\n",
    "\n",
    "# Add confidence categories\n",
    "results_df['confidence'] = pd.cut(ems_scores, \n",
    "                                 bins=[0, 0.3, 0.7, 1.0], \n",
    "                                 labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "print(f\"✅ EMS scores generated for {len(results_df)} variants\")\n",
    "print(\"\\nResults preview:\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n1o2p3q4-r5s6-7890-1234-567890abcdef",
   "metadata": {},
   "source": [
    "## Step 5: Interpret Results\n",
    "\n",
    "### Score Interpretation Guide\n",
    "- **High (>0.7)**: Strong evidence for regulatory function\n",
    "- **Medium (0.3-0.7)**: Uncertain, may require additional evidence  \n",
    "- **Low (<0.3)**: Limited evidence for functional impact\n",
    "\n",
    "### Recommended Actions\n",
    "- **High-scoring variants**: Priority for experimental validation\n",
    "- **Medium-scoring variants**: Consider additional computational analysis\n",
    "- **Low-scoring variants**: Likely neutral, lower priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o1p2q3r4-s5t6-7890-1234-567890abcdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"📊 PREDICTION SUMMARY\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Total variants: {len(results_df)}\")\n",
    "print(f\"Predicted functional: {sum(results_df['predicted_functional'])}\")\n",
    "print(f\"Average EMS score: {results_df['ems_score'].mean():.3f}\")\n",
    "print(f\"Score range: {results_df['ems_score'].min():.3f} - {results_df['ems_score'].max():.3f}\")\n",
    "\n",
    "print(\"\\nConfidence distribution:\")\n",
    "print(results_df['confidence'].value_counts())\n",
    "\n",
    "# Highlight top variants\n",
    "if results_df['ems_score'].max() > 0.5:\n",
    "    top_variants = results_df.nlargest(3, 'ems_score')[['variant_id', 'ems_score']]\n",
    "    print(\"\\n🎯 Top-scoring variants:\")\n",
    "    for _, row in top_variants.iterrows():\n",
    "        print(f\"   {row['variant_id']}: {row['ems_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p1q2r3s4-t5u6-7890-1234-567890abcdef",
   "metadata": {},
   "source": [
    "## Step 6: Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q1r2s3t4-u5v6-7890-1234-567890abcdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "output_file = \"ems_predictions.tsv\"\n",
    "results_df.to_csv(output_file, sep='\\t', index=False)\n",
    "\n",
    "print(f\"✅ Results saved to: {output_file}\")\n",
    "print(f\"\\nOutput columns:\")\n",
    "for col in results_df.columns:\n",
    "    print(f\"   - {col}\")\n",
    "\n",
    "# Optional: Filter high-confidence predictions\n",
    "high_confidence = results_df[results_df['ems_score'] > 0.7]\n",
    "if len(high_confidence) > 0:\n",
    "    high_conf_file = \"high_confidence_variants.tsv\"\n",
    "    high_confidence.to_csv(high_conf_file, sep='\\t', index=False)\n",
    "    print(f\"📈 High-confidence variants saved to: {high_conf_file}\")\n",
    "    print(f\"   ({len(high_confidence)} variants with score > 0.7)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r1s2t3u4-v5w6-7890-1234-567890abcdef",
   "metadata": {},
   "source": [
    "## Usage Notes\n",
    "\n",
    "### For Your Own Data\n",
    "1. **Replace toy variants** with your variant list (TSV/CSV format)\n",
    "2. **Ensure variant_id format**: \"chr:pos:ref:alt\" (e.g., \"2:12345:A:T\")\n",
    "3. **Chromosome compatibility**: Model trained on chr2, works best with chr2 variants\n",
    "4. **Feature imputation**: Missing genomic annotations filled with training defaults\n",
    "\n",
    "### Model Limitations\n",
    "- **Training scope**: Optimized for microglia cell type in brain tissue\n",
    "- **Chromosome bias**: Best performance on chromosome 2 variants\n",
    "- **Feature dependency**: Some genomic annotations approximated when unavailable\n",
    "- **Population**: Training data based on specific demographic groups\n",
    "\n",
    "### Validation Recommendations\n",
    "- **High-scoring variants**: Prioritize for experimental validation\n",
    "- **Cross-reference**: Compare with other variant annotation tools\n",
    "- **Literature check**: Review existing functional studies\n",
    "- **Clinical correlation**: Assess disease association when applicable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
