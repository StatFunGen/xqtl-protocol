{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-e5f6-7890-1234-567890abcdef",
   "metadata": {},
   "source": [
    "# EMS Prediction\n",
    "\n",
    "**Apply the trained sc-EMS model to score YOUR genetic variants for functional impact.** This notebook demonstrates prediction workflows using the model trained in the [EMS Training Tutorial](https://statfungen.github.io/xqtl-protocol/code/xqtl_modifier_score/ems_training.html).\n",
    "\n",
    "## What This Does\n",
    "- **Input**: Your variant list in VCF-style format (`chr:pos:ref:alt`)\n",
    "- **Output**: Variants annotated with EMS functional probability scores (continuous range: 0-1)\n",
    "  - **Score >0.8**: High functional probability - prioritize for experimental validation (CRISPR screens, luciferase assays)\n",
    "  - **Score 0.5-0.8**: Moderate functional probability - context-dependent prioritization recommended\n",
    "  - **Score <0.5**: Low functional probability\n",
    "- **Purpose**: Prioritize variants likely to affect gene expression using the trained feature-weighted CatBoost model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2d3e4-f5a6-7890-1234-567890abcdef",
   "metadata": {},
   "source": [
    "## Pipeline Execution Workflow\n",
    "\n",
    "### Step 1: Input Data Preparation\n",
    "\n",
    "Create a tab-separated file with variant identifiers:\n",
    "```\n",
    "variant_id\n",
    "2:12345:A:T\n",
    "2:67890:G:C\n",
    "2:11111:T:A\n",
    "```\n",
    "\n",
    "**Format requirements:**\n",
    "- Chromosome notation: Numeric (e.g., `2`) or with prefix (e.g., `chr2`)\n",
    "- Position: 1-based genomic coordinate (GRCh38/hg38 reference)\n",
    "- Alleles: Reference and alternate alleles (ACGT notation)\n",
    "\n",
    "### Step 2: Execute Prediction Pipeline\n",
    "\n",
    "```bash\n",
    "cd ~/xqtl-protocol/code/xqtl_modifier_score/\n",
    "python model_training_model5_only.py Mic_mega_eQTL 2 \\\n",
    "  --data_config data_config.yaml \\\n",
    "  --model_config model_config.yaml\n",
    "```\n",
    "\n",
    "**What happens during execution:**\n",
    "1. Variant parsing and coordinate validation\n",
    "2. Feature annotation (distance, regulatory, population genetics, conservation, deep learning predictions)\n",
    "3. Gene constraint and MAF integration with imputation using training statistics\n",
    "4. Feature subsetting and absolute value transformations\n",
    "5. Model inference with 10x weighting for regulatory features\n",
    "6. Probability calibration and output generation\n",
    "\n",
    "### Step 3: Output Files Generated\n",
    "\n",
    "| File | Description | Use Case |\n",
    "|------|-------------|----------|\n",
    "| `model_standard_subset_weighted_chr_chr2_NPR_10.joblib` | Serialized CatBoost model | Future predictions, model inspection |\n",
    "| `predictions_weighted_model_chr2.tsv` | Per-variant predictions with scores | Primary analysis, variant prioritization |\n",
    "| `summary_dict_catboost_weighted_model_chr_chr2_NPR_10.pkl` | AP/AUC metrics, class distributions | Model validation, quality control |\n",
    "| `features_importance_model5_chr_chr2_NPR_10.csv` | Feature importance rankings | Biological interpretation |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d2e3f4-f5a6-7890-1234-567890abcdef",
   "metadata": {},
   "source": [
    "## Load and Inspect Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2g3h4-i5j6-7890-1234-567890abcdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load trained CatBoost model\n",
    "MODEL_PATH = \"../../data/Mic_mega_eQTL/model_results/model_standard_subset_weighted_chr_chr2_NPR_10.joblib\"\n",
    "model = joblib.load(MODEL_PATH)\n",
    "\n",
    "print(\"Model Configuration:\")\n",
    "print(f\"  Algorithm: {model.__class__.__name__}\")\n",
    "print(f\"  Features: {model.feature_count_}\")\n",
    "print(f\"  Classes: {list(model.classes_)}\")\n",
    "print(f\"  Tree depth: {model.get_params()['depth']}\")\n",
    "print(f\"  Iterations: {model.tree_count_}\")\n",
    "\n",
    "# Load prediction results\n",
    "RESULTS_PATH = \"../../data/Mic_mega_eQTL/model_results/predictions_parquet_catboost/predictions_weighted_model_chr2.tsv\"\n",
    "results = pd.read_csv(RESULTS_PATH, sep='\\t')\n",
    "\n",
    "print(f\"\\n‚úÖ Loaded predictions for {len(results)} variants\")\n",
    "print(f\"\\nAvailable columns:\")\n",
    "print(f\"  - variant_id: Genomic coordinates\")\n",
    "print(f\"  - standard_subset_weighted_pred_prob: EMS functional score (0-1)\")\n",
    "print(f\"  - standard_subset_weighted_pred_label: Binary classification (0/1)\")\n",
    "print(f\"  - actual_label: True label from test set (if available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e2f3g4-f5a6-7890-1234-567890abcdef",
   "metadata": {},
   "source": [
    "## Statistical Summary of Predictions\n",
    "\n",
    "The `standard_subset_weighted_pred_prob` column contains continuous EMS scores representing the probability that each variant has functional regulatory impact on gene expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1g2h3i4-j5k6-7890-1234-567890abcdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_col = 'standard_subset_weighted_pred_prob'\n",
    "\n",
    "# Quantitative distribution analysis\n",
    "print(\"üìä SCORE DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total variants analyzed: {len(results)}\")\n",
    "print(f\"\\nPriority Classification:\")\n",
    "high = len(results[results[score_col] > 0.8])\n",
    "medium = len(results[(results[score_col] > 0.5) & (results[score_col] <= 0.8)])\n",
    "low = len(results[results[score_col] <= 0.5])\n",
    "print(f\"  High priority (>0.8):     {high:5d} ({high/len(results)*100:5.1f}%)\")\n",
    "print(f\"  Medium priority (0.5-0.8): {medium:5d} ({medium/len(results)*100:5.1f}%)\")\n",
    "print(f\"  Low priority (<0.5):      {low:5d} ({low/len(results)*100:5.1f}%)\")\n",
    "\n",
    "# Descriptive statistics\n",
    "print(f\"\\nScore Statistics:\")\n",
    "print(f\"  Mean:   {results[score_col].mean():.4f}\")\n",
    "print(f\"  Median: {results[score_col].median():.4f}\")\n",
    "print(f\"  Std:    {results[score_col].std():.4f}\")\n",
    "print(f\"  Min:    {results[score_col].min():.4f}\")\n",
    "print(f\"  Max:    {results[score_col].max():.4f}\")\n",
    "\n",
    "# Percentile distribution\n",
    "print(f\"\\nPercentile Distribution:\")\n",
    "for p in [90, 95, 99]:\n",
    "    val = np.percentile(results[score_col], p)\n",
    "    count = len(results[results[score_col] >= val])\n",
    "    print(f\"  {p}th percentile: {val:.4f} ({count} variants)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g1h2i3j4-k5l6-7890-1234-567890abcdef",
   "metadata": {},
   "source": [
    "## Variant Prioritization and Export\n",
    "\n",
    "Extract and rank high-confidence functional predictions for downstream experimental validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h1i2j3k4-l5m6-7890-1234-567890abcdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and sort high-priority variants\n",
    "high_priority = results[results[score_col] > 0.8].sort_values(score_col, ascending=False)\n",
    "\n",
    "print(f\"üèÜ HIGH-PRIORITY VARIANTS (Score >0.8)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total: {len(high_priority)} variants\")\n",
    "\n",
    "if len(high_priority) > 0:\n",
    "    print(f\"\\nTop 10 by EMS score:\")\n",
    "    display_cols = ['variant_id', score_col]\n",
    "    if 'actual_label' in results.columns:\n",
    "        display_cols.append('actual_label')\n",
    "    print(high_priority[display_cols].head(10).to_string(index=False))\n",
    "    \n",
    "    # Export for experimental design\n",
    "    output_file = \"high_priority_variants_validation.tsv\"\n",
    "    high_priority.to_csv(output_file, sep='\\t', index=False)\n",
    "    print(f\"\\nüìÅ Exported to: {output_file}\")\n",
    "    print(f\"   Contains all {len(high_priority)} high-priority variants\")\n",
    "    print(f\"   Ready for: CRISPR screens, luciferase assays, functional validation\")\n",
    "else:\n",
    "    print(\"\\n‚ÑπÔ∏è  No variants exceed 0.8 threshold\")\n",
    "    print(\"   Recommended actions:\")\n",
    "    print(\"   1. Review medium-priority variants (0.5-0.8)\")\n",
    "    print(\"   2. Consider lowering threshold based on experimental capacity\")\n",
    "    print(f\"   3. Top variant score: {results[score_col].max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i1j2k3l4-m5n6-7890-1234-567890abcdef",
   "metadata": {},
   "source": [
    "## Verify Model Performance\n",
    "\n",
    "Review metrics from the held-out test set to understand model reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j1k2l3m4-n5o6-7890-1234-567890abcdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display performance metrics\n",
    "SUMMARY_PATH = \"../../data/Mic_mega_eQTL/model_results/summary_dict_catboost_weighted_model_chr_chr2_NPR_10.pkl\"\n",
    "with open(SUMMARY_PATH, 'rb') as f:\n",
    "    summary = pickle.load(f)\n",
    "\n",
    "print(\"üìà MODEL PERFORMANCE ON TEST SET\")\n",
    "print(\"=\" * 50)\n",
    "metrics = summary['CatBoost']['standard_subset_weighted']\n",
    "print(f\"Average Precision (AP): {metrics['AP_test']:.4f}\")\n",
    "print(f\"AUC-ROC:                {metrics['AUC_test']:.4f}\")\n",
    "\n",
    "print(f\"\\nTest Set Composition:\")\n",
    "print(f\"  Positive labels (functional eQTLs): {summary['CatBoost']['test_num_positive_labels']}\")\n",
    "print(f\"  Negative labels (non-functional):   {summary['CatBoost']['test_num_negative_labels']}\")\n",
    "pos_rate = summary['CatBoost']['test_num_positive_labels'] / (summary['CatBoost']['test_num_positive_labels'] + summary['CatBoost']['test_num_negative_labels'])\n",
    "print(f\"  Positive rate:                       {pos_rate:.1%}\")\n",
    "\n",
    "print(\"\\n‚úÖ These metrics reflect performance on 761 held-out chromosome 2 variants\")\n",
    "print(\"   with stricter selection criteria (PIP >0.9 for positives) than training data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k1l2m3n4-m5n6-7890-1234-567890abcdef",
   "metadata": {},
   "source": [
    "## Application to New Variant Lists\n",
    "\n",
    "### Workflow for Novel Variants\n",
    "\n",
    "To score additional variants not included in the original training/test sets:\n",
    "\n",
    "**1. Prepare input file** matching the format above (`chr:pos:ref:alt`)\n",
    "\n",
    "**2. Update configuration** (`data_config.yaml`):\n",
    "- Point `training_data.base_dir` to directory containing your variant annotations\n",
    "- Ensure gene constraint file (GeneBayes scores) is accessible\n",
    "- Verify MAF file matches your chromosome\n",
    "\n",
    "**3. Execute pipeline** (same command, different input data):\n",
    "```bash\n",
    "python model_training_model5_only.py [cohort] [chromosome] \\\n",
    "  --data_config data_config.yaml \\\n",
    "  --model_config model_config.yaml\n",
    "```\n",
    "\n",
    "The pipeline will:\n",
    "- Generate all 4,839 genomic features for your variants\n",
    "- Apply the same preprocessing (subsetting, absolute values, imputation)\n",
    "- Use the trained model for inference\n",
    "- Output predictions in identical format\n",
    "\n",
    "**4. Analyze results** using the code blocks above\n",
    "\n",
    "### Expected Performance by Context\n",
    "\n",
    "| Variant Context | Expected Performance | Considerations |\n",
    "|-----------------|---------------------|----------------|\n",
    "| **Chromosome 2 variants** | Optimal (AUC ~0.90) | Direct match to training chromosome |\n",
    "| **Other autosomes** | Good (AUC 0.85-0.90) | Strong cross-chromosome generalization |\n",
    "| **Cross-ancestry** | Moderate | Population-specific LD patterns may differ |\n",
    "| **Non-brain cell types** | Variable | Microglia-specific regulatory features weighted 10x |\n",
    "| **Rare variants (MAF <0.01)** | Reduced | Training enriched for common variants (median imputation) |\n",
    "\n",
    "**Recommendations:**\n",
    "- Cross-reference high-priority predictions with orthogonal evidence (ATAC-seq, Hi-C, eQTL databases)\n",
    "- For non-microglia applications, consider retraining with cell-type appropriate regulatory annotations\n",
    "- Validate performance by comparing predictions to known functional variants in your system"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
