{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a760a51-c99d-481e-9e86-5c0072ef15bb",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## continuumio/miniconda3\n",
    "\n",
    "\n",
    "The continuumio/miniconda3 in the Dockerfile is the base Docker image that's being used to build the custom Docker image. It's the starting point for the Docker image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518dc78f-a7cc-4360-834b-292ee40b13e7",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## WORKDIR /app\n",
    "\n",
    "In a Dockerfile, the WORKDIR instruction is used to change the working directory of a Docker container for any following operations in the Dockerfile (RUN, CMD, ENTRYPOINT, COPY and ADD instructions). If the WORKDIR doesn’t exist, it will be created even if it’s not used in any subsequent Dockerfile instruction.\n",
    "\n",
    "So, WORKDIR /app means that the Docker container changes its working directory (the directory you're in when you start a command line session, or in this case, where Docker will execute subsequent commands) to /app. This /app directory is inside the Docker container, not on your host machine.\n",
    "\n",
    "If, for example, you have the following command later in your Dockerfile: COPY . ., this would copy files from your Docker context (the directory and its subdirectories on your machine where the Dockerfile is located) into the /app directory in the Docker container, because you've set that as the working directory.\n",
    "\n",
    "It's a good practice to set WORKDIR to a dedicated location in your Docker container for your application to keep your environment tidy and predictable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67dd5d0-dcf7-471f-850a-9e0a2448f4e4",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run xqtl-pipeline/code/misc/docker_build-Copy1.ipynb dcontainer_generator\\\n",
    "    --container_list xqtl-pipeline/code/misc/xQTL_conda_packages1.csv \\\n",
    "    --env bioinfo fastenloc leafcutter METAL methylation polyfun psichomics rna_quantification stephenslab TensorQTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf211b0-b7db-4cfa-8989-92e7cc86773f",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "parameter: container_list = path\n",
    "parameter: env = list\n",
    "parameter: output = env \n",
    "parameter: cwd=path(\"output6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea438a5-6ebf-4082-b57a-4b72684a92aa",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[dcontainer_generator_1]\n",
    "input: container_list, for_each=\"env\"\n",
    "output: f'{cwd}/{_env}/Dockerfile.{_env}'\n",
    "python: expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "    import csv\n",
    "    from collections import defaultdict\n",
    "\n",
    "    def write_dockerfile(env, packages):\n",
    "        header = \"\"\"\\\n",
    "    # Use miniconda as base image\n",
    "    FROM continuumio/miniconda3\n",
    "\n",
    "    # Set the working directory\n",
    "    WORKDIR /app\n",
    "\n",
    "    # Updating conda\n",
    "    RUN conda update -n base -c defaults conda\n",
    "    \"\"\"\n",
    "        with open(f'$[_output]', 'w') as f:\n",
    "            content = header + \"\\n\" + \"\\n\".join(packages)\n",
    "            f.write(content)\n",
    "\n",
    "    # Use defaultdict to automatically create a new list when a new key is encountered\n",
    "    packages_by_env = defaultdict(list)\n",
    "    packages_names_by_env = defaultdict(set)\n",
    "    universial_packages = []\n",
    "\n",
    "    with open('$[_input]', 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            if not row['Conda package']: \n",
    "                # Skip the current row if the 'Conda Package' field is empty\n",
    "                continue\n",
    "            # Parse environments (assuming they are comma-separated)\n",
    "            environments = row['Environment'].split(',')\n",
    "            for env in environments:\n",
    "                # Strip spaces and lower-case the environment name for comparison\n",
    "                env = env.strip().lower()\n",
    "                install_cmd = f\"RUN conda install -c {row['Channel']} {row['Conda package'].split('/')[-1]}{'=' if len(row['Version']) != 0 or len(row['CondaVersion']) != 0 else f''}{row['CondaVersion'] if len(row['CondaVersion']) != 0 else row['Version']} -y\"\n",
    "\n",
    "                # If the package is universial, add it to the universial_packages list\n",
    "                if env == 'universial':\n",
    "                    universial_packages.append(install_cmd)\n",
    "                else:\n",
    "                    # Add the installation command to the corresponding environment\n",
    "                    packages_by_env[env].append(install_cmd)\n",
    "                    packages_names_by_env[env].add(row['Conda package'].split('/')[-1])\n",
    "\n",
    "    # Write a Dockerfile for the environment only, including universal packages\n",
    "    env = '$[_env]'.lower()\n",
    "    packages = packages_by_env[env]\n",
    "\n",
    "    # Filter out universal packages that have been specifically requested by this environment\n",
    "    filtered_universial_packages = [cmd for cmd in universial_packages if cmd.split()[5].split('=')[0] not in packages_names_by_env[env]]\n",
    "\n",
    "    # Include universal packages in the environment\n",
    "    all_packages = filtered_universial_packages + packages\n",
    "\n",
    "    write_dockerfile(env, all_packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124cf03e-b0dd-40b9-909d-b72c7f28c16b",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[dcontainer_generator_2]\n",
    "output: f'{_input}.tar'\n",
    "bash: expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "    cd $[_input:d]\n",
    "    export DOCKER_BUILDKIT=1 #need docker vesion greater than 18.09 to change default value from 0 to 1 if it's greater than 23.0 then the default value is 1 already\n",
    "    docker build -t my-conda-env-[env] -f $[_input] .\n",
    "    docker save my-conda-env-[env] > $[_output:b].tar\n",
    "    # to use the container you can 'docker load' the tar file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.24.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
