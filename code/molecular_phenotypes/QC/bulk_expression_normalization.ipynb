{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stock-bulletin",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Bulk RNA-seq counts normalization\n",
    "\n",
    "Quantile normalization of TPM counts, and TMM normalization of read counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-chemical",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Overview\n",
    "\n",
    "Currently, we have implemented two pipelines for RNA-seq data normalization along the lines of the GTEx V8 workflow:\n",
    "\n",
    "\n",
    "A. Read counts -> TPM (within sample normalization) -> TPM level QC -> Quantile normalization (between sample normalization) -> inverse normal transformation\n",
    "B. Read counts -> TMM (via edgeR, between sample normalization) -> inverse normal transformation\n",
    "\n",
    "The GTEx protocol, described [here](https://gtexportal.org/home/documentationPage#staticTextAnalysisMethods), suggests that:\n",
    "\n",
    "1. Genes were selected based on expression thresholds of >0.1 TPM in at least 20% of samples and â‰¥6 reads in at least 20% of samples.\n",
    "2. Expression values were normalized between samples using TMM as implemented in edgeR (Robinson & Oshlack, Genome Biology, 2010 ).\n",
    "3. For each gene, expression values were normalized across samples using an inverse normal transform.\n",
    "\n",
    "In other words, GTEx implemented normalization on the count data using TMM (Pipeline B outlined above) although the TPM QC results were used to select samples and genes. \n",
    "\n",
    "## Caveats\n",
    "\n",
    "A couple of possible improvement over the existing pipeline:\n",
    "\n",
    "1. Should we try [GeTMM](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2246-7) instead? That seems to make more sense and is very easy to implement (add one line to TMM code, as shown in [this post](https://www.reneshbedre.com/blog/expression_units.html)).\n",
    "2. What if we have different batches of data and we know the batches explicitly so we can control for batch effect? What we can do are:\n",
    "    a. Read counts -> Combat-Seq -> inverse normal transformation\n",
    "    b. Do what we already have -> Add a batch adjustment using Combat on normalized data\n",
    "    \n",
    "**Currently we do not implement either of these improvements -- until future needs or discussions emerge.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-benefit",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Input\n",
    "\n",
    "1. TPM matrix and read count matrix in RNA-SeQC format\n",
    "    - the first two rows should be commented text with `#` prefix.\n",
    "    - the matrix should be tab delimited.\n",
    "    - the matrix files should end with `gct` suffix\n",
    "    - These requirements are satisfied if the inputs are outputs from [`bulk_expression_QC` pipeline](bulk_expression_QC.html).\n",
    "2. GTF for collapsed gene model\n",
    "    - the gene names must be consistent with the GCT matrices (eg ENSG00000000003 vs. ENSG00000000003.1 will not work) \n",
    "    - chromosome names must be consistent with the GCT matrices (eg chr1 vs 1 will not work)\n",
    "3. Meta-data to match between sample names in expression data and genotype files\n",
    "    - Required input\n",
    "    - Tab delimited with header\n",
    "    - Only 2 columns: first column is sample name in expression data, 2nd column is sample name in genotype data\n",
    "    - **must contains all the sample name in expression matrices even if they don't existing in genotype data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-league",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Output\n",
    "\n",
    "Normalized expression file in `bed` format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-width",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Minimal Working Example\n",
    "\n",
    "Expression matrices can be generated by the MWE of `bulk_expression_QC.ipynb`. A full set of MWE can be found [on Google Drive](https://drive.google.com/drive/u/0/folders/1Rv2bWHBbX_tastTh49ToYVDMV6rFP5Wk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-emerald",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run normalization.ipynb Normalization \\\n",
    "--tpm-gct \"mwe.low_expression_filtered.outlier_removed.processed.tpm.gct\"      \\\n",
    "--counts-gct \"mwe.low_expression_filtered.outlier_removed.processed.geneCount.gct\"      \\\n",
    "--sample_participant_lookup \"sampleSheetAfterQc.txt\" \\\n",
    "--container ./rna_quantification.sif --wd ./      \\\n",
    "--annotation_gtf Homo_sapiens.GRCh38.103.chr.reformated.ERCC.gene.gtf  &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "infrared-contributor",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Work directory & output directory\n",
    "parameter: cwd = path\n",
    "#  gene count table\n",
    "parameter: counts_gct = path\n",
    "#  gene TPM table\n",
    "parameter: tpm_gct = path\n",
    "#  gene gtf annotation table\n",
    "parameter: annotation_gtf = path\n",
    "# A file to map sample ID from expression to genotype,must contain two columns, sample_id and participant_id, mapping IDs in the expression files to IDs in the genotype (these can be the same).\n",
    "parameter: sample_participant_lookup = path\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"5h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 20\n",
    "parameter: container = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-canon",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[Normalization]\n",
    "# Path to the input molecular phenotype data, should be a processd and indexed bed.gz file, with tabix index.\n",
    "input: tpm_gct, counts_gct, annotation_gtf, sample_participant_lookup\n",
    "output: f'{wd}/{_input[0]:bnn}.bed.gz',  # For factor\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '4h',  mem = '20G', tags = f'{step_name}_{_output[0]:bn}'  \n",
    "bash: expand = \"${ }\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',container = container\n",
    "    eqtl_prepare_expression.py ${tpm_gct} ${counts_gct} ${_input[2]} \\\n",
    "    ${sample_participant_lookup} ${sample_participant_lookup if sample_participant_lookup else \"\"} ${_output[0]:bnnn} \\\n",
    "    --tpm_threshold 0.1 \\\n",
    "    --count_threshold 1 \\\n",
    "    --sample_frac_threshold 0.2 \\\n",
    "    --normalization_method tmm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
