{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27a44eb1-acb9-40f5-bcdb-7ede63d5db5e",
   "metadata": {},
   "source": [
    "# Kellis Lab Single-nuclei ATAC-seq Preprocessing Pipeline\n",
    "\n",
    "---\n",
    "\n",
    "### Overview\n",
    "\n",
    "This pipeline preprocesses single-nucleus ATAC-seq (snATAC-seq) data from the Kellis lab for downstream chromatin accessibility QTL (caQTL) analysis and region-specific studies. It processes pseudobulk peak count data across six major brain cell types with flexible workflow options depending on your analysis goals.\n",
    "\n",
    "**Pipeline Purpose:**\n",
    "- Transform raw pseudobulk peak counts into analysis-ready formats\n",
    "- Remove technical confounders and optionally biological covariates\n",
    "- Generate QTL-ready phenotype files or region-specific datasets\n",
    "\n",
    "**Supported Cell Types:**\n",
    "- **Mic** - Microglia\n",
    "- **Astro** - Astrocytes\n",
    "- **Oligo** - Oligodendrocytes\n",
    "- **Exc** - Excitatory neurons\n",
    "- **Inh** - Inhibitory neurons\n",
    "- **OPC** - Oligodendrocyte precursor cells\n",
    "\n",
    "---\n",
    "\n",
    "### Workflow Structure\n",
    "\n",
    "This pipeline consists of two main sequential steps, plus a complete pipeline for severe batch effects.\n",
    "\n",
    "#### Step 1: Pseudobulk QC with batch as covariates\n",
    "\n",
    "**Option A: Remove Biological Covariates**\n",
    "- Regresses out demographic variables (msex, age_death, pmi, study)\n",
    "- **Use when:** You want to identify genetic effects independent of sex/age\n",
    "- **Model includes:** technical covariates + sequencingBatch + msex + age_death + pmi + study\n",
    "\n",
    "**Option B: Preserve Biological Covariates**\n",
    "- Regresses out only non-demographic variables (pmi, study)\n",
    "- **Use when:** You want to study sex/age effects or preserve biological heterogeneity\n",
    "- **Model includes:** technical covariates + sequencingBatch + pmi + study (NO msex, age_death)\n",
    "\n",
    "#### Step 2: Format Output\n",
    "\n",
    "**Format A: Phenotype Reformatting**\n",
    "- Converts residuals to genome-wide BED format\n",
    "- **Input:** `{celltype}_residuals.txt` (from Step 1 Option A or B)\n",
    "- **Use for:** FastQTL, TensorQTL, MatrixEQTL (genome-wide caQTL mapping)\n",
    "\n",
    "**Format B: Region Peak Filtering**\n",
    "- Filters to specific genomic regions (chr7: 28-28.3 Mb, chr11: 85.05-86.2 Mb)\n",
    "- **Input:** `{celltype}_filtered_raw_counts.txt` (only from Step 1 Option B)\n",
    "- **Use for:** Hypothesis-driven locus analysis, region-specific comparisons\n",
    "\n",
    "#### Alternative Pseudobulk Pipeline: Explicit Batch Correction (Multiome Dataset)\n",
    "- Complete standalone pipeline with explicit batch correction using limma's `removeBatchEffect` or ComBat-seq\n",
    "- **Input:** Qc'ed Seurat object`{celltype}_qced.rds` and pseudobulk peak counts `{celltype}.rds`\n",
    "- **Use when:** Strong batch effects visible in PCA/t-SNE, many small fragmented batches, batch confounds with biology\n",
    "- **Note:** From different dataset (multiome) but demonstrates alternative batch correction approach\n",
    "\n",
    "---\n",
    "\n",
    "### Key Features:\n",
    "- Blacklist region filtering (ENCODE hg38)\n",
    "- Technical QC covariate adjustment (TSS enrichment, nucleosome signal, sequencing depth)\n",
    "- TMM normalization and expression filtering\n",
    "- Log-transformation of count-based covariates\n",
    "- Flexible batch handling (covariate vs explicit correction)\n",
    "\n",
    "#### Pipeline Outputs:\n",
    "\n",
    "**From Step 1:**\n",
    "- `{celltype}_residuals.txt`: Covariate-adjusted residuals (log2-CPM scale)\n",
    "- `{celltype}_results.rds`: Complete analysis results\n",
    "- `{celltype}_summary.txt`: QC summary and filtering statistics\n",
    "- `{celltype}_variable_explanation.txt`: Covariate documentation (Option A only)\n",
    "- `{celltype}_filtered_raw_counts.txt`: TMM-normalized counts (Option B only)\n",
    "\n",
    "**From Step 2, Format A:**\n",
    "- `{celltype}_kellis_snatac_phenotype.bed.gz`: Genome-wide QTL-ready BED file\n",
    "\n",
    "**From Step 2, Format B:**\n",
    "- `{celltype}_filtered_regions_of_interest.txt`: Region-specific count data (chr7, chr11)\n",
    "- `{celltype}_filtered_regions_of_interest_summary.txt`: Peak metadata and statistics\n",
    "\n",
    "**From Alternative Pseudobulk Pipeline: Multiome with Batch Correction:**\n",
    "- `{celltype}_residuals.txt`: Batch-corrected residuals (log2-CPM scale)\n",
    "- `{celltype}_results.rds`: Complete results with batch_adjusted_counts\n",
    "\n",
    "---\n",
    "\n",
    "### Input Files\n",
    "Input files needed to run this pipeline can be downloaded [here](https://drive.google.com/drive/folders/1UzJuHN8SotMn-PJTBp9uGShD25YxapKr?usp=drive_link)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5476354a-a9b1-45c4-bd41-010551ca96f1",
   "metadata": {},
   "source": [
    "#### Before you start, let's set up your working path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "955bda26-9f91-41bb-adb7-c09fbf361c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir <- \"/restricted/projectnb/xqtl/jaempawi/atac_seq/kellis_data\"  #set your input directory\n",
    "output_dir <- \"/restricted/projectnb/xqtl/jaempawi/atac_seq/output/kellis\" #set your output directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5540a4da-843a-4789-8123-47911cf519c5",
   "metadata": {},
   "source": [
    "## Step 1: Pseudobulk QC with batch as covariates\n",
    "\n",
    "This preprocessing workflow offers **two approaches** depending on whether you want to regress out biological covariates:\n",
    "\n",
    "---\n",
    "### Option A: Pseudobulk QC WITH Biological Variation(Standard QTL Analysis)\n",
    "\n",
    "Use this option when you want residuals adjusted for all technical AND biological covariates (sex, age, PMI).\n",
    "\n",
    "**Input:**\n",
    "- Pseudobulk peak counts (in 1_files_with_sampleid folder): `pseudobulk_peaks_counts{celltype}_50nuc.csv.gz`\n",
    "- Cell metadata (in 1_files_with_sampleid folder): `metadata_{celltype}_50nuc.csv`\n",
    "- Sample covariates: `rosmap_cov.txt`\n",
    "- hg38 blacklist: `hg38-blacklist.v2.bed.gz`\n",
    "\n",
    "**Process:**\n",
    "1. Loads pseudobulk peak count matrix and metadata per cell type\n",
    "2. Calculates technical QC metrics per sample:\n",
    "   - `log_n_nuclei`: Log-transformed number of nuclei\n",
    "   - `med_nucleosome_signal`: Median nucleosome signal\n",
    "   - `med_tss_enrich`: Median TSS enrichment score\n",
    "   - `log_med_n_tot_fragment`: Log-transformed median total fragments (sequencing depth)\n",
    "   - `log_total_unique_peaks`: Log-transformed count of unique peaks detected\n",
    "3. Filters blacklisted genomic regions using `foverlaps()`\n",
    "4. Merges with demographic covariates (msex, age_death, pmi, study)\n",
    "5. Applies expression filtering with `filterByExpr()`:\n",
    "   - `min.count = 2`: Minimum 2 reads in at least one sample\n",
    "   - `min.total.count = 15`: Minimum 15 total reads across all samples\n",
    "   - `min.prop = 0.1`: Peak must be expressed in ≥10% of samples\n",
    "6. TMM normalization with `calcNormFactors()`\n",
    "7. Handles sequencingBatch as a covariate (not batch-corrected)\n",
    "8. Fits linear model using `voom()` and `lmFit()`:\n",
    "\n",
    "   ```r\n",
    "   model <- ~ log_n_nuclei + med_nucleosome_signal + med_tss_enrich + log_med_n_tot_fragment + log_total_unique_peaks + sequencingBatch_factor + msex + age_death + pmi + study  \n",
    "   ```\n",
    "\n",
    "9. Calculates residuals adjusted for ALL covariates (technical + biological)\n",
    "10. Computes final adjusted data using predictOffset(): offset + residuals\n",
    "- `offset`: Predicted expression at median/reference covariate values\n",
    "- `residuals`: Unexplained variation after removing all covariate effects\n",
    "\n",
    "**Output:** `output/2_residuals/{celltype}/`\n",
    "\n",
    "- `{celltype}_residuals.txt`: Final covariate-adjusted peak accessibility (log2-CPM scale)\n",
    "- `{celltype}_results.rds`: Complete analysis results (DGEList, fit object, design matrix)\n",
    "- `{celltype}_summary.txt`: Filtering statistics and QC summary\n",
    "- `{celltype}_variable_explanation.txt`: Detailed covariate documentation\n",
    "\n",
    "**Key Variables Regressed Out**:\n",
    "\n",
    "- Technical: sequencing depth, nuclei count, nucleosome signal, TSS enrichment, batch\n",
    "- Biological: sex (msex), age at death (age_death), post-mortem interval (pmi), study cohort\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58dfe97-3e57-4ce9-b8bb-009aec26b1a5",
   "metadata": {},
   "source": [
    "#### Load libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77deb405-f916-42e5-a74a-c3569d587cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:data.table’:\n",
      "\n",
      "    between, first, last\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "Loading required package: limma\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(data.table)\n",
    "library(stringr)\n",
    "library(dplyr)\n",
    "library(edgeR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f5d8a77-91c8-4808-94cf-bc576378556c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing celltype: Astro \n"
     ]
    }
   ],
   "source": [
    "# Set cell type and create output directory\n",
    "celltype <- \"Astro\"  # Change this for different cell types eg. Exc, Inh, Mic, Oligo, OPC\n",
    "cat(\"Processing celltype:\", celltype, \"\\n\")\n",
    "\n",
    "out_dir <- paste0(file.path(output_dir,\"2_residuals/\", celltype))\n",
    "dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed15afb-f621-4dd3-be00-c15dd736835b",
   "metadata": {},
   "source": [
    "#### Create predictOffset function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "823abb05-f105-4f40-918a-5c470a04ffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictOffset <- function(fit) {\n",
    "  # Define which variables are factors and which are continuous\n",
    "  usedFactors <- c(\"sequencingBatch\", \"study\") \n",
    "  usedContinuous <- c(\"log_n_nuclei\", \"med_nucleosome_signal\", \"med_tss_enrich\", \"log_med_n_tot_fragment\",\n",
    "                      \"log_total_unique_peaks\", \"msex\", \"age_death\", \"pmi\")\n",
    "  \n",
    "  # Filter to only use variables actually in the design matrix\n",
    "  usedFactors <- usedFactors[sapply(usedFactors, function(f) any(grepl(paste0(\"^\", f), colnames(fit$design))))]\n",
    "  usedContinuous <- usedContinuous[sapply(usedContinuous, function(f) any(grepl(paste0(\"^\", f), colnames(fit$design))))]\n",
    "  \n",
    "  # Get indices for factor and continuous variables\n",
    "  facInd <- unlist(lapply(as.list(usedFactors), \n",
    "                         function(f) {return(grep(paste0(\"^\", f), \n",
    "                                                colnames(fit$design)))}))\n",
    "  contInd <- unlist(lapply(as.list(usedContinuous), \n",
    "                          function(f) {return(grep(paste0(\"^\", f), \n",
    "                                                 colnames(fit$design)))}))\n",
    "  \n",
    "  # Add the intercept\n",
    "  all_indices <- c(1, facInd, contInd)\n",
    "  \n",
    "  # Verify design matrix structure (using sorted indices to avoid duplication warning)\n",
    "  all_indices_sorted <- sort(unique(all_indices))\n",
    "  stopifnot(all(all_indices_sorted %in% 1:ncol(fit$design)))\n",
    "  \n",
    "  # Create new design matrix with median values\n",
    "  D <- fit$design\n",
    "  D[, facInd] <- 0  # Set all factor levels to reference level\n",
    "  \n",
    "  # For continuous variables, set to median value\n",
    "  if (length(contInd) > 0) {\n",
    "    medContVals <- apply(D[, contInd, drop=FALSE], 2, median)\n",
    "    for (i in 1:length(medContVals)) {\n",
    "      D[, names(medContVals)[i]] <- medContVals[i]\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Calculate offsets\n",
    "  stopifnot(all(colnames(coefficients(fit)) == colnames(D)))\n",
    "  offsets <- apply(coefficients(fit), 1, function(c) {\n",
    "    return(D %*% c)\n",
    "  })\n",
    "  offsets <- t(offsets)\n",
    "  colnames(offsets) <- rownames(fit$design)\n",
    "  \n",
    "  return(offsets)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d79ceae-e255-4a39-a288-12626481b0ac",
   "metadata": {},
   "source": [
    "#### Load input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46927164-2761-490f-afc2-86181e917a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded metadata with 82 samples and peak data with 531489 peaks\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 6 × 9</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>individualID</th><th scope=col>sampleid</th><th scope=col>sequencingBatch</th><th scope=col>main_cell_type</th><th scope=col>avg.pct.read.in.peak.ct</th><th scope=col>med.nucleosome_signal.ct</th><th scope=col>med.n_tot_fragment.ct</th><th scope=col>med.tss.enrich.ct</th><th scope=col>n.nuclei</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>R1042011</td><td>SM-CJK5G</td><td>191203Kel</td><td>Astro</td><td>0.3939189</td><td>0.7894187</td><td>10923.00</td><td>0.3762771</td><td>409</td></tr>\n",
       "\t<tr><td>R1154454</td><td>SM-CTDQN</td><td>191203Kel</td><td>Astro</td><td>0.2557693</td><td>0.7786428</td><td>23144.00</td><td>0.2516681</td><td>144</td></tr>\n",
       "\t<tr><td>R1213305</td><td>SM-CJEIE</td><td>191203Kel</td><td>Astro</td><td>0.3277831</td><td>0.8077042</td><td>16094.78</td><td>0.2896403</td><td>630</td></tr>\n",
       "\t<tr><td>R1407047</td><td>SM-CTEM5</td><td>191203Kel</td><td>Astro</td><td>0.3361316</td><td>0.8275109</td><td>59451.00</td><td>0.3266785</td><td>189</td></tr>\n",
       "\t<tr><td>R1609849</td><td>SM-CJJ27</td><td>191203Kel</td><td>Astro</td><td>0.2857020</td><td>0.7868788</td><td> 7522.00</td><td>0.2688059</td><td>186</td></tr>\n",
       "\t<tr><td>R1617674</td><td>SM-CJIWT</td><td>191203Kel</td><td>Astro</td><td>0.1934420</td><td>0.7879911</td><td>33724.00</td><td>0.1702281</td><td>141</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 6 × 9\n",
       "\\begin{tabular}{lllllllll}\n",
       " individualID & sampleid & sequencingBatch & main\\_cell\\_type & avg.pct.read.in.peak.ct & med.nucleosome\\_signal.ct & med.n\\_tot\\_fragment.ct & med.tss.enrich.ct & n.nuclei\\\\\n",
       " <chr> & <chr> & <chr> & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <int>\\\\\n",
       "\\hline\n",
       "\t R1042011 & SM-CJK5G & 191203Kel & Astro & 0.3939189 & 0.7894187 & 10923.00 & 0.3762771 & 409\\\\\n",
       "\t R1154454 & SM-CTDQN & 191203Kel & Astro & 0.2557693 & 0.7786428 & 23144.00 & 0.2516681 & 144\\\\\n",
       "\t R1213305 & SM-CJEIE & 191203Kel & Astro & 0.3277831 & 0.8077042 & 16094.78 & 0.2896403 & 630\\\\\n",
       "\t R1407047 & SM-CTEM5 & 191203Kel & Astro & 0.3361316 & 0.8275109 & 59451.00 & 0.3266785 & 189\\\\\n",
       "\t R1609849 & SM-CJJ27 & 191203Kel & Astro & 0.2857020 & 0.7868788 &  7522.00 & 0.2688059 & 186\\\\\n",
       "\t R1617674 & SM-CJIWT & 191203Kel & Astro & 0.1934420 & 0.7879911 & 33724.00 & 0.1702281 & 141\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 6 × 9\n",
       "\n",
       "| individualID &lt;chr&gt; | sampleid &lt;chr&gt; | sequencingBatch &lt;chr&gt; | main_cell_type &lt;chr&gt; | avg.pct.read.in.peak.ct &lt;dbl&gt; | med.nucleosome_signal.ct &lt;dbl&gt; | med.n_tot_fragment.ct &lt;dbl&gt; | med.tss.enrich.ct &lt;dbl&gt; | n.nuclei &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| R1042011 | SM-CJK5G | 191203Kel | Astro | 0.3939189 | 0.7894187 | 10923.00 | 0.3762771 | 409 |\n",
       "| R1154454 | SM-CTDQN | 191203Kel | Astro | 0.2557693 | 0.7786428 | 23144.00 | 0.2516681 | 144 |\n",
       "| R1213305 | SM-CJEIE | 191203Kel | Astro | 0.3277831 | 0.8077042 | 16094.78 | 0.2896403 | 630 |\n",
       "| R1407047 | SM-CTEM5 | 191203Kel | Astro | 0.3361316 | 0.8275109 | 59451.00 | 0.3266785 | 189 |\n",
       "| R1609849 | SM-CJJ27 | 191203Kel | Astro | 0.2857020 | 0.7868788 |  7522.00 | 0.2688059 | 186 |\n",
       "| R1617674 | SM-CJIWT | 191203Kel | Astro | 0.1934420 | 0.7879911 | 33724.00 | 0.1702281 | 141 |\n",
       "\n"
      ],
      "text/plain": [
       "  individualID sampleid sequencingBatch main_cell_type avg.pct.read.in.peak.ct\n",
       "1 R1042011     SM-CJK5G 191203Kel       Astro          0.3939189              \n",
       "2 R1154454     SM-CTDQN 191203Kel       Astro          0.2557693              \n",
       "3 R1213305     SM-CJEIE 191203Kel       Astro          0.3277831              \n",
       "4 R1407047     SM-CTEM5 191203Kel       Astro          0.3361316              \n",
       "5 R1609849     SM-CJJ27 191203Kel       Astro          0.2857020              \n",
       "6 R1617674     SM-CJIWT 191203Kel       Astro          0.1934420              \n",
       "  med.nucleosome_signal.ct med.n_tot_fragment.ct med.tss.enrich.ct n.nuclei\n",
       "1 0.7894187                10923.00              0.3762771         409     \n",
       "2 0.7786428                23144.00              0.2516681         144     \n",
       "3 0.8077042                16094.78              0.2896403         630     \n",
       "4 0.8275109                59451.00              0.3266785         189     \n",
       "5 0.7868788                 7522.00              0.2688059         186     \n",
       "6 0.7879911                33724.00              0.1702281         141     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 6 × 82</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>SM-CJK5G</th><th scope=col>SM-CTDQN</th><th scope=col>SM-CJEIE</th><th scope=col>SM-CTEM5</th><th scope=col>SM-CJJ27</th><th scope=col>SM-CJIWT</th><th scope=col>SM-CTEEG</th><th scope=col>ROS11430815</th><th scope=col>SM-CJGLG</th><th scope=col>SM-CJIXU</th><th scope=col>⋯</th><th scope=col>R9395022</th><th scope=col>SM-CJIX5</th><th scope=col>SM-CJEGU</th><th scope=col>SM-CJIYH</th><th scope=col>SM-CJGMS</th><th scope=col>SM-CTEGU</th><th scope=col>SM-CTEFJ</th><th scope=col>SM-CJEJU</th><th scope=col>SM-CTEGT</th><th scope=col>SM-CJIZE</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>⋯</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 4</td><td> 0</td><td> 0</td><td> 2</td><td>0</td><td> 0</td><td> 0</td><td> 2</td><td> 2</td><td>0</td><td>⋯</td><td> 1</td><td> 0</td><td>0</td><td> 0</td><td>1</td><td> 0</td><td> 0</td><td> 1</td><td> 0</td><td>0</td></tr>\n",
       "\t<tr><td>20</td><td>12</td><td>45</td><td>36</td><td>1</td><td> 7</td><td> 9</td><td>30</td><td>16</td><td>5</td><td>⋯</td><td>13</td><td> 5</td><td>7</td><td>10</td><td>3</td><td> 6</td><td>11</td><td>10</td><td>18</td><td>5</td></tr>\n",
       "\t<tr><td> 8</td><td> 1</td><td> 3</td><td> 6</td><td>0</td><td> 6</td><td>11</td><td> 1</td><td> 1</td><td>3</td><td>⋯</td><td> 5</td><td> 2</td><td>0</td><td> 1</td><td>3</td><td> 0</td><td> 2</td><td> 3</td><td> 5</td><td>4</td></tr>\n",
       "\t<tr><td> 0</td><td> 0</td><td> 0</td><td> 0</td><td>0</td><td> 0</td><td> 1</td><td> 0</td><td> 0</td><td>0</td><td>⋯</td><td> 0</td><td> 0</td><td>0</td><td> 0</td><td>0</td><td> 0</td><td> 0</td><td> 0</td><td> 0</td><td>0</td></tr>\n",
       "\t<tr><td>15</td><td> 4</td><td>15</td><td> 9</td><td>2</td><td> 3</td><td>16</td><td> 8</td><td> 3</td><td>5</td><td>⋯</td><td> 5</td><td> 6</td><td>5</td><td> 5</td><td>5</td><td> 2</td><td> 6</td><td>12</td><td> 7</td><td>7</td></tr>\n",
       "\t<tr><td>33</td><td> 4</td><td>55</td><td>70</td><td>4</td><td>10</td><td>26</td><td>21</td><td>22</td><td>5</td><td>⋯</td><td>30</td><td>15</td><td>8</td><td>21</td><td>5</td><td>20</td><td>35</td><td>26</td><td>48</td><td>6</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 6 × 82\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       " SM-CJK5G & SM-CTDQN & SM-CJEIE & SM-CTEM5 & SM-CJJ27 & SM-CJIWT & SM-CTEEG & ROS11430815 & SM-CJGLG & SM-CJIXU & ⋯ & R9395022 & SM-CJIX5 & SM-CJEGU & SM-CJIYH & SM-CJGMS & SM-CTEGU & SM-CTEFJ & SM-CJEJU & SM-CTEGT & SM-CJIZE\\\\\n",
       " <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & ⋯ & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int>\\\\\n",
       "\\hline\n",
       "\t  4 &  0 &  0 &  2 & 0 &  0 &  0 &  2 &  2 & 0 & ⋯ &  1 &  0 & 0 &  0 & 1 &  0 &  0 &  1 &  0 & 0\\\\\n",
       "\t 20 & 12 & 45 & 36 & 1 &  7 &  9 & 30 & 16 & 5 & ⋯ & 13 &  5 & 7 & 10 & 3 &  6 & 11 & 10 & 18 & 5\\\\\n",
       "\t  8 &  1 &  3 &  6 & 0 &  6 & 11 &  1 &  1 & 3 & ⋯ &  5 &  2 & 0 &  1 & 3 &  0 &  2 &  3 &  5 & 4\\\\\n",
       "\t  0 &  0 &  0 &  0 & 0 &  0 &  1 &  0 &  0 & 0 & ⋯ &  0 &  0 & 0 &  0 & 0 &  0 &  0 &  0 &  0 & 0\\\\\n",
       "\t 15 &  4 & 15 &  9 & 2 &  3 & 16 &  8 &  3 & 5 & ⋯ &  5 &  6 & 5 &  5 & 5 &  2 &  6 & 12 &  7 & 7\\\\\n",
       "\t 33 &  4 & 55 & 70 & 4 & 10 & 26 & 21 & 22 & 5 & ⋯ & 30 & 15 & 8 & 21 & 5 & 20 & 35 & 26 & 48 & 6\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 6 × 82\n",
       "\n",
       "| SM-CJK5G &lt;int&gt; | SM-CTDQN &lt;int&gt; | SM-CJEIE &lt;int&gt; | SM-CTEM5 &lt;int&gt; | SM-CJJ27 &lt;int&gt; | SM-CJIWT &lt;int&gt; | SM-CTEEG &lt;int&gt; | ROS11430815 &lt;int&gt; | SM-CJGLG &lt;int&gt; | SM-CJIXU &lt;int&gt; | ⋯ ⋯ | R9395022 &lt;int&gt; | SM-CJIX5 &lt;int&gt; | SM-CJEGU &lt;int&gt; | SM-CJIYH &lt;int&gt; | SM-CJGMS &lt;int&gt; | SM-CTEGU &lt;int&gt; | SM-CTEFJ &lt;int&gt; | SM-CJEJU &lt;int&gt; | SM-CTEGT &lt;int&gt; | SM-CJIZE &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "|  4 |  0 |  0 |  2 | 0 |  0 |  0 |  2 |  2 | 0 | ⋯ |  1 |  0 | 0 |  0 | 1 |  0 |  0 |  1 |  0 | 0 |\n",
       "| 20 | 12 | 45 | 36 | 1 |  7 |  9 | 30 | 16 | 5 | ⋯ | 13 |  5 | 7 | 10 | 3 |  6 | 11 | 10 | 18 | 5 |\n",
       "|  8 |  1 |  3 |  6 | 0 |  6 | 11 |  1 |  1 | 3 | ⋯ |  5 |  2 | 0 |  1 | 3 |  0 |  2 |  3 |  5 | 4 |\n",
       "|  0 |  0 |  0 |  0 | 0 |  0 |  1 |  0 |  0 | 0 | ⋯ |  0 |  0 | 0 |  0 | 0 |  0 |  0 |  0 |  0 | 0 |\n",
       "| 15 |  4 | 15 |  9 | 2 |  3 | 16 |  8 |  3 | 5 | ⋯ |  5 |  6 | 5 |  5 | 5 |  2 |  6 | 12 |  7 | 7 |\n",
       "| 33 |  4 | 55 | 70 | 4 | 10 | 26 | 21 | 22 | 5 | ⋯ | 30 | 15 | 8 | 21 | 5 | 20 | 35 | 26 | 48 | 6 |\n",
       "\n"
      ],
      "text/plain": [
       "  SM-CJK5G SM-CTDQN SM-CJEIE SM-CTEM5 SM-CJJ27 SM-CJIWT SM-CTEEG ROS11430815\n",
       "1  4        0        0        2       0         0        0        2         \n",
       "2 20       12       45       36       1         7        9       30         \n",
       "3  8        1        3        6       0         6       11        1         \n",
       "4  0        0        0        0       0         0        1        0         \n",
       "5 15        4       15        9       2         3       16        8         \n",
       "6 33        4       55       70       4        10       26       21         \n",
       "  SM-CJGLG SM-CJIXU ⋯ R9395022 SM-CJIX5 SM-CJEGU SM-CJIYH SM-CJGMS SM-CTEGU\n",
       "1  2       0        ⋯  1        0       0         0       1         0      \n",
       "2 16       5        ⋯ 13        5       7        10       3         6      \n",
       "3  1       3        ⋯  5        2       0         1       3         0      \n",
       "4  0       0        ⋯  0        0       0         0       0         0      \n",
       "5  3       5        ⋯  5        6       5         5       5         2      \n",
       "6 22       5        ⋯ 30       15       8        21       5        20      \n",
       "  SM-CTEFJ SM-CJEJU SM-CTEGT SM-CJIZE\n",
       "1  0        1        0       0       \n",
       "2 11       10       18       5       \n",
       "3  2        3        5       4       \n",
       "4  0        0        0       0       \n",
       "5  6       12        7       7       \n",
       "6 35       26       48       6       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "meta <- fread(file.path(input_dir, \"1_files_with_sampleid\", paste0(\"metadata_\", celltype, \"_50nuc.csv\")))\n",
    "peak_data <- fread(file.path(input_dir, \"1_files_with_sampleid\", paste0(\"pseudobulk_peaks_counts\", celltype, \"_50nuc.csv.gz\")))\n",
    "\n",
    "cat(\"Loaded metadata with\", nrow(meta), \"samples and peak data with\", nrow(peak_data), \"peaks\\n\")\n",
    "\n",
    "# Extract peak_id and set as rownames\n",
    "peak_id <- peak_data$peak_id\n",
    "peak_data <- peak_data[, -1, with = FALSE]  # Remove peak_id column\n",
    "peak_matrix <- as.matrix(peak_data)\n",
    "rownames(peak_matrix) <- peak_id\n",
    "\n",
    "head(meta)\n",
    "head(peak_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785bc2c7-8940-47c8-8dd4-769ab2c29f27",
   "metadata": {},
   "source": [
    "#### Process technical variables from meta data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6714741-5c18-47ed-a0f5-c6472120ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column name normalization (for easier handling)\n",
    "meta_clean <- meta %>%\n",
    "  rename(\n",
    "    med_nucleosome_signal = med.nucleosome_signal.ct,\n",
    "    med_tss_enrich = med.tss.enrich.ct,\n",
    "    med_n_tot_fragment = med.n_tot_fragment.ct,\n",
    "    n_nuclei = n.nuclei\n",
    "  )\n",
    "\n",
    "# Calculate peak metrics - total unique peaks per sample\n",
    "peak_metrics <- data.frame(\n",
    "  sampleid = colnames(peak_matrix),\n",
    "  total_unique_peaks = colSums(peak_matrix > 0)\n",
    ") %>%\n",
    "  mutate(log_total_unique_peaks = log(total_unique_peaks + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15031ec1-8106-45ce-9056-7ae771f2468e",
   "metadata": {},
   "source": [
    "####  Process peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06ee1c4e-7b39-4ba6-ab07-f7395de638dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of peak coordinates:\n",
      "            peak_name    chr  start    end\n",
      "               <char> <char>  <int>  <int>\n",
      "1: chr1-181293-181565   chr1 181293 181565\n",
      "2: chr1-190726-191626   chr1 190726 191626\n",
      "3: chr1-629712-630662   chr1 629712 630662\n",
      "4: chr1-631261-631470   chr1 631261 631470\n",
      "5: chr1-633891-634506   chr1 633891 634506\n",
      "6: chr1-777873-779958   chr1 777873 779958\n",
      "Number of blacklisted peaks: 2354 \n",
      "Number of peaks after blacklist filtering: 529135 \n"
     ]
    }
   ],
   "source": [
    "# Process peak coordinates\n",
    "peak_df <- data.table(\n",
    "  peak_name = peak_id,\n",
    "  chr = sapply(strsplit(peak_id, \"-\"), `[`, 1),\n",
    "  start = as.integer(sapply(strsplit(peak_id, \"-\"), `[`, 2)),\n",
    "  end = as.integer(sapply(strsplit(peak_id, \"-\"), `[`, 3)),\n",
    "  stringsAsFactors = FALSE\n",
    ")\n",
    "\n",
    "# Verify peak coordinates were extracted correctly\n",
    "cat(\"Sample of peak coordinates:\\n\")\n",
    "print(head(peak_df))\n",
    "\n",
    "# Load blacklist\n",
    "blacklist_file <- file.path(input_dir,\"hg38-blacklist.v2.bed.gz\")\n",
    "if (file.exists(blacklist_file)) {\n",
    "  blacklist_df <- fread(blacklist_file)\n",
    "  if (ncol(blacklist_df) >= 4) {\n",
    "    colnames(blacklist_df)[1:4] <- c(\"chr\", \"start\", \"end\", \"label\")\n",
    "  } else {\n",
    "    colnames(blacklist_df)[1:3] <- c(\"chr\", \"start\", \"end\")\n",
    "  }\n",
    "  \n",
    "  # Filter blacklisted peaks\n",
    "  setkey(blacklist_df, chr, start, end)\n",
    "  setkey(peak_df, chr, start, end)\n",
    "  overlapping_peaks <- foverlaps(peak_df, blacklist_df, nomatch=0)\n",
    "  blacklisted_peaks <- unique(overlapping_peaks$peak_name)\n",
    "  cat(\"Number of blacklisted peaks:\", length(blacklisted_peaks), \"\\n\")\n",
    "  \n",
    "  filtered_peak_idx <- !(peak_id %in% blacklisted_peaks)\n",
    "  filtered_peak <- peak_matrix[filtered_peak_idx, ]\n",
    "  cat(\"Number of peaks after blacklist filtering:\", nrow(filtered_peak), \"\\n\")\n",
    "} else {\n",
    "  cat(\"Warning: Blacklist file not found at\", blacklist_file, \"\\n\")\n",
    "  cat(\"Proceeding without blacklist filtering\\n\")\n",
    "  filtered_peak <- peak_matrix\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14144ad5-10bf-4475-9e60-370b48550fd1",
   "metadata": {},
   "source": [
    "#### Load covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1421c90d-6b16-40ff-a0c0-7b7c60a20d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable statistics before and after log transformation:\n",
      "n_nuclei: min=56.00, median=227.00, max=1293.00, SD=193.79\n",
      "log_n_nuclei: min=4.03, median=5.42, max=7.16, SD=0.64\n",
      "med_n_tot_fragment: min=2890.00, median=20306.00, max=73185.00, SD=15906.37\n",
      "log_med_n_tot_fragment: min=7.97, median=9.92, max=11.20, SD=0.66\n",
      "Number of samples after joining: 76 \n",
      "Sample IDs: SM-CJK5G, SM-CTDQN, SM-CJEIE, SM-CTEM5, SM-CJJ27, SM-CJIWT ...\n",
      "Available covariates: sampleid, individualID, sequencingBatch, main_cell_type, avg.pct.read.in.peak.ct, med_nucleosome_signal, med_n_tot_fragment, med_tss_enrich, n_nuclei, total_unique_peaks, log_total_unique_peaks, msex, age_death, pmi, study, log_n_nuclei, log_med_n_tot_fragment \n"
     ]
    }
   ],
   "source": [
    "covariates_file <- file.path(input_dir,\"rosmap_cov.txt\")\n",
    "if (file.exists(covariates_file)) {\n",
    "  covariates <- fread(covariates_file)\n",
    "  # Check column names and adjust if needed\n",
    "  if ('#id' %in% colnames(covariates)) {\n",
    "    id_col <- '#id'\n",
    "  } else if ('individualID' %in% colnames(covariates)) {\n",
    "    id_col <- 'individualID'\n",
    "  } else {\n",
    "    cat(\"Warning: Could not identify ID column in covariates file. Available columns:\", \n",
    "        paste(colnames(covariates), collapse=\", \"), \"\\n\")\n",
    "    id_col <- colnames(covariates)[1]\n",
    "    cat(\"Using\", id_col, \"as ID column\\n\")\n",
    "  }\n",
    "  \n",
    "  # Select relevant columns\n",
    "  cov_cols <- intersect(c(id_col, 'msex', 'age_death', 'pmi', 'study'), colnames(covariates))\n",
    "  covariates <- covariates[, ..cov_cols]\n",
    "  \n",
    "  # Merge with metadata\n",
    "  meta_with_ind <- meta_clean %>%\n",
    "    select(sampleid, everything())\n",
    "  \n",
    "  all_covs <- meta_with_ind %>%\n",
    "    inner_join(peak_metrics, by = \"sampleid\") %>%\n",
    "    inner_join(covariates, by = setNames(id_col, \"sampleid\"))\n",
    "  \n",
    "  # Impute missing values\n",
    "  for (col in c(\"pmi\", \"age_death\")) {\n",
    "    if (col %in% colnames(all_covs) && any(is.na(all_covs[[col]]))) {\n",
    "      cat(\"Imputing missing values for\", col, \"\\n\")\n",
    "      all_covs[[col]][is.na(all_covs[[col]])] <- median(all_covs[[col]], na.rm=TRUE)\n",
    "    }\n",
    "  }\n",
    "} else {\n",
    "  cat(\"Warning: Covariates file\", covariates_file, \"not found.\\n\")\n",
    "  cat(\"Proceeding with only technical variables.\\n\")\n",
    "  all_covs <- meta_clean %>%\n",
    "    inner_join(peak_metrics, by = \"sampleid\")\n",
    "}\n",
    "\n",
    "\n",
    "# Perform log transformations on necessary variables\n",
    "# Add a small constant to avoid log(0)\n",
    "epsilon <- 1e-6\n",
    "\n",
    "all_covs$log_n_nuclei <- log(all_covs$n_nuclei + epsilon)\n",
    "all_covs$log_med_n_tot_fragment <- log(all_covs$med_n_tot_fragment + epsilon)\n",
    "\n",
    "# Show distribution of original and log-transformed variables\n",
    "cat(\"\\nVariable statistics before and after log transformation:\\n\")\n",
    "for (var in c(\"n_nuclei\", \"med_n_tot_fragment\")) {\n",
    "  orig_var <- all_covs[[var]]\n",
    "  log_var <- all_covs[[paste0(\"log_\", var)]]\n",
    "  \n",
    "  cat(sprintf(\"%s: min=%.2f, median=%.2f, max=%.2f, SD=%.2f\\n\", \n",
    "              var, min(orig_var), median(orig_var), max(orig_var), sd(orig_var)))\n",
    "  cat(sprintf(\"log_%s: min=%.2f, median=%.2f, max=%.2f, SD=%.2f\\n\", \n",
    "              var, min(log_var), median(log_var), max(log_var), sd(log_var)))\n",
    "}\n",
    "\n",
    "cat(\"Number of samples after joining:\", nrow(all_covs), \"\\n\")\n",
    "cat(\"Sample IDs:\", paste(head(all_covs$sampleid), collapse=\", \"), \"...\\n\")\n",
    "cat(\"Available covariates:\", paste(colnames(all_covs), collapse=\", \"), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e8ab2a-87bb-46be-9c44-5e605b4cc179",
   "metadata": {},
   "source": [
    "#### Create DGE object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8146b2c5-56b5-449b-b86f-cb64deed05e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of valid samples: 76 \n"
     ]
    }
   ],
   "source": [
    "valid_samples <- intersect(colnames(filtered_peak), all_covs$sampleid)\n",
    "cat(\"Number of valid samples:\", length(valid_samples), \"\\n\")\n",
    "\n",
    "all_covs_filtered <- all_covs[all_covs$sampleid %in% valid_samples, ]\n",
    "filtered_peak_filtered <- filtered_peak[, valid_samples]\n",
    "\n",
    "dge <- DGEList(\n",
    "  counts = filtered_peak_filtered,\n",
    "  samples = all_covs_filtered\n",
    ")\n",
    "rownames(dge$samples) <- dge$samples$sampleid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bb8d6b-3e61-4f2b-9c29-c20d0f38663a",
   "metadata": {},
   "source": [
    "#### Filter low counts and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6862b6b6-0dfd-45f8-9d6c-c6dfca5247de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of peaks before filtering: 529135 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in filterByExpr.DGEList(dge, min.count = 2, min.total.count = 15, :\n",
      "“All samples appear to belong to the same group.”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of peaks after filtering: 323638 \n"
     ]
    }
   ],
   "source": [
    "cat(\"Number of peaks before filtering:\", nrow(dge), \"\\n\")\n",
    "keep <- filterByExpr(dge, \n",
    "                   min.count = 2,     # for one sample, min reads \n",
    "                   min.total.count = 15, # min reads overall\n",
    "                   min.prop = 0.1) \n",
    "\n",
    "dge <- dge[keep, , keep.lib.sizes=FALSE]\n",
    "cat(\"Number of peaks after filtering:\", nrow(dge), \"\\n\") #1368 in mic,2491 in Ast\n",
    "dge <- calcNormFactors(dge, method=\"TMM\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4d4f64-1e91-4edd-ad87-813db4f2547b",
   "metadata": {},
   "source": [
    "####  Handle batch as technical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0389e3c4-75fc-4195-b775-032da343b664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling sequencingBatch as a technical variable\n",
      "Found 2 unique batches\n",
      "Batch sizes:\n",
      "batches\n",
      "190820Kel 191203Kel \n",
      "        4        72 \n"
     ]
    }
   ],
   "source": [
    "# We'll handle batch as a technical variable rather than doing batch adjustment\n",
    "cat(\"Handling sequencingBatch as a technical variable\\n\")\n",
    "\n",
    "# Check batch information\n",
    "batches <- dge$samples$sequencingBatch\n",
    "cat(\"Found\", length(unique(batches)), \"unique batches\\n\")\n",
    "\n",
    "# Check batch size\n",
    "batch_counts <- table(batches)\n",
    "cat(\"Batch sizes:\\n\")\n",
    "print(batch_counts)\n",
    "\n",
    "# Convert sequencingBatch to factor with at least 2 levels\n",
    "if (length(unique(batches)) < 2) {\n",
    "  cat(\"Only one batch found. Adding dummy batch for model compatibility.\\n\")\n",
    "  # Create a dummy batch factor to avoid model errors\n",
    "  dge$samples$sequencingBatch_factor <- factor(rep(\"batch1\", ncol(dge)))\n",
    "} else {\n",
    "  # Use the existing batch information\n",
    "  dge$samples$sequencingBatch_factor <- factor(dge$samples$sequencingBatch)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b23595b-8bd0-471b-8c11-cb0819e9055e",
   "metadata": {},
   "source": [
    "#### Create model and run voom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efba3973-0cfc-4afd-9dcc-5842190a9995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using full model with demographic and technical covariates\n",
      "Model formula: ~log_n_nuclei + med_nucleosome_signal + med_tss_enrich + log_med_n_tot_fragment +      log_total_unique_peaks + sequencingBatch_factor + msex +      age_death + pmi + study \n",
      "Warning: Factor variable group has only one level. Converting to character.\n",
      "Successfully created design matrix with 11 columns\n",
      "Calculating offsets and residuals...\n"
     ]
    }
   ],
   "source": [
    "# Define the model based on available covariates - using log-transformed variables\n",
    "if (all(c(\"msex\", \"age_death\", \"pmi\", \"study\") %in% colnames(dge$samples))) {\n",
    "  # Full model with all covariates\n",
    "  cat(\"Using full model with demographic and technical covariates\\n\")\n",
    "  model <- ~ log_n_nuclei + med_nucleosome_signal + med_tss_enrich + log_med_n_tot_fragment  +\n",
    "    log_total_unique_peaks + sequencingBatch_factor + \n",
    "    msex + age_death + pmi + study\n",
    "} else {\n",
    "  # Technical variables only model\n",
    "  cat(\"Using model with technical covariates only\\n\")\n",
    "  model <- ~ log_n_nuclei + med_nucleosome_signal + med_tss_enrich + log_med_n_tot_fragment  +\n",
    "    log_total_unique_peaks + sequencingBatch_factor\n",
    "}\n",
    "\n",
    "# Print the model formula\n",
    "cat(\"Model formula:\", deparse(model), \"\\n\")\n",
    "\n",
    "# Check for factor variables with only one level\n",
    "for (col in colnames(dge$samples)) {\n",
    "  if (is.factor(dge$samples[[col]]) && nlevels(dge$samples[[col]]) < 2) {\n",
    "    cat(\"Warning: Factor variable\", col, \"has only one level. Converting to character.\\n\")\n",
    "    dge$samples[[col]] <- as.character(dge$samples[[col]])\n",
    "  }\n",
    "}\n",
    "\n",
    "# Create design matrix with error checking\n",
    "tryCatch({\n",
    "  design <- model.matrix(model, data=dge$samples)\n",
    "  cat(\"Successfully created design matrix with\", ncol(design), \"columns\\n\")\n",
    "}, error = function(e) {\n",
    "  cat(\"Error in creating design matrix:\", e$message, \"\\n\")\n",
    "  cat(\"Attempting to fix model formula...\\n\")\n",
    "  \n",
    "  # Check each term in the model\n",
    "  all_terms <- all.vars(model)\n",
    "  valid_terms <- character(0)\n",
    "  \n",
    "  for (term in all_terms) {\n",
    "    if (term %in% colnames(dge$samples)) {\n",
    "      # Check if it's a factor with at least 2 levels\n",
    "      if (is.factor(dge$samples[[term]])) {\n",
    "        if (nlevels(dge$samples[[term]]) >= 2) {\n",
    "          valid_terms <- c(valid_terms, term)\n",
    "        } else {\n",
    "          cat(\"Skipping factor\", term, \"with only\", nlevels(dge$samples[[term]]), \"level\\n\")\n",
    "        }\n",
    "      } else {\n",
    "        # Non-factor variables are fine\n",
    "        valid_terms <- c(valid_terms, term)\n",
    "      }\n",
    "    } else {\n",
    "      cat(\"Variable\", term, \"not found in sample data\\n\")\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Create a simplified model with valid terms\n",
    "  if (length(valid_terms) > 0) {\n",
    "    model_str <- paste(\"~\", paste(valid_terms, collapse = \" + \"))\n",
    "    model <- as.formula(model_str)\n",
    "    cat(\"New model formula:\", model_str, \"\\n\")\n",
    "    design <- model.matrix(model, data=dge$samples)\n",
    "    cat(\"Successfully created design matrix with\", ncol(design), \"columns\\n\")\n",
    "  } else {\n",
    "    stop(\"Could not create a valid model with the available variables\")\n",
    "  }\n",
    "})\n",
    "\n",
    "# Check if the design matrix is full rank\n",
    "if (!is.fullrank(design)) {\n",
    "  cat(\"Design matrix is not full rank. Adjusting...\\n\")\n",
    "  # Find and remove the problematic columns\n",
    "  qr_res <- qr(design)\n",
    "  design <- design[, qr_res$pivot[1:qr_res$rank]]\n",
    "  cat(\"Adjusted design matrix columns:\", ncol(design), \"\\n\")\n",
    "}\n",
    "\n",
    "# Run voom and fit model\n",
    "v <- voom(dge, design, plot=FALSE) #logCPM\n",
    "fit <- lmFit(v, design)\n",
    "fit <- eBayes(fit)\n",
    "\n",
    "# Calculate offset and residuals\n",
    "cat(\"Calculating offsets and residuals...\\n\")\n",
    "offset <- predictOffset(fit)\n",
    "resids <- residuals(fit, y=v)\n",
    "\n",
    "# Verify dimensions\n",
    "stopifnot(all(rownames(offset) == rownames(resids)) &\n",
    "          all(colnames(offset) == colnames(resids)))\n",
    "\n",
    "# Final adjusted data\n",
    "stopifnot(all(dim(offset) == dim(resids)))\n",
    "stopifnot(all(colnames(offset) == colnames(resids)))\n",
    "\n",
    "final_data <- offset + resids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc2d0da-33f0-4d51-ae43-4de228d57873",
   "metadata": {},
   "source": [
    "#### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0c15fea-c4d6-41a2-aa92-795b4fd0b9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed. Results and documentation saved to: /restricted/projectnb/xqtl/jaempawi/atac_seq/output/kellis/2_residuals//Astro \n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "saveRDS(list(\n",
    "  dge = dge,\n",
    "  offset = offset,\n",
    "  residuals = resids,\n",
    "  final_data = final_data,\n",
    "  valid_samples = colnames(dge),\n",
    "  design = design,\n",
    "  fit = fit,\n",
    "  model = model\n",
    "), file = file.path(out_dir, paste0(celltype,\"_results.rds\")))\n",
    "\n",
    "# Write final residual data to file\n",
    "write.table(final_data,\n",
    "            file = file.path(out_dir, paste0(celltype,\"_residuals.txt\")), \n",
    "            quote=FALSE, sep=\"\\t\", row.names=TRUE, col.names=TRUE)\n",
    "\n",
    "# Write summary statistics\n",
    "sink(file = file.path(out_dir, paste0(celltype, \"_summary.txt\")))\n",
    "cat(\"*** Processing Summary for\", celltype, \"***\\n\\n\")\n",
    "cat(\"Original peak count:\", length(peak_id), \"\\n\")\n",
    "cat(\"Peaks after blacklist filtering:\", nrow(filtered_peak), \"\\n\")\n",
    "cat(\"Peaks after expression filtering:\", nrow(dge), \"\\n\\n\")\n",
    "cat(\"Number of samples:\", ncol(dge), \"\\n\")\n",
    "cat(\"\\nTechnical Variables Used:\\n\")\n",
    "cat(\"- log_n_nuclei: Log-transformed number of nuclei per sample\\n\")\n",
    "cat(\"- med_nucleosome_signal: Median nucleosome signal\\n\")\n",
    "cat(\"- med_tss_enrich: Median TSS enrichment\\n\")\n",
    "cat(\"- log_med_n_tot_fragment: Log-transformed median number of total fragments\\n\")\n",
    "cat(\"- log_total_unique_peaks: Log-transformed count of unique peaks per sample\\n\")\n",
    "cat(\"\\nDemographic Variables Used:\\n\")\n",
    "cat(\"- msex: Sex (male=1, female=0)\\n\")\n",
    "cat(\"- age_death: Age at death\\n\")\n",
    "cat(\"- pmi: Post-mortem interval\\n\")\n",
    "cat(\"- study: Study cohort\\n\")\n",
    "sink()\n",
    "\n",
    "# Write an additional explanation file about the variables and log transformation\n",
    "sink(file = file.path(out_dir, paste0(celltype,\"_variable_explanation.txt\")))\n",
    "cat(\"# ATAC-seq Technical Variables Explanation\\n\\n\")\n",
    "\n",
    "cat(\"## Why Log Transformation?\\n\")\n",
    "cat(\"Log transformation is applied to certain variables for several reasons:\\n\")\n",
    "cat(\"1. To make the distribution more symmetric and closer to normal\\n\")\n",
    "cat(\"2. To stabilize variance across the range of values\\n\")\n",
    "cat(\"3. To match the scale of voom-transformed peak counts, which are on log2-CPM scale\\n\")\n",
    "cat(\"4. To be consistent with the approach used in related studies like haQTL\\n\\n\")\n",
    "\n",
    "cat(\"## Variables and Their Meanings\\n\\n\")\n",
    "\n",
    "cat(\"### Technical Variables\\n\")\n",
    "cat(\"- n_nuclei: Number of nuclei that contributed to this pseudobulk sample\\n\")\n",
    "cat(\"  * Log-transformed because count data typically has a right-skewed distribution\\n\\n\")\n",
    "\n",
    "cat(\"- med_n_tot_fragment: Median number of total fragments per cell\\n\")\n",
    "cat(\"  * Represents sequencing depth\\n\")\n",
    "cat(\"  * Log-transformed because sequencing depth typically has exponential effects\\n\\n\")\n",
    "\n",
    "cat(\"- total_unique_peaks: Number of unique peaks detected in each sample\\n\")\n",
    "cat(\"  * Log-transformed similar to 'TotalNumPeaks' in haQTL pipeline\\n\\n\")\n",
    "\n",
    "cat(\"- med_nucleosome_signal: Median nucleosome signal\\n\")\n",
    "cat(\"  * Measures the degree of nucleosome positioning\\n\")\n",
    "cat(\"  * Not log-transformed as it's already a ratio/normalized metric\\n\\n\")\n",
    "\n",
    "cat(\"- med_tss_enrich: Median transcription start site enrichment score\\n\")\n",
    "cat(\"  * Indicates the quality of the ATAC-seq data\\n\")\n",
    "cat(\"  * Not log-transformed as it's already a ratio/normalized metric\\n\\n\")\n",
    "\n",
    "cat(\"### Demographic Variables\\n\")\n",
    "cat(\"- msex: Sex (male=1, female=0)\\n\")\n",
    "cat(\"- age_death: Age at death\\n\")\n",
    "cat(\"- pmi: Post-mortem interval (time between death and tissue collection)\\n\")\n",
    "cat(\"- study: Study cohort (ROSMAP, MAP, ROS)\\n\\n\")\n",
    "\n",
    "cat(\"## Relationship to voom Transformation\\n\")\n",
    "cat(\"The voom transformation converts count data to log2-CPM (counts per million) values \")\n",
    "cat(\"and estimates the mean-variance relationship. By log-transforming certain technical \")\n",
    "cat(\"covariates, we ensure they're on a similar scale to the transformed expression data, \")\n",
    "cat(\"which can improve the fit of the linear model used for removing unwanted variation.\\n\")\n",
    "sink()\n",
    "\n",
    "cat(\"Processing completed. Results and documentation saved to:\", out_dir, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28beaf3-804a-4b88-9e7e-156a5d4ee3d0",
   "metadata": {},
   "source": [
    "### Option B: Pseudobulk QC WITHOUT Biological Variation (noBIOvar)\n",
    "Use this option when you want to preserve biological variation (e.g., for comparing across ages/sexes or region-specific analyses).\n",
    "\n",
    "**Input:** (Same as Option A)\n",
    "- Pseudobulk peak counts (in `1_files_with_sampleid` folder): `pseudobulk_peaks_counts{celltype}_50nuc.csv.gz`\n",
    "- Cell metadata (in `1_files_with_sampleid` folder): `metadata_{celltype}_50nuc.csv`\n",
    "- Sample covariates: `rosmap_cov.txt`\n",
    "- hg38 blacklist: `hg38-blacklist.v2.bed.gz`\n",
    "\n",
    "**Process:**\n",
    "1. Loads pseudobulk peak count matrix and metadata per cell type\n",
    "2. Calculates technical QC metrics per sample:\n",
    "   - `log_n_nuclei`: Log-transformed number of nuclei\n",
    "   - `med_nucleosome_signal`: Median nucleosome signal\n",
    "   - `med_tss_enrich`: Median TSS enrichment score\n",
    "   - `log_med_n_tot_fragment`: Log-transformed median total fragments (sequencing depth)\n",
    "   - `log_total_unique_peaks`: Log-transformed count of unique peaks detected\n",
    "3. Filters blacklisted genomic regions using `foverlaps()`\n",
    "4. Merges with demographic covariates (msex, age_death, pmi, study)\n",
    "5. Applies expression filtering with `filterByExpr()`:\n",
    "   - `min.count = 2`: Minimum 2 reads in at least one sample\n",
    "   - `min.total.count = 15`: Minimum 15 total reads across all samples\n",
    "   - `min.prop = 0.1`: Peak must be expressed in ≥10% of samples\n",
    "6. TMM normalization with `calcNormFactors()`\n",
    "7. Saves **filtered raw counts** without covariate adjustment\n",
    "\n",
    "**Key Difference:** \n",
    "- Does NOT regress out msex or age_death\n",
    "- No residual calculation performed (voom/lmFit section commented out)\n",
    "- Only saves TMM-normalized, filtered count matrix\n",
    "\n",
    "**Model formula (if residuals were computed):**\n",
    "```r\n",
    "model <- ~ log_n_nuclei + med_nucleosome_signal + med_tss_enrich + log_med_n_tot_fragment + log_total_unique_peaks + med_peakwidth + sequencingBatch_factor + pmi + study\n",
    "\n",
    "```\n",
    "Note: The voom/residual calculation section is commented out; only filtered counts are saved\n",
    "\n",
    "**Output:** `output/2_residuals/{celltype}/`\n",
    "\n",
    "`{celltype}_filtered_raw_counts.txt`: TMM-normalized, filtered peak counts without biological covariate adjustment\n",
    "\n",
    "**Key Variables NOT Regressed:**\n",
    "- Sex (msex)\n",
    "- Age at death (age_death)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee626cb-8aa6-4464-8066-4f501b5d6eaf",
   "metadata": {},
   "source": [
    "#### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bfb521c-fdc2-4029-b8e6-9c3459ee8872",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(data.table)\n",
    "library(stringr)\n",
    "library(dplyr)\n",
    "library(edgeR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e346a569-892d-43b7-974d-f55ca725d83b",
   "metadata": {},
   "source": [
    "#### Load input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55b554b2-722b-48d8-aa25-bbdae074963f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing celltype: Exc \n"
     ]
    }
   ],
   "source": [
    "# Set cell type and create output directory\n",
    "#args <- commandArgs(trailingOnly = TRUE)\n",
    "#celltype <- args[1]  # First argument is the cell type\n",
    "celltype <- \"Exc\"  # Change this for different cell types\n",
    "cat(\"Processing celltype:\", celltype, \"\\n\")\n",
    "\n",
    "out_dir <- paste0(file.path(output_dir,\"2_residuals/\", celltype))\n",
    "dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d336458-99cd-4ff0-838b-4423d6bf2e9a",
   "metadata": {},
   "source": [
    "#### Create predictOffset function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e01e3c57-8abc-4b09-94fb-1ec7fc55b0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictOffset <- function(fit) {\n",
    "  # Define which variables are factors and which are continuous\n",
    "  usedFactors <- c(\"sequencingBatch\", \"study\") \n",
    "  usedContinuous <- c(\"log_n_nuclei\", \"med_nucleosome_signal\", \"med_tss_enrich\", \"log_med_n_tot_fragment\",\n",
    "                      \"log_total_unique_peaks\", \"med_peakwidth\", \"pmi\")\n",
    "  \n",
    "  # Filter to only use variables actually in the design matrix\n",
    "  usedFactors <- usedFactors[sapply(usedFactors, function(f) any(grepl(paste0(\"^\", f), colnames(fit$design))))]\n",
    "  usedContinuous <- usedContinuous[sapply(usedContinuous, function(f) any(grepl(paste0(\"^\", f), colnames(fit$design))))]\n",
    "  \n",
    "  # Get indices for factor and continuous variables\n",
    "  facInd <- unlist(lapply(as.list(usedFactors), \n",
    "                         function(f) {return(grep(paste0(\"^\", f), \n",
    "                                                colnames(fit$design)))}))\n",
    "  contInd <- unlist(lapply(as.list(usedContinuous), \n",
    "                          function(f) {return(grep(paste0(\"^\", f), \n",
    "                                                 colnames(fit$design)))}))\n",
    "  \n",
    "  # Add the intercept\n",
    "  all_indices <- c(1, facInd, contInd)\n",
    "  \n",
    "  # Verify design matrix structure (using sorted indices to avoid duplication warning)\n",
    "  all_indices_sorted <- sort(unique(all_indices))\n",
    "  stopifnot(all(all_indices_sorted %in% 1:ncol(fit$design)))\n",
    "  \n",
    "  # Create new design matrix with median values\n",
    "  D <- fit$design\n",
    "  D[, facInd] <- 0  # Set all factor levels to reference level\n",
    "  \n",
    "  # For continuous variables, set to median value\n",
    "  if (length(contInd) > 0) {\n",
    "    medContVals <- apply(D[, contInd, drop=FALSE], 2, median)\n",
    "    for (i in 1:length(medContVals)) {\n",
    "      D[, names(medContVals)[i]] <- medContVals[i]\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Calculate offsets\n",
    "  stopifnot(all(colnames(coefficients(fit)) == colnames(D)))\n",
    "  offsets <- apply(coefficients(fit), 1, function(c) {\n",
    "    return(D %*% c)\n",
    "  })\n",
    "  offsets <- t(offsets)\n",
    "  colnames(offsets) <- rownames(fit$design)\n",
    "  \n",
    "  return(offsets)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4a5c28-5295-47e4-a5f5-26d6cbb995ca",
   "metadata": {},
   "source": [
    "#### Load input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ea62e42-0bbf-4166-8c51-ded8318a6463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded metadata with 90 samples and peak data with 531489 peaks\n"
     ]
    }
   ],
   "source": [
    "meta <- fread(paste0(file.path(input_dir, \"1_files_with_sampleid/metadata_\"), celltype, \"_50nuc.csv\"))\n",
    "peak_data <- fread(file.path(input_dir,\"1_files_with_sampleid\", paste0(\"pseudobulk_peaks_counts\", celltype, \"_50nuc.csv.gz\")))\n",
    "\n",
    "cat(\"Loaded metadata with\", nrow(meta), \"samples and peak data with\", nrow(peak_data), \"peaks\\n\")\n",
    "\n",
    "# Extract peak_id and set as rownames\n",
    "peak_id <- peak_data$peak_id\n",
    "peak_data <- peak_data[, -1, with = FALSE]  # Remove peak_id column\n",
    "peak_matrix <- as.matrix(peak_data)\n",
    "rownames(peak_matrix) <- peak_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b9c011-775e-41bc-b581-4269628592eb",
   "metadata": {},
   "source": [
    "#### Process technical variables from meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "866e1e87-0c20-4a71-9d83-450c49a3e647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column name normalization (for easier handling)\n",
    "meta_clean <- meta %>%\n",
    "  rename(\n",
    "    med_nucleosome_signal = med.nucleosome_signal.ct,\n",
    "    med_tss_enrich = med.tss.enrich.ct,\n",
    "    med_n_tot_fragment = med.n_tot_fragment.ct,\n",
    "    n_nuclei = n.nuclei\n",
    "  )\n",
    "\n",
    "# Calculate peak metrics - total unique peaks per sample and median peak width\n",
    "peak_metrics <- data.frame(\n",
    "  sampleid = colnames(peak_matrix),\n",
    "  total_unique_peaks = colSums(peak_matrix > 0)\n",
    ") %>%\n",
    "  mutate(log_total_unique_peaks = log(total_unique_peaks + 1))\n",
    "\n",
    "# Calculate median peak width for each sample using count as weight\n",
    "calculate_median_peakwidth <- function(peak_matrix, peak_info) {\n",
    "  # Create a data frame with peak widths\n",
    "  peak_widths <- peak_info$end - peak_info$start\n",
    "  \n",
    "  # Initialize a vector to store median peak widths\n",
    "  median_peak_widths <- numeric(ncol(peak_matrix))\n",
    "  names(median_peak_widths) <- colnames(peak_matrix)\n",
    "  \n",
    "  # For each sample, calculate the weighted median peak width\n",
    "  for (i in 1:ncol(peak_matrix)) {\n",
    "    sample_counts <- peak_matrix[, i]\n",
    "    # Only consider peaks with counts > 0\n",
    "    idx <- which(sample_counts > 0)\n",
    "    \n",
    "    if (length(idx) > 0) {\n",
    "      # Method 1: Use counts as weights\n",
    "      weights <- sample_counts[idx]\n",
    "      # Repeat each peak width by its count for weighted calculation\n",
    "      all_widths <- rep(peak_widths[idx], times=weights)\n",
    "      median_peak_widths[i] <- median(all_widths)\n",
    "    } else {\n",
    "      median_peak_widths[i] <- NA\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return(median_peak_widths)\n",
    "}\n",
    "\n",
    "# Calculate median peak width for each sample\n",
    "# Note: Using the peak_df that was created earlier for blacklist filtering\n",
    "median_peakwidths <- calculate_median_peakwidth(peak_matrix, data.frame(\n",
    "  start = as.integer(sapply(strsplit(peak_id, \"-\"), `[`, 2)),\n",
    "  end = as.integer(sapply(strsplit(peak_id, \"-\"), `[`, 3))\n",
    "))\n",
    "\n",
    "# Add median peak width to peak metrics\n",
    "peak_metrics$med_peakwidth <- median_peakwidths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7eee8d-91f2-48a8-b3df-f5f6fbd6ac9b",
   "metadata": {},
   "source": [
    "#### Process peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fc2bc63-131f-425d-bbcd-66d6eba93076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of peak coordinates:\n",
      "            peak_name    chr  start    end\n",
      "               <char> <char>  <int>  <int>\n",
      "1: chr1-181293-181565   chr1 181293 181565\n",
      "2: chr1-190726-191626   chr1 190726 191626\n",
      "3: chr1-629712-630662   chr1 629712 630662\n",
      "4: chr1-631261-631470   chr1 631261 631470\n",
      "5: chr1-633891-634506   chr1 633891 634506\n",
      "6: chr1-777873-779958   chr1 777873 779958\n",
      "Number of blacklisted peaks: 2354 \n",
      "Number of peaks after blacklist filtering: 529135 \n"
     ]
    }
   ],
   "source": [
    "# Process peak coordinates\n",
    "peak_df <- data.table(\n",
    "  peak_name = peak_id,\n",
    "  chr = sapply(strsplit(peak_id, \"-\"), `[`, 1),\n",
    "  start = as.integer(sapply(strsplit(peak_id, \"-\"), `[`, 2)),\n",
    "  end = as.integer(sapply(strsplit(peak_id, \"-\"), `[`, 3)),\n",
    "  stringsAsFactors = FALSE\n",
    ")\n",
    "\n",
    "# Verify peak coordinates were extracted correctly\n",
    "cat(\"Sample of peak coordinates:\\n\")\n",
    "print(head(peak_df))\n",
    "\n",
    "# Load blacklist\n",
    "blacklist_file <- file.path(input_dir,\"hg38-blacklist.v2.bed.gz\")\n",
    "if (file.exists(blacklist_file)) {\n",
    "  blacklist_df <- fread(blacklist_file)\n",
    "  if (ncol(blacklist_df) >= 4) {\n",
    "    colnames(blacklist_df)[1:4] <- c(\"chr\", \"start\", \"end\", \"label\")\n",
    "  } else {\n",
    "    colnames(blacklist_df)[1:3] <- c(\"chr\", \"start\", \"end\")\n",
    "  }\n",
    "  \n",
    "  # Filter blacklisted peaks\n",
    "  setkey(blacklist_df, chr, start, end)\n",
    "  setkey(peak_df, chr, start, end)\n",
    "  overlapping_peaks <- foverlaps(peak_df, blacklist_df, nomatch=0)\n",
    "  blacklisted_peaks <- unique(overlapping_peaks$peak_name)\n",
    "  cat(\"Number of blacklisted peaks:\", length(blacklisted_peaks), \"\\n\")\n",
    "  \n",
    "  filtered_peak_idx <- !(peak_id %in% blacklisted_peaks)\n",
    "  filtered_peak <- peak_matrix[filtered_peak_idx, ]\n",
    "  cat(\"Number of peaks after blacklist filtering:\", nrow(filtered_peak), \"\\n\")\n",
    "} else {\n",
    "  cat(\"Warning: Blacklist file not found at\", blacklist_file, \"\\n\")\n",
    "  cat(\"Proceeding without blacklist filtering\\n\")\n",
    "  filtered_peak <- peak_matrix\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d764e632-2fca-401e-9457-8174ff204000",
   "metadata": {},
   "source": [
    "#### Load covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8aaabbbf-70e3-421c-863d-1c8c08c0fc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable statistics before and after log transformation:\n",
      "n_nuclei: min=77.00, median=1762.00, max=7024.00, SD=1275.90\n",
      "log_n_nuclei: min=4.34, median=7.47, max=8.86, SD=0.88\n",
      "med_n_tot_fragment: min=3234.00, median=21072.00, max=133932.50, SD=20162.62\n",
      "log_med_n_tot_fragment: min=8.08, median=9.96, max=11.81, SD=0.73\n",
      "Number of samples after joining: 83 \n",
      "Sample IDs: SM-CJK5G, SM-CTDQN, SM-CJEIE, SM-CTEM5, SM-CJJ27, SM-CJIWT ...\n",
      "Available covariates: sampleid, individualID, sequencingBatch, main_cell_type, avg.pct.read.in.peak.ct, med_nucleosome_signal, med_n_tot_fragment, med_tss_enrich, n_nuclei, total_unique_peaks, log_total_unique_peaks, med_peakwidth, pmi, study, log_n_nuclei, log_med_n_tot_fragment \n"
     ]
    }
   ],
   "source": [
    "covariates_file <- file.path(input_dir,'rosmap_cov.txt')\n",
    "if (file.exists(covariates_file)) {\n",
    "  covariates <- fread(covariates_file)\n",
    "  # Check column names and adjust if needed\n",
    "  if ('#id' %in% colnames(covariates)) {\n",
    "    id_col <- '#id'\n",
    "  } else if ('individualID' %in% colnames(covariates)) {\n",
    "    id_col <- 'individualID'\n",
    "  } else {\n",
    "    cat(\"Warning: Could not identify ID column in covariates file. Available columns:\", \n",
    "        paste(colnames(covariates), collapse=\", \"), \"\\n\")\n",
    "    id_col <- colnames(covariates)[1]\n",
    "    cat(\"Using\", id_col, \"as ID column\\n\")\n",
    "  }\n",
    "  \n",
    "  # Select relevant columns - excluding msex and age_death\n",
    "  cov_cols <- intersect(c(id_col, 'pmi', 'study'), colnames(covariates))\n",
    "  covariates <- covariates[, ..cov_cols]\n",
    "  \n",
    "  # Merge with metadata\n",
    "  meta_with_ind <- meta_clean %>%\n",
    "    select(sampleid, everything())\n",
    "  \n",
    "  all_covs <- meta_with_ind %>%\n",
    "    inner_join(peak_metrics, by = \"sampleid\") %>%\n",
    "    inner_join(covariates, by = setNames(id_col, \"sampleid\"))\n",
    "  \n",
    "  # Impute missing values\n",
    "  for (col in c(\"pmi\")) {\n",
    "    if (col %in% colnames(all_covs) && any(is.na(all_covs[[col]]))) {\n",
    "      cat(\"Imputing missing values for\", col, \"\\n\")\n",
    "      all_covs[[col]][is.na(all_covs[[col]])] <- median(all_covs[[col]], na.rm=TRUE)\n",
    "    }\n",
    "  }\n",
    "} else {\n",
    "  cat(\"Warning: Covariates file\", covariates_file, \"not found.\\n\")\n",
    "  cat(\"Proceeding with only technical variables.\\n\")\n",
    "  all_covs <- meta_clean %>%\n",
    "    inner_join(peak_metrics, by = \"sampleid\")\n",
    "}\n",
    "\n",
    "\n",
    "# Perform log transformations on necessary variables\n",
    "# Add a small constant to avoid log(0)\n",
    "epsilon <- 1e-6\n",
    "\n",
    "all_covs$log_n_nuclei <- log(all_covs$n_nuclei + epsilon)\n",
    "all_covs$log_med_n_tot_fragment <- log(all_covs$med_n_tot_fragment + epsilon)\n",
    "\n",
    "# Show distribution of original and log-transformed variables\n",
    "cat(\"\\nVariable statistics before and after log transformation:\\n\")\n",
    "for (var in c(\"n_nuclei\", \"med_n_tot_fragment\")) {\n",
    "  orig_var <- all_covs[[var]]\n",
    "  log_var <- all_covs[[paste0(\"log_\", var)]]\n",
    "  \n",
    "  cat(sprintf(\"%s: min=%.2f, median=%.2f, max=%.2f, SD=%.2f\\n\", \n",
    "              var, min(orig_var), median(orig_var), max(orig_var), sd(orig_var)))\n",
    "  cat(sprintf(\"log_%s: min=%.2f, median=%.2f, max=%.2f, SD=%.2f\\n\", \n",
    "              var, min(log_var), median(log_var), max(log_var), sd(log_var)))\n",
    "}\n",
    "\n",
    "cat(\"Number of samples after joining:\", nrow(all_covs), \"\\n\")\n",
    "cat(\"Sample IDs:\", paste(head(all_covs$sampleid), collapse=\", \"), \"...\\n\")\n",
    "cat(\"Available covariates:\", paste(colnames(all_covs), collapse=\", \"), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbc0158-7095-48db-a80c-020fad7bd4ec",
   "metadata": {},
   "source": [
    "#### Create DGE object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13ebe29a-6598-4d9d-b9ff-223ae3a98656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of valid samples: 83 \n"
     ]
    }
   ],
   "source": [
    "valid_samples <- intersect(colnames(filtered_peak), all_covs$sampleid)\n",
    "cat(\"Number of valid samples:\", length(valid_samples), \"\\n\")\n",
    "\n",
    "all_covs_filtered <- all_covs[all_covs$sampleid %in% valid_samples, ]\n",
    "filtered_peak_filtered <- filtered_peak[, valid_samples]\n",
    "\n",
    "dge <- DGEList(\n",
    "  counts = filtered_peak_filtered,\n",
    "  samples = all_covs_filtered\n",
    ")\n",
    "rownames(dge$samples) <- dge$samples$sampleid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6962730b-7cdd-41e4-ba2c-51cd08d16013",
   "metadata": {},
   "source": [
    "#### Filter low counts and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f0f07a2-0b66-4031-acf9-cc0db9e8af4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of peaks before filtering: 529135 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in filterByExpr.DGEList(dge, min.count = 5, min.total.count = 15, :\n",
      "“All samples appear to belong to the same group.”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of peaks after filtering: 521515 \n",
      "Saved filtered raw counts to /restricted/projectnb/xqtl/jaempawi/atac_seq/output/kellis/2_residuals//Exc/Exc_filtered_raw_counts.txt \n"
     ]
    }
   ],
   "source": [
    "cat(\"Number of peaks before filtering:\", nrow(dge), \"\\n\")\n",
    "keep <- filterByExpr(dge, \n",
    "                   min.count = 5,     # for one sample, min reads \n",
    "                   min.total.count = 15, # min reads overall\n",
    "                   min.prop = 0.1) \n",
    "\n",
    "dge <- dge[keep, , keep.lib.sizes=FALSE]\n",
    "cat(\"Number of peaks after filtering:\", nrow(dge), \"\\n\") #1368 in mic,2491 in Ast\n",
    "\n",
    "# Save filtered raw count data\n",
    "filtered_raw_counts <- dge$counts\n",
    "write.table(filtered_raw_counts,\n",
    "            file = file.path(out_dir, paste0(celltype, \"_filtered_raw_counts.txt\")), \n",
    "            quote=FALSE, sep=\"\\t\", row.names=TRUE, col.names=TRUE)\n",
    "cat(\"Saved filtered raw counts to\", file.path(out_dir, paste0(celltype, \"_filtered_raw_counts.txt\")), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8ac9ec-e713-411e-940a-3e0e7eff0c27",
   "metadata": {},
   "source": [
    "#### Handle batch as technical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82da4179-feae-47f0-a566-a04127beacc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling sequencingBatch as a technical variable\n",
      "Found 2 unique batches\n",
      "Batch sizes:\n",
      "batches\n",
      "190820Kel 191203Kel \n",
      "        6        77 \n"
     ]
    }
   ],
   "source": [
    "dge <- calcNormFactors(dge, method=\"TMM\")\n",
    "# We'll handle batch as a technical variable rather than doing batch adjustment\n",
    "cat(\"Handling sequencingBatch as a technical variable\\n\")\n",
    "\n",
    "# Check batch information\n",
    "batches <- dge$samples$sequencingBatch\n",
    "cat(\"Found\", length(unique(batches)), \"unique batches\\n\")\n",
    "\n",
    "# Check batch size\n",
    "batch_counts <- table(batches)\n",
    "cat(\"Batch sizes:\\n\")\n",
    "print(batch_counts)\n",
    "\n",
    "# Convert sequencingBatch to factor with at least 2 levels\n",
    "if (length(unique(batches)) < 2) {\n",
    "  cat(\"Only one batch found. Adding dummy batch for model compatibility.\\n\")\n",
    "  # Create a dummy batch factor to avoid model errors\n",
    "  dge$samples$sequencingBatch_factor <- factor(rep(\"batch1\", ncol(dge)))\n",
    "} else {\n",
    "  # Use the existing batch information\n",
    "  dge$samples$sequencingBatch_factor <- factor(dge$samples$sequencingBatch)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6593bcae-cf9b-46d4-8411-37aa7b0d2f7a",
   "metadata": {},
   "source": [
    "#### Create model and run voom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d078474a-45e4-4762-adb2-06925885ff88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model with technical covariates plus pmi and study\n",
      "Model formula: ~log_n_nuclei + med_nucleosome_signal + med_tss_enrich + log_med_n_tot_fragment +      log_total_unique_peaks + med_peakwidth + sequencingBatch_factor +      pmi + study \n",
      "Warning: Factor variable group has only one level. Converting to character.\n",
      "Successfully created design matrix with 10 columns\n",
      "Calculating offsets and residuals...\n"
     ]
    }
   ],
   "source": [
    "# Define the model based on available covariates - using log-transformed variables\n",
    "# Removed msex and age_death from the model\n",
    "if (\"study\" %in% colnames(dge$samples) && \"pmi\" %in% colnames(dge$samples)) {\n",
    "  # Technical model with pmi and study\n",
    "  cat(\"Using model with technical covariates plus pmi and study\\n\")\n",
    "  model <- ~ log_n_nuclei + med_nucleosome_signal + med_tss_enrich + log_med_n_tot_fragment  +\n",
    "    log_total_unique_peaks + med_peakwidth + sequencingBatch_factor + pmi + study\n",
    "} else if (\"pmi\" %in% colnames(dge$samples)) {\n",
    "  # Technical model with pmi only\n",
    "  cat(\"Using model with technical covariates and pmi\\n\")\n",
    "  model <- ~ log_n_nuclei + med_nucleosome_signal + med_tss_enrich + log_med_n_tot_fragment  +\n",
    "    log_total_unique_peaks + med_peakwidth + sequencingBatch_factor + pmi\n",
    "} else {\n",
    "  # Technical variables only model\n",
    "  cat(\"Using model with technical covariates only\\n\")\n",
    "  model <- ~ log_n_nuclei + med_nucleosome_signal + med_tss_enrich + log_med_n_tot_fragment  +\n",
    "    log_total_unique_peaks + med_peakwidth + sequencingBatch_factor\n",
    "}\n",
    "\n",
    "# Print the model formula\n",
    "cat(\"Model formula:\", deparse(model), \"\\n\")\n",
    "\n",
    "# Check for factor variables with only one level\n",
    "for (col in colnames(dge$samples)) {\n",
    "  if (is.factor(dge$samples[[col]]) && nlevels(dge$samples[[col]]) < 2) {\n",
    "    cat(\"Warning: Factor variable\", col, \"has only one level. Converting to character.\\n\")\n",
    "    dge$samples[[col]] <- as.character(dge$samples[[col]])\n",
    "  }\n",
    "}\n",
    "\n",
    "# Create design matrix with error checking\n",
    "tryCatch({\n",
    "  design <- model.matrix(model, data=dge$samples)\n",
    "  cat(\"Successfully created design matrix with\", ncol(design), \"columns\\n\")\n",
    "}, error = function(e) {\n",
    "  cat(\"Error in creating design matrix:\", e$message, \"\\n\")\n",
    "  cat(\"Attempting to fix model formula...\\n\")\n",
    "  \n",
    "  # Check each term in the model\n",
    "  all_terms <- all.vars(model)\n",
    "  valid_terms <- character(0)\n",
    "  \n",
    "  for (term in all_terms) {\n",
    "    if (term %in% colnames(dge$samples)) {\n",
    "      # Check if it's a factor with at least 2 levels\n",
    "      if (is.factor(dge$samples[[term]])) {\n",
    "        if (nlevels(dge$samples[[term]]) >= 2) {\n",
    "          valid_terms <- c(valid_terms, term)\n",
    "        } else {\n",
    "          cat(\"Skipping factor\", term, \"with only\", nlevels(dge$samples[[term]]), \"level\\n\")\n",
    "        }\n",
    "      } else {\n",
    "        # Non-factor variables are fine\n",
    "        valid_terms <- c(valid_terms, term)\n",
    "      }\n",
    "    } else {\n",
    "      cat(\"Variable\", term, \"not found in sample data\\n\")\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Create a simplified model with valid terms\n",
    "  if (length(valid_terms) > 0) {\n",
    "    model_str <- paste(\"~\", paste(valid_terms, collapse = \" + \"))\n",
    "    model <- as.formula(model_str)\n",
    "    cat(\"New model formula:\", model_str, \"\\n\")\n",
    "    design <- model.matrix(model, data=dge$samples)\n",
    "    cat(\"Successfully created design matrix with\", ncol(design), \"columns\\n\")\n",
    "  } else {\n",
    "    stop(\"Could not create a valid model with the available variables\")\n",
    "  }\n",
    "})\n",
    "\n",
    "# Check if the design matrix is full rank\n",
    "if (!is.fullrank(design)) {\n",
    "  cat(\"Design matrix is not full rank. Adjusting...\\n\")\n",
    "  # Find and remove the problematic columns\n",
    "  qr_res <- qr(design)\n",
    "  design <- design[, qr_res$pivot[1:qr_res$rank]]\n",
    "  cat(\"Adjusted design matrix columns:\", ncol(design), \"\\n\")\n",
    "}\n",
    "\n",
    "# Run voom and fit model\n",
    "v <- voom(dge, design, plot=FALSE) #logCPM\n",
    "fit <- lmFit(v, design)\n",
    "fit <- eBayes(fit)\n",
    "\n",
    "# Calculate offset and residuals\n",
    "cat(\"Calculating offsets and residuals...\\n\")\n",
    "offset <- predictOffset(fit)\n",
    "resids <- residuals(fit, y=v)\n",
    "\n",
    "# Verify dimensions\n",
    "stopifnot(all(rownames(offset) == rownames(resids)) & all(colnames(offset) == colnames(resids)))\n",
    "\n",
    "# Final adjusted data\n",
    "stopifnot(all(dim(offset) == dim(resids)))\n",
    "stopifnot(all(colnames(offset) == colnames(resids)))\n",
    "\n",
    "final_data <- offset + resids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef172cf6-555f-49e7-834f-b0f706b4b3bf",
   "metadata": {},
   "source": [
    "#### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f002e9d7-d994-4cdf-9ecc-7a0f18210b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveRDS(list(\n",
    "  dge = dge,\n",
    "  offset = offset,\n",
    "  residuals = resids,\n",
    "  final_data = final_data,\n",
    "  valid_samples = colnames(dge),\n",
    "  design = design,\n",
    "  fit = fit,\n",
    "  model = model\n",
    "), file = file.path(out_dir, paste0(celltype, \"_results.rds\")))\n",
    "\n",
    "# Write final residual data to file\n",
    "write.table(final_data,\n",
    "            file = file.path(out_dir, paste0(celltype, \"_residuals.txt\")), \n",
    "            quote=FALSE, sep=\"\\t\", row.names=TRUE, col.names=TRUE)\n",
    "\n",
    "# Write summary statistics\n",
    "sink(file = file.path(out_dir, paste0(celltype, \"_summary.txt\")))\n",
    "cat(\"*** Processing Summary for\", celltype, \"***\\n\\n\")\n",
    "cat(\"Original peak count:\", length(peak_id), \"\\n\")\n",
    "cat(\"Peaks after blacklist filtering:\", nrow(filtered_peak), \"\\n\")\n",
    "cat(\"Peaks after expression filtering:\", nrow(dge), \"\\n\\n\")\n",
    "cat(\"Number of samples:\", ncol(dge), \"\\n\")\n",
    "cat(\"\\nTechnical Variables Used:\\n\")\n",
    "cat(\"- log_n_nuclei: Log-transformed number of nuclei per sample\\n\")\n",
    "cat(\"- med_nucleosome_signal: Median nucleosome signal\\n\")\n",
    "cat(\"- med_tss_enrich: Median TSS enrichment\\n\")\n",
    "cat(\"- log_med_n_tot_fragment: Log-transformed median number of total fragments\\n\")\n",
    "cat(\"- log_total_unique_peaks: Log-transformed count of unique peaks per sample\\n\")\n",
    "cat(\"\\nOther Variables Used:\\n\")\n",
    "cat(\"- pmi: Post-mortem interval\\n\")\n",
    "cat(\"- study: Study cohort\\n\")\n",
    "sink()\n",
    "\n",
    "# Write an additional explanation file about the variables and log transformation\n",
    "sink(file = file.path(out_dir, paste0(celltype, \"_variable_explanation.txt\")))\n",
    "cat(\"# ATAC-seq Technical Variables Explanation\\n\\n\")\n",
    "\n",
    "cat(\"## Why Log Transformation?\\n\")\n",
    "cat(\"Log transformation is applied to certain variables for several reasons:\\n\")\n",
    "cat(\"1. To make the distribution more symmetric and closer to normal\\n\")\n",
    "cat(\"2. To stabilize variance across the range of values\\n\")\n",
    "cat(\"3. To match the scale of voom-transformed peak counts, which are on log2-CPM scale\\n\")\n",
    "cat(\"4. To be consistent with the approach used in related studies like haQTL\\n\\n\")\n",
    "\n",
    "cat(\"## Variables and Their Meanings\\n\\n\")\n",
    "\n",
    "cat(\"### Technical Variables\\n\")\n",
    "cat(\"- n_nuclei: Number of nuclei that contributed to this pseudobulk sample\\n\")\n",
    "cat(\"  * Log-transformed because count data typically has a right-skewed distribution\\n\\n\")\n",
    "\n",
    "cat(\"- med_n_tot_fragment: Median number of total fragments per cell\\n\")\n",
    "cat(\"  * Represents sequencing depth\\n\")\n",
    "cat(\"  * Log-transformed because sequencing depth typically has exponential effects\\n\\n\")\n",
    "\n",
    "cat(\"- total_unique_peaks: Number of unique peaks detected in each sample\\n\")\n",
    "cat(\"  * Log-transformed similar to 'TotalNumPeaks' in haQTL pipeline\\n\\n\")\n",
    "\n",
    "cat(\"- med_peakwidth: Median width of peaks in each sample (weighted by counts)\\n\")\n",
    "cat(\"  * Represents the typical size of accessible regions\\n\\n\")\n",
    "\n",
    "cat(\"- med_nucleosome_signal: Median nucleosome signal\\n\")\n",
    "cat(\"  * Measures the degree of nucleosome positioning\\n\")\n",
    "cat(\"  * Not log-transformed as it's already a ratio/normalized metric\\n\\n\")\n",
    "\n",
    "cat(\"- med_tss_enrich: Median transcription start site enrichment score\\n\")\n",
    "cat(\"  * Indicates the quality of the ATAC-seq data\\n\")\n",
    "cat(\"  * Not log-transformed as it's already a ratio/normalized metric\\n\\n\")\n",
    "\n",
    "cat(\"### Other Variables\\n\")\n",
    "cat(\"- pmi: Post-mortem interval (time between death and tissue collection)\\n\")\n",
    "cat(\"- study: Study cohort (ROSMAP, MAP, ROS)\\n\\n\")\n",
    "\n",
    "cat(\"## Relationship to voom Transformation\\n\")\n",
    "cat(\"The voom transformation converts count data to log2-CPM (counts per million) values \")\n",
    "cat(\"and estimates the mean-variance relationship. By log-transforming certain technical \")\n",
    "cat(\"covariates, we ensure they're on a similar scale to the transformed expression data, \")\n",
    "cat(\"which can improve the fit of the linear model used for removing unwanted variation.\\n\")\n",
    "sink()\n",
    "\n",
    "cat(\"Processing completed. Results and documentation saved to:\", out_dir, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85d5b04-ec21-4c0c-8879-d78563d5ed96",
   "metadata": {},
   "source": [
    "## Step 2: Format Output\n",
    "### Format A: Phenotype Reformatting \n",
    "\n",
    "**Input:**\n",
    "- `{celltype}_residuals.txt` from Step 1 Option A (in `2_residuals/{celltype}/`)\n",
    "\n",
    "**Process:**\n",
    "1. Reads residuals file with proper handling of peak IDs and sample columns\n",
    "2. Parses peak coordinates from peak IDs (format: `chr-start-end`)\n",
    "3. Converts peaks to **midpoint coordinates**:\n",
    "   ```r\n",
    "   midpoint = (start + end) / 2\n",
    "   start = midpoint\n",
    "   end = midpoint + 1\n",
    "4. Creates BED format: `#chr`, `start`, `end`, `ID` (peak_id), followed by sample expression values\n",
    "5. Sorts by chromosome and genomic position using `setorder(bed_data, '#chr', start, end)`\n",
    "6. Writes BED file with headers\n",
    "7. Compresses with `bgzip -f`\n",
    "\n",
    "**Output:** `output/3_phenotype_processing/{celltype}`\n",
    "\n",
    "- `{celltype}_kellis_snatac_phenotype.bed.gz`: QTL-ready BED file with peak midpoint coordinates and bgzip-compressed format\n",
    "\n",
    "**Use Case:**\n",
    "Standard caQTL (chromatin accessibility QTL) mapping where you want to identify genetic variants affecting chromatin accessibility independent of demographic factors. Ready for FastQTL, TensorQTL, or QTLtools.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed50732-7daf-409e-af3a-b3014808cb46",
   "metadata": {},
   "source": [
    "#### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f4dbe14-2acf-4e8b-b63b-47c67f5f68e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(data.table)\n",
    "library(stringr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff83118f-c112-4b03-9256-0a5e98322422",
   "metadata": {},
   "source": [
    "#### Load input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f840ed2-3c7c-4a75-8a28-8c90c6f43d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get command line arguments\n",
    "#args <- commandArgs(trailingOnly = TRUE)\n",
    "#if (length(args) < 1) {\n",
    "#  celltype <- \"Astro\"  # Default cell type\n",
    "#  cat(\"No cell type specified, using default:\", celltype, \"\\n\")\n",
    "#} else {\n",
    "#  celltype <- args[1]\n",
    "#  cat(\"Processing cell type:\", celltype, \"\\n\")\n",
    "#}\n",
    "\n",
    "celltype <- \"Astro\"\n",
    "\n",
    "# Define input and output paths\n",
    "reformat_input_dir <- file.path(output_dir,\"2_residuals\")\n",
    "#output_dir <- \"/home/al4225/project/kellis_snatac/output/3_phenotype_processing\"\n",
    "reformat_output_dir <- paste0(output_dir,\"/3_phenotype_processing/\", celltype)\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "dir.create(reformat_output_dir, recursive = TRUE, showWarnings = FALSE)\n",
    "\n",
    "# Check if input directory exists\n",
    "celltype_dir <- file.path(reformat_input_dir, celltype)\n",
    "if (!dir.exists(reformat_input_dir)) {\n",
    "  cat(\"Cell type directory not found:\", celltype_dir, \"\\n\")\n",
    "  cat(\"Using backup directory...\\n\")\n",
    "  celltype_dir <- file.path(reformat_input_dir, \"backup\", celltype)\n",
    "  if (!dir.exists(celltype_dir)) {\n",
    "    stop(\"Backup directory not found either: \", celltype_dir)\n",
    "  }\n",
    "}\n",
    "\n",
    "input_file <- file.path(celltype_dir, paste0(celltype, \"_residuals.txt\"))\n",
    "output_bed <- file.path(reformat_output_dir, paste0(celltype, \"_kellis_snatac_phenotype.bed\"))\n",
    "\n",
    "# Check if input file exists\n",
    "if (!file.exists(input_file)) {\n",
    "  stop(\"Input file not found: \", input_file)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d4672d-41e7-4533-b2e3-2eccf8c3b4d4",
   "metadata": {},
   "source": [
    "#### Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90e6f9a9-8c97-4890-ae20-be758d8c7f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names from first line: SM-CJK5G, SM-CTDQN, SM-CJEIE, SM-CTEM5, SM-CJJ27, SM-CJIWT ...\n",
      "Reading residuals file: /restricted/projectnb/xqtl/jaempawi/atac_seq/output/kellis/2_residuals/Astro/Astro_residuals.txt \n",
      "File has more data columns than header columns. Assuming first column is peak IDs.\n",
      "First few peak IDs: chr1-816945-817430, chr1-817852-818227, chr1-818626-819158, chr1-826625-827679, chr1-869475-870473, chr1-903568-904912 \n",
      "First few column names: SM-CJK5G, SM-CTDQN, SM-CJEIE, SM-CTEM5, SM-CJJ27, SM-CJIWT \n"
     ]
    }
   ],
   "source": [
    "# Read the first line manually to get the column names\n",
    "first_line <- readLines(input_file, n = 1)\n",
    "col_names <- unlist(strsplit(first_line, split = \"\\t\"))\n",
    "cat(\"Column names from first line:\", paste(head(col_names), collapse = \", \"), \"...\\n\")\n",
    "\n",
    "# Read the residuals file using fread but skip the header\n",
    "cat(\"Reading residuals file:\", input_file, \"\\n\")\n",
    "residuals <- fread(input_file, header = FALSE, skip = 1)\n",
    "\n",
    "# If we have an extra column compared to the header line (often happens with rownames)\n",
    "if (ncol(residuals) > length(col_names)) {\n",
    "  cat(\"File has more data columns than header columns. Assuming first column is peak IDs.\\n\")\n",
    "  peak_ids <- residuals[[1]]\n",
    "  residuals <- residuals[, -1, with = FALSE]\n",
    "  # Set proper column names excluding the first one which was for peak IDs\n",
    "  if (length(col_names) >= 2) {\n",
    "    setnames(residuals, col_names)\n",
    "  }\n",
    "} else {\n",
    "  # Normal case - columns match\n",
    "  setnames(residuals, col_names)\n",
    "  peak_ids <- residuals[[1]]\n",
    "  residuals <- residuals[, -1, with = FALSE]\n",
    "}\n",
    "\n",
    "# Check that peak IDs and column names were properly extracted\n",
    "cat(\"First few peak IDs:\", paste(head(peak_ids), collapse = \", \"), \"\\n\")\n",
    "cat(\"First few column names:\", paste(head(colnames(residuals)), collapse = \", \"), \"\\n\")\n",
    "\n",
    "# Parse peak IDs to get chromosome, start, and end\n",
    "# cat(\"Parsing peak IDs into BED format\\n\")\n",
    "# parsed_peaks <- data.table(\n",
    "#   '#chr' = sapply(strsplit(peak_ids, \"-\"), `[`, 1),\n",
    "#   start = as.integer(sapply(strsplit(peak_ids, \"-\"), `[`, 2)),\n",
    "#   end = as.integer(sapply(strsplit(peak_ids, \"-\"), `[`, 3)),\n",
    "#   ID = peak_ids  # Use peak_id as the ID column (4th column in BED)\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfa7749-21b4-4db8-b0d1-a82d7d3b3994",
   "metadata": {},
   "source": [
    "#### Parse peak ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb6e8c9c-66f4-452e-b5ba-c88f9ca9de17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing peak IDs into BED format with midpoint coordinates\n"
     ]
    }
   ],
   "source": [
    "# Parse peak IDs to get chromosome, start, and end\n",
    "cat(\"Parsing peak IDs into BED format with midpoint coordinates\\n\")\n",
    "\n",
    "parsed_peaks <- data.table(\n",
    "  '#chr' = sapply(strsplit(peak_ids, \"-\"), `[`, 1),\n",
    "  start = as.integer((as.integer(sapply(strsplit(peak_ids, \"-\"), `[`, 2)) + \n",
    "                     as.integer(sapply(strsplit(peak_ids, \"-\"), `[`, 3))) / 2),\n",
    "  end = as.integer(((as.integer(sapply(strsplit(peak_ids, \"-\"), `[`, 2)) + \n",
    "                    as.integer(sapply(strsplit(peak_ids, \"-\"), `[`, 3))) / 2) + 1),                   \n",
    "  ID = peak_ids  # Use peak_id as the ID column (4th column in BED)\n",
    ")\n",
    "\n",
    "\n",
    "# Add validation to ensure end > start\n",
    "if (any(parsed_peaks$end <= parsed_peaks$start)) {\n",
    "  cat(\"Warning: Found records where end <= start. Fixing...\\n\")\n",
    "  parsed_peaks[end <= start, end := start + 1]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eb8753-a035-4b01-906d-d552abf522d5",
   "metadata": {},
   "source": [
    "#### Create BED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45df0f55-ce77-4e36-8af6-09511031d650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing BED file to: /restricted/projectnb/xqtl/jaempawi/atac_seq/output/kellis/3_phenotype_processing/Astro/Astro_kellis_snatac_phenotype.bed \n",
      "Compressing BED file with bgzip...\n",
      "Process completed.\n",
      "Output file: /restricted/projectnb/xqtl/jaempawi/atac_seq/output/kellis/3_phenotype_processing/Astro/Astro_kellis_snatac_phenotype.bed.gz \n"
     ]
    }
   ],
   "source": [
    "# Create BED format with all data columns\n",
    "# BED format: chr, start, end, ID, followed by phenotype values with sample IDs as column names\n",
    "bed_data <- cbind(parsed_peaks, residuals)\n",
    "\n",
    "# Sort by chromosome and position\n",
    "setorder(bed_data, '#chr', start, end)\n",
    "\n",
    "# Write BED file with headers\n",
    "cat(\"Writing BED file to:\", output_bed, \"\\n\")\n",
    "fwrite(bed_data, output_bed, sep = \"\\t\", col.names = TRUE, quote = FALSE)\n",
    "\n",
    "# Compress the BED file with bgzip\n",
    "cat(\"Compressing BED file with bgzip...\\n\")\n",
    "bgzip_cmd <- paste(\"bgzip -f\", output_bed)\n",
    "system(bgzip_cmd)\n",
    "\n",
    "cat(\"Process completed.\\n\")\n",
    "cat(\"Output file:\", paste0(output_bed, \".gz\"), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daba0745-5ce6-4a32-8ad0-3e0647f15052",
   "metadata": {},
   "source": [
    "### Format B: Regions Peak Filtering\n",
    "**Input:**\n",
    "- `{celltype}_filtered_raw_counts.txt` from Step 1 Option B (in `2_residuals/{celltype}/`)\n",
    "\n",
    "**Process:**\n",
    "1. Reads filtered raw counts for each cell type\n",
    "2. Parses peak coordinates from peak IDs (format: `chr-start-end`)\n",
    "3. Calculates peak metrics:\n",
    "   - `peakwidth`: End - Start\n",
    "   - `midpoint`: (Start + End) / 2\n",
    "4. Filters for **specific genomic regions of interest**:\n",
    "   - **Chr7:** 28,000,000 - 28,300,000 bp (300kb region)\n",
    "   - **Chr11:** 85,050,000 - 86,200,000 bp (1.15Mb region)\n",
    "5. Includes peaks that overlap these regions (start, end, or span the boundaries)\n",
    "6. Calculates summary statistics:\n",
    "   - `total_count`: Sum of counts across all samples per peak\n",
    "   - `weighted_count`: total_count / peakwidth (normalizes for peak size)\n",
    "\n",
    "**Output:** `output/4_regions/{celltype}/`\n",
    "- `filtered_regions_of_interest.txt`: Full count data for peaks in target regions (all samples × selected peaks)\n",
    "- `filtered_regions_of_interest_summary.txt`: Peak metadata with coordinates and count statistics\n",
    "\n",
    "**Use Case:** \n",
    "Hypothesis-driven analysis of specific genomic loci (e.g., AD risk loci like APOE region, TREM2 locus) where biological variation should be preserved for interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b87b48b-c7ec-4799-bba1-4574d4d660fe",
   "metadata": {},
   "source": [
    "#### Filter and save data for a specific cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "891a02b1-8f7c-4b97-b151-371b65ec52a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: /restricted/projectnb/xqtl/jaempawi/atac_seq/output/kellis/2_residuals/Mic/Mic_filtered_raw_counts.txt \n",
      "File not found: /restricted/projectnb/xqtl/jaempawi/atac_seq/output/kellis/2_residuals/Astro/Astro_filtered_raw_counts.txt \n",
      "File not found: /restricted/projectnb/xqtl/jaempawi/atac_seq/output/kellis/2_residuals/Oligo/Oligo_filtered_raw_counts.txt \n",
      "Processing Exc data from: /restricted/projectnb/xqtl/jaempawi/atac_seq/output/kellis/2_residuals/Exc/Exc_filtered_raw_counts.txt \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in fread(input_file, check.names = TRUE):\n",
      "“Detected 83 column names but the data has 84 columns (i.e. invalid file). Added an extra default column name for the first column which is guessed to be row names or an index. Use setnames() afterwards if this guess is not correct, or fix the file write command that created the file to create a valid file.”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 276 regions of interest for Exc \n",
      "Saved filtered data to: /restricted/projectnb/xqtl/jaempawi/atac_seq/output/kellis/3_regions/Exc/Exc_filtered_regions_of_interest.txt \n",
      "Saved summary data to: /restricted/projectnb/xqtl/jaempawi/atac_seq/output/kellis/3_regions/Exc/Exc_filtered_regions_of_interest_summary.txt \n",
      "\n",
      "File not found: /restricted/projectnb/xqtl/jaempawi/atac_seq/output/kellis/2_residuals/Inh/Inh_filtered_raw_counts.txt \n",
      "File not found: /restricted/projectnb/xqtl/jaempawi/atac_seq/output/kellis/2_residuals/OPC/OPC_filtered_raw_counts.txt \n"
     ]
    }
   ],
   "source": [
    "# Function to filter and save data for a specific cell type with additional summary information\n",
    "filter_and_save_by_celltype <- function(celltype) {\n",
    "  # Create output directory\n",
    "  peak_output_dir <- file.path(output_dir,\"3_regions\", celltype)\n",
    "  dir.create(peak_output_dir, recursive = TRUE, showWarnings = FALSE)\n",
    "  \n",
    "  # Load filtered raw counts for the cell type\n",
    "  input_file <- file.path(output_dir,\"2_residuals\", celltype, paste0(celltype, \"_filtered_raw_counts.txt\"))\n",
    "  \n",
    "  # Check if file exists before reading\n",
    "  if (!file.exists(input_file)) {\n",
    "    cat(\"File not found:\", input_file, \"\\n\")\n",
    "    return(FALSE)\n",
    "  }\n",
    "  \n",
    "  cat(\"Processing\", celltype, \"data from:\", input_file, \"\\n\")\n",
    "  \n",
    "  # Read data - handling the row names issue\n",
    "  cell_data <- fread(input_file, check.names = TRUE)\n",
    "  \n",
    "  # If the first column has no name (it's row names), give it a proper name\n",
    "  if (names(cell_data)[1] == \"V1\") {\n",
    "    setnames(cell_data, \"V1\", \"peak_id\")\n",
    "  }\n",
    "  \n",
    "  # Parse coordinates from peak IDs\n",
    "  cell_data$chr <- gsub(\"^(chr[^-]+)-.*$\", \"\\\\1\", cell_data$peak_id)\n",
    "  cell_data$start <- as.numeric(gsub(\"^chr[^-]+-([0-9]+)-.*$\", \"\\\\1\", cell_data$peak_id))\n",
    "  cell_data$end <- as.numeric(gsub(\"^chr[^-]+-[0-9]+-([0-9]+)$\", \"\\\\1\", cell_data$peak_id))\n",
    "  \n",
    "  # Calculate additional metrics\n",
    "  cell_data$peakwidth <- cell_data$end - cell_data$start\n",
    "  cell_data$midpoint <- (cell_data$start + cell_data$end) / 2\n",
    "  \n",
    "  # Filter for chr7 and chr11\n",
    "  chr_filtered <- cell_data[cell_data$chr %in% c(\"chr7\", \"chr11\"), ]\n",
    "  \n",
    "  # Filter for the specific regions\n",
    "  region_filtered <- chr_filtered[\n",
    "    # Chr7: 28,000kb-28,300kb\n",
    "    (chr_filtered$chr == \"chr7\" & \n",
    "     ((chr_filtered$start >= 28000000 & chr_filtered$start <= 28300000) | \n",
    "      (chr_filtered$end >= 28000000 & chr_filtered$end <= 28300000) |\n",
    "      (chr_filtered$start <= 28000000 & chr_filtered$end >= 28300000))) |\n",
    "    # Chr11: 85,050kb-86,200kb\n",
    "    (chr_filtered$chr == \"chr11\" & \n",
    "     ((chr_filtered$start >= 85050000 & chr_filtered$start <= 86200000) | \n",
    "      (chr_filtered$end >= 85050000 & chr_filtered$end <= 86200000) |\n",
    "      (chr_filtered$start <= 85050000 & chr_filtered$end >= 86200000))),\n",
    "  ]\n",
    "  \n",
    "  # Report results\n",
    "  cat(\"Found\", nrow(region_filtered), \"regions of interest for\", celltype, \"\\n\")\n",
    "  \n",
    "  # Save the original filtered data (with all columns)\n",
    "  output_file <- file.path(peak_output_dir, paste0(celltype,\"_filtered_regions_of_interest.txt\"))\n",
    "  write.table(region_filtered, output_file, sep=\"\\t\", quote=FALSE, row.names=FALSE)\n",
    "  cat(\"Saved filtered data to:\", output_file, \"\\n\")\n",
    "  \n",
    "  # Calculate total count for each peak (sum across all samples)\n",
    "  # Get only the numeric columns (exclude the metadata columns we added)\n",
    "  meta_cols <- c(\"peak_id\", \"chr\", \"start\", \"end\", \"peakwidth\", \"midpoint\")\n",
    "  count_cols <- setdiff(names(region_filtered), meta_cols)\n",
    "  \n",
    "  # Ensure all count columns are numeric\n",
    "  region_filtered_counts <- region_filtered[, ..count_cols]\n",
    "  region_filtered_counts <- as.data.frame(apply(region_filtered_counts, 2, as.numeric))\n",
    "  \n",
    "  # Calculate total count\n",
    "  region_filtered$total_count <- rowSums(region_filtered_counts)\n",
    "  \n",
    "  # Calculate weighted count (total count / peakwidth)\n",
    "  region_filtered$weighted_count <- region_filtered$total_count / region_filtered$peakwidth\n",
    "  \n",
    "  # Create a summary data frame with just the metadata columns\n",
    "  summary_df <- data.table(\n",
    "    peak_id = region_filtered$peak_id,\n",
    "    chr = region_filtered$chr,\n",
    "    start = region_filtered$start,\n",
    "    end = region_filtered$end,\n",
    "    midpoint = region_filtered$midpoint,\n",
    "    peakwidth = region_filtered$peakwidth,\n",
    "    total_count = region_filtered$total_count,\n",
    "    weighted_count = region_filtered$weighted_count\n",
    "  )\n",
    "  \n",
    "  # Save the summary data\n",
    "  summary_file <- file.path(peak_output_dir, paste0(celltype,\"_filtered_regions_of_interest_summary.txt\"))\n",
    "  write.table(summary_df, summary_file, sep=\"\\t\", quote=FALSE, row.names=FALSE)\n",
    "  cat(\"Saved summary data to:\", summary_file, \"\\n\\n\")\n",
    "  \n",
    "  return(TRUE)\n",
    "}\n",
    "\n",
    "# List of cell types to process\n",
    "celltypes <- c(\"Mic\", \"Astro\", \"Oligo\", \"Exc\", \"Inh\", \"OPC\")\n",
    "\n",
    "\n",
    "# Process each cell type\n",
    "for (ct in celltypes) {\n",
    "  filter_and_save_by_celltype(ct)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c7cc6f-5080-45c1-8204-3b77623a557e",
   "metadata": {},
   "source": [
    "## Alternative Pseudobulk Pipeline with Batch Correction\n",
    "\n",
    "This is an alternative preprocessing approach using ComBat-seq for explicit batch correction. It is from a different dataset (multiome) but demonstrates an alternative strategy when batch effects are severe.\n",
    "\n",
    "---\n",
    "\n",
    "#### When to Use This Approach:\n",
    "- Strong batch effects that need active correction (not just covariate adjustment)\n",
    "- Data from multiple sequencing runs with substantial technical artifacts\n",
    "- When batch confounds with biological variables of interest\n",
    "- Visible batch clusters in PCA/t-SNE plots\n",
    "\n",
    "---\n",
    "\n",
    "**Input:**\n",
    "- QC'd Seurat object with metadata: `{celltype}_qced.rds`\n",
    "- Pseudobulk peak counts: `{celltype}.rds`\n",
    "- Sample covariates: `rosmap_cov.txt`\n",
    "- Batch information: `SampleSheet.csv` and `sampleSheetAfterQc.csv`\n",
    "- hg38 blacklist: `hg38-blacklist.v2.bed.gz`\n",
    "\n",
    "**Process:**\n",
    "1. Loads Seurat object and extracts metadata\n",
    "2. Loads pseudobulk peak count matrix\n",
    "3. Calculates technical QC metrics per sample:\n",
    "   - `TSSEnrichment`: Median TSS enrichment\n",
    "   - `NucleosomeRatio`: Median nucleosome ratio\n",
    "   - `LogPercMt`: Log-transformed percent mitochondrial reads\n",
    "   - `LogUniqueFrags`: Log-transformed unique fragments per sample\n",
    "4. Filters blacklisted genomic regions using `foverlaps()`\n",
    "5. Calculates peak metrics:\n",
    "   - `LogTotalUniquePeaks`: Log-transformed count of unique peaks detected\n",
    "6. Merges with demographic covariates (msex, age_death, pmi, study)\n",
    "7. Creates DGEList object\n",
    "8. Applies expression filtering with `filterByExpr()`:\n",
    "   - `min.count = 5`: Minimum 5 reads in at least one sample\n",
    "   - `min.total.count = 7`: Minimum 7 total reads across all samples\n",
    "   - `min.prop = 0.7`: Peak must be expressed in ≥70% of samples\n",
    "9. TMM normalization with `calcNormFactors()`\n",
    "10. **Batch processing:**\n",
    "    - Loads sequencing batch information from sample sheets\n",
    "    - Filters singleton batches (batches with only 1 sample)\n",
    "    - Filters samples with low library sizes (< 5000 recommended)\n",
    "11. **ComBat-seq batch correction:**\n",
    "    ```r\n",
    "    adjusted_counts <- ComBat_seq(\n",
    "      counts = dge$counts, \n",
    "      batch = batches\n",
    "    )\n",
    "    ```\n",
    "12. Fits linear model on batch-corrected counts using `voom()` and `lmFit()`:\n",
    "    ```r\n",
    "    model <- ~ pmi + msex + age_death + \n",
    "               TSSEnrichment + NucleosomeRatio + LogPercMt +\n",
    "               LogUniqueFrags + LogTotalUniquePeaks + \n",
    "               study\n",
    "    ```\n",
    "    Note: Batch is NOT in the model because it was corrected by ComBat-seq\n",
    "13. Calculates residuals using `predictOffset()`: `offset + residuals`\n",
    "    - `offset`: Predicted expression at median/reference covariate values\n",
    "    - `residuals`: Unexplained variation after removing covariate effects\n",
    "\n",
    "However, ComBat-seq encountered persistent errors with this dataset:\n",
    "```\n",
    "Error in .compressOffsets(y, lib.size = lib.size, offset = offset):\n",
    "offsets must be finite values\n",
    "```\n",
    "\n",
    "**Issues with ComBat-seq for this data:**\n",
    "- Dataset had 232 samples across 60 batches (many small batches)\n",
    "- Error persisted even after:\n",
    "  - Filtering samples with low library sizes (< 5000)\n",
    "  - Removing singleton batches\n",
    "  - Ensuring all counts and library sizes were finite\n",
    "  - Verifying no zero-sum peaks\n",
    "- Likely due to internal ComBat-seq edge case with highly fragmented batch structure\n",
    "\n",
    "**Solution:** Use limma's `removeBatchEffect` which operates on log-CPM values and is more robust to small batch sizes.\n",
    "\n",
    "**Process:**\n",
    "1. Loads Seurat object and extracts metadata\n",
    "2. Loads pseudobulk peak count matrix\n",
    "3. Calculates technical QC metrics per sample:\n",
    "   - `TSSEnrichment`: Median TSS enrichment\n",
    "   - `NucleosomeRatio`: Median nucleosome ratio\n",
    "   - `LogPercMt`: Log-transformed percent mitochondrial reads\n",
    "   - `LogUniqueFrags`: Log-transformed unique fragments per sample\n",
    "4. Filters blacklisted genomic regions using `foverlaps()`\n",
    "5. Calculates peak metrics:\n",
    "   - `LogTotalUniquePeaks`: Log-transformed count of unique peaks detected\n",
    "6. Merges with demographic covariates (msex, age_death, pmi, study)\n",
    "7. Creates DGEList object\n",
    "8. Applies expression filtering with `filterByExpr()`:\n",
    "   - `min.count = 5`: Minimum 5 reads in at least one sample\n",
    "   - `min.total.count = 7`: Minimum 7 total reads across all samples\n",
    "   - `min.prop = 0.7`: Peak must be expressed in ≥70% of samples\n",
    "9. TMM normalization with `calcNormFactors()`\n",
    "10. **Batch processing:**\n",
    "    - Loads sequencing batch information from sample sheets\n",
    "    - Filters singleton batches (batches with only 1 sample)\n",
    "11. **Batch correction using limma's removeBatchEffect:**\n",
    "    ```r\n",
    "    # Get log-CPM values\n",
    "    logCPM <- cpm(dge, log=TRUE, prior.count=1)\n",
    "    \n",
    "    # Remove batch effects\n",
    "    adjusted_logCPM <- removeBatchEffect(\n",
    "      logCPM,\n",
    "      batch = batches,\n",
    "      design = model.matrix(~1, data=dge$samples)\n",
    "    )\n",
    "    \n",
    "    # Convert back to counts scale (approximate)\n",
    "    adjusted_counts <- 2^adjusted_logCPM * mean(dge$$samples$$lib.size) / 1e6\n",
    "    adjusted_counts <- round(adjusted_counts)\n",
    "    adjusted_counts[adjusted_counts < 0] <- 0\n",
    "    ```\n",
    "12. Updates sample alignment:\n",
    "    - Ensures valid_samples match current filtered data\n",
    "    - Aligns covariates with sample order\n",
    "    - Converts tibble to data.frame and sets rownames\n",
    "13. Fits linear model on batch-corrected counts using `voom()` and `lmFit()`:\n",
    "    ```r\n",
    "    model <- ~ pmi + msex + age_death + TSSEnrichment + NucleosomeRatio + LogPercMt + LogUniqueFrags + LogTotalUniquePeaks + study\n",
    "    ```\n",
    "    Note: Batch is NOT in the model because it was corrected by removeBatchEffect\n",
    "14. Creates new DGEList with batch-corrected counts\n",
    "15. Recalculates library sizes and TMM normalization factors\n",
    "16. Calculates residuals using `predictOffset()`: `offset + residuals`\n",
    "    - `offset`: Predicted expression at median/reference covariate values\n",
    "    - `residuals`: Unexplained variation after removing covariate effects\n",
    "\n",
    "\n",
    "**Output:** `output/3_calculateResiduals/{celltype})`\n",
    "- `{celltype}_results.rds`: Complete results object containing:\n",
    "  - `dge`: Batch-corrected DGEList\n",
    "  - `offset`: Predicted offset values\n",
    "  - `residuals`: Model residuals\n",
    "  - `batch_adjusted_counts`: removeBatchEffect corrected counts\n",
    "  - `final_data`: Final adjusted expression (offset + residuals)\n",
    "  - `valid_samples`: Sample IDs after filtering\n",
    "  - `design`: Design matrix\n",
    "  - `fit`: Linear model fit object\n",
    "- `{celltype}_residuals.txt`: Final covariate-adjusted peak accessibility (log2-CPM scale)\n",
    "\n",
    "\n",
    "**Key Differences from ComBat-seq:**\n",
    "- Operates on log-CPM values (not integer counts)\n",
    "- More robust to small/unbalanced batch sizes\n",
    "- Does not model mean-variance relationship (simpler correction)\n",
    "- Approximate back-transformation to count scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2d3390-250e-43dc-848d-a02bcea6bbee",
   "metadata": {},
   "source": [
    "#### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "780bafdb-0057-4b18-b5a7-7c7ea3450926",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(data.table)\n",
    "library(stringr)\n",
    "library(Seurat)\n",
    "library(dplyr)\n",
    "library(sva)\n",
    "library(edgeR)\n",
    "library(limma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c26a146-535e-4123-aca0-f41e6f3f5a0b",
   "metadata": {},
   "source": [
    "#### Create output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "52e0c2f0-73da-4cd5-b43d-b744e4b0d726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing celltype: Astro \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "'/restricted/projectnb/xqtl/jaempawi/atac_seq/output/kellis/2_residuals_batch_corrected/Astro'"
      ],
      "text/latex": [
       "'/restricted/projectnb/xqtl/jaempawi/atac\\_seq/output/kellis/2\\_residuals\\_batch\\_corrected/Astro'"
      ],
      "text/markdown": [
       "'/restricted/projectnb/xqtl/jaempawi/atac_seq/output/kellis/2_residuals_batch_corrected/Astro'"
      ],
      "text/plain": [
       "[1] \"/restricted/projectnb/xqtl/jaempawi/atac_seq/output/kellis/2_residuals_batch_corrected/Astro\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat(\"Processing celltype:\", celltype, \"\\n\")\n",
    "\n",
    "residual_out_dir <- file.path(output_dir,\"2_residuals_batch_corrected\", celltype)\n",
    "dir.create(residual_out_dir, recursive = TRUE, showWarnings = FALSE)\n",
    "residual_out_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9990a617-310c-47aa-9895-712db99b766f",
   "metadata": {},
   "source": [
    "#### Create predictOffset function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f0a1ed02-4744-422e-9830-90886cb9ec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictOffset <- function(fit) {\n",
    "  # Define which variables are factors and which are continuous\n",
    "  usedFactors <- c(\"study\") \n",
    "  usedContinuous <- c(\"pmi\", \"msex\", \"age_death\", \n",
    "                      \"TSSEnrichment\", \"NucleosomeRatio\", \"LogPercMt\",\n",
    "                      \"LogUniqueFrags\", \"LogTotalUniquePeaks\")\n",
    "  \n",
    "  # Get indices for factor and continuous variables\n",
    "  facInd <- unlist(lapply(as.list(usedFactors), \n",
    "                         function(f) {return(grep(paste(\"^\", f, sep=\"\"), \n",
    "                                                colnames(fit$design)))}))\n",
    "  contInd <- unlist(lapply(as.list(usedContinuous), \n",
    "                          function(f) {return(grep(paste(\"^\", f, sep=\"\"), \n",
    "                                                 colnames(fit$design)))}))\n",
    "  \n",
    "  # Verify design matrix structure\n",
    "  stopifnot(!any(duplicated(c(1, facInd, contInd))))\n",
    "  stopifnot(all(c(1, facInd, contInd) %in% 1:ncol(fit$design)))\n",
    "  stopifnot(1:ncol(fit$design) %in% c(1, facInd, contInd))\n",
    "  \n",
    "  # Create new design matrix with median values\n",
    "  D <- fit$design\n",
    "  D[, facInd] <- 0\n",
    "  medContVals <- apply(D[, contInd], 2, median)\n",
    "  for (i in 1:length(medContVals)) {\n",
    "    D[, names(medContVals)[i]] <- medContVals[i]\n",
    "  }\n",
    "  \n",
    "  # Calculate offsets\n",
    "  stopifnot(all(colnames(coefficients(fit)) == colnames(D)))\n",
    "  offsets <- apply(coefficients(fit), 1, function(c) {\n",
    "    return(D %*% c)\n",
    "  })\n",
    "  offsets <- t(offsets)\n",
    "  colnames(offsets) <- rownames(fit$design)\n",
    "  \n",
    "  return(offsets)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af303e3f-b918-4cc4-8155-1f7974b48cde",
   "metadata": {},
   "source": [
    "#### Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e00e96b8-9e1f-4387-8a3c-fcca2ae2d342",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = readRDS(file.path(input_dir,\"Endothelial_qced.rds\"))\n",
    "meta = meta_data@meta.data\n",
    "peak <- readRDS(file.path(input_dir,'Endothelial.rds'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d746195e-ca0a-4695-a42c-64bf9c677c85",
   "metadata": {},
   "source": [
    "#### Process technical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb915f93-9088-4db6-b663-dc893e25fe85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 7</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>demuxlet_SNG.BEST.GUESS</th><th scope=col>TSSEnrichment</th><th scope=col>NucleosomeRatio</th><th scope=col>PercMt</th><th scope=col>UniqueFrags</th><th scope=col>LogPercMt</th><th scope=col>LogUniqueFrags</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>MAP26637867</td><td> 7.315</td><td>1.4334204</td><td>0.5755396</td><td>87</td><td>-0.5524456</td><td>4.465908</td></tr>\n",
       "\t<tr><td>MAP50106992</td><td> 6.237</td><td>1.5703523</td><td>1.7753647</td><td>19</td><td> 0.5740064</td><td>2.944439</td></tr>\n",
       "\t<tr><td>MAP61344957</td><td>14.587</td><td>0.7494390</td><td>0.2781486</td><td> 7</td><td>-1.2795960</td><td>1.945910</td></tr>\n",
       "\t<tr><td>ROS11430815</td><td> 6.606</td><td>1.4644619</td><td>0.2029770</td><td> 9</td><td>-1.5946577</td><td>2.197225</td></tr>\n",
       "\t<tr><td>ROS15738428</td><td>12.620</td><td>0.9908817</td><td>0.1889933</td><td>32</td><td>-1.6660383</td><td>3.465736</td></tr>\n",
       "\t<tr><td>ROS20945666</td><td> 7.609</td><td>1.6842417</td><td>0.3885004</td><td>65</td><td>-0.9454585</td><td>4.174387</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 7\n",
       "\\begin{tabular}{lllllll}\n",
       " demuxlet\\_SNG.BEST.GUESS & TSSEnrichment & NucleosomeRatio & PercMt & UniqueFrags & LogPercMt & LogUniqueFrags\\\\\n",
       " <chr> & <dbl> & <dbl> & <dbl> & <int> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t MAP26637867 &  7.315 & 1.4334204 & 0.5755396 & 87 & -0.5524456 & 4.465908\\\\\n",
       "\t MAP50106992 &  6.237 & 1.5703523 & 1.7753647 & 19 &  0.5740064 & 2.944439\\\\\n",
       "\t MAP61344957 & 14.587 & 0.7494390 & 0.2781486 &  7 & -1.2795960 & 1.945910\\\\\n",
       "\t ROS11430815 &  6.606 & 1.4644619 & 0.2029770 &  9 & -1.5946577 & 2.197225\\\\\n",
       "\t ROS15738428 & 12.620 & 0.9908817 & 0.1889933 & 32 & -1.6660383 & 3.465736\\\\\n",
       "\t ROS20945666 &  7.609 & 1.6842417 & 0.3885004 & 65 & -0.9454585 & 4.174387\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 7\n",
       "\n",
       "| demuxlet_SNG.BEST.GUESS &lt;chr&gt; | TSSEnrichment &lt;dbl&gt; | NucleosomeRatio &lt;dbl&gt; | PercMt &lt;dbl&gt; | UniqueFrags &lt;int&gt; | LogPercMt &lt;dbl&gt; | LogUniqueFrags &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| MAP26637867 |  7.315 | 1.4334204 | 0.5755396 | 87 | -0.5524456 | 4.465908 |\n",
       "| MAP50106992 |  6.237 | 1.5703523 | 1.7753647 | 19 |  0.5740064 | 2.944439 |\n",
       "| MAP61344957 | 14.587 | 0.7494390 | 0.2781486 |  7 | -1.2795960 | 1.945910 |\n",
       "| ROS11430815 |  6.606 | 1.4644619 | 0.2029770 |  9 | -1.5946577 | 2.197225 |\n",
       "| ROS15738428 | 12.620 | 0.9908817 | 0.1889933 | 32 | -1.6660383 | 3.465736 |\n",
       "| ROS20945666 |  7.609 | 1.6842417 | 0.3885004 | 65 | -0.9454585 | 4.174387 |\n",
       "\n"
      ],
      "text/plain": [
       "  demuxlet_SNG.BEST.GUESS TSSEnrichment NucleosomeRatio PercMt    UniqueFrags\n",
       "1 MAP26637867              7.315        1.4334204       0.5755396 87         \n",
       "2 MAP50106992              6.237        1.5703523       1.7753647 19         \n",
       "3 MAP61344957             14.587        0.7494390       0.2781486  7         \n",
       "4 ROS11430815              6.606        1.4644619       0.2029770  9         \n",
       "5 ROS15738428             12.620        0.9908817       0.1889933 32         \n",
       "6 ROS20945666              7.609        1.6842417       0.3885004 65         \n",
       "  LogPercMt  LogUniqueFrags\n",
       "1 -0.5524456 4.465908      \n",
       "2  0.5740064 2.944439      \n",
       "3 -1.2795960 1.945910      \n",
       "4 -1.5946577 2.197225      \n",
       "5 -1.6660383 3.465736      \n",
       "6 -0.9454585 4.174387      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tech_vars <- meta %>%\n",
    "  group_by(demuxlet_SNG.BEST.GUESS) %>%\n",
    "  summarise(\n",
    "    TSSEnrichment = median(TSSEnrichment),\n",
    "    NucleosomeRatio = median(NucleosomeRatio),\n",
    "    PercMt = median(percent.mt),\n",
    "    UniqueFrags = n_distinct(demuxlet_BARCODE)\n",
    "  ) %>%\n",
    "  mutate(\n",
    "    LogPercMt = log(PercMt + 1e-6),\n",
    "    LogUniqueFrags = log(UniqueFrags + 1e-6)\n",
    "  )\n",
    "head(tech_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc81763-f662-4f49-a154-7002da0953dd",
   "metadata": {},
   "source": [
    "#### Process peaks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1ba88004-7088-4b2d-b169-3fc6f424a540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load blacklist\n",
    "blacklist_df <- fread(file.path(input_dir,\"hg38-blacklist.v2.bed.gz\"))\n",
    "colnames(blacklist_df) <- c(\"chr\", \"start\", \"end\", \"label\")\n",
    "\n",
    "# Process peak coordinates\n",
    "peak_df <- data.table(\n",
    "  peak_name = rownames(peak),\n",
    "  chr = str_extract(rownames(peak), \"chr[0-9XY]+\"),\n",
    "  start = as.integer(str_extract(rownames(peak), \"(?<=:)[0-9]+\")),\n",
    "  end = as.integer(str_extract(rownames(peak), \"(?<=-)[0-9]+\"))\n",
    ")\n",
    "\n",
    "# Filter blacklisted peaks\n",
    "setkey(blacklist_df, chr, start, end)\n",
    "setkey(peak_df, chr, start, end)\n",
    "overlapping_peaks <- foverlaps(peak_df, blacklist_df, nomatch=0)\n",
    "blacklisted_peaks <- unique(overlapping_peaks$peak_name)\n",
    "filtered_peak <- peak[!rownames(peak) %in% blacklisted_peaks,]\n",
    "\n",
    "# Calculate peak metrics\n",
    "peak_metrics <- data.frame(\n",
    "  sample = colnames(filtered_peak),\n",
    "  TotalUniquePeaks = colSums(filtered_peak > 0)\n",
    ") %>%\n",
    "  mutate(LogTotalUniquePeaks = log(TotalUniquePeaks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087e03aa-3830-4b0b-a291-2e0447b36d99",
   "metadata": {},
   "source": [
    "#### Load and merge covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "970879a5-7964-468d-9b53-7fbcc88ac24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples after joining: 233 \n",
      "Sample IDs: MAP26637867, MAP50106992, MAP61344957, ROS11430815, ROS15738428, ROS20945666 ...\n"
     ]
    }
   ],
   "source": [
    "covariates <- fread(file.path(input_dir,'rosmap_cov.txt')) %>%\n",
    "  select('#id', msex, age_death, pmi, study)\n",
    "\n",
    "all_covs <- tech_vars %>%\n",
    "  inner_join(peak_metrics, by = c(\"demuxlet_SNG.BEST.GUESS\" = \"sample\")) %>%\n",
    "  inner_join(covariates, by = c(\"demuxlet_SNG.BEST.GUESS\" = \"#id\"))\n",
    "\n",
    "cat(\"Number of samples after joining:\", nrow(all_covs), \"\\n\")\n",
    "cat(\"Sample IDs:\", paste(head(all_covs$demuxlet_SNG.BEST.GUESS), collapse=\", \"), \"...\\n\")\n",
    "\n",
    "# Impute missing values\n",
    "for(col in c(\"pmi\", \"age_death\")) {\n",
    "  all_covs[[col]][is.na(all_covs[[col]])] <- median(all_covs[[col]], na.rm=TRUE)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c51fa4-c3e4-4e1c-84f4-599d8d1bf156",
   "metadata": {},
   "source": [
    "#### Create DGE object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6608fc5-a07c-47aa-8996-96996f9297ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dge <- DGEList(\n",
    "  counts = filtered_peak,\n",
    "  samples = all_covs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4756f2-9410-4529-81f4-bca4e5ae510c",
   "metadata": {},
   "source": [
    "#### Filter low counts and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9ba397d-049e-4d80-bf6f-984ee8b50724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of peaks before filtering: 130930 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in filterByExpr.DGEList(dge, min.count = 5, min.total.count = 15, :\n",
      "“All samples appear to belong to the same group.”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of peaks after filtering: 21197 \n"
     ]
    }
   ],
   "source": [
    "cat(\"Number of peaks before filtering:\", nrow(dge), \"\\n\")\n",
    "\n",
    "# keep <- filterByExpr(dge) #only 2 peaks left in mic\n",
    "# default paramter:\n",
    "# keep <- filterByExpr(y, \n",
    "#                      min.count = 10,     # for one sample, min reads \n",
    "#                      min.total.count = 15, # min reads overall\n",
    "#                      min.prop = 0.7) \n",
    "\n",
    "keep <- filterByExpr(dge, \n",
    "                     min.count = 5,     # for one sample, min reads \n",
    "                     min.total.count = 15, # min reads overall\n",
    "                     min.prop = 0.1,\n",
    "                     group = NULL) \n",
    "\n",
    "dge <- dge[keep, , keep.lib.sizes=TRUE] #mic: from 130930 to 2\n",
    "cat(\"Number of peaks after filtering:\", nrow(dge), \"\\n\")\n",
    "dge <- calcNormFactors(dge, method=\"TMM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce856212-efb8-4a52-b16f-fb178d39b47b",
   "metadata": {},
   "source": [
    "#### Load batch information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7a2bcb0a-9e56-4cab-9439-259cb880a66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22mJoining with `by = join_by(ProjID)`\n"
     ]
    }
   ],
   "source": [
    "sample_file <- file.path(input_dir,\"SampleSheet.csv\")\n",
    "wgs_qc_file <- file.path(input_dir,\"sampleSheetAfterQc.csv\")\n",
    "\n",
    "sample <- fread(sample_file, colClasses = \"character\")\n",
    "wgs_qc <- fread(wgs_qc_file, colClasses = \"character\")\n",
    "sample <- sample %>%\n",
    "  inner_join(wgs_qc) %>%\n",
    "  select(SequencingID, SampleID)\n",
    "\n",
    "# Extract batch information\n",
    "batches <- sample$SequencingID\n",
    "names(batches) <- sample$SampleID\n",
    "\n",
    "valid_samples <- colnames(dge$counts)\n",
    "batches <- batches[valid_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e9ccbe-c1c5-4f29-9f7e-bd9fa967e367",
   "metadata": {},
   "source": [
    "#### Run ComBat-seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d278d1bf-b8d9-47af-8cc3-8d0fb7d8eebe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error: all(colnames(dge$counts) == names(batches)) is not TRUE\n",
     "output_type": "error",
     "traceback": [
      "Error: all(colnames(dge$counts) == names(batches)) is not TRUE\nTraceback:\n",
      "1. stop(simpleError(msg, call = if (p <- sys.parent(1L)) sys.call(p)))"
     ]
    }
   ],
   "source": [
    "# Filter batches with only one sample\n",
    "batch_counts <- table(batches)\n",
    "valid_batches <- names(batch_counts[batch_counts > 1])\n",
    "batches <- batches[batches %in% valid_batches]\n",
    "valid_samples <- names(batches)\n",
    "\n",
    "keep <- colnames(dge$counts) %in% names(batches)\n",
    "dge <- dge[keep, , keep.lib.sizes=TRUE]\n",
    "batches <- batches[colnames(dge$counts)]\n",
    "stopifnot(all(colnames(dge$counts) == names(batches)))\n",
    "\n",
    "cat(\"Number of samples after batch filtering:\", length(valid_samples), \"\\n\")\n",
    "cat(\"Number of batches:\", length(unique(batches)), \"\\n\")\n",
    "\n",
    "# Run ComBat-seq\n",
    "adjusted_counts <- ComBat_seq(\n",
    "  counts = dge$counts, \n",
    "  batch = batches\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e219247-72d4-44e5-bd5c-4dffe90537e9",
   "metadata": {},
   "source": [
    "#### Create model and run voom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fef7c108-0ca0-42ca-b6b8-4ca3410bb507",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]): contrasts can be applied only to factors with 2 or more levels\n",
     "output_type": "error",
     "traceback": [
      "Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]): contrasts can be applied only to factors with 2 or more levels\nTraceback:\n",
      "1. model.matrix.default(model, data = all_covs[valid_samples, ])",
      "2. `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]])",
      "3. stop(\"contrasts can be applied only to factors with 2 or more levels\")",
      "4. .handleSimpleError(function (cnd) \n . {\n .     watcher$capture_plot_and_output()\n .     cnd <- sanitize_call(cnd)\n .     watcher$push(cnd)\n .     switch(on_error, continue = invokeRestart(\"eval_continue\"), \n .         stop = invokeRestart(\"eval_stop\"), error = NULL)\n . }, \"contrasts can be applied only to factors with 2 or more levels\", \n .     base::quote(`contrasts<-`(`*tmp*`, value = contr.funs[1 + \n .         isOF[nn]])))"
     ]
    }
   ],
   "source": [
    "model <- ~ pmi + msex + age_death + \n",
    "  TSSEnrichment + NucleosomeRatio + LogPercMt +\n",
    "  LogUniqueFrags + LogTotalUniquePeaks + \n",
    "  study\n",
    "\n",
    "# Update design matrix for remaining samples\n",
    "design <- model.matrix(model, data=all_covs[valid_samples,])\n",
    "stopifnot(is.fullrank(design))\n",
    "\n",
    "dge_adjusted <- dge[, valid_samples]  \n",
    "dge_adjusted$counts <- adjusted_counts[, valid_samples] \n",
    "\n",
    "# Run voom and fit model\n",
    "v <- voom(dge_adjusted[, valid_samples], design, plot=FALSE)\n",
    "fit <- lmFit(v, design)\n",
    "fit <- eBayes(fit)\n",
    "\n",
    "# Calculate offset and residuals\n",
    "offset <- predictOffset(fit)\n",
    "resids <- residuals(fit, y=v)\n",
    "\n",
    "# Verify dimensions\n",
    "stopifnot(all(rownames(offset) == rownames(resids)) &\n",
    "          all(colnames(offset) == colnames(resids)))\n",
    "\n",
    "# Final adjusted data\n",
    "stopifnot(all(dim(offset) == dim(resids)))\n",
    "stopifnot(all(colnames(offset) == colnames(resids)))\n",
    "\n",
    "final_data <- offset + resids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba1b486-bfcf-4488-90b8-252d94d256a2",
   "metadata": {},
   "source": [
    "#### Run LIMMA as Combat-seq alternative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dbbe0cd9-9375-40d4-8d44-1d6556d12dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Use limma's removeBatchEffect instead\n",
    "# Get log-CPM values\n",
    "logCPM <- cpm(dge, log=TRUE, prior.count=1)\n",
    "\n",
    "# Remove batch effects\n",
    "adjusted_logCPM <- removeBatchEffect(\n",
    "  logCPM,\n",
    "  batch = batches,\n",
    "  design = model.matrix(~1, data=dge$samples)\n",
    ")\n",
    "\n",
    "# Convert back to counts scale (approximate)\n",
    "adjusted_counts <- 2^adjusted_logCPM * mean(dge$samples$lib.size) / 1e6\n",
    "adjusted_counts <- round(adjusted_counts)\n",
    "adjusted_counts[adjusted_counts < 0] <- 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8e252b-bf0d-467f-9990-3fc4b0b2f99c",
   "metadata": {},
   "source": [
    "#### Create model and run voom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "56c20501-f7db-43b2-bd7d-47d32cc43d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update valid_samples to match current data\n",
    "valid_samples <- colnames(dge)\n",
    "\n",
    "# Get aligned covariates\n",
    "filtered_covs <- all_covs[match(valid_samples, all_covs$demuxlet_SNG.BEST.GUESS), ]\n",
    "filtered_covs <- as.data.frame(filtered_covs)  # Convert from tibble\n",
    "rownames(filtered_covs) <- valid_samples\n",
    "\n",
    "\n",
    "# Build model formula\n",
    "model_formula <- ~ pmi + msex + age_death + \n",
    "  TSSEnrichment + NucleosomeRatio + LogPercMt +\n",
    "  LogUniqueFrags + LogTotalUniquePeaks + \n",
    "  study\n",
    "\n",
    "# Create design matrix\n",
    "design <- model.matrix(model_formula, data=filtered_covs)\n",
    "rownames(design) <- valid_samples\n",
    "\n",
    "stopifnot(is.fullrank(design))\n",
    "stopifnot(all(rownames(design) == colnames(dge)))\n",
    "\n",
    "# Create properly formatted DGEList with adjusted counts\n",
    "dge_adjusted <- DGEList(\n",
    "  counts = adjusted_counts,\n",
    "  samples = filtered_covs\n",
    ")\n",
    "\n",
    "# Recalculate library sizes and normalization factors\n",
    "dge_adjusted$samples$lib.size <- colSums(dge_adjusted$counts)\n",
    "dge_adjusted <- calcNormFactors(dge_adjusted, method=\"TMM\")\n",
    "\n",
    "stopifnot(all(rownames(design) == colnames(dge_adjusted)))\n",
    "\n",
    "# Run voom and fit model\n",
    "v <- voom(dge_adjusted, design, plot=FALSE)\n",
    "fit <- lmFit(v, design)\n",
    "fit <- eBayes(fit)\n",
    "\n",
    "# Calculate offset and residuals\n",
    "offset <- predictOffset(fit)\n",
    "resids <- residuals(fit, y=v)\n",
    "\n",
    "# Final adjusted data\n",
    "final_data <- offset + resids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0093455-7ff7-47cb-9e31-baf913bbb4cd",
   "metadata": {},
   "source": [
    "#### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "10cce409-a132-41a6-b294-877e55e136c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: /restricted/projectnb/xqtl/jaempawi/atac_seq/output/kellis/2_residuals_batch_corrected/Astro \n"
     ]
    }
   ],
   "source": [
    "saveRDS(list(\n",
    "  dge = dge_adjusted,\n",
    "  offset = offset,\n",
    "  residuals = resids,\n",
    "  batch_adjusted_counts = adjusted_counts,\n",
    "  final_data = final_data,\n",
    "  valid_samples = valid_samples,\n",
    "  design = design,\n",
    "  fit = fit\n",
    "), file = file.path(residual_out_dir, paste0(celltype, \"_results.rds\")))\n",
    "\n",
    "# Write final residual data to file\n",
    "write.table(final_data,\n",
    "            file = file.path(residual_out_dir, paste0(celltype, \"_residuals.txt\")), \n",
    "            quote=FALSE)\n",
    "\n",
    "cat(\"Results saved to:\", residual_out_dir, \"\\n\")               "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
