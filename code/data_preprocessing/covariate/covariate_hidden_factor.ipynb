{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Factor Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This workflow implements three procedures for hidden factor analysis for omcis data:\n",
    "\n",
    "1. The [Probabilistic Estimation of Expression Residuals (PEER) method](https://github.com/PMBio/peer/wiki/Tutorial), a method also used for GTEx eQTL data analysis. \n",
    "2. Factor analysis using Bi-Cross validation, Owen, Art & Wang, Jingshu. (2015). Bi-Cross-Validation for Factor Analysis. Statistical Science. 31. 10.1214/15-STS539. with software package `APEX` (Corbin Quick, Li Guan, Zilin Li, Xihao Li, Rounak Dey, Yaowu Liu, Laura Scott, Xihong Lin, bioRxiv 2020.12.18.423490; doi: https://doi.org/10.1101/2020.12.18.423490)\n",
    "3. PCA with automatic determination of the number of factors to use. This is mainly inspired by a [recent benchmark from Jessica Li's group](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-022-02761-4).\n",
    "\n",
    "\n",
    "We chose to use a PCA based approach for the xQTL project, although additional considerations should be taken for single-cell eQTL analysis as investigated in [this paper](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-023-02873-5)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input\n",
    "\n",
    "1. `protocol_example.protein.bed.gz`\n",
    "2. `protocol_example.samples.protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.gz`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "\n",
    "1. `protocol_example.protein.protocol_example.samples.protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.residual.bed.gz`\n",
    "2. `protocol_example.protein.protocol_example.samples.protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.Marchenko_PC.gz`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minumal Working Example\n",
    "\n",
    "The proteomics data used in this MWE can be found on [synapse](https://www.synapse.org/#!Synapse:syn52369482)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Compute Residual on Merged Conflicts and Perform Hidden Factor Analysis\n",
    "Timing: < 1 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sos run pipeline/covariate_hidden_factor.ipynb Marchenko_PC \\\n",
    "   --cwd output/covariate \\\n",
    "   --phenoFile output/phenotype/protocol_example.protein.bed.gz  \\\n",
    "   --covFile output/covariate/protocol_example.samples.protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.gz \\\n",
    "   --mean-impute-missing \\\n",
    "   --container singularity/PCAtools.sif"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "INFO: Running computing residual on merged covariates:\n",
    "INFO: computing residual on merged covariates is completed.\n",
    "INFO: computing residual on merged covariates output:   output/covariate/protocol_example.protein.protocol_example.samples.protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.residual.bed.gz\n",
    "INFO: Running Marchenko_PC_2:\n",
    "INFO: Marchenko_PC_2 is completed.\n",
    "INFO: Marchenko_PC_2 output:   output/covariate/protocol_example.protein.protocol_example.samples.protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.Marchenko_PC.gz\n",
    "INFO: Workflow Marchenko_PC (ID=wb2797da52c726752) is executed successfully with 2 completed steps.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sos run covariate_hidden_factor.ipynb -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "usage: sos run pipeline/covariate_hidden_factor.ipynb\n",
    "               [workflow_name | -t targets] [options] [workflow_options]\n",
    "  workflow_name:        Single or combined workflows defined in this script\n",
    "  targets:              One or more targets to generate\n",
    "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
    "  workflow_options:     Double-hyphen workflow-specific parameters\n",
    "\n",
    "Workflows:\n",
    "  Marchenko_PC\n",
    "  PEER\n",
    "  BiCV\n",
    "\n",
    "Global Workflow Options:\n",
    "  --cwd output (as path)\n",
    "                        The output directory for generated files. MUST BE FULL\n",
    "                        PATH\n",
    "  --covFile VAL (as path, required)\n",
    "                        Merged Covariates File\n",
    "  --phenoFile VAL (as path, required)\n",
    "                        Path to the input molecular phenotype data.\n",
    "  --name  f'{phenoFile:bnn}.{covFile:bn}'\n",
    "\n",
    "  --job-size 1 (as int)\n",
    "                        For cluster jobs, number commands to run per job\n",
    "  --walltime 5h\n",
    "                        Wall clock time expected\n",
    "  --mem 16G\n",
    "                        Memory expected\n",
    "  --numThreads 8 (as int)\n",
    "                        Number of threads\n",
    "  --container ''\n",
    "                        Software container option\n",
    "  --entrypoint  ('micromamba run -a \"\" -n' + ' ' + re.sub(r'(_apptainer:latest|_docker:latest|\\.sif)$', '', container.split('/')[-1])) if container else \"\"\n",
    "\n",
    "\n",
    "Sections\n",
    "  *_1:\n",
    "    Workflow Options:\n",
    "      --[no-]mean-impute-missing (default to False)\n",
    "  Marchenko_PC_2:\n",
    "  PEER_2:\n",
    "    Workflow Options:\n",
    "      --N 0 (as int)\n",
    "                        N PEER factors, If do not specify or specified as 0,\n",
    "                        default values suggested by GTEx (based on different\n",
    "                        sample size) will be used\n",
    "      --iteration 1000 (as int)\n",
    "                        Default values from PEER software: The number of max\n",
    "                        iteration\n",
    "      --tol 0.001 (as float)\n",
    "                        Prior parameters parameter: Alpha_a = 0.001 parameter:\n",
    "                        Alpha_b = 0.1 parameter: Eps_a = 0.1 parameter: Eps_b =\n",
    "                        10.0 Tolarance parameters\n",
    "      --[no-]r2-tol (default to False)\n",
    "                        parameter: var_tol = 0.00001 minimum variance explained\n",
    "                        criteria to drop factors while training\n",
    "      --convergence-mode fast\n",
    "                        Convergence mode: Convergence mode for MOFAr \"slow\",\n",
    "                        \"medium\" or \"fast\", corresponding to 1e-5%, 1e-4% or\n",
    "                        1e-3% deltaELBO change.\n",
    "  PEER_3:\n",
    "  BiCV_2:\n",
    "  BiCV_3:\n",
    "    Workflow Options:\n",
    "      --N 0 (as int)\n",
    "                        N factors, if not specify, calculated based on sample\n",
    "                        size according to GTeX\n",
    "      --iteration 10 (as int)\n",
    "                        The number of iteration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Compute Residual on Merged Conflicts and Perform Hidden Factor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "[*_1(computing residual on merged covariates)]\n",
    "parameter: mean_impute_missing = False\n",
    "input: phenoFile, covFile\n",
    "output: f'{cwd}/{name}.residual.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = \"${ }\", stderr = f'{_output:nn}.stderr', stdout = f'{_output:nn}.stdout' , container = container, entrypoint = entrypoint\n",
    "\n",
    "    mean_impute <- function(d){\n",
    "      f <- apply(d, 2, function(x) mean(x, na.rm = TRUE))\n",
    "      for (i in 1:length(f)) d[,i][which(is.na(d[,i]))] <- f[i]\n",
    "      return(d)\n",
    "    }\n",
    "  \n",
    "    library(dplyr)\n",
    "    library(readr)\n",
    "    pheno = read_delim(${_input[0]:r},delim = \"\\t\")\n",
    "    covariate= read_delim(${_input[1]:r},delim = \"\\t\") \n",
    "\n",
    "    # Extract samples in both files (Outliers will be removed in here as they are no longer presented in the header of factor)\n",
    "    extraction_sample_list <- intersect(colnames(pheno), colnames(covariate)) \n",
    "    \n",
    "    \n",
    "    if(length(extraction_sample_list) == 0){\n",
    "      stop(\"No samples are overlapped in two files!\")\n",
    "    }\n",
    "    \n",
    "    ## Report sample counts:\n",
    "    print(paste((ncol(pheno) - 4), \"samples are in the phenotype file\", sep = \" \"))\n",
    "    print(paste((ncol(covariate) - 1), \"samples are in the covariate file\", sep = \" \"))\n",
    "\n",
    "    ## Report identical samples:\n",
    "    print(paste(length(extraction_sample_list), \"samples overlap between phenotype & covariate files and are included in the analysis:\", sep = \" \"))\n",
    "    print(extraction_sample_list)\n",
    "\n",
    "    ## Report non-overlapping samples :\n",
    "    covariate_missing = covariate %>% select(-all_of('#id')) %>% select(-all_of(extraction_sample_list))\n",
    "    print(paste(ncol(covariate_missing), \"samples in the covariate file are missing from the phenotype file:\", sep = \" \"))\n",
    "    print(colnames(covariate_missing))\n",
    "\n",
    "    pheno_missing = pheno %>% select(-c(1:4)) %>% select(-all_of(extraction_sample_list))\n",
    "    print(paste(ncol(pheno_missing), \"samples in the phenotype file are missing from the covariate file:\", sep = \" \"))\n",
    "    print(colnames(pheno_missing))\n",
    "\n",
    "    # Subset the data:\n",
    "    covariate = covariate[,extraction_sample_list]%>%as.matrix()%>%t()\n",
    "    pheno_id = pheno%>%select(1:4)\n",
    "    pheno = pheno%>%select(all_of(rownames(covariate)))%>%as.matrix()%>%t()\n",
    "    if (${\"T\" if mean_impute_missing else \"F\"}) {\n",
    "      pheno = mean_impute(pheno)\n",
    "    } else {\n",
    "      if(sum(is.na(pheno)) > 0){ stop(\"NA in phenotype input is not allowed!\") }\n",
    "    }\n",
    "    # Get residual \n",
    "    pheno_resid = .lm.fit(x = cbind(1,covariate), y = pheno)$residuals\n",
    "    pheno_output = cbind(pheno_id, pheno_resid%>%t())\n",
    "    pheno_output%>%write_delim(\"${_output:n}\",delim = \"\\t\")\n",
    "  \n",
    "bash: expand = \"${ }\", stderr = f'{_output:nn}.stderr', stdout = f'{_output:nn}.stdout', container = container, entrypoint = entrypoint\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix -p bed ${_output}\n",
    "\n",
    "    stdout=${_output:n}.stdout \n",
    "    for i in ${_output} ; do \n",
    "    echo \"output_info: $i \" >> $stdout;\n",
    "    echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "    echo \"output_rows:\" `zcat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "    echo \"output_column:\" `zcat $i | head -1 | wc -w `   >> $stdout;\n",
    "    echo \"output_preview:\"   >> $stdout;\n",
    "    zcat $i | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "[Marchenko_PC_2]\n",
    "output: f'{cwd}/{_input:bnnn}.Marchenko_PC.gz'\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: container=container, expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', entrypoint = entrypoint\n",
    "    library(\"dplyr\")\n",
    "    library(\"readr\")\n",
    "    library(\"PCAtools\")\n",
    "    library('BiocSingular')\n",
    "    residExpPath  = \"${_input}\"\n",
    "    covPath = \"${covFile}\"\n",
    "    residExpDF <- read_delim(residExpPath, show_col_types=FALSE)\n",
    "    covDF <- read_delim(covPath, show_col_types=FALSE)\n",
    "    commonMPSamples <- intersect(colnames(covDF), colnames(residExpDF))\n",
    "    covDFcommon <- cbind(covDF[, 1], covDF[, commonMPSamples])\n",
    "  \n",
    "    residExpPC <- pca(\n",
    "        residExpDF[,commonMPSamples], # The first four columns are: chr, start, end, and gene_id; so we skip those.\n",
    "        scale = TRUE,\n",
    "        center = TRUE,\n",
    "        BSPARAM = ExactParam())\n",
    "    M <- apply(residExpDF[, commonMPSamples], 1, function(X){ (X - mean(X))/sqrt(var(X))});\n",
    "    residSigma2 <- var(as.vector(M));\n",
    "    paste('sigma2:', residSigma2)\n",
    "    \n",
    "    MPPCNum <- chooseMarchenkoPastur(\n",
    "        .dim = dim(residExpDF[, commonMPSamples]), var.explained=residExpPC$sdev^2, noise=residSigma2)\n",
    "    \n",
    "    MPPCsDF <- as.data.frame(residExpPC$rotated[, 1:MPPCNum])\n",
    "\n",
    "    MPColMatrix <-  matrix(c(rep('Hidden_Factor_PC', times=MPPCNum), seq(1, MPPCNum)), ncol=2, nrow=MPPCNum)\n",
    "    colnames(MPPCsDF) <- apply(MPColMatrix, 1, function(X){return(paste0(X[1], X[2]))})\n",
    "    rownames(MPPCsDF) <- colnames(residExpDF[, 5:ncol(residExpDF)])\n",
    "    # Add #id Column\n",
    "    MPPCsDF <- as.data.frame(t(MPPCsDF))\n",
    "    MPPCsDF$id <- rownames(MPPCsDF)\n",
    "    MPPCsDF <- MPPCsDF %>% select(id, everything()) %>% rename(\"#id\" = \"id\")\n",
    "    write_delim((rbind(covDFcommon, MPPCsDF)), \"${_output}\", \"\\t\")\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint = entrypoint\n",
    "        stdout=$[_output:n].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `zcat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `zcat $i | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        zcat $i | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
