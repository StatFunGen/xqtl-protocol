{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "322c23a8",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Covariate data formatting\n",
    "This is the module where the output of factor analysis were merged into 1 covariate file that can be fed into both APEX and tensorQTL\n",
    "\n",
    "## Input\n",
    "1. factor+cov file as output from peer or BiCV factor module, It is assumed it to have columns as #id + samplesname and each rows is a covariateor factor (start with factor_)\n",
    "\n",
    "1. pca file as output from the PCA module\n",
    "\n",
    "## Output\n",
    "1. PCA + Factor + Covariate file\n",
    "\n",
    "## Minumal Working Example\n",
    "\n",
    "An MWE is uploaded to [google drive](https://drive.google.com/drive/folders/1yjTwoO0DYGi-J9ouMsh9fHKfDmsXJ_4I?usp=sharing).\n",
    "The singularity image (sif) for running this MWE is uploaded to [google drive](https://drive.google.com/drive/folders/1mLOS3AVQM8yTaWtCbO8Q3xla98Nr5bZQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab3181d",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "\n",
    "sos run pipeline/covariate_formatting.ipynb merge_pca_covariate \\\n",
    "        --cwd output \\\n",
    "        --pcaFile ../genotype/MWE.pca.rds \\\n",
    "        --covFile MWE.covariate.cov.gz \\\n",
    "        --tol_cov 0.3  \\\n",
    "        --k 3 \\\n",
    "        --container containers/bioinfo.sif\n",
    "\n",
    "sos run /home/hs3163/GIT/xqtl-pipeline/pipeline/covariate_formatting.ipynb merge_pca_covariate \\\n",
    "        --cwd output/data_preprocessing/MWE/covariates \\\n",
    "        --pcaFile output/data_preprocessing/MWE/pca/MWE.MWE.related.filtered.extracted.pca.projected.rds \\\n",
    "        --covFile  MWE.covariate.cov.gz \\\n",
    "        --tol_cov 0.3  \\\n",
    "        --k `awk '$3 < 0.7' output/data_preprocessing/MWE/pca/MWE.MWE.related.filtered.extracted.pca.projected.scree.txt | tail -1 | cut -f 1 ` \\\n",
    "        --container containers/bioinfo.sif\n",
    "\n",
    "\n",
    "sos run pipeline/covariate_formatting.ipynb compute_residual \\\n",
    "        --cwd output \\\n",
    "        --phenoFile MWE.log2cpm.mol_phe.bed.gz \\\n",
    "        --covFile MWE.covariate.cov.gz \\\n",
    "        --container containers/bioinfo.sif\n",
    "\n",
    "sos run pipeline/covariate_formatting.ipynb merge_factor_covariate \\\n",
    "        --cwd output \\\n",
    "        --factorFile ALL.covariate.pca.BiCV.cov.gz \\\n",
    "        --covFile MWE.covariate.cov.gz  \\\n",
    "        --container containers/bioinfo.sif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7804369e",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "The default file name can be overwritten by the `--name` parameter, as demonstrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4835628b",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/covariate_formatting.ipynb merge_factor_covariate \\\n",
    "        --cwd output \\\n",
    "        --factorFile ALL.covariate.pca.BiCV.cov.gz \\\n",
    "        --covFile MWE.covariate.cov.gz  \\\n",
    "        --container containers/bioinfo.sif --name \"demo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ff958",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Command Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1b1516f",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run covariate_formatting.ipynb\n",
      "               [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  merge_pca_covariate\n",
      "  compute_residual\n",
      "  merge_factor_covariate\n",
      "\n",
      "Global Workflow Options:\n",
      "  --cwd output (as path)\n",
      "                        The output directory for generated files.\n",
      "  --covFile VAL (as path, required)\n",
      "                        The covariate file\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "  --walltime 5h\n",
      "                        Wall clock time expected\n",
      "  --mem 2G\n",
      "                        Memory expected\n",
      "  --numThreads 8 (as int)\n",
      "                        Number of threads\n",
      "  --container ''\n",
      "                        Software container option\n",
      "  --nCov -1 (as int)\n",
      "                        The number of the external covariates to be included, -1\n",
      "                        means includs all of them, 0 means include none of them,\n",
      "                        but keeping only the header (Basicaaly just formatting\n",
      "                        the PCs).\n",
      "  --tol-cov -1.0 (as float)\n",
      "                        Tolerance of missingness in covariates, -1 means quit,\n",
      "                        otherwise for covariate with missing rate larger than\n",
      "                        tol_cov will be removed, with missing rate smaller than\n",
      "                        tol_cov will be mean_imputed.\n",
      "\n",
      "Sections\n",
      "  merge_pca_covariate:\n",
      "    Workflow Options:\n",
      "      --pcaFile VAL (as path, required)\n",
      "                        The PCA file. an RDS file as the output of the pca\n",
      "                        module\n",
      "      --k 20 (as int)\n",
      "                        The number of PCs to retained, by default is 20, in\n",
      "                        pratice should be the number of pc that captured more\n",
      "                        than 70% PVE\n",
      "      --name  f'{covFile:bn}.{pcaFile:bn}'\n",
      "\n",
      "  compute_residual_1:\n",
      "    Workflow Options:\n",
      "      --phenoFile VAL (as path, required)\n",
      "                        Path to the input molecular phenotype data.\n",
      "      --name  f'{phenoFile:bnn}.{covFile:bn}'\n",
      "\n",
      "  compute_residual_2:   tabix via samtools\n",
      "  merge_factor_covariate:\n",
      "    Workflow Options:\n",
      "      --factorFile VAL (as path, required)\n",
      "      --name  f'{factorFile:bnn}.{covFile:bn}'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sos run covariate_formatting.ipynb -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebbf33c0",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# The output directory for generated files. \n",
    "parameter: cwd = path(\"output\")\n",
    "# The covariate file\n",
    "parameter: covFile = path\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"5h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"2G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 8\n",
    "# Software container option\n",
    "parameter: container = \"\"\n",
    "# The number of the external covariates to be included, -1 means includs all of them, 0 means include none of them,\n",
    "# but keeping only the header (Basicaaly just formatting the PCs).\n",
    "parameter: nCov = -1\n",
    "\n",
    "# Tolerance of missingness in covariates, -1 means quit, otherwise for covariate with missing rate larger than tol_cov will be removed,\n",
    "# with missing rate smaller than tol_cov will be mean_imputed.\n",
    "parameter: tol_cov = -1.0\n",
    "\n",
    "cwd = path(f\"{cwd:a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4466f8de",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[merge_pca_covariate]\n",
    "# The PCA file. an RDS file as the output of the pca module\n",
    "parameter: pcaFile = path\n",
    "# The number of PCs to retained, by default is 20, in pratice should be the number of pc that captured more than 70% PVE\n",
    "parameter: k = 20\n",
    "parameter:name = f'{covFile:bn}.{pcaFile:bn}'\n",
    "# Outliers\n",
    "parameter: outliersFile = path(\".\") \n",
    "parameter: remove_outliers = False\n",
    "## stop if no outliersFile was provided.\n",
    "stop_if(remove_outliers and not outliersFile.is_file(), msg = \"No outliers file specified, please add outliers file or remove the remove-outliers flag\")\n",
    "input: pcaFile, covFile\n",
    "output:  f'{cwd:a}/{name}.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "        library(\"dplyr\")\n",
    "        library(\"tibble\")\n",
    "        library(\"readr\")\n",
    "        compute_missing <- function(mtx){\n",
    "          miss <- sum(is.na(mtx))/length(mtx)\n",
    "          return(miss)\n",
    "        }\n",
    "\n",
    "        mean_impute <- function(mtx){\n",
    "          f <- apply(mtx, 2, function(x) mean(x,na.rm = TRUE))\n",
    "          for (i in 1:length(f)) mtx[,i][which(is.na(mtx[,i]))] <- f[i]\n",
    "          return(mtx)\n",
    "        }\n",
    "    \n",
    "        filter_mtx <- function(X, missing_rate_thresh) {\n",
    "            rm_col <- which(apply(X, 2, compute_missing) > missing_rate_thresh)\n",
    "            if (length(rm_col)) X <- X[, -rm_col]\n",
    "            return(mean_impute(X))\n",
    "        }  \n",
    "        pca_output = readRDS(\"$[_input[0]]\")$pc_scores\n",
    "        mtx = pca_output%>%select(contains(\"PC\"))%>%t()\n",
    "        colnames(mtx) <- pca_output$IID\n",
    "        ## Keep only the number of PCs specified\n",
    "        mtx = mtx[1:$[k],]\n",
    "        mtx = mtx%>%as_tibble(rownames = \"#id\")\n",
    "        cov = read_delim(\"$[_input[1]]\",\"\\t\")\n",
    "        colnames(cov)[1] = \"#id\"\n",
    "        ## Retaining only the overlapped samples\n",
    "        int = intersect(colnames(cov),colnames(mtx))\n",
    "        ### Removal of outlier if needed\n",
    "        if ($[\"TRUE\" if remove_outliers else \"FALSE\"]){\n",
    "              outlier = read_delim(\"$[outliersFile]\",\"\\t\",col_names = FALSE)$X2\n",
    "              int = setdiff(int,outlier)\n",
    "              }\n",
    "        cov = cov%>%select(int)\n",
    "        # keep only the desired amount of covariates\n",
    "        if($[nCov] > 0 ){cov = cov[1:$[nCov],]} else if ($[nCov] == 0){cov = cov[$[nCov],]}\n",
    "        mtx = mtx%>%select(int)\n",
    "        output = bind_rows(cov,mtx)\n",
    "        ## Handle missingess in ncov\n",
    "        if($[tol_cov] == -1){if(sum(is.na(output)) > 0 ){ stop(\"NA in covariates/PCs input: Check input file or raise parameter tol_cov to allow for imputation & filtering\")}}\n",
    "        output = output%>%as.data.frame\n",
    "        rownames(output) = output$`#id`\n",
    "        output = filter_mtx(output[,2:ncol(output)],$[tol_cov])%>%as_tibble(rownames = \"#id\")\n",
    "        output%>%write_delim(\"$[_output]\",\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6a451c",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[compute_residual_1]\n",
    "# Path to the input molecular phenotype data.\n",
    "parameter: phenoFile = path\n",
    "parameter:name = f'{phenoFile:bnn}.{covFile:bn}'\n",
    "input: phenoFile, covFile\n",
    "output: f'{cwd}/{name}.resid.bed'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '4h',  mem = '20G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand = \"${ }\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout' , container = container\n",
    "\n",
    "    library(dplyr)\n",
    "    library(readr)\n",
    "\n",
    "    pheno = read_delim(${_input[0]:r},delim = \"\\t\")\n",
    "    covariate= read_delim(${_input[1]:r},delim = \"\\t\") \n",
    "\n",
    "    # Extract samples in both files (Outliers will be removed in here as they are no longer presented in the header of factor)\n",
    "    extraction_sample_list <- intersect(colnames(pheno), colnames(covariate)) \n",
    "    \n",
    "    \n",
    "    if(length(extraction_sample_list) == 0){\n",
    "      stop(\"No samples are overlapped in two files!\")\n",
    "    }\n",
    "    \n",
    "    # Report identical samples:\n",
    "    \n",
    "    print(\"Listed samples are included in the analysis:\")\n",
    "    print(extraction_sample_list)\n",
    "    \n",
    "    # Subset the data:\n",
    "    covariate = covariate[,extraction_sample_list]%>%as.matrix()%>%t()\n",
    "    pheno_id = pheno%>%select(1:4)\n",
    "    pheno = pheno%>%select(rownames(covariate))%>%as.matrix()%>%t()\n",
    "    \n",
    "    # Get residual \n",
    "    pheno_resid = .lm.fit(x = cbind(1,covariate), y = pheno)$residuals\n",
    "    pheno_output = cbind(pheno_id, pheno_resid%>%t())\n",
    "    pheno_output%>%write_delim(${_output[0]:r},delim = \"\\t\")\n",
    "  \n",
    "\n",
    "# tabix via samtools\n",
    "[compute_residual_2]\n",
    "output: f'{_input}.gz'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '4h',  mem = '20G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: expand = \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container\n",
    "    bgzip -f ${_input}\n",
    "    tabix -p bed ${_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c40c8c",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[compute_residual_per_chr_1]\n",
    "# Path to the input molecular phenotype data.\n",
    "parameter: all_phenoFile = path\n",
    "parameter: chr_recipe = path\n",
    "parameter: sample_rate = 0.1\n",
    "import os\n",
    "import pandas as pd\n",
    "chrom_path_ls = pd.read_csv(chr_recipe, sep = \"\\t\")\n",
    "chrom = chrom_path_ls['#id'].tolist() \n",
    "input: for_each = \"chrom\"\n",
    "output: full = f'{cwd}/{all_phenoFile:bn}_chr{_chrom}.{covFile:bn}.resid.bed.gz',\n",
    "        sample = f'{cwd}/{all_phenoFile:bn}_chr{_chrom}.{covFile:bn}.resid_sample.bed'\n",
    "        \n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand = \"${ }\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout' , container = container\n",
    "    library(dplyr)\n",
    "    library(readr)\n",
    "    chr_recipe = read_delim(\"${chr_recipe}\", delim = \"\\t\")\n",
    "    path = chr_recipe %>% filter(`#id` == \"${_chrom}\") %>% pull(`#dir`)\n",
    "    pheno = read_delim(path[[1]] ,delim = \"\\t\")\n",
    "    covariate= read_delim(\"${covFile}\",delim = \"\\t\") \n",
    "\n",
    "    # Extract samples in both files (Outliers will be removed in here as they are no longer presented in the header of factor)\n",
    "    extraction_sample_list <- intersect(colnames(pheno), colnames(covariate)) \n",
    "    \n",
    "    \n",
    "    if(length(extraction_sample_list) == 0){\n",
    "      stop(\"No samples are overlapped in two files!\")\n",
    "    }\n",
    "    \n",
    "    # Report identical samples:\n",
    "    \n",
    "    print(\"Listed samples are included in the analysis:\")\n",
    "    print(extraction_sample_list)\n",
    "    \n",
    "    # Subset the data:\n",
    "    covariate = covariate[,extraction_sample_list]%>%as.matrix()%>%t()\n",
    "    pheno_id = pheno%>%select(1:4)\n",
    "    pheno = pheno%>%select(rownames(covariate))%>%as.matrix()%>%t()\n",
    "    \n",
    "    # Get residual \n",
    "    pheno_resid = .lm.fit(x = cbind(1,covariate), y = pheno)$residuals\n",
    "    pheno_output = cbind(pheno_id, pheno_resid%>%t())\n",
    "    pheno_output%>%write_delim(\"${_output[0]:n}\",delim = \"\\t\")\n",
    "  \n",
    "    # sample features\n",
    "    n = nrow(pheno_output)\n",
    "    n_sample = ceiling(n * ${sample_rate})\n",
    "    pheno_sample = pheno_output[sample(1:n, n_sample),]\n",
    "    pheno_sample %>% write_delim(\"${_output[1]}\", delim = \"\\t\")\n",
    "\n",
    "  \n",
    "bash: expand= \"${ }\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout', container=container\n",
    "    bgzip -f ${_output[0]:n}\n",
    "    tabix '${_output[0]}' -f\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d04fe7f",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# This step also output a sampled residual matrix in case the peer process can't take the large residual matrix\n",
    "# But Peer step is robust enough for the large residuals\n",
    "[compute_residual_per_chr_2]\n",
    "input: group_by = \"all\"\n",
    "parameter: all_phenoFile = path\n",
    "output: recipe = f'{cwd}/{all_phenoFile:bn}.{covFile:bn}.resid.recipe',\n",
    "        sample_pheno_gz = f'{cwd}/{all_phenoFile:bn}.{covFile:bn}.resid.sample.bed.gz',\n",
    "        pheno_gz = f'{cwd}/{all_phenoFile:bn}.{covFile:bn}.all.resid.bed.gz'\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'        \n",
    "R: expand = \"${ }\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout', container = container\n",
    "    library(dplyr)\n",
    "    input_all = str_split(\"${_input}\", \" \")[[1]]\n",
    "    n = length(input_all)\n",
    "    input_recipe = input_all[seq(1, n-1, 2)]\n",
    "    input_sample = input_all[seq(2, n, 2)]\n",
    "  \n",
    "    # sample pheno\n",
    "    sample_pheno = NULL\n",
    "    for(i in 1:length(input_sample)){\n",
    "      tmp = read_delim(input_sample[i], \"\\t\")\n",
    "      sample_pheno = rbind(sample_pheno, tmp)\n",
    "      rm(tmp)}\n",
    "    sample_pheno %>% write_delim(\"${_output[1]:n}\", delim = \"\\t\")\n",
    "  \n",
    "    # pheno\n",
    "    pheno = NULL\n",
    "    for(i in 1:length(input_recipe)){\n",
    "      tmp = read_delim(input_recipe[i], \"\\t\")\n",
    "      pheno = rbind(pheno, tmp)\n",
    "      rm(tmp)}\n",
    "    pheno %>% write_delim(\"${_output[2]:n}\", delim = \"\\t\")\n",
    "  \n",
    "    # recipe\n",
    "    chr = str_extract(input_recipe, \"chr\\\\d+\")\n",
    "    recipe = tibble(`#id` = chr, `#dir` = input_recipe)\n",
    "    recipe $>% write_delim(\"${_output[0]}\",\"\\t\")\n",
    "  \n",
    "bash: expand= \"${ }\", stderr = f'{_output[2]}.stderr', stdout = f'{_output[2]}.stdout', container=container\n",
    "    bgzip -f ${_output[1]:n}\n",
    "    tabix '${_output[1]}' -f\n",
    "    bgzip -f ${_output[2]:n}\n",
    "    tabix '${_output[2]}' -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e4baa04",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[merge_factor_covariate]\n",
    "parameter: factorFile = path\n",
    "parameter:name = f'{factorFile:bnn}.{covFile:bn}'\n",
    "input: factorFile, covFile\n",
    "output:  f'{cwd:a}/{name}.gz'\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "        library(\"dplyr\")\n",
    "        library(\"readr\")\n",
    "        peer_res = read_delim(\"$[_input[0]]\", delim = \"\\t\")\n",
    "        cov_pca = read_delim(\"$[_input[1]]\", delim = \"\\t\")\n",
    "        ## Keep only common samples\n",
    "        com_col = intersect(colnames(peer_res), colnames(cov_pca))\n",
    "        write_delim((rbind(cov_pca[,com_col], peer_res[,com_col])), \"$[_output]\", \"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.21.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
