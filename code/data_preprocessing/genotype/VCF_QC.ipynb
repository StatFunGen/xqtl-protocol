{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unlimited-turtle",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Genotype VCF file quality control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-lincoln",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This implements some recommendations from UK Biobank on [exome sequence data quality control](https://www.medrxiv.org/content/10.1101/2020.11.02.20222232v1.full-text)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-cream",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Overview\n",
    "\n",
    "The goal of this module is to perform QC on VCF files, including \n",
    "\n",
    "1. Handling the formatting of multi-allelic sites, \n",
    "2. Genotype and variant level filtering based on genotype calling qualities. \n",
    "3. Known/novel variants annotation\n",
    "4. Summary statistics before and after QC, in particular the ts/tv ratio, to assess the effectiveness of QC.\n",
    "\n",
    "3 and 4 above are for explorative analysis on the overall quality assessment of genotype data in the VCF files. We annotate known and novel variants because ts/tv are expected to be different between known and novel variants, and is important QC metric to assess the effectiveness of our QC.\n",
    "\n",
    "### Multi-allelic sites\n",
    "\n",
    "Mult-allelic sites can be problematic in many ways for downstreams analysis, even of they are handled in terms of formatting after QC. We provide an optional workflow module to keep only bi-allelic sites from data, although by default we will include these sites in the VCF file we generate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-federal",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Default VCF QC filters\n",
    "\n",
    "\n",
    "1. Genotype depth filters: SNPs DP>10 and Indels DP>10 for indels.\n",
    "2. At least one sample per site passed the allele balance threshold >= 0.15 for SNPs and >=0.20 for indels (heterozygous variants). \n",
    "    - Allele balance is calculated for heterozygotes as the number of bases supporting the least-represented allele over the total number of base observations.\n",
    "3. Genotype quality GQ>20.\n",
    "\n",
    "Filtering are done with `bcftools`. Here is a [useful cheatsheet from github user @elowy01](https://gist.github.com/elowy01/93922762e131d7abd3c7e8e166a74a0b).\n",
    "\n",
    "## A note on TS/TV summary from VCF genotype data\n",
    "\n",
    "`bcftools stats` command provides useful summary statistics including TS/TV ratio, which is routinely used as a quality measure of variant calls. With dbSNP based annotation of novel and known variants, `bcftools` can compute TS/TV for novel and known variants at variant level, and at sample level. It should be noted that variant level TS/TV does not take sample genotype into consideration -- it simply counts the TS and TV event for observed SNPs in the data. Other tools, such as `snpsift`, implements variant level TS/TV by counting TS and TV events in sample genotypes and compute the ratio after summing up TS and TV across all samples. See [here](https://github.com/samtools/bcftools/issues/1526) some discussions on this issue. We provide these TS/TV calculations before and after QC but users should be aware of the difference when interpreting the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-lottery",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Input\n",
    "\n",
    "1. The target `VCF` file\n",
    "    - If its chromosome name does not have the `chr` prefix and you need it to match with reference `fasta` file, please run `rename_chrs` workflow to add `chr`.\n",
    "2. dbSNP database in `VCF` format\n",
    "3. A reference sequence `fasta` file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-possibility",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Output\n",
    "1. QC-ed genotype data in VCF and in PLINK format\n",
    "2. A set of sumstats to help evaluate quality of genotype before and after QC\n",
    "    - Particularly useful is the TS/TV ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-importance",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Minimal working example\n",
    "The MWE is generated via \n",
    "```\n",
    "bcftools query -l get-dosage.ALL.vcf.gz | head -40 > MWE_sample_list\n",
    "bcftools view -S MWE_sample_list  get-dosage.ALL.vcf.gz > sample_filtered.vcf &\n",
    "bgzip -c sample_filtered.vcf >  sample_filtered.vcf.gz\n",
    "tabix -p vcf sample_filtered.vcf.gz\n",
    "bcftools view --regions chr1 sample_filtered.vcf.gz > chr1_sample_filtered.vcf &\n",
    "cat chr1_sample_filtered.vcf | head -20000 > MWE_genotype.vcf\n",
    "```\n",
    "and was stored here: https://drive.google.com/file/d/1sxxPdPIyKma0mAl8TKwhgyRHlOh0Oyrc/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-lyric",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "The MWE was used as follows:\n",
    "\n",
    "```\n",
    "sos run VCF_QC.ipynb rename_chrs \\\n",
    "    --genoFile reference_data/00-All.vcf.gz \\\n",
    "    --cwd reference_data --container ./bioinfo.sif\n",
    "```\n",
    "\n",
    "```\n",
    "sos run VCF_QC.ipynb dbsnp_annotate \\\n",
    "    --genoFile reference_data/00-All.add_chr.vcf.gz \\\n",
    "    --cwd reference_data --container ./bioinfo.sif\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "sos run VCF_QC.ipynb qc    \\\n",
    "--genoFile data/MWE/MWE_genotype.vcf     \\\n",
    "--dbsnp-variants data/reference_data/00-All.add_chr.variants.gz  \\\n",
    "--reference-genome data/reference_data/GRCh38_full_analysis_set_plus_decoy_hla.noALT_noHLA_noDecoy_ERCC.fasta   \\\n",
    "--cwd MWE/output/genotype_1 --container ./bioinfo.sif -J 1 -c csg.yml -q csg  &\n",
    "```\n",
    "To produce the following results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-princeton",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "- Total TS/TV for 19639 known variants before QC: 2.599\n",
    "- Total TS/TV for 19573 known variants after QC: 2.600\n",
    "- There is no novel variants included in the MWE.\n",
    "\n",
    "The Total TS/TV is extracted from the last step of QC. For known variant before QC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "labeled-eating",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.599\n"
     ]
    }
   ],
   "source": [
    "grep Ts/Tv MWE_genotype.leftnorm.known_variant.snipsift_tstv | rev | cut -d',' -f1 | rev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-factory",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "For known variant after QC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "turned-mitchell",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.600\n"
     ]
    }
   ],
   "source": [
    "grep Ts/Tv MWE_genotype.leftnorm.filtered.*_variant.snipsift_tstv | rev | cut -d',' -f1 | rev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-foster",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "For novel variant before/after QC, TS/TV is not avaible since no novel_variants presented in the MWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-score",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "grep Ts/Tv MWE_genotype.leftnorm.novel_variant.snipsift_tstv | rev | cut -d',' -f1 | rev\n",
    "grep Ts/Tv MWE_genotype.leftnorm.filtered.novel_variant.snipsift_tstv | rev | cut -d',' -f1 | rev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-third",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Command Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ongoing-segment",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run VCF_QC.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  rename_chrs\n",
      "  dbsnp_annotate\n",
      "  qc\n",
      "\n",
      "Global Workflow Options:\n",
      "  --genoFile VAL (as path, required)\n",
      "                        input\n",
      "  --cwd VAL (as path, required)\n",
      "                        Workdir\n",
      "  --numThreads 1 (as int)\n",
      "                        Number of threads\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "  --walltime 5h\n",
      "                        Walltime\n",
      "  --mem 60G\n",
      "  --container ''\n",
      "                        Software container option\n",
      "\n",
      "Sections\n",
      "  rename_chrs:\n",
      "  dbsnp_annotate:\n",
      "  qc_1:                 Handel multi-allelic sites, left normalization of indels\n",
      "                        and add variant ID\n",
      "    Workflow Options:\n",
      "      --dbsnp-variants VAL (as path, required)\n",
      "                        Path to dbSNP variants generated previously\n",
      "      --reference-genome VAL (as path, required)\n",
      "                        Path to fasta file for HG reference genome, eg\n",
      "                        GRCh38_full_analysis_set_plus_decoy_hla.fa\n",
      "      --[no-]bi-allelic (default to False)\n",
      "      --[no-]snp-only (default to False)\n",
      "  qc_2:                 genotype QC\n",
      "    Workflow Options:\n",
      "      --geno-filter 0.1 (as float)\n",
      "                        Maximum missingess per-variant\n",
      "      --DP-snp 10 (as int)\n",
      "                        Sample level QC - read depth (DP) to filter out SNPs\n",
      "                        below this value\n",
      "      --GQ 20 (as int)\n",
      "                        Sample level QC - genotype quality (GQ) of specific\n",
      "                        sample. This measure tells you how confident we are that\n",
      "                        the genotype we assigned to a particular sample is\n",
      "                        correct\n",
      "      --DP-indel 10 (as int)\n",
      "                        Sample level QC - read depth (DP) to filter out indels\n",
      "                        below this value\n",
      "      --AB-snp 0.15 (as float)\n",
      "                        Allele balance for snps\n",
      "      --AB-indel 0.2 (as float)\n",
      "                        Allele balance for indels\n",
      "      --hwe-filter 1e-06 (as float)\n",
      "                        HWE filter\n",
      "  qc_3:\n",
      "  qc_4:\n"
     ]
    }
   ],
   "source": [
    "sos run VCF_QC.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-strain",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "silver-moderator",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# input\n",
    "parameter: genoFile = path\n",
    "# Workdir\n",
    "parameter: cwd = path\n",
    "# Number of threads\n",
    "parameter: numThreads = 1\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Walltime \n",
    "parameter: walltime = '5h'\n",
    "parameter: mem = '60G'\n",
    "# Software container option\n",
    "parameter: container = \"\"\n",
    "# use this function to edit memory string for PLINK input\n",
    "from sos.utils import expand_size\n",
    "cwd = path(f\"{cwd:a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-springfield",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Annotation of known and novel variants\n",
    "\n",
    "The known variant reference can be downloaded from https://ftp.ncbi.nlm.nih.gov/snp/organisms//human_9606_b150_GRCh38p7/VCF/00-All.vcf.gz.\n",
    "\n",
    "The procedure/rationale is [explained in this post](https://hbctraining.github.io/In-depth-NGS-Data-Analysis-Course/sessionVI/lessons/03_annotation-snpeff.html).\n",
    "\n",
    "It takes ~1hr for `rename_chrs` to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-library",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[rename_chrs]\n",
    "# This file can be downloaded from https://ftp.ncbi.nlm.nih.gov/snp/organisms//human_9606_b150_GRCh38p7/VCF/00-All.vcf.gz.\n",
    "input: genoFile\n",
    "output: f\"{cwd}/{_input:bnn}.add_chr.vcf.gz\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container = container, expand= \"${ }\", stderr = f'{_output:nn}.stderr', stdout = f'{_output:nn}.stdout'\n",
    "    for i in {1..22} X Y MT; do echo \"$i chr$i\"; done > ${_output:nn}.chr_name_conv.txt\n",
    "    bcftools annotate --rename-chrs ${_output:nn}.chr_name_conv.txt ${_input} -Oz -o ${_output}\n",
    "    tabix -p vcf ${_output}\n",
    "    rm -f ${_output:nn}.chr_name_conv.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-motion",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[dbsnp_annotate]\n",
    "output: f\"{_input:nn}.variants.gz\"\n",
    "task: trunk_workers = 1, trunk_size=5, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container = container, expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    bcftools query  -f'%CHROM\\t%POS\\t%ID\\t%REF\\t%ALT\\n' ${_input}  | \\\n",
    "        awk 'BEGIN{OFS=\"\\t\";} {if (length ($4) > length ($5)) {print $1,$2,$2+ (length ($4) - 1),$3} else {print $1,$2, $2 + (length ($4) -1 ),$3}}' | \\\n",
    "        bgzip -c > ${_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-radical",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Genotype QC\n",
    "\n",
    "This step handles multi-allelic sites and annotate variants to known and novel. We add an RS ID to variants in dbSNP. Variants without rsID are considered novel variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "twelve-eating",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Handel multi-allelic sites, left normalization of indels and add variant ID\n",
    "[qc_1 (variant preprocessing)]\n",
    "# Path to dbSNP variants generated previously\n",
    "parameter: dbsnp_variants = path\n",
    "# Path to fasta file for HG reference genome, eg GRCh38_full_analysis_set_plus_decoy_hla.fa\n",
    "parameter: reference_genome = path\n",
    "parameter: bi_allelic = False\n",
    "parameter: snp_only = False\n",
    "input: genoFile, group_by = 1\n",
    "output: f'{cwd}/{_input:bnn}.{\"leftnorm\" if not bi_allelic else \"biallelic\"}{\".snp\" if snp_only else \"\"}.vcf.gz'\n",
    "task: trunk_workers = 1, trunk_size=job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container = container, expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "        ${'bcftools norm -m-any' if not bi_allelic else 'bcftools view -m2 -M2'} ${'-v snps' if snp_only else \"\"} ${_input} |\\\n",
    "        bcftools norm --check-ref w -f ${reference_genome}  -Oz|\\\n",
    "        bcftools +fill-tags -- -t all,F_MISSING,'VD=sum(DP)' | \\\n",
    "        bcftools annotate -x ID -I +'%CHROM:%POS:%REF:%ALT' | \\\n",
    "        bcftools annotate -a ${dbsnp_variants}  -h <(echo '##INFO=<ID=RSID,Number=1,Type=String,Description=\"dbSNP rsID\">') -c CHROM,FROM,TO,ID -Oz > ${_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-formation",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This step filter variants based on FILTER PASS, DP and QC, fraction of missing genotypes (all samples), and on HWE, for snps and indels. It will also remove monomorphic sites -- using `bcftools view -c1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "interim-caribbean",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# genotype QC\n",
    "[qc_2 (variant level QC)]\n",
    "# Maximum missingess per-variant\n",
    "parameter: geno_filter = 0.1\n",
    "# Sample level QC - read depth (DP) to filter out SNPs below this value\n",
    "parameter: DP_snp = 10\n",
    "# Sample level QC - genotype quality (GQ) of specific sample. This measure tells you how confident we are that the genotype we assigned to a particular sample is correct\n",
    "parameter: GQ = 20\n",
    "# Sample level QC - read depth (DP) to filter out indels below this value\n",
    "parameter: DP_indel = 10\n",
    "# Allele balance for snps\n",
    "parameter: AB_snp = 0.15\n",
    "# Allele balance for indels\n",
    "parameter: AB_indel = 0.2\n",
    "# HWE filter \n",
    "parameter: hwe_filter = 1e-06\n",
    "output: f\"{_input:nn}.filtered.vcf.gz\"\n",
    "task: trunk_workers = 1, trunk_size=job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container = container, expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    bcftools filter -S . -e '(TYPE=\"SNP\" & (FMT/DP)<${DP_snp} & (FMT/GQ)<${GQ})|(TYPE=\"INDEL\" & (FMT/DP)<${DP_indel} & (FMT/GQ)<${GQ})' ${_input} | \\\n",
    "    bcftools view -c1  | bcftools view -f PASS | \\\n",
    "    bcftools filter -i 'GT=\"hom\" | TYPE=\"snp\" & GT=\"het\" & (FORMAT/AD[*:1])/(FORMAT/AD[*:0] + FORMAT/AD[*:1]) >= ${AB_snp} | TYPE=\"indel\" & GT=\"het\" & (FORMAT/AD[*:1])/(FORMAT/AD[*:0] + FORMAT/AD[*:1]) >= ${AB_indel}' | \\\n",
    "    bcftools filter -i 'F_MISSING<${geno_filter} & HWE>${hwe_filter}' -Oz -o ${_output} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-oxide",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Finally we export it to PLINK 1.0 format, **without keeping allele orders**. Notice that PLINK 1.0 format does not allow for dosages. PLINK 2.0 format support it, but it is generally not supported by downstreams data analysis.  \n",
    "\n",
    "In the following code block the option `--vcf-half-call m`  treat half-call as missing.\n",
    "\n",
    "Also, intentionally, `--keep-allele-order` is not applied. The resulting PLINK will lose ref/alt allele information but will go by major/minor allele, as conventionally used in standard PLINK format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-string",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[qc_3 (export to PLINK)]\n",
    "output: f'{_input:nn}.bed'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container = container, expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    plink --vcf ${_input} \\\n",
    "        --vcf-half-call m \\\n",
    "        --vcf-require-gt \\\n",
    "        --allow-extra-chr \\\n",
    "        --make-bed --out ${_output:n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-influence",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[qc_4 (genotype data summary statistics)]\n",
    "input: output_from('qc_1'), output_from('qc_2'), group_by = 1\n",
    "output: f\"{cwd}/{_input:bnn}.novel_variant_sumstats\", \n",
    "        f\"{cwd}/{_input:bnn}.known_variant_sumstats\", \n",
    "        f\"{cwd}/{_input:bnn}.novel_variant.snipsift_tstv\",\n",
    "        f\"{cwd}/{_input:bnn}.known_variant.snipsift_tstv\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container = container, expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    # Compute summary statistics, including TS/TV\n",
    "    bcftools stats -i 'ID=\".\"' -v  ${_input} > ${_output[0]}\n",
    "    bcftools stats -i 'ID!=\".\"' -v  ${_input} > ${_output[1]}\n",
    "    bcftools filter -i 'ID=\".\"'  ${_input}   | java -jar /opt/snpEff/SnpSift.jar tstv - > ${_output[2]}\n",
    "    bcftools filter -i 'ID!=\".\"' ${_input}  | java -jar /opt/snpEff/SnpSift.jar tstv - > ${_output[3]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "Markdown",
     "markdown",
     "markdown",
     "",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
