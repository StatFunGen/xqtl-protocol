{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Components Analysis\n",
    "\n",
    "This notebook will conduct the final data preparation steps and perform PCA, generating plots and summary statistics."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Steps to generate a PCA include \n",
    "\n",
    "- removing related individuals\n",
    "- pruning variants in linkage disequilibrium (LD)\n",
    "- perform PCA analysis on genotype of unrelated individuals\n",
    "- excluding outlier samples in the PCA space for individuals of homogeneous self-reported ancestry. These outliers may suggest poor genotyping quality or distant relatedness.\n",
    "\n",
    "Pitfalls\n",
    "\n",
    "1. Some of the PCs may capture LD structure rather than population structure (decrease in power to detect associations in these regions of high LD)\n",
    "2. When projecting a new study dataset to the PCA space computed from a reference dataset: projected PCs are shrunk toward 0 in the new dataset\n",
    "3. PC scores may capture outliers that are due to family structure, population structure or other reasons; it might be beneficial to detect and remove these individuals to maximize the population structure captured by PCA (in the case of removing a few outliers) or to restrict analyses to genetically homogeneous samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "\n",
    "Here is a quick recap of PCA analysis for those not immediately familiar with the method. PCA is a mathematical method to reduce dimensionality of the data while retaining most of the variation in the dataset. \n",
    "This is accomplished by identifying directions or Principal Components (PC's) that account for the maximum variation in the data. \n",
    "\n",
    "One common approach to PCA is based on the singular-value decomposition of the the data matrix $X$ (in our case the genotype matrix),\n",
    "\n",
    "$$X = U D V^T,$$\n",
    "\n",
    "where $U$ are the left eigenvectors, $D$ is the diagonal matrix of singular values, and $V$ are the right eigenvectors (also called loadings). \n",
    "\n",
    "PCA can also be done using the eigen-decomposition of $X X^T$:\n",
    "\n",
    "$$X X^T = U S U^T,$$ \n",
    "\n",
    "where $S=D^2$ is the diagonal matrix of eigenvalues.\n",
    "$X$ is usually centred (mean-subtracted) or standardised (mean subtracted, then divided by standard deviation) before PCA.\n",
    "\n",
    "For PCA of SNP genotypes (at least in diploid organisms), the common standardisation is\n",
    "\n",
    "$$X_{ij}^{\\prime} = \\frac{X_{ij} - 2p_j}{\\sqrt{2 p_j (1 - p_j)}},$$\n",
    "\n",
    "where $X_{ij}$ is the genotype (minor allele dosage $\\{0, 1, 2\\}$) for the $i$th individual and the $j$th SNP, and $p_j$ is the minor allele frequency (MAF) for the $j$th SNP. In addition, the eigenvalues are scaled by the number of SNPs $m$ (equivalent to performing the eigen-decomposition of $XX^T/m$)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "1. Estimate relatedness of the individuals in the sample by PLINK 2 that implements the KING algorithm\n",
    "2. Select specific SNPs and samples using PLINK and remove related individuals\n",
    "3. SNPs thining by doing LD-pruning \n",
    "\n",
    "The above steps are implemented in `GWAS_QC.ipynb` workflow.\n",
    "\n",
    "4. Run PCA using only unrelated individuals for all populations, and examine the resulting plot\n",
    "5. Project back related individuals, and generate a list of suggested samples to remove based on Mahalanobis distance test statistic per population. Default criteria is 0.997 percentile (two-sided) but we recommend checking the output plot before and after removal and rethink about it.\n",
    "\n",
    "The analysis above can be performed with reference data eg 1000 Genomes integrated, to help diagnose population substructure in data.\n",
    "\n",
    "If you have subpopulations in the data, then additional steps should be applied for:\n",
    "\n",
    "6. Split data into different populations, each population data should have both related vs unrelated individual data-sets\n",
    "7. For each population, perform QC\n",
    "8. For each population, re-calculate per population PC's for unrelated individuals\n",
    "9. For each population, project related samples back to the PC space\n",
    "10. Remove outliers based on list previously generated"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input\n",
    "\n",
    "1. `protocol_example.genotype.chr21_22.fam`\n",
    "2. `protocol_example.protein.csv`\n",
    "3. `protocol_example.genotype.chr21_22.bed`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "\n",
    "1. PCA models and scores (`.rds` file)\n",
    "2. Mahalanobis Distance Summary Statistics (`.md` file)\n",
    "3. Mahalanobis Distance Histogram & QQ-plots (`.png` file)\n",
    "4. Scree Plot and Cumulative PVE Plot (`.png` file)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal Working Example\n",
    "\n",
    "The proteomics data used in this MWE can be found on [synapse](https://www.synapse.org/#!Synapse:syn52369482)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Sample match with genotype\n",
    "Timing: < 1 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sos run pipeline/GWAS_QC.ipynb genotype_phenotype_sample_overlap \\\n",
    "        --cwd output/sample_meta \\\n",
    "        --genoFile input/protocol_example.genotype.chr21_22.fam  \\\n",
    "        --phenoFile input/protocol_example.protein.csv \\\n",
    "        --container singularity/bioinfo.sif \\\n",
    "        --mem 5G"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "INFO: Running genotype_phenotype_sample_overlap: This workflow extracts overlapping samples for genotype data with phenotype data, and output the filtered sample genotype list as well as sample phenotype list\n",
    "INFO: genotype_phenotype_sample_overlap is completed.\n",
    "INFO: genotype_phenotype_sample_overlap output:   /Users/alexmccreight/xqtl-pipeline-new/output/sample_meta/protocol_example.protein.sample_overlap.txt /Users/alexmccreight/xqtl-pipeline-new/output/sample_meta/protocol_example.protein.sample_genotypes.txt\n",
    "INFO: Workflow genotype_phenotype_sample_overlap (ID=waecd9cbee7d661b4) is executed successfully with 1 completed step.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Kinship quality control\n",
    "Timing: < 1 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sos run pipeline/GWAS_QC.ipynb king \\\n",
    "    --cwd output/kinship \\\n",
    "    --genoFile input/protocol_example.genotype.chr21_22.bed \\\n",
    "    --name pQTL \\\n",
    "    --keep-samples output/sample_meta/protocol_example.protein.sample_genotypes.txt \\\n",
    "    --container singularity/bioinfo.sif \\\n",
    "    --no-maximize-unrelated \\\n",
    "    --mem 40G"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "INFO: Running king_1: Inference of relationships in the sample to identify closely related individuals\n",
    "INFO: king_1 is completed.\n",
    "INFO: king_1 output:   /Users/alexmccreight/xqtl-pipeline-new/output/kinship/protocol_example.genotype.chr21_22.pQTL.kin0\n",
    "INFO: Running king_2: Select a list of unrelated individual with an attempt to maximize the unrelated individuals selected from the data\n",
    "INFO: king_2 is completed.\n",
    "INFO: king_2 output:   /Users/alexmccreight/xqtl-pipeline-new/output/kinship/protocol_example.genotype.chr21_22.pQTL.related_id\n",
    "INFO: Running king_3: Split genotype data into related and unrelated samples, if related individuals are detected\n",
    "INFO: king_3 is completed.\n",
    "INFO: king_3 output:   /Users/alexmccreight/xqtl-pipeline-new/output/kinship/protocol_example.genotype.chr21_22.pQTL.unrelated.bed /Users/alexmccreight/xqtl-pipeline-new/output/kinship/protocol_example.genotype.chr21_22.pQTL.related.bed\n",
    "INFO: Workflow king (ID=w2be67e3f13a70573) is executed successfully with 3 completed steps.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Prepare unrelated individuals data for PCA\n",
    "Timing: < 1 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sos run pipeline/GWAS_QC.ipynb qc \\\n",
    "   --cwd output/cache \\\n",
    "   --genoFile output/kinship/protocol_example.genotype.chr21_22.pQTL.unrelated.bed \\\n",
    "   --mac-filter 5 \\\n",
    "   --container singularity/bioinfo.sif \\\n",
    "   --mem 16G"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "INFO: Running basic QC filters: Filter SNPs and select individuals\n",
    "INFO: basic QC filters is completed.\n",
    "INFO: basic QC filters output:   /Users/alexmccreight/xqtl-pipeline-new/output/cache/protocol_example.genotype.chr21_22.pQTL.unrelated.plink_qc.bed\n",
    "INFO: Running LD pruning: LD prunning and remove related individuals (both ind of a pair) Plink2 has multi-threaded calculation for LD prunning\n",
    "INFO: LD pruning is completed.\n",
    "INFO: LD pruning output:   /Users/alexmccreight/xqtl-pipeline-new/output/cache/protocol_example.genotype.chr21_22.pQTL.unrelated.plink_qc.prune.bed /Users/alexmccreight/xqtl-pipeline-new/output/cache/protocol_example.genotype.chr21_22.pQTL.unrelated.plink_qc.prune.in\n",
    "INFO: Workflow qc (ID=w0f1d12c1e1c1d52a) is executed successfully with 2 completed steps.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sos run pipeline/GWAS_QC.ipynb qc \\\n",
    "   --cwd output/cache \\\n",
    "   --genoFile input/protocol_example.genotype.chr21_22.bed \\\n",
    "   --keep-samples output/sample_meta/protocol_example.protein.sample_genotypes.txt \\\n",
    "   --name pQTL \\\n",
    "   --mac-filter 5 \\\n",
    "   --container singularity/bioinfo.sif \\\n",
    "   --mem 40G"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "INFO: Running basic QC filters: Filter SNPs and select individuals\n",
    "INFO: basic QC filters is completed.\n",
    "INFO: basic QC filters output:   /Users/alexmccreight/xqtl-pipeline-new/output/cache/protocol_example.genotype.chr21_22.pQTL.plink_qc.bed\n",
    "INFO: Running LD pruning: LD prunning and remove related individuals (both ind of a pair) Plink2 has multi-threaded calculation for LD prunning\n",
    "INFO: LD pruning is completed.\n",
    "INFO: LD pruning output:   /Users/alexmccreight/xqtl-pipeline-new/output/cache/protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.bed /Users/alexmccreight/xqtl-pipeline-new/output/cache/protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.in\n",
    "INFO: Workflow qc (ID=wf360e1c84c1a8ec4) is executed successfully with 2 completed steps.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Principal Components Analysis on genotype\n",
    "Timing: < 1 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sos run pipeline/PCA.ipynb flashpca \\\n",
    "   --cwd output/genotype_pca \\\n",
    "   --genoFile output/cache/protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.bed \\\n",
    "   --container singularity/flashpcaR.sif \\\n",
    "   --mem 16G"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "INFO: Running flashpca_1: Run PCA analysis using flashpca\n",
    "INFO: flashpca_1 is completed.\n",
    "INFO: flashpca_1 output:   /Users/alexmccreight/xqtl-pipeline-new/output/genotype_pca/protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.rds\n",
    "INFO: Running flashpca_2:\n",
    "INFO: flashpca_2 is completed (pending nested workflow).\n",
    "INFO: Running detect_outliers: Calculate Mahalanobis distance per population and report outliers\n",
    "INFO: detect_outliers is completed.\n",
    "INFO: detect_outliers output:   /Users/alexmccreight/xqtl-pipeline-new/output/genotype_pca/protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.mahalanobis.rds /Users/alexmccreight/xqtl-pipeline-new/output/genotype_pca/protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.outliers... (5 items)\n",
    "INFO: flashpca_2 output:   /Users/alexmccreight/xqtl-pipeline-new/output/genotype_pca/protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.mahalanobis.rds /Users/alexmccreight/xqtl-pipeline-new/output/genotype_pca/protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.outliers... (5 items)\n",
    "INFO: Running flashpca_3:\n",
    "INFO: flashpca_3 is completed (pending nested workflow).\n",
    "INFO: Running plot_pca: Plot PCA results. Can be used independently as \"plot_pca\" or combined with other workflow as eg \"flashpca+plot_pca\"\n",
    "INFO: plot_pca is completed.\n",
    "INFO: plot_pca output:   /Users/alexmccreight/xqtl-pipeline-new/output/genotype_pca/protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.pc.png /Users/alexmccreight/xqtl-pipeline-new/output/genotype_pca/protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.scree.png... (3 items)\n",
    "INFO: flashpca_3 output:   /Users/alexmccreight/xqtl-pipeline-new/output/genotype_pca/protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.pc.png /Users/alexmccreight/xqtl-pipeline-new/output/genotype_pca/protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.scree.png\n",
    "INFO: Workflow flashpca (ID=wb64a3efe8d5f81b8) is executed successfully with 5 completed steps.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sos run PCA.ipynb -h\n",
    "sos run GWAS_QC.ipynb -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "usage: sos run PCA.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
    "  workflow_name:        Single or combined workflows defined in this script\n",
    "  targets:              One or more targets to generate\n",
    "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
    "  workflow_options:     Double-hyphen workflow-specific parameters\n",
    "\n",
    "Workflows:\n",
    "  pca_plink\n",
    "  flashpca\n",
    "  project_samples\n",
    "  plot_pca\n",
    "  detect_outliers\n",
    "\n",
    "Global Workflow Options:\n",
    "  --cwd output (as path)\n",
    "                        the output directory for generated files\n",
    "  --name ''\n",
    "                        A string to identify your analysis run\n",
    "  --pop-col ''\n",
    "                        Name of the population column in the phenoFile\n",
    "  --pops  (as list)\n",
    "                        Name of the populations (from the population column) you\n",
    "                        would like to plot and show on the PCA plot\n",
    "  --label-col ''\n",
    "                        Name of the color label column in the phenoFile; can be\n",
    "                        the same as population column. Can also be a separate\n",
    "                        column eg a \"super population\" column as a way to enable\n",
    "                        you to combine selected populations based on another\n",
    "                        column.\n",
    "  --k 20 (as int)\n",
    "                        Number of Principal Components to output,must be\n",
    "                        consistant between flashpca run and project samples run\n",
    "                        (flashpca partial PCA method).\n",
    "  --maha-k 5 (as int)\n",
    "                        Number of Principal Components based on which outliers\n",
    "                        should be evaluated. Default is 5 but this should be\n",
    "                        based on examine the scree plot\n",
    "  --[no-]homogeneous (default to False)\n",
    "                        Homogeneity of populations. Set to --homogeneous when\n",
    "                        true and --no-homogeneous when false\n",
    "  --container ''\n",
    "                        Software container option\n",
    "  --entrypoint ('micromamba run -a \"\" -n' + ' ' + container.split('/')[-1][:-4]) if container.endswith('.sif') else \"\"\n",
    "\n",
    "  --job-size 1 (as int)\n",
    "                        For cluster jobs, number commands to run per job\n",
    "  --walltime 5h\n",
    "                        Wall clock time expected\n",
    "  --mem 16G\n",
    "                        Memory expected\n",
    "  --numThreads 10 (as int)\n",
    "                        Number of threads\n",
    "\n",
    "Sections\n",
    "  pca_plink:            PCA command with PLINK, as a sanity check\n",
    "    Workflow Options:\n",
    "      --genoFile VAL (as path, required)\n",
    "                        PLINK binary file\n",
    "  flashpca_1:           Run PCA analysis using flashpca\n",
    "    Workflow Options:\n",
    "      --genoFile VAL (as path, required)\n",
    "                        Plink binary file\n",
    "      --phenoFile  path(f'{genoFile}'.replace(\".bed\",\".fam\"))\n",
    "\n",
    "                        The phenotypic file\n",
    "      --min-pop-size 2 (as int)\n",
    "                        minimum population size to consider in the analysis\n",
    "      --stand binom2\n",
    "                        How to standardize X before PCA\n",
    "  project_samples_1:    Project back to PCA model additional samples\n",
    "    Workflow Options:\n",
    "      --genoFile VAL (as path, required)\n",
    "                        Plink binary file\n",
    "      --phenoFile  path(f'{genoFile}'.replace(\".bed\",\".fam\"))\n",
    "\n",
    "                        The phenotypic file\n",
    "      --pca-model  f'{cwd}/{phenoFile:bn}{(\".\"+name) if name else \"\"}.{(suffix+\".\") if suffix != \"\" else \"\"}pca.rds'\n",
    "\n",
    "  plot_pca:             Plot PCA results. Can be used independently as\n",
    "                        \"plot_pca\" or combined with other workflow as eg\n",
    "                        \"flashpca+plot_pca\"\n",
    "    Workflow Options:\n",
    "      --outlier-file . (as path)\n",
    "      --plot-data VAL (as path, required)\n",
    "      --min-axis ''\n",
    "      --max-axis ''\n",
    "  detect_outliers:      Calculate Mahalanobis distance per population and report\n",
    "                        outliers\n",
    "    Workflow Options:\n",
    "      --prob 0.997 (as float)\n",
    "                        Set the probability to remove outliers eg 0.95 or 0.997\n",
    "      --pval 0.05 (as float)\n",
    "                        Mahalanobis distance p-value cutoff\n",
    "      --[no-]robust (default to True)\n",
    "                        Robust Mahalanobis to outliers\n",
    "      --pca-result VAL (as path, required)\n",
    "  flashpca_2, project_samples_2:\n",
    "    Workflow Options:\n",
    "      --prob 0.997 (as float)\n",
    "                        Set the probability to remove outliers eg 0.95 or 0.997\n",
    "      --[no-]robust (default to True)\n",
    "                        Robust Mahalanobis to outliers\n",
    "  flashpca_3, project_samples_3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "usage: sos run GWAS_QC.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
    "  workflow_name:        Single or combined workflows defined in this script\n",
    "  targets:              One or more targets to generate\n",
    "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
    "  workflow_options:     Double-hyphen workflow-specific parameters\n",
    "\n",
    "Workflows:\n",
    "  king\n",
    "  qc_no_prune\n",
    "  qc\n",
    "  genotype_phenotype_sample_overlap\n",
    "\n",
    "Global Workflow Options:\n",
    "  --cwd output (as path)\n",
    "                        the output directory for generated files\n",
    "  --name ''\n",
    "                        A string to identify your analysis run\n",
    "  --genoFile  paths\n",
    "\n",
    "                        PLINK binary files\n",
    "  --remove-samples . (as path)\n",
    "                        The path to the file that contains the list of samples\n",
    "                        to remove (format FID, IID)\n",
    "  --keep-samples . (as path)\n",
    "                        The path to the file that contains the list of samples\n",
    "                        to keep (format FID, IID)\n",
    "  --keep-variants . (as path)\n",
    "                        The path to the file that contains the list of variants\n",
    "                        to keep\n",
    "  --exclude-variants . (as path)\n",
    "                        The path to the file that contains the list of variants\n",
    "                        to exclude\n",
    "  --kinship 0.0625 (as float)\n",
    "                        Kinship coefficient threshold for related individuals\n",
    "                        (e.g first degree above 0.25, second degree above 0.125,\n",
    "                        third degree above 0.0625)\n",
    "  --job-size 1 (as int)\n",
    "                        For cluster jobs, number commands to run per job\n",
    "  --walltime 5h\n",
    "                        Wall clock time expected\n",
    "  --mem 16G\n",
    "                        Memory expected\n",
    "  --numThreads 20 (as int)\n",
    "                        Number of threads\n",
    "  --container ''\n",
    "                        Software container option\n",
    "  --entrypoint ('micromamba run -a \"\" -n' + ' ' + container.split('/')[-1][:-4]) if container.endswith('.sif') else \"\"\n",
    "\n",
    "\n",
    "Sections\n",
    "  king_1:               Inference of relationships in the sample to identify\n",
    "                        closely related individuals\n",
    "    Workflow Options:\n",
    "      --kin-maf 0.01 (as float)\n",
    "                        PLINK binary file\n",
    "  king_2:               Select a list of unrelated individual with an attempt to\n",
    "                        maximize the unrelated individuals selected from the\n",
    "                        data\n",
    "    Workflow Options:\n",
    "      --[no-]maximize-unrelated (default to False)\n",
    "                        If set to true, the unrelated individuals in a family\n",
    "                        will be kept without being reported. Otherwise (use\n",
    "                        `--no-maximize-unrelated`) the entire family will be\n",
    "                        removed Note that attempting to maximize unrelated\n",
    "                        individuals is computationally intensive on large data.\n",
    "  king_3:               Split genotype data into related and unrelated samples,\n",
    "                        if related individuals are detected\n",
    "  qc_no_prune, qc_1:    Filter SNPs and select individuals\n",
    "    Workflow Options:\n",
    "      --maf-filter 0.0 (as float)\n",
    "                        minimum MAF filter to use. 0 means do not apply this\n",
    "                        filter.\n",
    "      --maf-max-filter 0.0 (as float)\n",
    "                        maximum MAF filter to use. 0 means do not apply this\n",
    "                        filter.\n",
    "      --mac-filter 0.0 (as float)\n",
    "                        minimum MAC filter to use. 0 means do not apply this\n",
    "                        filter.\n",
    "      --mac-max-filter 0.0 (as float)\n",
    "                        maximum MAC filter to use. 0 means do not apply this\n",
    "                        filter.\n",
    "      --geno-filter 0.1 (as float)\n",
    "                        Maximum missingess per-variant\n",
    "      --mind-filter 0.1 (as float)\n",
    "                        Maximum missingness per-sample\n",
    "      --hwe-filter 1e-15 (as float)\n",
    "                        HWE filter -- a very lenient one\n",
    "      --other-args  (as list)\n",
    "                        Other PLINK arguments e.g snps_only, write-samples, etc\n",
    "      --[no-]meta-only (default to False)\n",
    "                        Only output SNP and sample list, rather than the PLINK\n",
    "                        binary format of subset data\n",
    "      --[no-]rm-dups (default to False)\n",
    "                        Remove duplicate variants\n",
    "  qc_2:                 LD prunning and remove related individuals (both ind of\n",
    "                        a pair) Plink2 has multi-threaded calculation for LD\n",
    "                        prunning\n",
    "    Workflow Options:\n",
    "      --window 50 (as int)\n",
    "                        Window size\n",
    "      --shift 10 (as int)\n",
    "                        Shift window every 10 snps\n",
    "      --r2 0.1 (as float)\n",
    "  genotype_phenotype_sample_overlap: This workflow extracts overlapping samples\n",
    "                        for genotype data with phenotype data, and output the\n",
    "                        filtered sample genotype list as well as sample\n",
    "                        phenotype list\n",
    "    Workflow Options:\n",
    "      --phenoFile VAL (as path, required)\n",
    "                        A phenotype file, can be bed.gz or tsv\n",
    "      --sample-participant-lookup . (as path)\n",
    "                        If this file is provided, a genotype/phenotype sample\n",
    "                        name match will be performed It must contain two column\n",
    "                        names: genotype_id, sample_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Sample match with genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# This workflow extracts overlapping samples for genotype data with phenotype data, and output the filtered sample genotype list as well as sample phenotype list\n",
    "[genotype_phenotype_sample_overlap]\n",
    "# A genotype fam file\n",
    "parameter: genoFile = path\n",
    "# A phenotype file, can be bed.gz or tsv\n",
    "parameter: phenoFile = path\n",
    "# If this file is provided, a genotype/phenotype sample name match will be performed\n",
    "# It must contain two column names: genotype_id, sample_id\n",
    "parameter: sample_participant_lookup = path(\".\")\n",
    "input: genoFile, phenoFile\n",
    "output: f'{cwd:a}/{path(_input[1]):bn}.sample_overlap.txt', f'{cwd:a}/{path(_input[1]):bn}.sample_genotypes.txt'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', container = container, entrypoint=entrypoint\n",
    "    # Load required libraries\n",
    "    library(dplyr)\n",
    "    library(readr)\n",
    "    library(data.table)\n",
    "\n",
    "    # Read data files; let read_delim auto-determine the delimiter\n",
    "    genoFam <- fread(${_input[0]:ar}, header=FALSE)\n",
    "    phenoFile <- read_delim(${_input[1]:ar}, col_names=TRUE)\n",
    "    if (${\"TRUE\" if sample_participant_lookup.is_file() else \"FALSE\"}) {\n",
    "        sample_lookup <- fread(${sample_participant_lookup:ar}, header=TRUE)\n",
    "    } else {\n",
    "        sample_lookup <- cbind(genoFam[,2], genoFam[,2])\n",
    "        colnames(sample_lookup) <- c(\"genotype_id\", \"sample_id\")\n",
    "    }\n",
    "    sample_lookup <- sample_lookup %>%\n",
    "    filter(\n",
    "        genotype_id %in% genoFam$V2,\n",
    "        sample_id %in% colnames(phenoFile)\n",
    "    )\n",
    "    \n",
    "    genoFam %>%\n",
    "    filter(\n",
    "        V2 %in% sample_lookup$genotype_id,\n",
    "    ) %>%\n",
    "    select(V1, V2) %>%\n",
    "    fwrite(${_output[1]:r}, col.names=FALSE, sep=\"\\t\")\n",
    "\n",
    "    sample_lookup %>%\n",
    "    fwrite(${_output[0]:r}, sep=\"\\t\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Kinship quality control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Inference of relationships in the sample to identify closely related individuals\n",
    "[king_1]\n",
    "# PLINK binary file\n",
    "parameter: kin_maf = 0.01\n",
    "input: genoFile\n",
    "output: f'{cwd}/{_input:bn}{(\".\"+name) if name else \"\"}.kin0'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container, expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', entrypoint=entrypoint\n",
    "    plink2 \\\n",
    "      --bfile ${_input:n} \\\n",
    "      --make-king-table \\\n",
    "      --king-table-filter ${kinship} \\\n",
    "      ${('--keep %s' % keep_samples) if keep_samples.is_file() else \"\"} \\\n",
    "      ${('--remove %s' % remove_samples) if remove_samples.is_file() else \"\"} \\\n",
    "      --min-af ${kin_maf} \\\n",
    "      --max-af ${1-kin_maf} \\\n",
    "      --out ${_output:n} \\\n",
    "      --threads ${numThreads} \\\n",
    "      --memory ${int(expand_size(mem) * 0.9)/1e6} \n",
    "    \n",
    "bash: expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container, entrypoint=entrypoint\n",
    "    i=\"${_output}\"\n",
    "    output_size=$(ls -lh $i | cut -f 5 -d ' ')\n",
    "    output_rows=$(zcat $i | wc -l | cut -f 1 -d ' ')\n",
    "    output_column=$(zcat $i | head -1 | wc -w)\n",
    "    output_preview=$(cat $i | grep -v \"##\" | head | cut -f 1,2,3,4,5,6)\n",
    "    \n",
    "    printf \"output_info: %s\\noutput_size: %s\\noutput_rows: %s\\noutput_column: %s\\noutput_preview:\\n%s\\n\" \\\n",
    "        \"$i\" \"$output_size\" \"$output_rows\" \"$output_column\" \"$output_preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Select a list of unrelated individual with an attempt to maximize the unrelated individuals selected from the data \n",
    "[king_2]\n",
    "# If set to true, the unrelated individuals in a family will be kept without being reported. \n",
    "# Otherwise (use `--no-maximize-unrelated`) the entire family will be removed\n",
    "# Note that attempting to maximize unrelated individuals is computationally intensive on large data.\n",
    "parameter: maximize_unrelated = False\n",
    "related_id = [x.strip() for x in open(_input).readlines() if not x.startswith(\"#\")]\n",
    "done_if(len(related_id) == 0, msg = f\"No related individuals detected from {_input}.\")\n",
    "output: f'{_input:n}.related_id'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R:  container=container, expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', entrypoint=entrypoint\n",
    "    library(dplyr)\n",
    "    library(igraph)\n",
    "    # Remove related individuals while keeping maximum number of individuals\n",
    "    # this function is simplified from: \n",
    "    # https://rdrr.io/cran/plinkQC/src/R/utils.R\n",
    "    #' @param relatedness [data.frame] containing pair-wise relatedness estimates\n",
    "    #' (in column [relatednessRelatedness]) for individual 1 (in column\n",
    "    #' [relatednessIID1] and individual 2 (in column [relatednessIID1]). Columns\n",
    "    #' relatednessIID1, relatednessIID2 and relatednessRelatedness have to present,\n",
    "    #' while additional columns such as family IDs can be present. Default column\n",
    "    #' names correspond to column names in output of plink --genome\n",
    "    #' (\\url{https://www.cog-genomics.org/plink/1.9/ibd}). All original\n",
    "    #' columns for pair-wise highIBDTh fails will be returned in fail_IBD.\n",
    "    #' @param relatednessTh [double] Threshold for filtering related individuals.\n",
    "    #' Individuals, whose pair-wise relatedness estimates are greater than this\n",
    "    #' threshold are considered related.\n",
    "    relatednessFilter <- function(relatedness, \n",
    "                                  relatednessTh,\n",
    "                                  relatednessIID1=\"IID1\", \n",
    "                                  relatednessIID2=\"IID2\",\n",
    "                                  relatednessRelatedness=\"KINSHIP\") {\n",
    "        # format data\n",
    "        if (!(relatednessIID1 %in% names(relatedness))) {\n",
    "            stop(paste(\"Column\", relatednessIID1, \"for relatedness not found!\"))\n",
    "        }\n",
    "        if (!(relatednessIID2 %in% names(relatedness))) {\n",
    "            stop(paste(\"Column\", relatednessIID1, \"for relatedness not found!\"))\n",
    "        }\n",
    "        if (!(relatednessRelatedness %in% names(relatedness))) {\n",
    "            stop(paste(\"Column\", relatednessRelatedness,\n",
    "                       \"for relatedness not found!\"))\n",
    "        }\n",
    "\n",
    "        iid1_index <- which(colnames(relatedness) == relatednessIID1)\n",
    "        iid2_index <- which(colnames(relatedness) == relatednessIID2)\n",
    "\n",
    "        relatedness[,iid1_index] <- as.character(relatedness[,iid1_index])\n",
    "        relatedness[,iid2_index] <- as.character(relatedness[,iid2_index])\n",
    "\n",
    "        relatedness_names <- names(relatedness)\n",
    "        names(relatedness)[iid1_index] <- \"IID1\"\n",
    "        names(relatedness)[iid2_index] <- \"IID2\"\n",
    "        names(relatedness)[names(relatedness) == relatednessRelatedness] <- \"M\"\n",
    "\n",
    "        # Remove symmetric IID rows\n",
    "        relatedness_original <- relatedness\n",
    "        relatedness <- dplyr::select_(relatedness, ~IID1, ~IID2, ~M)\n",
    "\n",
    "        sortedIDs <- data.frame(t(apply(relatedness, 1, function(pair) {\n",
    "            c(sort(c(pair[1], pair[2])))\n",
    "            })), stringsAsFactors=FALSE)\n",
    "        keepIndex <- which(!duplicated(sortedIDs))\n",
    "\n",
    "        relatedness_original <- relatedness_original[keepIndex,]\n",
    "        relatedness <- relatedness[keepIndex,]\n",
    "\n",
    "        # individuals with at least one pair-wise comparison > relatednessTh\n",
    "        # return NULL to failIDs if no one fails the relatedness check\n",
    "        highRelated <- dplyr::filter_(relatedness, ~M > relatednessTh)\n",
    "        if (nrow(highRelated) == 0) {\n",
    "            return(list(relatednessFails=NULL, failIDs=NULL))\n",
    "        }\n",
    "\n",
    "        # all samples with related individuals\n",
    "        allRelated <- c(highRelated$IID1, highRelated$IID2)\n",
    "        uniqueIIDs <- unique(allRelated)\n",
    "\n",
    "        # Further selection of samples with relatives in cohort\n",
    "        multipleRelative <- unique(allRelated[duplicated(allRelated)])\n",
    "        singleRelative <- uniqueIIDs[!uniqueIIDs %in% multipleRelative]\n",
    "\n",
    "        highRelatedMultiple <- highRelated[highRelated$IID1 %in% multipleRelative |\n",
    "                                            highRelated$IID2 %in% multipleRelative,]\n",
    "        highRelatedSingle <- highRelated[highRelated$IID1 %in% singleRelative &\n",
    "                                           highRelated$IID2 %in% singleRelative,]\n",
    "\n",
    "        # Only one related samples per individual\n",
    "        if(length(singleRelative) != 0) {\n",
    "          # randomly choose one to exclude\n",
    "          failIDs_single <- highRelatedSingle[,1]\n",
    "            \n",
    "        } else {\n",
    "          failIDs_single <- NULL\n",
    "        }\n",
    "  \n",
    "        # An individual has multiple relatives\n",
    "        if(length(multipleRelative) != 0) {\n",
    "            relatedPerID <- lapply(multipleRelative, function(x) {\n",
    "                tmp <- highRelatedMultiple[rowSums(\n",
    "                    cbind(highRelatedMultiple$IID1 %in% x,\n",
    "                          highRelatedMultiple$IID2 %in% x)) != 0,1:2]\n",
    "                rel <- unique(unlist(tmp))\n",
    "                return(rel)\n",
    "            })\n",
    "            names(relatedPerID) <- multipleRelative\n",
    "\n",
    "            keepIDs_multiple <- lapply(relatedPerID, function(x) {\n",
    "                pairwise <- t(combn(x, 2))\n",
    "                index <- (highRelatedMultiple$IID1 %in% pairwise[,1] &\n",
    "                              highRelatedMultiple$IID2 %in% pairwise[,2]) |\n",
    "                    (highRelatedMultiple$IID1 %in% pairwise[,2] &\n",
    "                         highRelatedMultiple$IID2 %in% pairwise[,1])\n",
    "                combination <- highRelatedMultiple[index,]\n",
    "                combination_graph <- igraph::graph_from_data_frame(combination,\n",
    "                                                                   directed=FALSE)\n",
    "                all_iv_set <- igraph::ivs(combination_graph)\n",
    "                length_iv_set <- sapply(all_iv_set, function(x) length(x))\n",
    "\n",
    "                if (all(length_iv_set == 1)) {\n",
    "                    # check how often they occurr elsewhere\n",
    "                    occurrence <- sapply(x, function(id) {\n",
    "                        sum(sapply(relatedPerID, function(idlist) id %in% idlist))\n",
    "                    })\n",
    "                    # if occurrence the same everywhere, pick the first, else keep\n",
    "                    # the one with minimum occurrence elsewhere\n",
    "                    if (length(unique(occurrence)) == 1) {\n",
    "                        nonRelated <- sort(x)[1]\n",
    "                    } else {\n",
    "                        nonRelated <- names(occurrence)[which.min(occurrence)]\n",
    "                    }\n",
    "                } else {\n",
    "                    nonRelated <- all_iv_set[which.max(length_iv_set)]\n",
    "                }\n",
    "                return(nonRelated)\n",
    "            })\n",
    "            keepIDs_multiple <- unique(unlist(keepIDs_multiple))\n",
    "            failIDs_multiple <- c(multipleRelative[!multipleRelative %in%\n",
    "                                                       keepIDs_multiple])\n",
    "        } else {\n",
    "            failIDs_multiple <- NULL\n",
    "        }\n",
    "        allFailIIDs <- c(failIDs_single, failIDs_multiple)\n",
    "        relatednessFails <- lapply(allFailIIDs, function(id) {\n",
    "            fail_inorder <- relatedness_original$IID1 == id &\n",
    "                relatedness_original$M > relatednessTh\n",
    "            fail_inreverse <- relatedness_original$IID2 == id &\n",
    "                relatedness_original$M > relatednessTh\n",
    "            if (any(fail_inreverse)) {\n",
    "                inreverse <- relatedness_original[fail_inreverse, ]\n",
    "                id1 <- iid1_index\n",
    "                id2 <- iid2_index\n",
    "                inreverse[,c(id1, id2)] <- inreverse[,c(id2, id1)]\n",
    "                names(inreverse) <- relatedness_names\n",
    "            } else {\n",
    "                inreverse <- NULL\n",
    "            }\n",
    "            inorder <- relatedness_original[fail_inorder, ]\n",
    "            names(inorder) <- relatedness_names\n",
    "            return(rbind(inorder, inreverse))\n",
    "        })\n",
    "        relatednessFails <- do.call(rbind, relatednessFails)\n",
    "        if (nrow(relatednessFails) == 0) {\n",
    "            relatednessFails <- NULL\n",
    "            failIDs <- NULL\n",
    "        } else {\n",
    "            names(relatednessFails) <- relatedness_names\n",
    "            rownames(relatednessFails) <- 1:nrow(relatednessFails)\n",
    "            uniqueFails <- relatednessFails[!duplicated(relatednessFails[,iid1_index]),]\n",
    "            failIDs <- uniqueFails[,iid1_index]\n",
    "        }\n",
    "        return(list(relatednessFails=relatednessFails, failIDs=failIDs))\n",
    "    }\n",
    "    \n",
    "  \n",
    "    # main code\n",
    "    kin0 <- read.table(${_input:r}, header=F, stringsAsFactor=F)\n",
    "    colnames(kin0) <- c(\"FID1\",\"ID1\",\"FID2\",\"ID2\",\"NSNP\",\"HETHET\",\"IBS0\",\"KINSHIP\")\n",
    "    if (${\"TRUE\" if maximize_unrelated else \"FALSE\"}) {\n",
    "        rel <- relatednessFilter(kin0, ${kinship}, \"ID1\", \"ID2\", \"KINSHIP\")$failIDs\n",
    "        tmp1 <- kin0[,1:2]\n",
    "        tmp2 <- kin0[,3:4]\n",
    "        colnames(tmp1) = colnames(tmp2) = c(\"FID\", \"ID\")\n",
    "        # Get the family ID for these rels so there are two columns FID and IID in the output\n",
    "        lookup <- dplyr::distinct(rbind(tmp1,tmp2))\n",
    "        dat <- lookup[which(lookup[,2] %in% rel),]\n",
    "    } else {\n",
    "        rel <- kin0 %>% filter(KINSHIP >= ${kinship})\n",
    "        dat = rbind(rel[,c(\"FID1\",\"ID1\")],setNames(rel[,c(\"FID2\",\"ID2\")],c(\"FID1\",\"ID1\")))\n",
    "        dat = dat[!duplicated(dat),] ## This is to remove duplicated FID and IID caused by one sample being related to multiple samples\n",
    "       }    \n",
    "\n",
    "    cat(\"There are\", nrow(dat),\"related individuals using a kinship threshold of ${kinship}\\n\")\n",
    "    write.table(dat,${_output:r}, quote=FALSE, row.names=FALSE, col.names=FALSE)\n",
    "    \n",
    "bash: expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container, entrypoint=entrypoint\n",
    "    i=\"${_output}\"\n",
    "    output_size=$(ls -lh $i | cut -f 5 -d ' ')\n",
    "    output_rows=$(zcat $i | wc -l | cut -f 1 -d ' ')\n",
    "    output_column=$(zcat $i | head -1 | wc -w)\n",
    "    output_preview=$(cat $i | grep -v \"##\" | head | cut -f 1,2,3,4,5,6)\n",
    "    \n",
    "    printf \"output_info: %s\\noutput_size: %s\\noutput_rows: %s\\noutput_column: %s\\noutput_preview:\\n%s\\n\" \\\n",
    "        \"$i\" \"$output_size\" \"$output_rows\" \"$output_column\" \"$output_preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Split genotype data into related and unrelated samples, if related individuals are detected\n",
    "[king_3]\n",
    "input: output_from(2), genoFile\n",
    "output: unrelated_bed = f'{cwd}/{_input[0]:bn}.unrelated.bed',\n",
    "        related_bed = f'{cwd}/{_input[0]:bn}.related.bed'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash:  expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', container = container, entrypoint=entrypoint\n",
    "    plink2 \\\n",
    "      --bfile ${_input[1]:n} \\\n",
    "      --remove ${_input[0]} \\\n",
    "      ${('--keep %s' % keep_samples) if keep_samples.is_file() else \"\"} \\\n",
    "      --make-bed \\\n",
    "      --out ${_output[0]:n} \\\n",
    "      --threads ${numThreads} \\\n",
    "      --memory ${int(expand_size(mem) * 0.9)/1e6} --new-id-max-allele-len 1000 --set-all-var-ids chr@:#_\\$r_\\$a \n",
    "\n",
    "    plink2 \\\n",
    "      --bfile ${_input[1]:n} \\\n",
    "      --keep ${_input[0]} \\\n",
    "      --make-bed \\\n",
    "      --out ${_output[1]:n} \\\n",
    "      --threads ${numThreads} \\\n",
    "      --memory ${int(expand_size(mem) * 0.9)/1e6} --new-id-max-allele-len 1000 --set-all-var-ids chr@:#_\\$r_\\$a \n",
    "        \n",
    "bash: expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', container = container, entrypoint=entrypoint\n",
    "    for i in ${_output}; do     \n",
    "        output_size=$(ls -lh $i | cut -f 5 -d ' ')\n",
    "        printf \"output_info: %s\\noutput_size: %s\\n\" \"$i\" \"$output_size\" >> ${_output[0]:n}.stdout\n",
    "    done"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Prepare unrelated individuals data for PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Filter SNPs and select individuals \n",
    "[qc_no_prune, qc_1 (basic QC filters)]\n",
    "# minimum MAF filter to use. 0 means do not apply this filter.\n",
    "parameter: maf_filter = 0.0\n",
    "# maximum MAF filter to use. 0 means do not apply this filter.\n",
    "parameter: maf_max_filter = 0.0\n",
    "# minimum MAC filter to use. 0 means do not apply this filter.\n",
    "parameter: mac_filter = 0.0\n",
    "# maximum MAC filter to use. 0 means do not apply this filter.\n",
    "parameter: mac_max_filter = 0.0 \n",
    "# Maximum missingess per-variant\n",
    "parameter: geno_filter = 0.1\n",
    "# Maximum missingness per-sample\n",
    "parameter: mind_filter = 0.1\n",
    "# HWE filter -- a very lenient one\n",
    "parameter: hwe_filter = 1e-15\n",
    "# Other PLINK arguments e.g snps_only, write-samples, etc\n",
    "parameter: other_args = []\n",
    "# Only output SNP and sample list, rather than the PLINK binary format of subset data\n",
    "parameter: meta_only = False\n",
    "# Remove duplicate variants\n",
    "parameter: rm_dups = False\n",
    "\n",
    "fail_if(not (keep_samples.is_file() or keep_samples == path('.')), msg = f'Cannot find ``{keep_samples}``')\n",
    "fail_if(not (keep_variants.is_file() or keep_variants == path('.')), msg = f'Cannot find ``{keep_variants}``')\n",
    "fail_if(not (remove_samples.is_file() or remove_samples == path('.')), msg = f'Cannot find ``{remove_samples}``')\n",
    "\n",
    "input: genoFile, group_by=1\n",
    "output: f'{cwd}/{_input:bn}{(\".\"+name) if name else \"\"}.plink_qc{\".extracted\" if keep_variants.is_file() else \"\"}{\".bed\" if not meta_only else \".snplist\"}'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container, expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', entrypoint=entrypoint\n",
    "    plink2 \\\n",
    "      --bfile ${_input:n} \\\n",
    "      ${('--maf %s' % maf_filter) if maf_filter > 0 else ''} \\\n",
    "      ${('--max-maf %s' % maf_max_filter) if maf_max_filter > 0 else ''} \\\n",
    "      ${('--mac %s' % mac_filter) if mac_filter > 0 else ''} \\\n",
    "      ${('--max-mac %s' % mac_max_filter) if mac_max_filter > 0 else ''} \\\n",
    "      ${('--geno %s' % geno_filter) if geno_filter > 0 else ''} \\\n",
    "      ${('--hwe %s' % hwe_filter) if hwe_filter > 0 else ''} \\\n",
    "      ${('--mind %s' % mind_filter) if mind_filter > 0 else ''} \\\n",
    "      ${('--keep %s' % keep_samples) if keep_samples.is_file() else \"\"} \\\n",
    "      ${('--remove %s' % remove_samples) if remove_samples.is_file() else \"\"} \\\n",
    "      ${('--exclude %s' % exclude_variants) if exclude_variants.is_file() else \"\"} \\\n",
    "      ${('--extract %s' % keep_variants) if keep_variants.is_file() else \"\"} \\\n",
    "      ${('--make-bed') if not meta_only else \"--write-snplist --write-samples\"} \\\n",
    "      ${(\"\") if not rm_dups else \"--rm-dup force-first 'list'\"} \\\n",
    "      ${paths([\"--%s\" % x for x in other_args]) if other_args else \"\"} \\\n",
    "      --out ${_output:n} \\\n",
    "      --threads ${numThreads} \\\n",
    "      --memory ${int(expand_size(mem) * 0.9)/1e6} --new-id-max-allele-len 1000 --set-all-var-ids chr@:#_\\$r_\\$a \n",
    "        \n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "    i=\"${_output}\"\n",
    "    output_size=$(ls -lh $i | cut -f 5 -d ' ')\n",
    "    printf \"output_info: %s\\noutput_size: %s\\n\" \"$i\" \"$output_size\" >> ${_output:n}.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# LD prunning and remove related individuals (both ind of a pair)\n",
    "# Plink2 has multi-threaded calculation for LD prunning\n",
    "[qc_2 (LD pruning)]\n",
    "# Window size\n",
    "parameter: window = 50\n",
    "# Shift window every 10 snps\n",
    "parameter: shift = 10\n",
    "parameter: r2 = 0.1\n",
    "stop_if(r2==0)\n",
    "output: bed=f'{cwd}/{_input:bn}.prune.bed', prune=f'{cwd}/{_input:bn}.prune.in'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container=container, expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', entrypoint=entrypoint\n",
    "    plink2 \\\n",
    "    --bfile ${_input:n} \\\n",
    "    --indep-pairwise ${window} ${shift} ${r2}  \\\n",
    "    --out ${_output[\"prune\"]:nn} \\\n",
    "    --threads ${numThreads} \\\n",
    "    --memory ${int(expand_size(mem) * 0.9)/1e6}\n",
    "   \n",
    "    plink2 \\\n",
    "    --bfile ${_input:n} \\\n",
    "    --extract ${_output['prune']} \\\n",
    "    --make-bed \\\n",
    "    --out ${_output['bed']:n} \\\n",
    "    --threads ${numThreads} \\\n",
    "    --memory ${int(expand_size(mem) * 0.9)/1e6}\n",
    "    \n",
    "bash: expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', container = container, entrypoint=entrypoint\n",
    "    i=\"${_output[0]}\"\n",
    "    output_size=$(ls -lh $i | cut -f 5 -d ' ')\n",
    "    printf \"output_info: %s\\noutput_size: %s\\n\" \"$i\" \"$output_size\" >> ${_output[0]:n}.stdout\n",
    "    i=\"${_output[1]}\"\n",
    "    output_size=$(ls -lh $i | cut -f 5 -d ' ')\n",
    "    output_rows=$(zcat $i | wc -l | cut -f 1 -d ' ')\n",
    "    output_column=$(zcat $i | head -1 | wc -w)\n",
    "    output_preview=$(cat $i | grep -v \"##\" | head | cut -f 1,2,3,4,5,6) \n",
    "    printf \"output_info: %s\\noutput_size: %s\\noutput_rows: %s\\noutput_column: %s\\noutput_preview:\\n%s\\n\" \\\n",
    "        \"$i\" \"$output_size\" \"$output_rows\" \"$output_column\" \"$output_preview\" >> ${_output[1]}.stdout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Principal Components Analysis on genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Run PCA analysis using flashpca \n",
    "[flashpca_1]\n",
    "# Plink binary file\n",
    "parameter: genoFile = path\n",
    "# The phenotypic file\n",
    "parameter: phenoFile = path(f'{genoFile}'.replace(\".bed\",\".fam\"))\n",
    "# minimum population size to consider in the analysis\n",
    "parameter: min_pop_size = 2\n",
    "# How to standardize X before PCA\n",
    "parameter: stand = \"binom2\"\n",
    "## Input genoFile here is for unrelated samples\n",
    "input: genoFile, phenoFile\n",
    "output: f'{cwd}/{phenoFile:bn}{(\".\"+name) if name else \"\"}.{(suffix+\".\") if suffix != \"\" else \"\"}pca.rds'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: container = container, expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', entrypoint=entrypoint\n",
    "    # Load required libraries\n",
    "    library(flashpcaR)\n",
    "    library(dplyr)\n",
    "    pops = c(${paths(pops):r,})\n",
    "    f <- flashpca(${_input[0]:nr}, ndim=${k}, stand=\"${stand}\", do_loadings=TRUE, check_geno=TRUE)\n",
    "    rownames(f$loadings) <- read.table('${_input[0]:n}.bim',stringsAsFactors =F)[,2]\n",
    "    # Use the projection file to generate pca plot\n",
    "    pca <- as.data.frame(f$projection)\n",
    "    pca <- tibble::rownames_to_column(pca, \"ID\")\n",
    "    colnames(pca) <- c(\"ID\",paste0(\"PC\", 1:${k}))\n",
    "  \n",
    "    # Read fam file with phenotypes\n",
    "    if(stringr::str_detect(${_input[1]:r},\".fam$\")){\n",
    "        pheno <- read.table(${_input[1]:r}, header=F,stringsAsFactors =F)\n",
    "        colnames(pheno) = c(\"FID\", \"IID\", \"MID\", \"PID\", \"SEX\", \"STATUS\")\n",
    "    } else {\n",
    "        pheno <- read.table(${_input[1]:r}, header=T,stringsAsFactors =F)\n",
    "        if(\"IID\" %in% colnames(pheno) == FALSE) stop(\"No IID column in the phenoFile. Please rename the header of the phenoFile\")\n",
    "        if(\"FID\" %in% colnames(pheno) == FALSE) pheno$FID = pheno$IID\n",
    "    }\n",
    "    # Make the unique ID by merge FID and IID\n",
    "    pheno$ID = paste(pheno$FID,pheno$IID,sep = \":\")\n",
    "    #check duplicated ID\n",
    "    if(length(unique(pheno$ID))!=length(pheno$ID)) stop(\"There are duplicated names in IID column of phenoFile\")\n",
    "\n",
    "    if (length(pops)>0) pheno <- pheno %>%filter(${pop_col if pop_col else  \"pop\"} %in% pops | ${label_col if label_col else  \"pop\"} %in% pops)\n",
    "    pca <-merge(pheno, pca,by =\"ID\", all=FALSE) \n",
    "    #\n",
    "    if (${\"TRUE\" if pop_col else \"FALSE\"}) {\n",
    "        # remove populations have less than ${min_pop_size} samples\n",
    "        pop<-names(table(pca$${pop_col if pop_col else \"pop\"}))\n",
    "        pop_filter<-pop[table(pca$pop)<${min_pop_size}] # pop to be removed\n",
    "        if (length(pop_filter)>0) {\n",
    "            warning(for (i in pop_filter){cat(i,';')},'these ', length(pop_filter),\" population will be removed due to having less than ${min_pop_size} samples in data.\")\n",
    "            # remove\n",
    "            pca<-pca%>% filter(${f'!{pop_col}%in%pop_filter' if pop_col else pop_col})\n",
    "        }\n",
    "    } else {\n",
    "      pca$pop <- 1 \n",
    "    }\n",
    "\n",
    "    # Write the PC scores to a file\n",
    "    write.table(pca,\"${_output:n}.txt\", sep=\"\\t\", quote=FALSE, row.names=FALSE, col.names=TRUE)\n",
    "    dat = list(pca_model = f, pc_scores = pca, meta = \"${_input[1]:bn} ${suffix}\")\n",
    "    # compute centroids before projecting back the samples\n",
    "    # (calculate mean/median/cov per pop)\n",
    "    if(${\"FALSE\" if homogeneous else \"TRUE\"}){\n",
    "        pop_group <- split(dat$pc_scores[ ,c(paste0(\"PC\", 1:${maha_k}))], list(Group = dat$pc_scores$${pop_col if pop_col else \"pop\"}))\n",
    "        dat$pc_cov <- lapply(pop_group, function(x) cov(x))\n",
    "        dat$pc_mean <- lapply(pop_group, function(x) sapply(x, mean))\n",
    "        dat$pc_median <- lapply(pop_group, function(x) sapply(x, median))\n",
    "    } else {\n",
    "        dat$pc_cov <- cov(f$projection[,1:${maha_k}])\n",
    "        dat$pc_mean <- apply(f$projection[,1:${maha_k}], 2, mean)\n",
    "        dat$pc_median <- apply(f$projection[,1:${maha_k}], 2, median)\n",
    "    }\n",
    "  \n",
    "    # save results\n",
    "    saveRDS(dat, ${_output:r})\n",
    "  \n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output:n].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"This rds file is a list containing the pca for unrelated sample\" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "[flashpca_2, project_samples_2]\n",
    "# Set the probability to remove outliers eg 0.95 or 0.997\n",
    "parameter: prob = 0.997\n",
    "# Robust Mahalanobis to outliers\n",
    "parameter: robust = True\n",
    "output: distance=f'{_input:n}.mahalanobis.rds',\n",
    "        identified_outliers=f'{_input:n}.outliers',\n",
    "        analysis_summary=f'{_input:n}.analysis_summary.md',\n",
    "        qqplot_mahalanobis=f'{_input:n}.mahalanobis_qq.png',\n",
    "        hist_mahalanobis=f'{_input:n}.mahalanobis_hist.png'\n",
    "sos_run(\"detect_outliers\", pca_result=_input, prob=prob, robust=robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "[flashpca_3, project_samples_3]\n",
    "input: output_from(1), output_from(2)['identified_outliers']\n",
    "outliers = [x.strip() for x in open(_input[1]).readlines() if x.strip()]\n",
    "output: f\"{cwd}/{_input[0]:bn}.pc.png\",\n",
    "        f\"{cwd}/{_input[0]:bn}.scree.png\"\n",
    "sos_run(\"plot_pca\", plot_data = _input[0], outlier_file = _input[1] if len(outliers) else path())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
