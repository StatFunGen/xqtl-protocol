{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene Coordinate Annotation\n",
    "\n",
    "This workflow adds genomic coordinate annotation to gene-level molecular phenotype files generated in `.gct` format and convert them to `.bed` format for downstreams analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input\n",
    "\n",
    "1. `protocol_example.protein.csv`\n",
    "2. `reference_data/Homo_sapiens.GRCh38.103.chr.reformatted.collapse_only.gene.ERCC.gtf`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "\n",
    "1. `protocol_example.protein.bed.gz`\n",
    "2. `protocol_example.protein.region_list.txt`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal Working Example\n",
    "\n",
    "The proteomics data used in this MWE can be found on [synapse](https://www.synapse.org/#!Synapse:syn52369482)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Phenotype Annotation\n",
    "Timing: < 1 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sos run pipeline/gene_annotation.ipynb annotate_coord_protein \\\n",
    "    --cwd output/phenotype \\\n",
    "    --phenoFile input/protocol_example.protein.csv \\\n",
    "    --annotation-gtf reference_data/Homo_sapiens.GRCh38.103.chr.reformatted.collapse_only.gene.ERCC.gtf \\\n",
    "    --phenotype-id-type gene_name \\\n",
    "    --sample-participant-lookup output/sample_meta/protocol_example.protein.sample_overlap.txt \\\n",
    "    --container singularity/rna_quantification.sif"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "INFO: Running annotate_coord_protein:\n",
    "INFO: annotate_coord_protein is completed.\n",
    "INFO: annotate_coord_protein output:   /Users/alexmccreight/xqtl-pipeline-new/output/phenotype/protocol_example.protein.bed.gz /Users/alexmccreight/xqtl-pipeline-new/output/phenotype/protocol_example.protein.region_list.txt\n",
    "INFO: Workflow annotate_coord_protein (ID=we5e99e82ff5b579b) is executed successfully with 1 completed step.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sos run gene_annotation.ipynb -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "usage: sos run gene_annotation.ipynb\n",
    "               [workflow_name | -t targets] [options] [workflow_options]\n",
    "  workflow_name:        Single or combined workflows defined in this script\n",
    "  targets:              One or more targets to generate\n",
    "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
    "  workflow_options:     Double-hyphen workflow-specific parameters\n",
    "\n",
    "Workflows:\n",
    "  region_list_generation\n",
    "  annotate_coord_gene\n",
    "  annotate_coord_protein\n",
    "  annotate_coord_biomart\n",
    "  map_leafcutter_cluster_to_gene\n",
    "  annotate_leafcutter_isoforms\n",
    "  annotate_psichomics_isoforms\n",
    "\n",
    "Global Workflow Options:\n",
    "  --cwd output (as path)\n",
    "                        Work directory & output directory\n",
    "  --annotation-gtf VAL (as path, required)\n",
    "                        gene gtf annotation table\n",
    "  --phenoFile VAL (as path, required)\n",
    "                        Molecular phenotype matrix\n",
    "  --phenotype-id-type 'gene_id'\n",
    "                        Whether the input data is named by gene_id or gene_name.\n",
    "                        By default it is gene_id, if not, please change it to\n",
    "                        gene_name\n",
    "  --job-size 1 (as int)\n",
    "                        For cluster jobs, number commands to run per job\n",
    "  --walltime 5h\n",
    "                        Wall clock time expected\n",
    "  --mem 16G\n",
    "                        Memory expected\n",
    "  --numThreads 1 (as int)\n",
    "                        Number of threads\n",
    "  --container ''\n",
    "  --entrypoint {('micromamba run -a \"\" -n' + ' ' + container.split('/')[-1][:-4]) if container.endswith('.sif') else f''}\n",
    "\n",
    "\n",
    "Sections\n",
    "  region_list_generation:\n",
    "  annotate_coord_gene:\n",
    "    Workflow Options:\n",
    "      --sample-participant-lookup . (as path)\n",
    "                        A file to map sample ID from expression to genotype,\n",
    "                        must contain two columns, sample_id and participant_id,\n",
    "                        mapping IDs in the expression files to IDs in the\n",
    "                        genotype (these can be the same).\n",
    "  annotate_coord_protein:\n",
    "    Workflow Options:\n",
    "      --sample-participant-lookup . (as path)\n",
    "                        A file to map sample ID from expression to genotype,\n",
    "                        must contain two columns, sample_id and participant_id,\n",
    "                        mapping IDs in the expression files to IDs in the\n",
    "                        genotype (these can be the same).\n",
    "      --protein-name-index . (as path)\n",
    "      --protein-ID-type SOMAseqID\n",
    "  annotate_coord_biomart:\n",
    "    Workflow Options:\n",
    "      --ensembl-version VAL (as int, required)\n",
    "  map_leafcutter_cluster_to_gene:\n",
    "    Workflow Options:\n",
    "      --intron-count VAL (as path, required)\n",
    "                        Extract the code in case psichromatic needs to be\n",
    "                        processed the same way PheoFile in this step is the\n",
    "                        intron_count file\n",
    "  annotate_leafcutter_isoforms:\n",
    "    Workflow Options:\n",
    "      --sample-participant-lookup . (as path)\n",
    "  annotate_psichomics_isoforms:\n",
    "    Workflow Options:\n",
    "      --sample-participant-lookup . (as path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Phenotype Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "[annotate_coord_protein]\n",
    "# A file to map sample ID from expression to genotype, must contain two columns, sample_id and participant_id, mapping IDs in the expression files to IDs in the genotype (these can be the same).\n",
    "parameter: sample_participant_lookup = path()\n",
    "parameter: protein_name_index = path()\n",
    "parameter: protein_ID_type = \"SOMAseqID\"\n",
    "input: phenoFile, annotation_gtf\n",
    "output: f'{cwd:a}/{_input[0]:bn}.bed.gz', f'{cwd:a}/{_input[0]:bn}.region_list.txt'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output[0]:bn}'  \n",
    "python: expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', container = container, entrypoint=entrypoint\n",
    "\n",
    "    import pandas as pd\n",
    "    import qtl.io\n",
    "    from pathlib import Path\n",
    "\n",
    "    def prepare_bed(df, bed_template_df, chr_subset=None):\n",
    "        bed_df = pd.merge(bed_template_df, df, left_index=True, right_index=True)\n",
    "        bed_df = bed_df.groupby('#chr', sort=False, group_keys=False).apply(lambda x: x.sort_values('start'))\n",
    "        if chr_subset is not None:\n",
    "            bed_df = bed_df[bed_df.chr.isin(chr_subset)]\n",
    "        return bed_df\n",
    "\n",
    "    def load_and_preprocess_data(input_path, drop_columns):\n",
    "        df = pd.read_csv(input_path, skiprows=0)\n",
    "        if any(col in df.columns for col in drop_columns):\n",
    "            df = df.drop(drop_columns)\n",
    "        return df\n",
    "\n",
    "    def rename_samples_using_lookup(df, lookup_path):\n",
    "        sample_participant_lookup = Path(lookup_path)\n",
    "        if sample_participant_lookup.is_file():\n",
    "            sample_participant_lookup_s = pd.read_csv(sample_participant_lookup, sep=\"\\t\", index_col=0, dtype={0:str,1:str})\n",
    "            df.rename(columns=sample_participant_lookup_s.to_dict(), inplace=True)\n",
    "        return df\n",
    "\n",
    "    def load_bed_template(input_path, phenotype_id_type):\n",
    "        if sum(qtl.io.gtf_to_tss_bed(input_path, feature='gene',phenotype_id = \"gene_id\").index.duplicated()) > 0:\n",
    "            raise valueerror(f\"gtf file {input_path} needs to be collapsed into gene model by reference data processing module\")\n",
    "\n",
    "        bed_template_df_id = qtl.io.gtf_to_tss_bed(input_path, feature='transcript', phenotype_id=\"gene_id\")\n",
    "        bed_template_df_name = qtl.io.gtf_to_tss_bed(input_path, feature='transcript', phenotype_id=\"gene_name\")\n",
    "        bed_template_df = bed_template_df_id.merge(bed_template_df_name, on=[\"chr\", \"start\", \"end\"])\n",
    "        bed_template_df.columns = [\"#chr\", \"start\", \"end\", \"gene_id\", \"gene_name\"]\n",
    "        bed_template_df = bed_template_df.set_index(phenotype_id_type, drop=False)\n",
    "\n",
    "        return bed_template_df\n",
    "\n",
    "    df = load_and_preprocess_data(${_input[0]:ar}, [\"chr\", \"start\", \"end\"])\n",
    "    protein_ID = df.columns.values[0]\n",
    "    protein_name_index = Path(\"${protein_name_index:a}\")\n",
    "    if protein_name_index.is_file():\n",
    "        df_info = pd.read_csv(protein_name_index).rename(columns={'${protein_ID_type}': protein_ID, 'EntrezGeneSymbol':'gene_name'})[['gene_name',protein_ID,'UniProt']]\n",
    "        df = df_info.merge(df, on=protein_ID).drop(protein_ID,axis=1)\n",
    "    else:\n",
    "        df[[protein_ID, 'UniProt']] = df[protein_ID].astype(str).str.split('|', 1, expand=True)\n",
    "    df.set_index(df.columns[0], inplace=True)\n",
    "    df = rename_samples_using_lookup(df, \"${sample_participant_lookup:a}\")\n",
    "    bed_template_df = load_bed_template(${_input[1]:ar}, \"${phenotype_id_type}\")\n",
    "    bed_df = prepare_bed(df, bed_template_df)\n",
    "    bed_df[\"ID\"] = bed_df[\"gene_id\"] + \"_\" + bed_df[\"UniProt\"]\n",
    "    bed_df = bed_df.drop_duplicates(\"ID\", keep=False)[[\"#chr\",\"start\",\"end\",\"ID\"] + df.drop([\"UniProt\"],axis=1).columns.values.tolist()]\n",
    "    qtl.io.write_bed(bed_df, ${_output[0]:r})\n",
    "    bed_df[[\"#chr\",\"start\",\"end\",\"ID\"]].assign(path = ${_output[0]:r}).to_csv(${_output[1]:r},\"\\t\",index = False) "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
